[{
    "py/object": "data.DataClassPaper",
    "Title": "A Combination Method for Android Malware Detection Based on Control Flow Graphs and Machine Learning Algorithms",
    "year": 2019,
    "ML_Techniques": "RF, DNN, LSTM",
    "Category": "Vulnerability analysis",
    "Sub_category": ",Malware detection",
    "Venue": "IEEE Access",
    "Link": "https://ieeexplore.ieee.org/abstract/document/8629067",
    "bibtex": "ARTICLE{Ma2019_3,\n    author = \"{Ma}, Z. and {Ge}, H. and {Liu}, Y. and {Zhao}, M. and {Ma}, J.\",\n    journal = \"IEEE Access\",\n    title = \"A Combination Method for Android Malware Detection Based on Control Flow Graphs and Machine Learning Algorithms\",\n    year = \"2019\",\n    volume = \"7\",\n    number = \"\",\n    pages = \"21235-21245\",\n    doi = \"10.1109/ACCESS.2019.2896003\"\n}\n\n",
    "abstract": "Android malware severely threaten system and user security in terms of privilege escalation, remote control, tariff theft, and privacy leakage. Therefore, it is of great importance and necessity to detect Android malware. In this paper, we present a combination method for Android malware detection based on the machine learning algorithm. First, we construct the control flow graph of the application to obtain API information. Based on the API information, we innovatively construct Boolean, frequency, and time-series data sets. Based on these three data sets, three detection models for Android malware detection regarding API calls, API frequency, and API sequence aspects are constructed. Ultimately, an ensemble model is constructed for conformity. We tested and compared the accuracy and stability of our detection models through a large number of experiments. The experiments were conducted on 10010 benign applications and 10683 malicious applications. The results show that our detection model achieves 98.98% detection precision and has high accuracy and stability. All of the results are consistent with the theoretical analysis in this paper."
}, {
    "py/object": "data.DataClassPaper",
    "Title": "A Comparative Study of Deep Learning-Based Vulnerability Detection System",
    "year": 2019,
    "ML_Techniques": "",
    "Category": "Vulnerability analysis",
    "Sub_category": ",different types of vulnerabilities",
    "Venue": "IEEE Access",
    "Link": "https://ieeexplore.ieee.org/document/8769937",
    "bibtex": "ARTICLE{Li2019_4,\n    author = \"{Li}, Z. and {Zou}, D. and {Tang}, J. and {Zhang}, Z. and {Sun}, M. and {Jin}, H.\",\n    journal = \"IEEE Access\",\n    title = \"A Comparative Study of Deep Learning-Based Vulnerability Detection System\",\n    year = \"2019\",\n    volume = \"7\",\n    number = \"\",\n    pages = \"103184-103197\",\n    doi = \"10.1109/ACCESS.2019.2930578\"\n}\n\n",
    "abstract": "Source code static analysis has been widely used to detect vulnerabilities in the development of software products. The vulnerability patterns purely based on human experts are laborious and error prone, which has motivated the use of machine learning for vulnerability detection. In order to relieve human experts of defining vulnerability rules or features, a recent study shows the feasibility of leveraging deep learning to detect vulnerabilities automatically. However, the impact of different factors on the effectiveness of vulnerability detection is unknown. In this paper, we collect two datasets from the programs involving 126 types of vulnerabilities, on which we conduct the first comparative study to quantitatively evaluate the impact of different factors on the effectiveness of vulnerability detection. The experimental results show that accommodating control dependency can increase the overall effectiveness of vulnerability detection F1-measure by 20.3%; the imbalanced data processing methods are not effective for the dataset we create; bidirectional recurrent neural networks (RNNs) are more effective than unidirectional RNNs and convolutional neural network, which in turn are more effective than multi-layer perception; using the last output corresponding to the time step for the bidirectional long short-term memory (BLSTM) can reduce the false negative rate by 2.0% at the price of increasing the false positive rate by 0.5%."
}, {
    "py/object": "data.DataClassPaper",
    "Title": "A machine learning approach to detection of JavaScript-based attacks using AST features and paragraph vectors",
    "year": 2019,
    "ML_Techniques": "Doc2Vec, SVM",
    "Category": "Vulnerability analysis",
    "Sub_category": ",Malware detection",
    "Venue": "ASC",
    "Link": "https://www.sciencedirect.com/science/article/pii/S1568494619305022",
    "bibtex": "article{Ndichu2019_5,\n    author = \"Ndichu, Samuel and Kim, Sangwook and Ozawa, Seiichi and Misu, Takeshi and Makishima, Kazuo\",\n    title = \"A machine learning approach to detection of JavaScript-based attacks using AST features and paragraph vectors\",\n    journal = \"Applied Soft Computing\",\n    volume = \"84\",\n    pages = \"105721\",\n    year = \"2019\",\n    issn = \"1568-4946\",\n    doi = \"https://doi.org/10.1016/j.asoc.2019.105721\",\n    url = \"http://www.sciencedirect.com/science/article/pii/S1568494619305022\",\n    keywords = \"Cybersecurity, Machine learning, Doc2Vec, Malicious JavaScript detection, Feature learning, Abstract Syntax Tree\",\n    abstract = \"Websites attract millions of visitors due to the convenience of services they offer, which provide for interesting targets for cyber attackers. Most of these websites use JavaScript (JS) to create dynamic content. The exploitation of vulnerabilities in servers, plugins, and other third-party systems enables the insertion of malicious codes into websites. These exploits use methods such as drive-by-downloads, pop up ads, and phishing attacks on news, porn, piracy, torrent or free software websites, among others. Many of the recent cyber-attacks exploit JS vulnerabilities, in some cases employing obfuscation to hide their maliciousness and evade detection. It is, therefore, primal to develop an accurate detection system for malicious JS to protect users from such attacks. This study adopts Abstract Syntax Tree (AST) for code structure representation and a machine learning approach to conduct feature learning called Doc2vec to address this issue. Doc2vec is a neural network model that can learn context information of texts with variable length. This model is a well-suited feature learning method for JS codes, which consist of text content ranging among single line sentences, paragraphs, and full-length documents. Besides, features learned with Doc2Vec are of low dimensions which ensure faster detections. A classifier model judges the maliciousness of a JS code using the learned features. The performance of this approach is evaluated using the D3M dataset (Drive-by-Download Data by Marionette) for malicious JS codes and the JSUNPACK plus Alexa top 100 websites datasets for benign JS codes. We then compare the performance of Doc2Vec on plain JS codes (Plain-JS) and AST form of JS codes (AST-JS) to other feature learning methods. Our experimental results show that the proposed AST features and Doc2Vec for feature learning provide better accuracy and fast classification in malicious JS codes detection compared to conventional approaches and can flag malicious JS codes previously identified as hard-to-detect.\"\n}\n\n",
    "abstract": "Websites attract millions of visitors due to the convenience of services they offer, which provide for interesting targets for cyber attackers. Most of these websites use JavaScript (JS) to create dynamic content. The exploitation of vulnerabilities in servers, plugins, and other third-party systems enables the insertion of malicious codes into websites. These exploits use methods such as drive-by-downloads, pop up ads, and phishing attacks on news, porn, piracy, torrent or free software websites, among others. Many of the recent cyber-attacks exploit JS vulnerabilities, in some cases employing obfuscation to hide their maliciousness and evade detection. It is, therefore, primal to develop an accurate detection system for malicious JS to protect users from such attacks. This study adopts Abstract Syntax Tree (AST) for code structure representation and a machine learning approach to conduct feature learning called Doc2vec to address this issue. Doc2vec is a neural network model that can learn context information of texts with variable length. This model is a well-suited feature learning method for JS codes, which consist of text content ranging among single line sentences, paragraphs, and full-length documents. Besides, features learned with Doc2Vec are of low dimensions which ensure faster detections. A classifier model judges the maliciousness of a JS code using the learned features. The performance of this approach is evaluated using the D3M dataset (Drive-by-Download Data by Marionette) for malicious JS codes and the JSUNPACK plus Alexa top 100 websites datasets for benign JS codes. We then compare the performance of Doc2Vec on plain JS codes (Plain-JS) and AST form of JS codes (AST-JS) to other feature learning methods. Our experimental results show that the proposed AST features and Doc2Vec for feature learning provide better accuracy and fast classification in malicious JS codes detection compared to conventional approaches and can flag malicious JS codes previously identified as hard-to-detect."
}, {
    "py/object": "data.DataClassPaper",
    "Title": "A Machine Learning Approach to Malicious JavaScript Detection using Fixed Length Vector Representation",
    "year": 2018,
    "ML_Techniques": "Doc2Vec, SVM",
    "Category": "Vulnerability analysis",
    "Sub_category": ",Malware detection",
    "Venue": "IJCNN",
    "Link": "https://ieeexplore.ieee.org/abstract/document/8489414",
    "bibtex": "INPROCEEDINGS{Ndichu2018_6,\n    author = \"{Ndichu}, S. and {Ozawa}, S. and {Misu}, T. and {Okada}, K.\",\n    booktitle = \"2018 International Joint Conference on Neural Networks (IJCNN)\",\n    title = \"A Machine Learning Approach to Malicious JavaScript Detection using Fixed Length Vector Representation\",\n    year = \"2018\",\n    volume = \"\",\n    number = \"\",\n    pages = \"1-8\",\n    doi = \"10.1109/IJCNN.2018.8489414\"\n}\n\n",
    "abstract": "To add more functionality and enhance usability of web applications, JavaScript (JS) is frequently used. Even with many advantages and usefulness of JS, an annoying fact is that many recent cyberattacks such as drive-by-download attacks exploit vulnerability of JS codes. In general, malicious JS codes are not easy to detect, because they sneakily exploit vulnerabilities of browsers and plugin software, and attack visitors of a web site unknowingly. To protect users from such threads, the development of an accurate detection system for malicious JS is soliciting. Conventional approaches often employ signature and heuristic-based methods, which are prone to suffer from zero-day attacks, i.e., causing many false negatives and/or false positives. For this problem, this paper adopts a machine-learning approach to feature learning called Doc2Vec, which is a neural network model that can learn context information of texts. The extracted features are given to a classifier model (e.g., SVM and neural networks) and it judges the maliciousness of a JS code. In the performance evaluation, we use the D3M Dataset (Drive-by-Download Data by Marionette) for malicious JS codes and JSUPACK for benign ones for both training and test purposes. We then compare the performance to other feature learning methods. Our experimental results show that the proposed Doc2Vec features provide better accuracy and fast classification in malicious JS code detection compared to conventional approaches."
}, {
    "py/object": "data.DataClassPaper",
    "Title": "A Proposed Approach to Build an Automated Software Security Assessment Framework using Mined Patterns and Metrics",
    "year": 2019,
    "ML_Techniques": "",
    "Category": "Vulnerability analysis",
    "Sub_category": ",Malware detection",
    "Venue": "CSE & EUC",
    "Link": "https://ieeexplore.ieee.org/document/8919532",
    "bibtex": "INPROCEEDINGS{Sultana2019_8,\n    author = \"{Sultana}, K. Z. and {Chong}, T.\",\n    booktitle = \"2019 IEEE International Conference on Computational Science and Engineering (CSE) and IEEE International Conference on Embedded and Ubiquitous Computing (EUC)\",\n    title = \"A Proposed Approach to Build an Automated Software Security Assessment Framework using Mined Patterns and Metrics\",\n    year = \"2019\",\n    volume = \"\",\n    number = \"\",\n    pages = \"176-181\",\n    doi = \"10.1109/CSE/EUC.2019.00042\"\n}\n\n",
    "abstract": "Software security is a major concern of the developers who intend to deliver a reliable software. Although there is research that focuses on vulnerability prediction and discovery, there is still a need for building security-specific metrics to measure software security and vulnerability-proneness quantitatively. The existing methods are either based on software metrics (defined on the physical characteristics of code; e.g. complexity or lines of code) which are not security-specific or some generic patterns known as nano-patterns (Java method-level traceable patterns that characterize a Java method or function). Other methods predict vulnerabilities using text mining approaches or graph algorithms which perform poorly in cross-project validation and fail to be a generalized prediction model for any system. In this paper, we envision to construct an automated framework that will assist developers to assess the security level of their code and guide them towards developing secure code. To accomplish this goal, we aim to refine and redefine the existing nano-patterns and software metrics to make them more security-centric so that they can be used for measuring the software security level of a source code (either file or function) with higher accuracy. In this paper, we present our visionary approach through a series of three consecutive studies where we (1) will study the challenges of the current software metrics and nano-patterns in vulnerability prediction, (2) will redefine and characterize the nano-patterns and software metrics so that they can capture security-specific properties of code and measure the security level quantitatively, and finally (3) will implement an automated framework for the developers to automatically extract the values of all the patterns and metrics for the given code segment and then flag the estimated security level as a feedback based on our research results. We accomplished some preliminary experiments and presented the results which indicate that our vision can be practically implemented and will have valuable implications in the community of software security."
}, {
    "py/object": "data.DataClassPaper",
    "Title": "A Survey of Automatic Software Vulnerability Detection, Program Repair, and Defect Prediction Techniques",
    "year": 2020,
    "ML_Techniques": "",
    "Category": "Vulnerability analysis",
    "Sub_category": "",
    "Venue": "SCN",
    "Link": "https://www.hindawi.com/journals/scn/2020/8858010/",
    "bibtex": "article{Shen2020_9,\n    author = \"Shen, Zhidong and Chen, S.\",\n    title = \"A Survey of Automatic Software Vulnerability Detection, Program Repair, and Defect Prediction Techniques\",\n    journal = \"Secur. Commun. Networks\",\n    year = \"2020\",\n    volume = \"2020\",\n    pages = \"8858010:1-8858010:16\"\n}\n\n",
    "abstract": "Open source software has been widely used in various industries due to its openness and flexibility, but it also brings potential software security problems. Together with the large-scale increase in the number of software and the increase in complexity, the traditional manual methods to deal with these security issues are inefficient and cannot meet the current cyberspace security requirements. Therefore, it is an important research topic for researchers in the field of software security to develop more intelligent technologies to apply to potential security issues in software. The development of deep learning technology has brought new opportunities for the study of potential security issues in software, and researchers have successively proposed many automation methods. In this paper, these automation technologies are evaluated and analysed in detail from three aspects: software vulnerability detection, software program repair, and software defect prediction. At the same time, we point out some problems of these research methods, give corresponding solutions, and finally look forward to the application prospect of deep learning technology in automated software vulnerability detection, automated program repair, and automated defect prediction."
}, {
    "py/object": "data.DataClassPaper",
    "Title": "An Exploratory Study on Machine Learning to Combine Security Vulnerability Alerts from Static Analysis Tools",
    "year": 2019,
    "ML_Techniques": "LR, DT, Lasso",
    "Category": "Vulnerability analysis",
    "Sub_category": ",XSS, SQL-injection",
    "Venue": "LADC",
    "Link": "https://ieeexplore.ieee.org/document/8995685",
    "bibtex": "INPROCEEDINGS{Pereira2019_12,\n    author = \"{Pereira}, J. D. and {Campos}, J. R. and {Vieira}, M.\",\n    booktitle = \"2019 9th Latin-American Symposium on Dependable Computing (LADC)\",\n    title = \"An Exploratory Study on Machine Learning to Combine Security Vulnerability Alerts from Static Analysis Tools\",\n    year = \"2019\",\n    volume = \"\",\n    number = \"\",\n    pages = \"1-10\",\n    doi = \"10.1109/LADC48089.2019.8995685\"\n}\n\n",
    "abstract": "Due to time-to-market needs and cost of manual validation techniques, software systems are often deployed with vulnerabilities that may be exploited to gain illegitimate access/control, ultimately resulting in non-negligible consequences. Static Analysis Tools (SATs) are widely used for vulnerability detection, where the source code is analyzed without executing it. However, the performance of SATs varies considerably and a high detection rate usually comes with significant false alarms. Recent studies considered combining various SATs to improve the overall detection ability, but they do not allow exploring different performance trade-offs, as basic and rigid rules are normally followed. Machine Learning (ML) algorithms have shown promising results in several complex problems, due to their ability to fit specific needs. This paper presents an exploratory study on the combination of the output of SATs through ML algorithms to improve vulnerability detection while trying to reduce false alarms. The dataset consists of SQL Injection (SQLi) and Cross-Site Scripting (XSS) vulnerabilities detected by five different SATs in a large set of WordPress plugins developed in PHP. Results show that, for the case of SQLi, a false alarm reduction is possible without compromising the vulnerabilities detected, and that using ML allows trade-offs (e.g., reduction in false alarms at the expense of a few vulnerabilities) that are not possible with existing techniques. The paper also proposes a regression-based approach for ranking source code files considering estimates of vulnerabilities computed using the output of SATs. Results show that the approach allows creating a ranking of the source code files that largely overlaps the real ranking (based on real known vulnerabilities)."
}, {
    "py/object": "data.DataClassPaper",
    "Title": "Android Malware Detection Using Category-Based Machine Learning Classifiers",
    "year": 2016,
    "ML_Techniques": "SVM",
    "Category": "Vulnerability analysis",
    "Sub_category": ",Malware detection",
    "Venue": "SIGITE",
    "Link": "https://dl.acm.org/doi/10.1145/2978192.2978218",
    "bibtex": "inproceedings{Ali2016_14,\n    author = \"Ali Alatwi, Huda and Oh, Tae and Fokoue, Ernest and Stackpole, Bill\",\n    title = \"Android Malware Detection Using Category-Based Machine Learning Classifiers\",\n    year = \"2016\",\n    isbn = \"9781450344524\",\n    publisher = \"Association for Computing Machinery\",\n    address = \"New York, NY, USA\",\n    url = \"https://doi.org/10.1145/2978192.2978218\",\n    doi = \"10.1145/2978192.2978218\",\n    abstract = \"Android malware growth has been increasing dramatically as well as the diversity and complicity of their developing techniques. Machine learning techniques have been applied to detect malware by modeling patterns of static features and dynamic behaviors of malware. The accuracy rates of the machine learning classifiers differ depending on the quality of the features. We increase the quality of the features by relating between the apps' features and the features that are required to deliver its category's functionality. To measure the benign app references, the features of the top rated apps in a specific category are utilized to train a malware detection classifier for that given category. Android apps stores such as Google Play organize apps into different categories. Each category has its distinct functionalities which means the apps under a specific category are similar in their static and dynamic features. In other words, benign apps under a certain category tend to share a common set of features. On the contrary, malicious apps tend to have abnormal features, which are uncommon for the category that they belong to. This paper proposes category-based machine learning classifiers to enhance the performance of classification models at detecting malicious apps under a certain category. The intensive machine learning experiments proved that category-based classifiers report a remarkable higher average performance compared to non-category based.\",\n    booktitle = \"Proceedings of the 17th Annual Conference on Information Technology Education\",\n    pages = \"54\u201359\",\n    numpages = \"6\",\n    keywords = \"android malware detection, machine learning, static analysis\",\n    location = \"Boston, Massachusetts, USA\",\n    series = \"SIGITE '16\"\n}\n\n",
    "abstract": "Android malware growth has been increasing dramatically as well as the diversity and complicity of their developing techniques. Machine learning techniques have been applied to detect malware by modeling patterns of static features and dynamic behaviors of malware. The accuracy rates of the machine learning classifiers differ depending on the quality of the features. We increase the quality of the features by relating between the apps' features and the features that are required to deliver its category's functionality. To measure the benign app references, the features of the top rated apps in a specific category are utilized to train a malware detection classifier for that given category. Android apps stores such as Google Play organize apps into different categories. Each category has its distinct functionalities which means the apps under a specific category are similar in their static and dynamic features. In other words, benign apps under a certain category tend to share a common set of features. On the contrary, malicious apps tend to have abnormal features, which are uncommon for the category that they belong to. This paper proposes category-based machine learning classifiers to enhance the performance of classification models at detecting malicious apps under a certain category. The intensive machine learning experiments proved that category-based classifiers report a remarkable higher average performance compared to non-category based."
}, {
    "py/object": "data.DataClassPaper",
    "Title": "Applying Machine Learning Techniques for Detection of Malicious Code in Network Traffic",
    "year": 2007,
    "ML_Techniques": "DT, ANN, BN",
    "Category": "Vulnerability analysis",
    "Sub_category": ",Malware detection",
    "Venue": "AAI",
    "Link": "https://link.springer.com/chapter/10.1007/978-3-540-74565-5_5",
    "bibtex": "InProceedings{Elovici2007_15,\n    author = \"Elovici, Yuval and Shabtai, Asaf and Moskovitch, Robert and Tahan, Gil and Glezer, Chanan\",\n    editor = \"Hertzberg, Joachim and Beetz, Michael and Englert, Roman\",\n    title = \"Applying Machine Learning Techniques for Detection of Malicious Code in Network Traffic\",\n    booktitle = \"KI 2007: Advances in Artificial Intelligence\",\n    year = \"2007\",\n    publisher = \"Springer Berlin Heidelberg\",\n    address = \"Berlin, Heidelberg\",\n    pages = \"44--50\",\n    abstract = \"The Early Detection, Alert and Response (eDare) system is aimed at purifying Web traffic propagating via the premises of Network Service Providers (NSP) from malicious code. To achieve this goal, the system employs powerful network traffic scanners capable of cleaning traffic from known malicious code. The remaining traffic is monitored and Machine Learning (ML) algorithms are invoked in an attempt to pinpoint unknown malicious code exhibiting suspicious morphological patterns. Decision trees, Neural Networks and Bayesian Networks are used for static code analysis in order to determine whether a suspicious executable file actually inhabits malicious code. These algorithms are being evaluated and preliminary results are encouraging.\",\n    isbn = \"978-3-540-74565-5\"\n}\n\n",
    "abstract": "The Early Detection, Alert and Response (eDare) system is aimed at purifying Web traffic propagating via the premises of Network Service Providers (NSP) from malicious code. To achieve this goal, the system employs powerful network traffic scanners capable of cleaning traffic from known malicious code. The remaining traffic is monitored and Machine Learning (ML) algorithms are invoked in an attempt to pinpoint unknown malicious code exhibiting suspicious morphological patterns. Decision trees, Neural Networks and Bayesian Networks are used for static code analysis in order to determine whether a suspicious executable file actually inhabits malicious code. These algorithms are being evaluated and preliminary results are encouraging."
}, {
    "py/object": "data.DataClassPaper",
    "Title": "Automated Vulnerability Detection in Source Code Using Deep Representation Learning",
    "year": 2018,
    "ML_Techniques": "RF, CNN, RNN",
    "Category": "Vulnerability analysis",
    "Sub_category": ",bufferoverflow, nullpointer derefernce, and so on",
    "Venue": "ICMLA",
    "Link": "https://ieeexplore.ieee.org/abstract/document/8614145",
    "bibtex": "INPROCEEDINGS{Russell2018_16,\n    author = \"{Russell}, R. and {Kim}, L. and {Hamilton}, L. and {Lazovich}, T. and {Harer}, J. and {Ozdemir}, O. and {Ellingwood}, P. and {McConley}, M.\",\n    booktitle = \"2018 17th IEEE International Conference on Machine Learning and Applications (ICMLA)\",\n    title = \"Automated Vulnerability Detection in Source Code Using Deep Representation Learning\",\n    year = \"2018\",\n    volume = \"\",\n    number = \"\",\n    pages = \"757-762\",\n    doi = \"10.1109/ICMLA.2018.00120\"\n}\n\n",
    "abstract": "Increasing numbers of software vulnerabilities are discovered every year whether they are reported publicly or discovered internally in proprietary code. These vulnerabilities can pose serious risk of exploit and result in system compromise, information leaks, or denial of service. We leveraged the wealth of C and C++ open-source code available to develop a large-scale function-level vulnerability detection system using machine learning. To supplement existing labeled vulnerability datasets, we compiled a vast dataset of millions of open-source functions and labeled it with carefully-selected findings from three different static analyzers that indicate potential exploits. The labeled dataset is available at: this https URL. Using these datasets, we developed a fast and scalable vulnerability detection tool based on deep feature representation learning that directly interprets lexed source code. We evaluated our tool on code from both real software packages and the NIST SATE IV benchmark dataset. Our results demonstrate that deep feature representation learning on source code is a promising approach for automated software vulnerability detection."
}, {
    "py/object": "data.DataClassPaper",
    "Title": "Automatic detection and correction of web application vulnerabilities using data mining to predict false positives",
    "year": 2014,
    "ML_Techniques": "DT, RF, KNN, NB, BN, MLP, SVM, LOG",
    "Category": "Vulnerability analysis",
    "Sub_category": ",SQL-injections, XSS",
    "Venue": "WWW ",
    "Link": "https://dl.acm.org/doi/10.1145/2566486.2568024",
    "bibtex": "INPROCEEDINGS{Russell2018_16,\n    author = \"{Russell}, R. and {Kim}, L. and {Hamilton}, L. and {Lazovich}, T. and {Harer}, J. and {Ozdemir}, O. and {Ellingwood}, P. and {McConley}, M.\",\n    booktitle = \"2018 17th IEEE International Conference on Machine Learning and Applications (ICMLA)\",\n    title = \"Automated Vulnerability Detection in Source Code Using Deep Representation Learning\",\n    year = \"2018\",\n    volume = \"\",\n    number = \"\",\n    pages = \"757-762\",\n    doi = \"10.1109/ICMLA.2018.00120\"\n}\n\n",
    "abstract": "Web application security is an important problem in today's internet. A major cause of this status is that many programmers do not have adequate knowledge about secure coding, so they leave applications with vulnerabilities. An approach to solve this problem is to use source code static analysis to find these bugs, but these tools are known to report many false positives that make hard the task of correcting the application. This paper explores the use of a hybrid of methods to detect vulnerabilities with less false positives. After an initial step that uses taint analysis to flag candidate vulnerabilities, our approach uses data mining to predict the existence of false positives. This approach reaches a trade-off between two apparently opposite approaches: humans coding the knowledge about vulnerabilities (for taint analysis) versus automatically obtaining that knowledge (with machine learning, for data mining). Given this more precise form of detection, we do automatic code correction by inserting fixes in the source code. The approach was implemented in the WAP tool and an experimental evaluation was performed with a large set of open source PHP applications."
}, {
    "py/object": "data.DataClassPaper",
    "Title": "Challenging machine learning algorithms in predicting vulnerable JavaScript functions",
    "year": 2019,
    "ML_Techniques": "DNN, KNN, DT, RF, SVM, LR, NB",
    "Category": "Vulnerability analysis",
    "Sub_category": ",different types of vulnerabilities",
    "Venue": "RAISE",
    "Link": "https://dl.acm.org/doi/10.1109/RAISE.2019.00010",
    "bibtex": "INPROCEEDINGS{Russell2018_16,\n    author = \"{Russell}, R. and {Kim}, L. and {Hamilton}, L. and {Lazovich}, T. and {Harer}, J. and {Ozdemir}, O. and {Ellingwood}, P. and {McConley}, M.\",\n    booktitle = \"2018 17th IEEE International Conference on Machine Learning and Applications (ICMLA)\",\n    title = \"Automated Vulnerability Detection in Source Code Using Deep Representation Learning\",\n    year = \"2018\",\n    volume = \"\",\n    number = \"\",\n    pages = \"757-762\",\n    doi = \"10.1109/ICMLA.2018.00120\"\n}\n\n",
    "abstract": "The rapid rise of cyber-crime activities and the growing number of devices threatened by them place software security issues in the spotlight. As around 90% of all attacks exploit known types of security issues, finding vulnerable components and applying existing mitigation techniques is a viable practical approach for fighting against cyber-crime. In this paper, we investigate how the state-of-the-art machine learning techniques, including a popular deep learning algorithm, perform in predicting functions with possible security vulnerabilities in JavaScript programs.\n\nWe applied 8 machine learning algorithms to build prediction models using a new dataset constructed for this research from the vulnerability information in public databases of the Node Security Project and the Snyk platform, and code fixing patches from GitHub. We used static source code metrics as predictors and an extensive grid-search algorithm to find the best performing models. We also examined the effect of various re-sampling strategies to handle the imbalanced nature of the dataset.\n\nThe best performing algorithm was KNN, which created a model for the prediction of vulnerable functions with an F-measure of 0.76 (0.91 precision and 0.66 recall). Moreover, deep learning, tree and forest based classifiers, and SVM were competitive with F-measures over 0.70. Although the F-measures did not vary significantly with the re-sampling strategies, the distribution of precision and recall did change. No re-sampling seemed to produce models preferring high precision, while resampling strategies balanced the IR measures."
}, {
    "py/object": "data.DataClassPaper",
    "Title": "Classification of malicious web code by machine learning",
    "year": 2011,
    "ML_Techniques": "SVM, NB, KNN",
    "Category": "Vulnerability analysis",
    "Sub_category": ",SQL-injections, XSS",
    "Venue": "iCAST",
    "Link": "https://ieeexplore.ieee.org/document/6163109",
    "bibtex": "INPROCEEDINGS{Komiya2011_19,\n    author = \"{Komiya}, R. and {Paik}, I. and {Hisada}, M.\",\n    booktitle = \"2011 3rd International Conference on Awareness Science and Technology (iCAST)\",\n    title = \"Classification of malicious web code by machine learning\",\n    year = \"2011\",\n    volume = \"\",\n    number = \"\",\n    pages = \"406-411\"\n}\n\n",
    "abstract": "Web applications make life more convenient through on the activities. Many web applications have several kind of user input (e.g. personal information, a user's comment of commercial goods, etc.) for the activities. However, there are various vulnerabilities in input functions of web applications. It is possible to try malicious actions using free accessibility of the web applications. The attacks by exploitation of these input vulnerabilities enable to be performed by injecting malicious web code; it enables one to perform various illegal actions, such as SQL Injection Attacks (SQLIAs) and Cross Site Scripting (XSS). These actions come down to theft, replacing personal information, or phishing. Many solutions have devised for the malicious web code, such as AMNESIA [1] and SQL Check [2], etc. The methods use parser for the code, and limited to fixed and very small patterns, and are difficult to adapt to variations. Machine learning method can give leverage to cover far broader range of malicious web code and is easy to adapt to variations and changes. Therefore, we suggests adaptable classification of malicious web code by machine learning approach such as Support Vector Machine (SVM) [3], Na\u00efve-Bayes [4], and k-Nearest Neighbor Algorithm [5] for detecting the exploitation user inputs."
}, {
    "py/object": "data.DataClassPaper",
    "Title": "Codebase-adaptive detection of security-relevant methods",
    "year": 2019,
    "ML_Techniques": "SVM, BN, LOG, DT, DS, Ripper",
    "Category": "Vulnerability analysis",
    "Sub_category": "",
    "Venue": "ISSTA",
    "Link": "https://dl.acm.org/doi/10.1145/3293882.3330556",
    "bibtex": "INPROCEEDINGS{Komiya2011_19,\n    author = \"{Komiya}, R. and {Paik}, I. and {Hisada}, M.\",\n    booktitle = \"2011 3rd International Conference on Awareness Science and Technology (iCAST)\",\n    title = \"Classification of malicious web code by machine learning\",\n    year = \"2011\",\n    volume = \"\",\n    number = \"\",\n    pages = \"406-411\"\n}\n\n",
    "abstract": "More and more companies use static analysis to perform regular code reviews to detect security vulnerabilities in their code, configuring them to detect various types of bugs and vulnerabilities such as the SANS top 25 or the OWASP top 10. For such analyses to be as precise as possible, they must be adapted to the code base they scan. The particular challenge we address in this paper is to provide analyses with the correct security-relevant methods (Srm): sources, sinks, etc. We present SWAN, a fully-automated machine-learning approach to detect sources, sinks, validators, and authentication methods for Java programs. SWAN further classifies the Srm into specific vulnerability classes of the SANS top 25. To further adapt the lists detected by SWAN to the code base and to improve its precision, we also introduce SWANAssist, an extension to SWAN that allows analysis users to refine the classifications. On twelve popular Java frameworks, SWAN achieves an average precision of 0.826, which is better or comparable to existing approaches. Our experiments show that SWANAssist requires a relatively low effort from the developer to significantly improve its precision."
}, {
    "py/object": "data.DataClassPaper",
    "Title": "Detection of malicious code by applying machine learning classifiers on static features: A state-of-the-art survey",
    "year": 2009,
    "ML_Techniques": "",
    "Category": "Vulnerability analysis",
    "Sub_category": ",survey",
    "Venue": "ISTR",
    "Link": "https://dl.acm.org/doi/10.1016/j.istr.2009.03.003",
    "bibtex": "article{Shabtai2009_25,\n    author = \"Shabtai, Asaf and Moskovitch, Robert and Elovici, Yuval and Glezer, Chanan\",\n    title = \"Detection of malicious code by applying machine learning classifiers on static features: A state-of-the-art survey\",\n    journal = \"Information Security Technical Report\",\n    volume = \"14\",\n    number = \"1\",\n    pages = \"16 - 29\",\n    year = \"2009\",\n    note = \"Malware\",\n    issn = \"1363-4127\",\n    doi = \"https://doi.org/10.1016/j.istr.2009.03.003\",\n    url = \"http://www.sciencedirect.com/science/article/pii/S1363412709000041\"\n}\n\n",
    "abstract": "This research synthesizes a taxonomy for classifying detection methods of new malicious code by Machine Learning (ML) methods based on static features extracted from executables. The taxonomy is then operationalized to classify research on this topic and pinpoint critical open research issues in light of emerging threats. The article addresses various facets of the detection challenge, including: file representation and feature selection methods, classification algorithms, weighting ensembles, as well as the imbalance problem, active learning, and chronological evaluation. From the survey we conclude that a framework for detecting new malicious code in executable files can be designed to achieve very high accuracy while maintaining low false positives (i.e. misclassifying benign files as malicious). The framework should include training of multiple classifiers on various types of features (mainly OpCode and byte n-grams and Portable Executable Features), applying weighting algorithm on the classification results of the individual classifiers, as well as an active learning mechanism to maintain high detection accuracy. The training of classifiers should also consider the imbalance problem by generating classifiers that will perform accurately in a real-life situation where the percentage of malicious files among all files is estimated to be approximately 10%."
}, {
    "py/object": "data.DataClassPaper",
    "Title": "Discovering software vulnerabilities using data-flow analysis and machine learning",
    "year": 2018,
    "ML_Techniques": "DT, RF, NB, BN, LR",
    "Category": "Vulnerability analysis",
    "Sub_category": ",SQL-injections, XSS",
    "Venue": "ARES",
    "Link": "https://dl.acm.org/doi/abs/10.1145/3230833.3230856",
    "bibtex": "article{Shabtai2009_25,\n    author = \"Shabtai, Asaf and Moskovitch, Robert and Elovici, Yuval and Glezer, Chanan\",\n    title = \"Detection of malicious code by applying machine learning classifiers on static features: A state-of-the-art survey\",\n    journal = \"Information Security Technical Report\",\n    volume = \"14\",\n    number = \"1\",\n    pages = \"16 - 29\",\n    year = \"2009\",\n    note = \"Malware\",\n    issn = \"1363-4127\",\n    doi = \"https://doi.org/10.1016/j.istr.2009.03.003\",\n    url = \"http://www.sciencedirect.com/science/article/pii/S1363412709000041\"\n}\n\n",
    "abstract": "We present a novel method for static analysis in which we combine data-flow analysis with machine learning to detect SQL injection (SQLi) and Cross-Site Scripting (XSS) vulnerabilities in PHP applications. We assembled a dataset from the National Vulnerability Database and the SAMATE project, containing vulnerable PHP code samples and their patched versions in which the vulnerability is solved. We extracted features from the code samples by applying data-flow analysis techniques, including reaching definitions analysis, taint analysis, and reaching constants analysis. We used these features in machine learning to train various probabilistic classifiers. To demonstrate the effectiveness of our approach, we built a tool called WIRECAML, and compared our tool to other tools for vulnerability detection in PHP code. Our tool performed best for detecting both SQLi and XSS vulnerabilities. We also tried our approach on a number of open-source software applications, and found a previously unknown vulnerability in a photo-sharing web application."
}, {
    "py/object": "data.DataClassPaper",
    "Title": "Early Identification of Vulnerable Software Components via Ensemble Learning",
    "year": 2016,
    "ML_Techniques": "SVM",
    "Category": "Vulnerability analysis",
    "Sub_category": "",
    "Venue": "ICMLA",
    "Link": " https://ieeexplore.ieee.org/document/7838188",
    "bibtex": "INPROCEEDINGS{Pang2016_27,\n    author = \"{Pang}, Y. and {Xue}, X. and {Namin}, A. S.\",\n    booktitle = \"2016 15th IEEE International Conference on Machine Learning and Applications (ICMLA)\",\n    title = \"Early Identification of Vulnerable Software Components via Ensemble Learning\",\n    year = \"2016\",\n    volume = \"\",\n    number = \"\",\n    pages = \"476-481\",\n    doi = \"10.1109/ICMLA.2016.0084\"\n}\n\n",
    "abstract": "Software components, which are vulnerable to being exploited, need to be identified and patched. Employing any prevention techniques designed for the purpose of detecting vulnerable software components in early stages can reduce the expenses associated with the software testing process significantly and thus help building a more reliable and robust software system. Although previous studies have demonstrated the effectiveness of adapting prediction techniques in vulnerability detection, the feasibility of those techniques is limited mainly because of insufficient training data sets. This paper proposes a prediction technique targeting at early identification of potentially vulnerable software components. In the proposed scheme, the potentially vulnerable components are viewed as mislabeled data that may contain true but not yet observed vulnerabilities. The proposed hybrid technique combines the supports vector machine algorithm and ensemble learning strategy to better identify potential vulnerable components. The proposed vulnerability detection scheme is evaluated using some Java Android applications. The results demonstrated that the proposed hybrid technique could identify potentially vulnerable classes with high precision and relatively acceptable accuracy and recall."
}, {
    "py/object": "data.DataClassPaper",
    "Title": "Experimental Study with Real-world Data for Android App Security Analysis using Machine Learning",
    "year": 2015,
    "ML_Techniques": "",
    "Category": "Vulnerability analysis",
    "Sub_category": ",challenges",
    "Venue": "ACSAC",
    "Link": "https://dl.acm.org/doi/abs/10.1145/2818000.2818038",
    "bibtex": "INPROCEEDINGS{Pang2016_27,\n    author = \"{Pang}, Y. and {Xue}, X. and {Namin}, A. S.\",\n    booktitle = \"2016 15th IEEE International Conference on Machine Learning and Applications (ICMLA)\",\n    title = \"Early Identification of Vulnerable Software Components via Ensemble Learning\",\n    year = \"2016\",\n    volume = \"\",\n    number = \"\",\n    pages = \"476-481\",\n    doi = \"10.1109/ICMLA.2016.0084\"\n}\n\n",
    "abstract": "Although Machine Learning (ML) based approaches have\nshown promise for Android malware detection, a set of critical challenges remain unaddressed. Some of those challenges\narise in relation to proper evaluation of the detection approach while others are related to the design decisions of the\nsame. In this paper, we systematically study the impact of\nthese challenges as a set of research questions (i.e., hypotheses). We design an experimentation framework where we can\nreliably vary several parameters while evaluating ML-based\nAndroid malware detection approaches. The results from\nthe experiments are then used to answer the research questions. Meanwhile, we also demonstrate the impact of some\nchallenges on some existing ML-based approaches. The large\n(market-scale) dataset (benign and malicious apps) we use\nin the above experiments represents the real-world Android\napp security analysis scale. We envision this study to encourage the practice of employing a better evaluation strategy and better designs of future ML-based approaches for\nAndroid malware detection."
}, {
    "py/object": "data.DataClassPaper",
    "Title": "Experimenting Machine Learning Techniques to Predict Vulnerabilities",
    "year": 2016,
    "ML_Techniques": "RF, NB, LR, DT",
    "Category": "Vulnerability analysis",
    "Sub_category": "",
    "Venue": "LADC",
    "Link": "https://ieeexplore.ieee.org/abstract/document/7781850",
    "bibtex": "INPROCEEDINGS{Alves2016_29,\n    author = \"{Alves}, H. and {Fonseca}, B. and {Antunes}, N.\",\n    booktitle = \"2016 Seventh Latin-American Symposium on Dependable Computing (LADC)\",\n    title = \"Experimenting Machine Learning Techniques to Predict Vulnerabilities\",\n    year = \"2016\",\n    volume = \"\",\n    number = \"\",\n    pages = \"151-156\",\n    doi = \"10.1109/LADC.2016.32\"\n}\n\n",
    "abstract": "Software metrics can be used as a indicator of the presence of software vulnerabilities. These metrics have been used with machine learning to predict source code prone to contain vulnerabilities. Although it is not possible to find the exact location of the flaws, the models can show which components require more attention during inspections and testing. Each new technique uses his own evaluation dataset, which many times has limited size and representativeness. In this experience report, we use a large and representative dataset to evaluate several state of the art vulnerability prediction techniques. This dataset was built with information of 2186 vulnerabilities from five widely used open source projects. Results show that the dataset can be used to distinguish which are the best techniques. It is also shown that some of the techniques can predict nearly all of the vulnerabilities present in the dataset, although with very low precisions. Finally, accuracy, precision and recall are not the most effective to characterize the effectiveness of this tools."
}, {
    "py/object": "data.DataClassPaper",
    "Title": "Extracting rules for vulnerabilities detection with static metrics using machine learning",
    "year": 2020,
    "ML_Techniques": "AB, DS, RF, DT, LB, Ripper, RT, LR, BN, NB, B",
    "Category": "Vulnerability analysis",
    "Sub_category": "",
    "Venue": "IJSAEM",
    "Link": "https://link.springer.com/article/10.1007/s13198-020-01036-0",
    "bibtex": "article{Gupta2021_30,\n    author = \"Gupta, Aakanshi and Suri, Bharti and Kumar, Vijay and Jain, Pragyashree\",\n    title = \"Extracting rules for vulnerabilities detection with static metrics using machine learning\",\n    journal = \"International Journal of System Assurance Engineering and Management\",\n    year = \"2021\",\n    volume = \"12\",\n    pages = \"65-76\"\n}\n\n",
    "abstract": "Software quality is the prime solicitude in software engineering and vulnerability is one of the major threat in this respect. Vulnerability hampers the security of the software and also impairs the quality of the software. In this paper, we have conducted experimental research on evaluating the utility of machine learning algorithms to detect the vulnerabilities. To execute this experiment; a set of software metrics was extracted using machine learning in the form of easily accessible laws. Here, 32 supervised machine learning algorithms have been considered for 3 most occurred vulnerabilities namely: Lawofdemeter, BeanMemberShouldSerialize,and LocalVariablecouldBeFinal in a software system. Using the J48 machine learning algorithm in this research, up to 96% of accurate result in vulnerability detection was achieved. The results are validated against tenfold cross validation and also, the statistical parameters like ROC curve, Kappa statistics; Recall, Precision, etc. have been used for analyzing the result."
}, {
    "py/object": "data.DataClassPaper",
    "Title": "Is Predicting Software Security Bugs Using Deep Learning Better Than the Traditional Machine Learning Algorithms?",
    "year": 2018,
    "ML_Techniques": "DT, RF, NB, SVM",
    "Category": "Vulnerability analysis",
    "Sub_category": ",operational vulnerabilities",
    "Venue": "QRS",
    "Link": "https://ieeexplore.ieee.org/abstract/document/8424961",
    "bibtex": "INPROCEEDINGS{Clemente2018_34,\n    author = \"{Clemente}, C. J. and {Jaafar}, F. and {Malik}, Y.\",\n    booktitle = \"2018 IEEE International Conference on Software Quality, Reliability and Security (QRS)\",\n    title = \"Is Predicting Software Security Bugs Using Deep Learning Better Than the Traditional Machine Learning Algorithms?\",\n    year = \"2018\",\n    volume = \"\",\n    number = \"\",\n    pages = \"95-102\",\n    doi = \"10.1109/QRS.2018.00023\"\n}\n\n",
    "abstract": "Software insecurity is being identified as one of the leading causes of security breaches. In this paper, we revisited one of the strategies in solving software insecurity, which is the use of software quality metrics. We utilized a multilayer deep feedforward network in examining whether there is a combination of metrics that can predict the appearance of security-related bugs. We also applied the traditional machine learning algorithms such as decision tree, random forest, na\u00efve bayes, and support vector machines and compared the results with that of the Deep Learning technique. The results have successfully demonstrated that it was possible to develop an effective predictive model to forecast software insecurity based on the software metrics and using Deep Learning. All the models generated have shown an accuracy of more than sixty percent with Deep Learning leading the list. This finding proved that utilizing Deep Learning methods and a combination of software metrics can be tapped to create a better forecasting model thereby aiding software developers in predicting security bugs."
}, {
    "py/object": "data.DataClassPaper",
    "Title": "Learning to Repair Software Vulnerabilities with Generative Adversarial Networks",
    "year": 2018,
    "ML_Techniques": "NMT",
    "Category": "Vulnerability analysis",
    "Sub_category": "",
    "Venue": "NIPS",
    "Link": "https://papers.nips.cc/paper/2018/hash/68abef8ee1ac9b664a90b0bbaff4f770-Abstract.html",
    "bibtex": "inproceedings{Harer2018_35,\n    author = \"Harer, Jacob and Ozdemir, Onur and Lazovich, Tomo and Reale, Christopher and Russell, Rebecca and Kim, Louis and chin, peter\",\n    editor = \"Bengio, S. and Wallach, H. and Larochelle, H. and Grauman, K. and Cesa-Bianchi, N. and Garnett, R.\",\n    booktitle = \"Advances in Neural Information Processing Systems\",\n    pages = \"7933--7943\",\n    publisher = \"Curran Associates, Inc.\",\n    title = \"Learning to Repair Software Vulnerabilities with Generative Adversarial Networks\",\n    url = \"https://proceedings.neurips.cc/paper/2018/file/68abef8ee1ac9b664a90b0bbaff4f770-Paper.pdf\",\n    volume = \"31\",\n    year = \"2018\"\n}\n\n",
    "abstract": "Motivated by the problem of automated repair of software vulnerabilities, we propose an adversarial learning approach that maps from one discrete source domain to another target domain without requiring paired labeled examples or source and target domains to be bijections. We demonstrate that the proposed adversarial learning approach is an effective technique for repairing software vulnerabilities, performing close to seq2seq approaches that require labeled pairs. The proposed Generative Adversarial Network approach is application-agnostic in that it can be applied to other problems similar to code repair, such as grammar correction or sentiment translation."
}, {
    "py/object": "data.DataClassPaper",
    "Title": "Machine learning aided Android malware classification",
    "year": 2017,
    "ML_Techniques": "SVM, NB, DT, Ripper, AB",
    "Category": "Vulnerability analysis",
    "Sub_category": ",Malware detection",
    "Venue": "Computers & Electrical Engineering",
    "Link": "https://www.sciencedirect.com/science/article/abs/pii/S0045790617303087",
    "bibtex": "article{Milosevic2017_36,\n    author = \"Milosevic, Nikola and Dehghantanha, Ali and Choo, Kim-Kwang Raymond\",\n    title = \"Machine learning aided Android malware classification\",\n    journal = \"Computers \\& Electrical Engineering\",\n    volume = \"61\",\n    pages = \"266 - 274\",\n    year = \"2017\",\n    issn = \"0045-7906\",\n    doi = \"https://doi.org/10.1016/j.compeleceng.2017.02.013\",\n    url = \"http://www.sciencedirect.com/science/article/pii/S0045790617303087\",\n    keywords = \"Static malware analysis, OWASP, Seraphimdroid Android app, OWASP Seraphimdroid Android app, Machine learning\"\n}\n\n",
    "abstract": "The widespread adoption of Android devices and their capability to access significant private and confidential information have resulted in these devices being targeted by malware developers. Existing Android malware analysis techniques can be broadly categorized into static and dynamic analysis. In this paper, we present two machine learning aided approaches for static analysis of Android malware. The first approach is based on permissions and the other is based on source code analysis utilizing a bag-of-words representation model. Our permission-based model is computationally inexpensive, and is implemented as the feature of OWASP Seraphimdroid Android app that can be obtained from Google Play Store. Our evaluations of both approaches indicate an F-score of 95.1% and F-measure of 89% for the source code-based classification and permission-based classification models, respectively."
}, {
    "py/object": "data.DataClassPaper",
    "Title": "Machine Learning Methods for Software Vulnerability Detection",
    "year": 2018,
    "ML_Techniques": "NB, KNN, KM, SVM, DT, RF",
    "Category": "Vulnerability analysis",
    "Sub_category": "",
    "Venue": "IWSPA",
    "Link": "https://dl.acm.org/doi/abs/10.1145/3180445.3180453",
    "bibtex": "inproceedings{Chernis2018_39,\n    author = \"Chernis, Boris and Verma, Rakesh\",\n    title = \"Machine Learning Methods for Software Vulnerability Detection\",\n    year = \"2018\",\n    isbn = \"9781450356343\",\n    publisher = \"Association for Computing Machinery\",\n    address = \"New York, NY, USA\",\n    url = \"https://doi.org/10.1145/3180445.3180453\",\n    doi = \"10.1145/3180445.3180453\",\n    booktitle = \"Proceedings of the Fourth ACM International Workshop on Security and Privacy Analytics\",\n    pages = \"31\u201339\",\n    numpages = \"9\",\n    keywords = \"suffix trees, machine learning, static analysis, buffer overflow, vulnerability detection, N-grams, software metrics\",\n    location = \"Tempe, AZ, USA\",\n    series = \"IWSPA '18\"\n}\n\n",
    "abstract": "Software vulnerabilities are a primary concern in the IT security industry, as malicious hackers who discover these vulnerabilities can often exploit them for nefarious purposes. However, complex programs, particularly those written in a relatively low-level language like C, are difficult to fully scan for bugs, even when both manual and automated techniques are used. Since analyzing code and making sure it is securely written is proven to be a non-trivial task, both static analysis and dynamic analysis techniques have been heavily investigated, and this work focuses on the former. The contribution of this paper is a demonstration of how it is possible to catch a large percentage of bugs by extracting text features from functions in C source code and analyzing them with a machine learning classifier. Relatively simple features (character count, character diversity, entropy, maximum nesting depth, arrow count, \"if\" count, \"if\" complexity, \"while\" count, and \"for\" count) were extracted from these functions, and so were complex features (character n-grams, word n-grams, and suffix trees). The simple features performed unexpectedly better compared to the complex features (74% accuracy compared to 69% accuracy)."
}, {
    "py/object": "data.DataClassPaper",
    "Title": "Malicious Code Detection and Acquisition Using Active Learning",
    "year": 2007,
    "ML_Techniques": "SVM",
    "Category": "Vulnerability analysis",
    "Sub_category": "",
    "Venue": "ISI",
    "Link": "https://ieeexplore.ieee.org/document/4258731",
    "bibtex": "INPROCEEDINGS{Moskovitch2007_42,\n    author = \"{Moskovitch}, R. and {Nissim}, N. and {Elovici}, Y.\",\n    booktitle = \"2007 IEEE Intelligence and Security Informatics\",\n    title = \"Malicious Code Detection and Acquisition Using Active Learning\",\n    year = \"2007\",\n    volume = \"\",\n    number = \"\",\n    pages = \"371-371\",\n    doi = \"10.1109/ISI.2007.379505\"\n}\n\n",
    "abstract": "Detection of known malicious code is commonly performed by anti-virus tools. These tools detect the known malicious code using signature detection methods. Each time a new malicious code is found the anti-virus vendors create a new signature and update their clients. During the period between the appearance of a new unknown malicious code and the update of the signature base of the anti-virus clients, millions of computers might be infected. In order to cope with this problem, new solutions must be found for detecting unknown malicious code at the entrance of a client's computer. We presented here the use of active learning in the acquisition of unknown malicious code. Preliminary Results are encouraging. We are currently in the process of creating a wide test collection of more than 30,000 benign and malicious files to evaluate several active learning criterions."
}, {
    "py/object": "data.DataClassPaper",
    "Title": "Malicious Code Detection Using Active Learning",
    "year": 2009,
    "ML_Techniques": "SVM",
    "Category": "Vulnerability analysis",
    "Sub_category": "",
    "Venue": "PST",
    "Link": "https://link.springer.com/chapter/10.1007/978-3-642-01718-6_6",
    "bibtex": "InProceedings{Moskovitch2009_43,\n    author = \"Moskovitch, Robert and Nissim, Nir and Elovici, Yuval\",\n    editor = \"Bonchi, Francesco and Ferrari, Elena and Jiang, Wei and Malin, Bradley\",\n    title = \"Malicious Code Detection Using Active Learning\",\n    booktitle = \"Privacy, Security, and Trust in KDD\",\n    year = \"2009\",\n    publisher = \"Springer Berlin Heidelberg\",\n    address = \"Berlin, Heidelberg\",\n    pages = \"74--91\",\n    abstract = \"The recent growth in network usage has motivated the creation of new malicious code for various purposes, including economic and other malicious purposes. Currently, dozens of new malicious codes are created every day and this number is expected to increase in the coming years. Today's signature-based anti-viruses and heuristic-based methods are accurate, but cannot detect new malicious code. Recently, classification algorithms were used successfully for the detection of malicious code. We present a complete methodology for the detection of unknown malicious code, inspired by text categorization concepts. However, this approach can be exploited further to achieve a more accurate and efficient acquisition method of unknown malicious files. We use an Active-Learning framework that enables the selection of the unknown files for fast acquisition. We performed an extensive evaluation of a test collection consisting of more than 30,000 files. We present a rigorous evaluation setup, consisting of real-life scenarios, in which the malicious file content is expected to be low, at about 10{\\\\%} of the files in the stream. We define specific evaluation measures based on the known precision and recall measures, which show the accuracy of the acquisition process and the improvement in the classifier resulting from the efficient acquisition process.\",\n    isbn = \"978-3-642-01718-6\"\n}\n\n",
    "abstract": "The recent growth in network usage has motivated the creation of new malicious code for various purposes, including economic and other malicious purposes. Currently, dozens of new malicious codes are created every day and this number is expected to increase in the coming years. Today\u2019s signature-based anti-viruses and heuristic-based methods are accurate, but cannot detect new malicious code. Recently, classification algorithms were used successfully for the detection of malicious code. We present a complete methodology for the detection of unknown malicious code, inspired by text categorization concepts. However, this approach can be exploited further to achieve a more accurate and efficient acquisition method of unknown malicious files. We use an Active-Learning framework that enables the selection of the unknown files for fast acquisition. We performed an extensive evaluation of a test collection consisting of more than 30,000 files. We present a rigorous evaluation setup, consisting of real-life scenarios, in which the malicious file content is expected to be low, at about 10% of the files in the stream. We define specific evaluation measures based on the known precision and recall measures, which show the accuracy of the acquisition process and the improvement in the classifier resulting from the efficient acquisition process."
}, {
    "py/object": "data.DataClassPaper",
    "Title": "Malicious web content detection by machine learning",
    "year": 2010,
    "ML_Techniques": "DT, NB, SVM",
    "Category": "Vulnerability analysis",
    "Sub_category": "",
    "Venue": "ESA",
    "Link": "https://www.sciencedirect.com/science/article/abs/pii/S095741740900445X",
    "bibtex": "article{Hou2010_44,\n    author = \"Hou, Yung-Tsung and Chang, Yimeng and Chen, Tsuhan and Laih, Chi-Sung and Chen, Chia-Mei\",\n    title = \"Malicious web content detection by machine learning\",\n    journal = \"Expert Systems with Applications\",\n    volume = \"37\",\n    number = \"1\",\n    pages = \"55 - 60\",\n    year = \"2010\",\n    issn = \"0957-4174\",\n    doi = \"https://doi.org/10.1016/j.eswa.2009.05.023\",\n    url = \"http://www.sciencedirect.com/science/article/pii/S095741740900445X\",\n    keywords = \"Dynamic HTML, Malicious webpage, Machine learning\",\n    abstract = \"The recent development of the dynamic HTML gives attackers a new and powerful technique to compromise computer systems. A malicious dynamic HTML code is usually embedded in a normal webpage. The malicious webpage infects the victim when a user browses it. Furthermore, such DHTML code can disguise itself easily through obfuscation or transformation, which makes the detection even harder. Anti-virus software packages commonly use signature-based approaches which might not be able to efficiently identify camouflaged malicious HTML codes. Therefore, our paper proposes a malicious web page detection using the technique of machine learning. Our study analyzes the characteristic of a malicious webpage systematically and presents important features for machine learning. Experimental results demonstrate that our method is resilient to code obfuscations and can correctly determine whether a webpage is malicious or not.\"\n}\n\n",
    "abstract": "The recent development of the dynamic HTML gives attackers a new and powerful technique to compromise computer systems. A malicious dynamic HTML code is usually embedded in a normal webpage. The malicious webpage infects the victim when a user browses it. Furthermore, such DHTML code can disguise itself easily through obfuscation or transformation, which makes the detection even harder. Anti-virus software packages commonly use signature-based approaches which might not be able to efficiently identify camouflaged malicious HTML codes. Therefore, our paper proposes a malicious web page detection using the technique of machine learning. Our study analyzes the characteristic of a malicious webpage systematically and presents important features for machine learning. Experimental results demonstrate that our method is resilient to code obfuscations and can correctly determine whether a webpage is malicious or not."
}, {
    "py/object": "data.DataClassPaper",
    "Title": "OPEM: A Static-Dynamic Approach for Machine-Learning-Based Malware Detection",
    "year": 2013,
    "ML_Techniques": "DT, SVM, BN, KNN",
    "Category": "Vulnerability analysis",
    "Sub_category": ",Malware detection",
    "Venue": "AISC",
    "Link": "https://link.springer.com/chapter/10.1007/978-3-642-33018-6_28",
    "bibtex": "InProceedings{Santos2013_46,\n    author = \"Santos, Igor and Devesa, Jaime and Brezo, F{\\'e}lix and Nieves, Javier and Bringas, Pablo Garcia\",\n    editor = \"Herrero, {\\'A}lvaro and Sn{\\'a}{\\v{s}}el, V{\\'a}clav and Abraham, Ajith and Zelinka, Ivan and Baruque, Bruno and Quinti{\\'a}n, H{\\'e}ctor and Calvo, Jos{\\'e} Luis and Sedano, Javier and Corchado, Emilio\",\n    title = \"OPEM: A Static-Dynamic Approach for Machine-Learning-Based Malware Detection\",\n    booktitle = \"International Joint Conference CISIS'12-ICEUTE{\\textasciiacute}12-SOCO{\\textasciiacute}12 Special Sessions\",\n    year = \"2013\",\n    publisher = \"Springer Berlin Heidelberg\",\n    address = \"Berlin, Heidelberg\",\n    pages = \"271--280\",\n    isbn = \"978-3-642-33018-6\"\n}\n\n",
    "abstract": "Malware is any computer software potentially harmful to both computers and networks. The amount of malware is growing every year and poses a serious global security threat. Signature-based detection is the most extended method in commercial antivirus software, however, it consistently fails to detect new malware. Supervised machine learning has been adopted to solve this issue. There are two types of features that supervised malware detectors use: (i) static features and (ii) dynamic features. Static features are extracted without executing the sample whereas dynamic ones requires an execution. Both approaches have their advantages and disadvantages. In this paper, we propose for the first time, OPEM, an hybrid unknown malware detector which combines the frequency of occurrence of operational codes (statically obtained) with the information of the execution trace of an executable (dynamically obtained). We show that this hybrid approach enhances the performance of both approaches when run separately."
}, {
    "py/object": "data.DataClassPaper",
    "Title": "Pre-Patch: Find Hidden Threats in Open Software Based on Machine Learning Method",
    "year": 2018,
    "ML_Techniques": "BP-ANN",
    "Category": "Vulnerability analysis",
    "Sub_category": ",Malware detection",
    "Venue": "SERVICES",
    "Link": "https://link.springer.com/chapter/10.1007/978-3-319-94472-2_4",
    "bibtex": "InProceedings{Yang2018_47,\n    author = \"Yang, Mutian and Wu, Jingzheng and Ji, Shouling and Luo, Tianyue and Wu, Yanjun\",\n    editor = \"Yang, Alvin and Kantamneni, Siva and Li, Ying and Dico, Awel and Chen, Xiangang and Subramanyan, Rajesh and Zhang, Liang-Jie\",\n    title = \"Pre-Patch: Find Hidden Threats in Open Software Based on Machine Learning Method\",\n    booktitle = \"Services -- SERVICES 2018\",\n    year = \"2018\",\n    publisher = \"Springer International Publishing\",\n    address = \"Cham\",\n    pages = \"48--65\",\n    abstract = \"The details of vulnerabilities are always kept confidential until fixed, which is an efficient way to avoid the exploitations and attacks. However, the Security Related Commits (SRCs), used to fix the vulnerabilities in open source software, usually lack proper protections. Most SRCs are released in code repositories such as Git, Github, Sourceforge, etc. earlier than the corresponding vulnerabilities published. These commits often previously disclose the vital information which can be used by the attackers to locate and exploit the vulnerable code. Therefore, we defined the pre-leaked SRC as the Pre-Patch problem and studied its hidden threats to the open source software. In this paper, we presented an Automatic Security Related Commits Detector (ASRCD) to rapidly identify the Pre-Patch problems from the numerous commits in code repositories by learning the features of SRCs. We implemented ASRCD and evaluated it with 78,218 real-world commits collected from Linux Kernel, OpenSSL, phpMyadmin and Mantisbt released between 2016 to 2017, which contain 227 confirmed SRCs. ASRCD successfully identified 206 SRCs from the 4 projects, including 140 known SRCs (recall rate: 61.7{\\\\%} on average) and 66 new high-suspicious. In addition, 5 of the SRCs have been published after our prediction. The results show that: (1) the Pre-Patch is really a hidden threat to open source software; and (2) the proposed ASRCD is effective in identifying such SRCs. Finally, we recommended the identified SRCs should be fixed as soon as possible.\",\n    isbn = \"978-3-319-94472-2\"\n}\n\n",
    "abstract": "The details of vulnerabilities are always kept confidential until fixed, which is an efficient way to avoid the exploitations and attacks. However, the Security Related Commits (SRCs), used to fix the vulnerabilities in open source software, usually lack proper protections. Most SRCs are released in code repositories such as Git, Github, Sourceforge, etc. earlier than the corresponding vulnerabilities published. These commits often previously disclose the vital information which can be used by the attackers to locate and exploit the vulnerable code. Therefore, we defined the pre-leaked SRC as the Pre-Patch problem and studied its hidden threats to the open source software. In this paper, we presented an Automatic Security Related Commits Detector (ASRCD) to rapidly identify the Pre-Patch problems from the numerous commits in code repositories by learning the features of SRCs. We implemented ASRCD and evaluated it with 78,218 real-world commits collected from Linux Kernel, OpenSSL, phpMyadmin and Mantisbt released between 2016 to 2017, which contain 227 confirmed SRCs. ASRCD successfully identified 206 SRCs from the 4 projects, including 140 known SRCs (recall rate: 61.7% on average) and 66 new high-suspicious. In addition, 5 of the SRCs have been published after our prediction. The results show that: (1) the Pre-Patch is really a hidden threat to open source software; and (2) the proposed ASRCD is effective in identifying such SRCs. Finally, we recommended the identified SRCs should be fixed as soon as possible."
}, {
    "py/object": "data.DataClassPaper",
    "Title": "Predicting Android application security and privacy risk with static code metrics",
    "year": 2017,
    "ML_Techniques": "SVM, RF, LR, KNN",
    "Category": "Vulnerability analysis",
    "Sub_category": "",
    "Venue": "MOBILESoft",
    "Link": "https://dl.acm.org/doi/10.1109/MOBILESoft.2017.14",
    "bibtex": "InProceedings{Yang2018_47,\n    author = \"Yang, Mutian and Wu, Jingzheng and Ji, Shouling and Luo, Tianyue and Wu, Yanjun\",\n    editor = \"Yang, Alvin and Kantamneni, Siva and Li, Ying and Dico, Awel and Chen, Xiangang and Subramanyan, Rajesh and Zhang, Liang-Jie\",\n    title = \"Pre-Patch: Find Hidden Threats in Open Software Based on Machine Learning Method\",\n    booktitle = \"Services -- SERVICES 2018\",\n    year = \"2018\",\n    publisher = \"Springer International Publishing\",\n    address = \"Cham\",\n    pages = \"48--65\",\n    abstract = \"The details of vulnerabilities are always kept confidential until fixed, which is an efficient way to avoid the exploitations and attacks. However, the Security Related Commits (SRCs), used to fix the vulnerabilities in open source software, usually lack proper protections. Most SRCs are released in code repositories such as Git, Github, Sourceforge, etc. earlier than the corresponding vulnerabilities published. These commits often previously disclose the vital information which can be used by the attackers to locate and exploit the vulnerable code. Therefore, we defined the pre-leaked SRC as the Pre-Patch problem and studied its hidden threats to the open source software. In this paper, we presented an Automatic Security Related Commits Detector (ASRCD) to rapidly identify the Pre-Patch problems from the numerous commits in code repositories by learning the features of SRCs. We implemented ASRCD and evaluated it with 78,218 real-world commits collected from Linux Kernel, OpenSSL, phpMyadmin and Mantisbt released between 2016 to 2017, which contain 227 confirmed SRCs. ASRCD successfully identified 206 SRCs from the 4 projects, including 140 known SRCs (recall rate: 61.7{\\\\%} on average) and 66 new high-suspicious. In addition, 5 of the SRCs have been published after our prediction. The results show that: (1) the Pre-Patch is really a hidden threat to open source software; and (2) the proposed ASRCD is effective in identifying such SRCs. Finally, we recommended the identified SRCs should be fixed as soon as possible.\",\n    isbn = \"978-3-319-94472-2\"\n}\n\n",
    "abstract": "Android applications pose security and privacy risks for end-users. These risks are often quantified by performing dynamic analysis and permission analysis of the Android applications after release. Prediction of security and privacy risks associated with Android applications at early stages of application development, e.g. when the developer (s) are writing the code of the application, might help Android application developers in releasing applications to end-users that have less security and privacy risk. The goal of this paper is to aid Android application developers in assessing the security and privacy risk associated with Android applications by using static code metrics as predictors. In our paper, we consider security and privacy risk of Android application as how susceptible the application is to leaking private information of end-users and to releasing vulnerabilities. We investigate how effectively static code metrics that are extracted from the source code of Android applications, can be used to predict security and privacy risk of Android applications. We collected 21 static code metrics of 1,407 Android applications, and use the collected static code metrics to predict security and privacy risk of the applications. As the oracle of security and privacy risk, we used Androrisk, a tool that quantifies the amount of security and privacy risk of an Android application using analysis of Android permissions and dynamic analysis. To accomplish our goal, we used statistical learners such as, radial-based support vector machine (r-SVM). For r-SVM, we observe a precision of 0.83. Findings from our paper suggest that with proper selection of static code metrics, r-SVM can be used effectively to predict security and privacy risk of Android applications."
}, {
    "py/object": "data.DataClassPaper",
    "Title": "Project Achilles: A Prototype Tool for Static Method-Level Vulnerability Detection of Java Source Code Using a Recurrent Neural Network",
    "year": 2019,
    "ML_Techniques": "LSTM",
    "Category": "Vulnerability analysis",
    "Sub_category": ",29 different CWE",
    "Venue": "ASEW",
    "Link": "https://ieeexplore.ieee.org/document/8967427",
    "bibtex": "INPROCEEDINGS{Saccente2019_50,\n    author = \"{Saccente}, N. and {Dehlinger}, J. and {Deng}, L. and {Chakraborty}, S. and {Xiong}, Y.\",\n    booktitle = \"2019 34th IEEE/ACM International Conference on Automated Software Engineering Workshop (ASEW)\",\n    title = \"Project Achilles: A Prototype Tool for Static Method-Level Vulnerability Detection of Java Source Code Using a Recurrent Neural Network\",\n    year = \"2019\",\n    volume = \"\",\n    number = \"\",\n    pages = \"114-121\",\n    doi = \"10.1109/ASEW.2019.00040\"\n}\n\n",
    "abstract": "Software has become an essential component of modern life, but when software vulnerabilities threaten the security of users, new ways of analyzing for software security must be explored. Using the National Institute of Standards and Technology's Juliet Java Suite, containing thousands of examples of defective Java methods for a variety of vulnerabilities, a prototype tool was developed implementing an array of Long-Short Term Memory Recurrent Neural Networks to detect vulnerabilities within source code. The tool employs various data preparation methods to be independent of coding style and to automate the process of extracting methods, labeling data, and partitioning the dataset. The result is a prototype command-line utility that generates an n-dimensional vulnerability prediction vector. The experimental evaluation using 44,495 test cases indicates that the tool can achieve an accuracy higher than 90% for 24 out of 29 different types of CWE vulnerabilities."
}, {
    "py/object": "data.DataClassPaper",
    "Title": "Software Vulnerability Analysis and Discovery Using Machine-Learning and Data-Mining Techniques: A Survey",
    "year": 2017,
    "ML_Techniques": "",
    "Category": "Vulnerability analysis",
    "Sub_category": "",
    "Venue": "CSUR",
    "Link": "https://dl.acm.org/doi/abs/10.1145/3092566",
    "bibtex": "article{Ghaffarian2017_52,\n    author = \"Ghaffarian, Seyed Mohammad and Shahriari, Hamid Reza\",\n    title = \"Software Vulnerability Analysis and Discovery Using Machine-Learning and Data-Mining Techniques: A Survey\",\n    year = \"2017\",\n    issue_date = \"November 2017\",\n    publisher = \"Association for Computing Machinery\",\n    address = \"New York, NY, USA\",\n    volume = \"50\",\n    number = \"4\",\n    issn = \"0360-0300\",\n    url = \"https://doi.org/10.1145/3092566\",\n    doi = \"10.1145/3092566\",\n    abstract = \"Software security vulnerabilities are one of the critical issues in the realm of computer security. Due to their potential high severity impacts, many different approaches have been proposed in the past decades to mitigate the damages of software vulnerabilities. Machine-learning and data-mining techniques are also among the many approaches to address this issue. In this article, we provide an extensive review of the many different works in the field of software vulnerability analysis and discovery that utilize machine-learning and data-mining techniques. We review different categories of works in this domain, discuss both advantages and shortcomings, and point out challenges and some uncharted territories in the field.\",\n    journal = \"ACM Comput. Surv.\",\n    month = \"August\",\n    articleno = \"56\",\n    numpages = \"36\",\n    keywords = \"software vulnerability discovery, survey, machine-learning, Software vulnerability analysis, review, software security, data-mining\"\n}\n\n",
    "abstract": "Software security vulnerabilities are one of the critical issues in the realm of computer security. Due to their potential high severity impacts, many different approaches have been proposed in the past decades to mitigate the damages of software vulnerabilities. Machine-learning and data-mining techniques are also among the many approaches to address this issue. In this article, we provide an extensive review of the many different works in the field of software vulnerability analysis and discovery that utilize machine-learning and data-mining techniques. We review different categories of works in this domain, discuss both advantages and shortcomings, and point out challenges and some uncharted territories in the field."
}, {
    "py/object": "data.DataClassPaper",
    "Title": "Survey of machine learning techniques for malware analysis",
    "year": 2019,
    "ML_Techniques": "",
    "Category": "Vulnerability analysis",
    "Sub_category": ",survey",
    "Venue": "Computers & Security",
    "Link": "https://www.sciencedirect.com/science/article/pii/S0167404818303808",
    "bibtex": "article{Ucci2019_54,\n    author = \"Ucci, Daniele and Aniello, Leonardo and Baldoni, Roberto\",\n    title = \"Survey of machine learning techniques for malware analysis\",\n    journal = \"Computers \\& Security\",\n    volume = \"81\",\n    pages = \"123 - 147\",\n    year = \"2019\",\n    issn = \"0167-4048\",\n    doi = \"https://doi.org/10.1016/j.cose.2018.11.001\",\n    url = \"http://www.sciencedirect.com/science/article/pii/S0167404818303808\",\n    keywords = \"Portable executable, Malware analysis, Machine learning, Benchmark, Malware analysis economics\"\n}\n\n",
    "abstract": "Coping with malware is getting more and more challenging, given their relentless growth in complexity and volume. One of the most common approaches in literature is using machine learning techniques, to automatically learn models and patterns behind such complexity, and to develop technologies to keep pace with malware evolution. This survey aims at providing an overview on the way machine learning has been used so far in the context of malware analysis in Windows environments, i.e. for the analysis of Portable Executables. We systematize surveyed papers according to their objectives (i.e., the expected output), what information about malware they specifically use (i.e., the features), and what machine learning techniques they employ (i.e., what algorithm is used to process the input and produce the output). We also outline a number of issues and challenges, including those concerning the used datasets, and identify the main current topical trends and how to possibly advance them. In particular, we introduce the novel concept of malware analysis economics, regarding the study of existing trade-offs among key metrics, such as analysis accuracy and economical costs."
}, {
    "py/object": "data.DataClassPaper",
    "Title": "The impact factors on the performance of machine learning-based vulnerability detection: A comparative study",
    "year": 2020,
    "ML_Techniques": "RF, GBDT, KNN, SVM, LR, BLSTM, GRU, CNN",
    "Category": "Vulnerability analysis",
    "Sub_category": "",
    "Venue": "JSS",
    "Link": "https://www.sciencedirect.com/science/article/abs/pii/S0164121220301229",
    "bibtex": "article{Zheng2020_56,\n    author = \"Zheng, Wei and Gao, Jialiang and Wu, Xiaoxue and Liu, Fengyu and Xun, Yuxing and Liu, Guoliang and Chen, Xiang\",\n    title = \"The impact factors on the performance of machine learning-based vulnerability detection: A comparative study\",\n    journal = \"Journal of Systems and Software\",\n    volume = \"168\",\n    pages = \"110659\",\n    year = \"2020\",\n    issn = \"0164-1212\",\n    doi = \"https://doi.org/10.1016/j.jss.2020.110659\",\n    url = \"http://www.sciencedirect.com/science/article/pii/S0164121220301229\",\n    keywords = \"Vulnerability detection, Machine learning, Comparative study, Deep learning, Feature extraction\",\n    abstract = \"Machine learning-based Vulnerability detection is an active research topic in software security. Different traditional machine learning-based and deep learning-based vulnerability detection methods have been proposed. To our best knowledge, we are the first to identify four impact factors and conduct a comparative study to investigate the performance influence of these factors. In particular, the quality of datasets, classification models and vectorization methods can directly affect the detection performance, in contrast function/variable name replacement can affect the features of vulnerability detection and indirectly affect the performance. We collect three different vulnerability code datasets from two various sources (i.e., NVD and SARD). These datasets can correspond to different types of vulnerabilities. Moreover, we extract and analyze the features of vulnerability code datasets to explain some experimental results. Our findings based on the experimental results can be summarized as follows: (1) Deep learning models can achieve better performance than traditional machine learning models. Of all the models, BLSTM can achieve the best performance. (2) CountVectorizer can significantly improve the performance of traditional machine learning models. (3) Features generated by the random forest algorithm include system-related functions, syntax keywords, and user-defined names. Different vulnerability types and code sources will generate different features. (4) Datasets with user-defined variable and function name replacement will decrease the performance of vulnerability detection. (5) As the proportion of code from SARD increases, the performance of vulnerability detection will increase.\"\n}\n\n",
    "abstract": "Machine learning-based Vulnerability detection is an active research topic in software security. Different traditional machine learning-based and deep learning-based vulnerability detection methods have been proposed. To our best knowledge, we are the first to identify four impact factors and conduct a comparative study to investigate the performance influence of these factors. In particular, the quality of datasets, classification models and vectorization methods can directly affect the detection performance, in contrast function/variable name replacement can affect the features of vulnerability detection and indirectly affect the performance. We collect three different vulnerability code datasets from two various sources (i.e., NVD and SARD). These datasets can correspond to different types of vulnerabilities. Moreover, we extract and analyze the features of vulnerability code datasets to explain some experimental results. Our findings based on the experimental results can be summarized as follows: (1) Deep learning models can achieve better performance than traditional machine learning models. Of all the models, BLSTM can achieve the best performance. (2) CountVectorizer can significantly improve the performance of traditional machine learning models. (3) Features generated by the random forest algorithm include system-related functions, syntax keywords, and user-defined names. Different vulnerability types and code sources will generate different features. (4) Datasets with user-defined variable and function name replacement will decrease the performance of vulnerability detection. (5) As the proportion of code from SARD increases, the performance of vulnerability detection will increase."
}, {
    "py/object": "data.DataClassPaper",
    "Title": "The rise of machine learning for detection and classification of malware: Research developments, trends and challenges",
    "year": 2020,
    "ML_Techniques": "",
    "Category": "Vulnerability analysis",
    "Sub_category": ",survey",
    "Venue": "JNCA",
    "Link": "https://www.sciencedirect.com/science/article/pii/S1084804519303868",
    "bibtex": "article{Gibert2020_57,\n    author = \"Gibert, Daniel and Mateu, Carles and Planes, Jordi\",\n    title = \"The rise of machine learning for detection and classification of malware: Research developments, trends and challenges\",\n    journal = \"Journal of Network and Computer Applications\",\n    volume = \"153\",\n    pages = \"102526\",\n    year = \"2020\",\n    issn = \"1084-8045\",\n    doi = \"https://doi.org/10.1016/j.jnca.2019.102526\",\n    url = \"http://www.sciencedirect.com/science/article/pii/S1084804519303868\",\n    keywords = \"Malware detection, Feature engineering, Machine learning, Deep learning, Multimodal learning\",\n    abstract = \"The struggle between security analysts and malware developers is a never-ending battle with the complexity of malware changing as quickly as innovation grows. Current state-of-the-art research focus on the development and application of machine learning techniques for malware detection due to its ability to keep pace with malware evolution. This survey aims at providing a systematic and detailed overview of machine learning techniques for malware detection and in particular, deep learning techniques. The main contributions of the paper are: (1) it provides a complete description of the methods and features in a traditional machine learning workflow for malware detection and classification, (2) it explores the challenges and limitations of traditional machine learning and (3) it analyzes recent trends and developments in the field with special emphasis on deep learning approaches. Furthermore, (4) it presents the research issues and unsolved challenges of the state-of-the-art techniques and (5) it discusses the new directions of research. The survey helps researchers to have an understanding of the malware detection field and of the new developments and directions of research explored by the scientific community to tackle the problem.\"\n}\n\n",
    "abstract": "The struggle between security analysts and malware developers is a never-ending battle with the complexity of malware changing as quickly as innovation grows. Current state-of-the-art research focus on the development and application of machine learning techniques for malware detection due to its ability to keep pace with malware evolution. This survey aims at providing a systematic and detailed overview of machine learning techniques for malware detection and in particular, deep learning techniques. The main contributions of the paper are: (1) it provides a complete description of the methods and features in a traditional machine learning workflow for malware detection and classification, (2) it explores the challenges and limitations of traditional machine learning and (3) it analyzes recent trends and developments in the field with special emphasis on deep learning approaches. Furthermore, (4) it presents the research issues and unsolved challenges of the state-of-the-art techniques and (5) it discusses the new directions of research. The survey helps researchers to have an understanding of the malware detection field and of the new developments and directions of research explored by the scientific community to tackle the problem."
}, {
    "py/object": "data.DataClassPaper",
    "Title": "Towards Attention Based Vulnerability Discovery Using Source Code Representation",
    "year": 2019,
    "ML_Techniques": "BLSTM",
    "Category": "Vulnerability analysis",
    "Sub_category": ",Malware detection",
    "Venue": "ICANN",
    "Link": "https://link.springer.com/chapter/10.1007/978-3-030-30490-4_58",
    "bibtex": "InProceedings{Kim2019_59,\n    author = \"Kim, Junae and Hubczenko, David and Montague, Paul\",\n    editor = \"Tetko, Igor V. and K{\\r{u}}rkov{\\'a}, V{\\v{e}}ra and Karpov, Pavel and Theis, Fabian\",\n    title = \"Towards Attention Based Vulnerability Discovery Using Source Code Representation\",\n    booktitle = \"Artificial Neural Networks and Machine Learning -- ICANN 2019: Text and Time Series\",\n    year = \"2019\",\n    publisher = \"Springer International Publishing\",\n    address = \"Cham\",\n    pages = \"731--746\",\n    abstract = \"Vulnerability discovery in software is an important task in the field of computer security. As vulnerabilities can be abused to enable cyber criminals and other malicious actors to exploit systems, it is crucial to keep software as free from vulnerabilities as is possible. Traditional approaches often comprise code scanning tasks to find specific and already-known classes of cyber vulnerabilities. However these approaches do not in general discover new classes of vulnerabilities. In this paper, we leverage a machine learning approach to model source code representation using syntax, semantics and control flow of source code and to infer vulnerable code patterns to tackle large code bases and identify potential vulnerabilities that missed by any existing static software analysis tools. In addition, our attention-based bidirectional long short-term memory framework adaptively localise regions of code illustrating where the possible vulnerable code fragment exists. The highlighted region may provide informative guidance to human developers or security experts. The experimental results demonstrate the feasibility of the proposed approach in the problem of software vulnerability discovery.\",\n    isbn = \"978-3-030-30490-4\"\n}\n\n",
    "abstract": "Vulnerability discovery in software is an important task in the field of computer security. As vulnerabilities can be abused to enable cyber criminals and other malicious actors to exploit systems, it is crucial to keep software as free from vulnerabilities as is possible. Traditional approaches often comprise code scanning tasks to find specific and already-known classes of cyber vulnerabilities. However these approaches do not in general discover new classes of vulnerabilities. In this paper, we leverage a machine learning approach to model source code representation using syntax, semantics and control flow of source code and to infer vulnerable code patterns to tackle large code bases and identify potential vulnerabilities that missed by any existing static software analysis tools. In addition, our attention-based bidirectional long short-term memory framework adaptively localise regions of code illustrating where the possible vulnerable code fragment exists. The highlighted region may provide informative guidance to human developers or security experts. The experimental results demonstrate the feasibility of the proposed approach in the problem of software vulnerability discovery."
}, {
    "py/object": "data.DataClassPaper",
    "Title": "Towards predictive analysis of android vulnerability using statistical codes and machine learning for IoT applications",
    "year": 2020,
    "ML_Techniques": "KNN, LR, RF, DT, SVM, GDBT",
    "Category": "Vulnerability analysis",
    "Sub_category": ",risk level prediction",
    "Venue": "CC",
    "Link": "https://www.sciencedirect.com/science/article/abs/pii/S0140366420300049",
    "bibtex": "article{Cui2020_60,\n    author = \"Cui, Jianfeng and Wang, Lixin and Zhao, Xin and Zhang, Hongyi\",\n    title = \"Towards predictive analysis of android vulnerability using statistical codes and machine learning for IoT applications\",\n    journal = \"Computer Communications\",\n    volume = \"155\",\n    pages = \"125 - 131\",\n    year = \"2020\",\n    issn = \"0140-3664\",\n    doi = \"https://doi.org/10.1016/j.comcom.2020.02.078\",\n    url = \"http://www.sciencedirect.com/science/article/pii/S0140366420300049\",\n    keywords = \"Android vulnerability, Prediction, IoT applications, Software metrics, Machine learning\",\n    abstract = \"Recently, the Internet of Things (IoT) technology is used for several applications for exchanging information among various devices. The intelligent IoT based system utilizes an Android operating system because it is also primarily used in mobile devices. One of the main problems for different IoT applications is associated with android vulnerability is its complicated and large size. To overcome the main issue of IoT, the existing studies have proposed several effective prediction models using machine learning algorithms and software metrics. In this paper, we are focused on conducting android vulnerability prediction analysis using machine learning for intelligent IoT applications. We conducted an empirical investigation for examining security risk prediction of 1406 Android applications with varying levels of risk using a metric set of 21 static code metrics and 6 machine learning (ML) techniques. It is observed from results that ML algorithms have different performances for predicting security risks. RF algorithm performs better for Android applications of all risk levels. By analyzing the findings of the conducted empirical study, it is suggested that developers may consider object-oriented metrics and RF algorithm in the software development process for android based intelligent IoT systems.\"\n}\n\n",
    "abstract": "Recently, the Internet of Things (IoT) technology is used for several applications for exchanging information among various devices. The intelligent IoT based system utilizes an Android operating system because it is also primarily used in mobile devices. One of the main problems for different IoT applications is associated with android vulnerability is its complicated and large size. To overcome the main issue of IoT, the existing studies have proposed several effective prediction models using machine learning algorithms and software metrics. In this paper, we are focused on conducting android vulnerability prediction analysis using machine learning for intelligent IoT applications. We conducted an empirical investigation for examining security risk prediction of 1406 Android applications with varying levels of risk using a metric set of 21 static code metrics and 6 machine learning (ML) techniques. It is observed from results that ML algorithms have different performances for predicting security risks. RF algorithm performs better for Android applications of all risk levels. By analyzing the findings of the conducted empirical study, it is suggested that developers may consider object-oriented metrics and RF algorithm in the software development process for android based intelligent IoT systems."
}, {
    "py/object": "data.DataClassPaper",
    "Title": "VCCFinder: Finding Potential Vulnerabilities in Open-Source Projects to Assist Code Audits",
    "year": 2015,
    "ML_Techniques": "SVM",
    "Category": "Vulnerability analysis",
    "Sub_category": ",commit level",
    "Venue": "CCS",
    "Link": "https://dl.acm.org/doi/10.1145/2810103.2813604",
    "bibtex": "inproceedings{Perl2015_61,\n    author = \"Perl, Henning and Dechand, Sergej and Smith, Matthew and Arp, Daniel and Yamaguchi, Fabian and Rieck, Konrad and Fahl, Sascha and Acar, Yasemin\",\n    title = \"VCCFinder: Finding Potential Vulnerabilities in Open-Source Projects to Assist Code Audits\",\n    year = \"2015\",\n    isbn = \"9781450338325\",\n    publisher = \"Association for Computing Machinery\",\n    address = \"New York, NY, USA\",\n    url = \"https://doi.org/10.1145/2810103.2813604\",\n    doi = \"10.1145/2810103.2813604\",\n    abstract = \"Despite the security community's best effort, the number of serious vulnerabilities discovered in software is increasing rapidly. In theory, security audits should find and remove the vulnerabilities before the code ever gets deployed. However, due to the enormous amount of code being produced, as well as a the lack of manpower and expertise, not all code is sufficiently audited. Thus, many vulnerabilities slip into production systems. A best-practice approach is to use a code metric analysis tool, such as Flawfinder, to flag potentially dangerous code so that it can receive special attention. However, because these tools have a very high false-positive rate, the manual effort needed to find vulnerabilities remains overwhelming. In this paper, we present a new method of finding potentially dangerous code in code repositories with a significantly lower false-positive rate than comparable systems. We combine code-metric analysis with metadata gathered from code repositories to help code review teams prioritize their work. The paper makes three contributions. First, we conducted the first large-scale mapping of CVEs to GitHub commits in order to create a vulnerable commit database. Second, based on this database, we trained a SVM classifier to flag suspicious commits. Compared to Flawfinder, our approach reduces the amount of false alarms by over 99 \\% at the same level of recall. Finally, we present a thorough quantitative and qualitative analysis of our approach and discuss lessons learned from the results. We will share the database as a benchmark for future research and will also provide our analysis tool as a web service.\",\n    booktitle = \"Proceedings of the 22nd ACM SIGSAC Conference on Computer and Communications Security\",\n    pages = \"426\u2013437\",\n    numpages = \"12\",\n    keywords = \"vulnerabilities, machine learning, static analysis\",\n    location = \"Denver, Colorado, USA\",\n    series = \"CCS '15\"\n}\n\n",
    "abstract": "Despite the security community's best effort, the number of serious vulnerabilities discovered in software is increasing rapidly. In theory, security audits should find and remove the vulnerabilities before the code ever gets deployed. However, due to the enormous amount of code being produced, as well as a the lack of manpower and expertise, not all code is sufficiently audited. Thus, many vulnerabilities slip into production systems. A best-practice approach is to use a code metric analysis tool, such as Flawfinder, to flag potentially dangerous code so that it can receive special attention. However, because these tools have a very high false-positive rate, the manual effort needed to find vulnerabilities remains overwhelming. In this paper, we present a new method of finding potentially dangerous code in code repositories with a significantly lower false-positive rate than comparable systems. We combine code-metric analysis with metadata gathered from code repositories to help code review teams prioritize their work. The paper makes three contributions. First, we conducted the first large-scale mapping of CVEs to GitHub commits in order to create a vulnerable commit database. Second, based on this database, we trained a SVM classifier to flag suspicious commits. Compared to Flawfinder, our approach reduces the amount of false alarms by over 99 % at the same level of recall. Finally, we present a thorough quantitative and qualitative analysis of our approach and discuss lessons learned from the results. We will share the database as a benchmark for future research and will also provide our analysis tool as a web service."
}, {
    "py/object": "data.DataClassPaper",
    "Title": "Vulnerability Prediction From Source Code Using Machine Learning",
    "year": 2020,
    "ML_Techniques": "CNN",
    "Category": "Vulnerability analysis",
    "Sub_category": "",
    "Venue": "IEEE Access",
    "Link": "https://ieeexplore.ieee.org/abstract/document/9167194",
    "bibtex": "ARTICLE{Bilgin2020_63,\n    author = \"{Bilgin}, Z. and {Ersoy}, M. A. and {Soykan}, E. U. and {Tomur}, E. and {\u00c7omak}, P. and {Kara\u00e7ay}, L.\",\n    journal = \"IEEE Access\",\n    title = \"Vulnerability Prediction From Source Code Using Machine Learning\",\n    year = \"2020\",\n    volume = \"8\",\n    number = \"\",\n    pages = \"150672-150684\",\n    doi = \"10.1109/ACCESS.2020.3016774\"\n}\n\n",
    "abstract": "As the role of information and communication technologies gradually increases in our lives, software security becomes a major issue to provide protection against malicious attempts and to avoid ending up with noncompensable damages to the system. With the advent of data-driven techniques, there is now a growing interest in how to leverage machine learning (ML) as a software assurance method to build trustworthy software systems. In this study, we examine how to predict software vulnerabilities from source code by employing ML prior to their release. To this end, we develop a source code representation method that enables us to perform intelligent analysis on the Abstract Syntax Tree (AST) form of source code and then investigate whether ML can distinguish vulnerable and nonvulnerable code fragments. To make a comprehensive performance evaluation, we use a public dataset that contains a large amount of function-level real source code parts mined from open-source projects and carefully labeled according to the type of vulnerability if they have any.We show the effectiveness of our proposed method for vulnerability prediction from source code by carrying out exhaustive and realistic experiments under different regimes in comparison with state-of-art methods.\n"
}, {
    "py/object": "data.DataClassPaper",
    "Title": "Web Application Vulnerability Prediction Using Hybrid Program Analysis and Machine Learning",
    "year": 2015,
    "ML_Techniques": "RF, LR, CoForest-RF",
    "Category": "Vulnerability analysis",
    "Sub_category": ",Input validation",
    "Venue": "TDSC",
    "Link": "https://ieeexplore.ieee.org/abstract/document/6963442",
    "bibtex": "ARTICLE{Shar2015_64,\n    author = \"{Shar}, L. K. and {Briand}, L. C. and {Tan}, H. B. K.\",\n    journal = \"IEEE Transactions on Dependable and Secure Computing\",\n    title = \"Web Application Vulnerability Prediction Using Hybrid Program Analysis and Machine Learning\",\n    year = \"2015\",\n    volume = \"12\",\n    number = \"6\",\n    pages = \"688-707\",\n    doi = \"10.1109/TDSC.2014.2373377\"\n}\n\n",
    "abstract": "Due to limited time and resources, web software engineers need support in identifying vulnerable code. A practical approach to predicting vulnerable code would enable them to prioritize security auditing efforts. In this paper, we propose using a set of hybrid (static+dynamic) code attributes that characterize input validation and input sanitization code patterns and are expected to be significant indicators of web application vulnerabilities. Because static and dynamic program analyses complement each other, both techniques are used to extract the proposed attributes in an accurate and scalable way. Current vulnerability prediction techniques rely on the availability of data labeled with vulnerability information for training. For many real world applications, past vulnerability data is often not available or at least not complete. Hence, to address both situations where labeled past data is fully available or not, we apply both supervised and semi-supervised learning when building vulnerability predictors based on hybrid code attributes. Given that semi-supervised learning is entirely unexplored in this domain, we describe how to use this learning scheme effectively for vulnerability prediction. We performed empirical case studies on seven open source projects where we built and evaluated supervised and semi-supervised models. When cross validated with fully available labeled data, the supervised models achieve an average of 77 percent recall and 5 percent probability of false alarm for predicting SQL injection, cross site scripting, remote code execution and file inclusion vulnerabilities. With a low amount of labeled data, when compared to the supervised model, the semi-supervised model showed an average improvement of 24 percent higher recall and 3 percent lower probability of false alarm, thus suggesting semi-supervised learning may be a preferable solution for many real world applications where vulnerability data is missing."
}, {
    "py/object": "data.DataClassPaper",
    "Title": "A Comparative Analysis for Machine Learning based Software Defect Prediction Systems",
    "year": 2020,
    "ML_Techniques": "DT, NB, KNN, SVM, RF, AB, GB, B, MLP",
    "Category": "Testing",
    "Sub_category": "Defect prediction",
    "Venue": "ICCCNT",
    "Link": "https://ieeexplore.ieee.org/document/9225352",
    "bibtex": "INPROCEEDINGS{Cetiner2020_65,\n    author = \"{Cetiner}, M. and {Sahingoz}, O. K.\",\n    booktitle = \"2020 11th International Conference on Computing, Communication and Networking Technologies (ICCCNT)\",\n    title = \"A Comparative Analysis for Machine Learning based Software Defect Prediction Systems\",\n    year = \"2020\",\n    volume = \"\",\n    number = \"\",\n    pages = \"1-7\",\n    doi = \"10.1109/ICCCNT49239.2020.9225352\"\n}\n\n",
    "abstract": "In the Software Engineering concept, the prediction of the software defects plays a vital role in increasing the quality of the software systems, which is one of the most critical and expensive phases of the software development lifecycle. While the use of software systems is increasing in our daily lives, their dependencies and complexities are also increasing, and this results in a suitable environment for defects. Due to the existence of software defects, the software produces incorrect results and behaviors. What is more critical than defects, is finding them before they occur. Therefore detection (and also prediction) of the software defects enables the managers of the software to make an efficient allocation of the resources for the maintenance and testing phases. In the literature, there are different proposals for the prediction of software defects. In this paper, we made a comparative analysis about the machine learning-based software defect prediction systems by comparing 10 learning algorithms like Decision Tree, Naive Bayes, K-Nearest Neighbor, Support Vector Machine, Random Forest, Extra Trees, Adaboost, Gradient Boosting, Bagging, and Multi-Layer Perceptron, on the public datasets CM1, KC1, KC2, JM1, and PC1 from the PROMISE warehouse. The experimental results showed that proposed models result in proper accuracy levels for software defect prediction to increase the quality of the software."
}, {
    "py/object": "data.DataClassPaper",
    "Title": "A Machine Learning Approach for Statistical Software Testing \u2217",
    "year": 2007,
    "ML_Techniques": "",
    "Category": "Testing",
    "Sub_category": ",Effort prediction",
    "Venue": "IJCAI",
    "Link": "https://www.aaai.org/Papers/IJCAI/2007/IJCAI07-366.pdf",
    "bibtex": "INPROCEEDINGS{Cetiner2020_65,\n    author = \"{Cetiner}, M. and {Sahingoz}, O. K.\",\n    booktitle = \"2020 11th International Conference on Computing, Communication and Networking Technologies (ICCCNT)\",\n    title = \"A Comparative Analysis for Machine Learning based Software Defect Prediction Systems\",\n    year = \"2020\",\n    volume = \"\",\n    number = \"\",\n    pages = \"1-7\",\n    doi = \"10.1109/ICCCNT49239.2020.9225352\"\n}\n\n",
    "abstract": "Some Statistical Software Testing approaches rely\non sampling the feasible paths in the control flow\ngraph of the program; the difficulty comes from the\ntiny ratio of feasible paths. This paper presents an\nadaptive sampling mechanism called EXIST for Exploration/eXploitation Inference for Software Testing, able to retrieve distinct feasible paths with high\nprobability. EXIST proceeds by alternatively exploiting and updating a distribution on the set of\nprogram paths. An original representation of paths,\naccommodating long-range dependencies and data\nsparsity and based on extended Parikh maps, is proposed. Experimental validation on real-world and\nartificial problems demonstrates dramatic improvements compared to the state of the art."
}, {
    "py/object": "data.DataClassPaper",
    "Title": "A machine learning approach to generate test oracles",
    "year": 2018,
    "ML_Techniques": "AB",
    "Category": "Testing",
    "Sub_category": "Test data/case generation",
    "Venue": "SBES",
    "Link": "https://dl.acm.org/doi/abs/10.1145/3266237.3266273",
    "bibtex": "INPROCEEDINGS{Cetiner2020_65,\n    author = \"{Cetiner}, M. and {Sahingoz}, O. K.\",\n    booktitle = \"2020 11th International Conference on Computing, Communication and Networking Technologies (ICCCNT)\",\n    title = \"A Comparative Analysis for Machine Learning based Software Defect Prediction Systems\",\n    year = \"2020\",\n    volume = \"\",\n    number = \"\",\n    pages = \"1-7\",\n    doi = \"10.1109/ICCCNT49239.2020.9225352\"\n}\n\n",
    "abstract": "One of the essential activities for quality assurance in software development is the software testing. Studies report that Software Testing is one of the most costly activities in the development process, can reach up to 50 percent of its total cost. One of the great challenges of conducting software testing is related to the automation of a mechanism known as \"test oracle\". This work presents an approach based on machine learning (ML) for automation of the test oracle mechanism in software. The approach uses historical usage data from an application captured by inserting a capture component into the application under test. These data go through a Knowledge Discovery in Database step and are then used for training to generate an oracle suitable for the application under test. Four experiments were executed with web applications to evaluate the proposed approach. The first and second experiments were performed with a fictitious application, with faults inserted randomly in the first experiment, inserted by a developer in the second one and inserted by mutation tests in third one. The fourth experiment was carried out with a large real application in order to assure the results of the preliminary experiments. The experiments presented indications of the suitability of the approach to the solution of the problem."
}, {
    "py/object": "data.DataClassPaper",
    "Title": "A systematic review of machine learning techniques for software fault prediction",
    "year": 2015,
    "ML_Techniques": "",
    "Category": "Testing",
    "Sub_category": "Defect prediction",
    "Venue": "ASC",
    "Link": "https://www.sciencedirect.com/science/article/abs/pii/S1568494614005857",
    "bibtex": "article{Malhotra2015_69,\n    author = \"Malhotra, Ruchika\",\n    title = \"A systematic review of machine learning techniques for software fault prediction\",\n    journal = \"Applied Soft Computing\",\n    volume = \"27\",\n    pages = \"504 - 518\",\n    year = \"2015\",\n    issn = \"1568-4946\",\n    doi = \"https://doi.org/10.1016/j.asoc.2014.11.023\",\n    url = \"http://www.sciencedirect.com/science/article/pii/S1568494614005857\",\n    keywords = \"Machine learning, Software fault proneness, Systematic literature review\",\n    abstract = \"Background Software fault prediction is the process of developing models that can be used by the software practitioners in the early phases of software development life cycle for detecting faulty constructs such as modules or classes. There are various machine learning techniques used in the past for predicting faults. Method In this study we perform a systematic review of studies from January 1991 to October 2013 in the literature that use the machine learning techniques for software fault prediction. We assess the performance capability of the machine learning techniques in existing research for software fault prediction. We also compare the performance of the machine learning techniques with the statistical techniques and other machine learning techniques. Further the strengths and weaknesses of machine learning techniques are summarized. Results In this paper we have identified 64 primary studies and seven categories of the machine learning techniques. The results prove the prediction capability of the machine learning techniques for classifying module/class as fault prone or not fault prone. The models using the machine learning techniques for estimating software fault proneness outperform the traditional statistical models. Conclusion Based on the results obtained from the systematic review, we conclude that the machine learning techniques have the ability for predicting software fault proneness and can be used by software practitioners and researchers. However, the application of the machine learning techniques in software fault prediction is still limited and more number of studies should be carried out in order to obtain well formed and generalizable results. We provide future guidelines to practitioners and researchers based on the results obtained in this work.\"\n}\n\n",
    "abstract": "Background\nSoftware fault prediction is the process of developing models that can be used by the software practitioners in the early phases of software development life cycle for detecting faulty constructs such as modules or classes. There are various machine learning techniques used in the past for predicting faults.\n\nMethod\nIn this study we perform a systematic review of studies from January 1991 to October 2013 in the literature that use the machine learning techniques for software fault prediction. We assess the performance capability of the machine learning techniques in existing research for software fault prediction. We also compare the performance of the machine learning techniques with the statistical techniques and other machine learning techniques. Further the strengths and weaknesses of machine learning techniques are summarized.\n\nResults\nIn this paper we have identified 64 primary studies and seven categories of the machine learning techniques. The results prove the prediction capability of the machine learning techniques for classifying module/class as fault prone or not fault prone. The models using the machine learning techniques for estimating software fault proneness outperform the traditional statistical models.\n\nConclusion\nBased on the results obtained from the systematic review, we conclude that the machine learning techniques have the ability for predicting software fault proneness and can be used by software practitioners and researchers. However, the application of the machine learning techniques in software fault prediction is still limited and more number of studies should be carried out in order to obtain well formed and generalizable results. We provide future guidelines to practitioners and researchers based on the results obtained in this work."
}, {
    "py/object": "data.DataClassPaper",
    "Title": "An empirical study of software entropy based bug prediction using machine learning",
    "year": 2017,
    "ML_Techniques": "GEP, RGNN, SVR, LMSR",
    "Category": "Testing",
    "Sub_category": "Defect prediction",
    "Venue": "IJSAEM",
    "Link": "https://link.springer.com/article/10.1007/s13198-016-0479-2",
    "bibtex": "article{Kaur2017_71,\n    author = \"Kaur, Arvinder and Kaur, Kamaldeep and Chopra, Deepti\",\n    title = \"An empirical study of software entropy based bug prediction using machine learning\",\n    volume = \"8\",\n    issn = \"0976-4348\",\n    url = \"https://doi.org/10.1007/s13198-016-0479-2\",\n    doi = \"10.1007/s13198-016-0479-2\",\n    abstract = \"There are many approaches for predicting bugs in software systems. A popular approach for bug prediction is using entropy of changes as proposed by Hassan (2009). This paper uses the metrics derived using entropy of changes to compare five machine learning techniques, namely Gene Expression Programming (GEP), General Regression Neural Network, Locally Weighted Regression, Support Vector Regression (SVR) and Least Median Square Regression for predicting bugs. Four software subsystems: mozilla/layout/generic, mozilla/layout/forms, apache/httpd/modules/ssl and apache/httpd/modules/mappers are used for the validation purpose. The data extraction for the validation purpose is automated by developing an algorithm that employs web scraping and regular expressions. The study suggests GEP and SVR as stable regression techniques for bug prediction using entropy of changes.\",\n    language = \"en\",\n    number = \"2\",\n    urldate = \"2021-01-01\",\n    journal = \"International Journal of System Assurance Engineering and Management\",\n    month = \"November\",\n    year = \"2017\",\n    pages = \"599--616\"\n}\n\n",
    "abstract": "There are many approaches for predicting bugs in software systems. A popular approach for bug prediction is using entropy of changes as proposed by Hassan (2009). This paper uses the metrics derived using entropy of changes to compare five machine learning techniques, namely Gene Expression Programming (GEP), General Regression Neural Network, Locally Weighted Regression, Support Vector Regression (SVR) and Least Median Square Regression for predicting bugs. Four software subsystems: mozilla/layout/generic, mozilla/layout/forms, apache/httpd/modules/ssl and apache/httpd/modules/mappers are used for the validation purpose. The data extraction for the validation purpose is automated by developing an algorithm that employs web scraping and regular expressions. The study suggests GEP and SVR as stable regression techniques for bug prediction using entropy of changes."
}, {
    "py/object": "data.DataClassPaper",
    "Title": "AppFlow: using machine learning to synthesize robust, reusable UI tests",
    "year": 2018,
    "ML_Techniques": "SVM",
    "Category": "Testing",
    "Sub_category": ",Test data/case generation",
    "Venue": "FSE",
    "Link": "https://dl.acm.org/doi/10.1145/3236024.3236055",
    "bibtex": "article{Kaur2017_71,\n    author = \"Kaur, Arvinder and Kaur, Kamaldeep and Chopra, Deepti\",\n    title = \"An empirical study of software entropy based bug prediction using machine learning\",\n    volume = \"8\",\n    issn = \"0976-4348\",\n    url = \"https://doi.org/10.1007/s13198-016-0479-2\",\n    doi = \"10.1007/s13198-016-0479-2\",\n    abstract = \"There are many approaches for predicting bugs in software systems. A popular approach for bug prediction is using entropy of changes as proposed by Hassan (2009). This paper uses the metrics derived using entropy of changes to compare five machine learning techniques, namely Gene Expression Programming (GEP), General Regression Neural Network, Locally Weighted Regression, Support Vector Regression (SVR) and Least Median Square Regression for predicting bugs. Four software subsystems: mozilla/layout/generic, mozilla/layout/forms, apache/httpd/modules/ssl and apache/httpd/modules/mappers are used for the validation purpose. The data extraction for the validation purpose is automated by developing an algorithm that employs web scraping and regular expressions. The study suggests GEP and SVR as stable regression techniques for bug prediction using entropy of changes.\",\n    language = \"en\",\n    number = \"2\",\n    urldate = \"2021-01-01\",\n    journal = \"International Journal of System Assurance Engineering and Management\",\n    month = \"November\",\n    year = \"2017\",\n    pages = \"599--616\"\n}\n\n",
    "abstract": "UI testing is known to be difficult, especially as today\u2019s development cycles become faster. Manual UI testing is tedious, costly and error- prone. Automated UI tests are costly to write and maintain. This paper presents AppFlow, a system for synthesizing highly robust, highly reusable UI tests. It leverages machine learning to automatically recognize common screens and widgets, relieving developers from writing ad hoc, fragile logic to use them in tests. It enables developers to write a library of modular tests for the main functionality of an app category (e.g., an \u201cadd to cart\u201d test for shopping apps). It can then quickly test a new app in the same category by synthesizing full tests from the modular ones in the library. By focusing on the main functionality, AppFlow provides \u201csmoke testing\u201d requiring little manual work. Optionally, developers can customize AppFlow by adding app-specific tests for completeness. We evaluated AppFlow on 60 popular apps in the shopping and the news category, two case studies on the BBC news app and the JackThreads shopping app, and a user-study of 15 subjects on the Wish shopping app. Results show that AppFlow accurately recognizes screens and widgets, synthesizes highly robust and reusable tests, covers 46.6% of all automatable tests for Jackthreads with the tests it synthesizes, and reduces the effort to test a new app by up to 90%. Interestingly, it found eight bugs in the evaluated apps, including seven functionality bugs, despite that they were publicly released and supposedly went through thorough testing."
}, {
    "py/object": "data.DataClassPaper",
    "Title": "Applying machine learning to software fault-proneness prediction",
    "year": 2008,
    "ML_Techniques": "SVM, ANN",
    "Category": "Testing",
    "Sub_category": "Defect prediction",
    "Venue": "JSS",
    "Link": "https://www.sciencedirect.com/science/article/abs/pii/S0164121207001240",
    "bibtex": "article{Gondra2008_73,\n    author = \"Gondra, Iker\",\n    title = \"Applying machine learning to software fault-proneness prediction\",\n    journal = \"Journal of Systems and Software\",\n    volume = \"81\",\n    number = \"2\",\n    pages = \"186 - 195\",\n    year = \"2008\",\n    note = \"Model-Based Software Testing\",\n    issn = \"0164-1212\",\n    doi = \"https://doi.org/10.1016/j.jss.2007.05.035\",\n    url = \"http://www.sciencedirect.com/science/article/pii/S0164121207001240\",\n    keywords = \"Software testing, Software metrics, Fault-proneness, Machine learning, Neural network, Sensitivity analysis, Support vector machine\",\n    abstract = \"The importance of software testing to quality assurance cannot be overemphasized. The estimation of a module\u2019s fault-proneness is important for minimizing cost and improving the effectiveness of the software testing process. Unfortunately, no general technique for estimating software fault-proneness is available. The observed correlation between some software metrics and fault-proneness has resulted in a variety of predictive models based on multiple metrics. Much work has concentrated on how to select the software metrics that are most likely to indicate fault-proneness. In this paper, we propose the use of machine learning for this purpose. Specifically, given historical data on software metric values and number of reported errors, an Artificial Neural Network (ANN) is trained. Then, in order to determine the importance of each software metric in predicting fault-proneness, a sensitivity analysis is performed on the trained ANN. The software metrics that are deemed to be the most critical are then used as the basis of an ANN-based predictive model of a continuous measure of fault-proneness. We also view fault-proneness prediction as a binary classification task (i.e., a module can either contain errors or be error-free) and use Support Vector Machines (SVM) as a state-of-the-art classification method. We perform a comparative experimental study of the effectiveness of ANNs and SVMs on a data set obtained from NASA\u2019s Metrics Data Program data repository.\"\n}\n\n",
    "abstract": "The importance of software testing to quality assurance cannot be overemphasized. The estimation of a module\u2019s fault-proneness is important for minimizing cost and improving the effectiveness of the software testing process. Unfortunately, no general technique for estimating software fault-proneness is available. The observed correlation between some software metrics and fault-proneness has resulted in a variety of predictive models based on multiple metrics. Much work has concentrated on how to select the software metrics that are most likely to indicate fault-proneness. In this paper, we propose the use of machine learning for this purpose. Specifically, given historical data on software metric values and number of reported errors, an Artificial Neural Network (ANN) is trained. Then, in order to determine the importance of each software metric in predicting fault-proneness, a sensitivity analysis is performed on the trained ANN. The software metrics that are deemed to be the most critical are then used as the basis of an ANN-based predictive model of a continuous measure of fault-proneness. We also view fault-proneness prediction as a binary classification task (i.e., a module can either contain errors or be error-free) and use Support Vector Machines (SVM) as a state-of-the-art classification method. We perform a comparative experimental study of the effectiveness of ANNs and SVMs on a data set obtained from NASA\u2019s Metrics Data Program data repository."
}, {
    "py/object": "data.DataClassPaper",
    "Title": "Artificial Intelligence Applied to Software Testing: A Literature Review",
    "year": 2020,
    "ML_Techniques": "",
    "Category": "Testing",
    "Sub_category": "",
    "Venue": "CISTI",
    "Link": "https://ieeexplore.ieee.org/document/9141124",
    "bibtex": "INPROCEEDINGS{Lima2020_74,\n    author = \"{Lima}, R. and {da Cruz}, A. M. R. and {Ribeiro}, J.\",\n    booktitle = \"2020 15th Iberian Conference on Information Systems and Technologies (CISTI)\",\n    title = \"Artificial Intelligence Applied to Software Testing: A Literature Review\",\n    year = \"2020\",\n    volume = \"\",\n    number = \"\",\n    pages = \"1-6\",\n    doi = \"10.23919/CISTI49556.2020.9141124\"\n}\n\n",
    "abstract": "In the last few years Artificial Intelligence (AI) algorithms and Machine Learning (ML) approaches have been successfully applied in real-world scenarios like commerce, industry and digital services, but they are not a widespread reality in Software Testing. Due to the complexity of software testing, most of the work of AI/ML applied to it is still academic. This paper briefly presents the state of the art in the field of software testing, applying ML approaches and AI algorithms. The progress analysis of the AI and ML methods used for this purpose during the last three years is based on the Scopus Elsevier, web of Science and Google Scholar databases. Algorithms used in software testing have been grouped by test types. The paper also tries to create relations between the main AI approaches and which type of tests they are applied to, in particular white-box, grey-box and black-box software testing types. We conclude that black-box testing is, by far, the preferred method of software testing, when AI is applied, and all three methods of ML (supervised, unsupervised and reinforcement) are commonly used in black-box testing being the \u201cclustering\u201d technique, Artificial Neural Networks and Genetic Algorithms applied to \u201cfuzzing\u201d and regression testing."
}, {
    "py/object": "data.DataClassPaper",
    "Title": "Assessment of machine learning algorithms for determining defective classes in an object-oriented software",
    "year": 2017,
    "ML_Techniques": "MLP,  CART, KNN",
    "Category": "Testing",
    "Sub_category": "Defect prediction",
    "Venue": "ICRITO",
    "Link": "https://ieeexplore.ieee.org/document/8342425",
    "bibtex": "INPROCEEDINGS{Singh2017_76,\n    author = \"{Singh}, P. and {Malhotra}, R.\",\n    booktitle = \"2017 6th International Conference on Reliability, Infocom Technologies and Optimization (Trends and Future Directions) (ICRITO)\",\n    title = \"Assessment of machine learning algorithms for determining defective classes in an object-oriented software\",\n    year = \"2017\",\n    volume = \"\",\n    number = \"\",\n    pages = \"204-209\",\n    doi = \"10.1109/ICRITO.2017.8342425\"\n}\n\n",
    "abstract": "Software defect prediction is a well renowned field of software engineering. Determination of defective classes early in the lifecycle of a software product helps software practitioners in effective allocation of resources. More resources are allocated to probable defective classes so that defects can be removed in the initial phases of the software product. Such a practice would lead to a good quality software product. Although, hundreds of defect prediction models have been developed and validated by researchers, there is still a need to develop and evaluate more models to draw generalized conclusions. Literature studies have found Machine Learning (ML) algorithms to be effective classifiers in this domain. Thus, this study evaluates four ML algorithms on data collected from seven open source software projects for developing software defect prediction models. The results indicate superior performance of the Multilayer Perceptron algorithm over all the other investigated algorithms. The results of the study are also statistically evaluated to establish their effectiveness."
}, {
    "py/object": "data.DataClassPaper",
    "Title": "Assessment of software testing time using soft computing techniques",
    "year": 2012,
    "ML_Techniques": "LR, ANN, SVM, DT, FIS, ANFIS",
    "Category": "Testing",
    "Sub_category": "",
    "Venue": "SEN",
    "Link": "https://dl.acm.org/doi/10.1145/2088883.2088895",
    "bibtex": "INPROCEEDINGS{Singh2017_76,\n    author = \"{Singh}, P. and {Malhotra}, R.\",\n    booktitle = \"2017 6th International Conference on Reliability, Infocom Technologies and Optimization (Trends and Future Directions) (ICRITO)\",\n    title = \"Assessment of machine learning algorithms for determining defective classes in an object-oriented software\",\n    year = \"2017\",\n    volume = \"\",\n    number = \"\",\n    pages = \"204-209\",\n    doi = \"10.1109/ICRITO.2017.8342425\"\n}\n\n",
    "abstract": "Application of a soft computing approach in place of traditional statistical techniques has shown a remarkable improvement in reliability prediction. This paper examines and compares Linear Regression (LR) and five machine learning methods: (Artificial Neural Network, Support Vector Machine, Decision Tree, Fuzzy Inference System and Adaptive Neuro-Fuzzy Inference System). These methods are explored empirically to find the effect of severity of errors for the assessment of software testing time. We use two publicly available failure datasets to analyse and compare the regression and machine learning methods for assessing the software testing time. The performance of the proposed model is compared by computing mean absolute error (MAE) and root mean square error (RMSE). Based on the results from rigours experiments, it is observed that model accuracy using FIS and ANFIS method is better and outperformed the model predicted using linear regression and other machine learning methods. Finally, we conclude that Adaptive Neuro-fuzzy Inference System is useful in constructing software quality models having better capability of generalization and less dependent on sample size."
}, {
    "py/object": "data.DataClassPaper",
    "Title": "Automatically learning semantic features for defect prediction",
    "year": 2016,
    "ML_Techniques": "DBN",
    "Category": "Testing",
    "Sub_category": "Defect prediction",
    "Venue": "ICSE",
    "Link": "https://dl.acm.org/doi/10.1145/2884781.2884804",
    "bibtex": "INPROCEEDINGS{Singh2017_76,\n    author = \"{Singh}, P. and {Malhotra}, R.\",\n    booktitle = \"2017 6th International Conference on Reliability, Infocom Technologies and Optimization (Trends and Future Directions) (ICRITO)\",\n    title = \"Assessment of machine learning algorithms for determining defective classes in an object-oriented software\",\n    year = \"2017\",\n    volume = \"\",\n    number = \"\",\n    pages = \"204-209\",\n    doi = \"10.1109/ICRITO.2017.8342425\"\n}\n\n",
    "abstract": "Software defect prediction, which predicts defective code regions, can help developers find bugs and prioritize their testing efforts. To build accurate prediction models, previous studies focus on manually designing features that encode the characteristics of programs and exploring different machine learning algorithms. Existing traditional features often fail to capture the semantic differences of programs, and such a capability is needed for building accurate prediction models. To bridge the gap between programs' semantics and defect prediction features, this paper proposes to leverage a powerful representation-learning algorithm, deep learning, to learn semantic representation of programs automatically from source code. Specifically, we leverage Deep Belief Network (DBN) to automatically learn semantic features from token vectors extracted from programs' Abstract Syntax Trees (ASTs). Our evaluation on ten open source projects shows that our automatically learned semantic features significantly improve both within-project defect prediction (WPDP) and cross-project defect prediction (CPDP) compared to traditional features. Our semantic features improve WPDP on average by 14.7% in precision, 11.5% in recall, and 14.2% in F1. For CPDP, our semantic features based approach outperforms the state-of-the-art technique TCA+ with traditional features by 8.9% in F1."
}, {
    "py/object": "data.DataClassPaper",
    "Title": "Automating Root Cause Analysis via Machine Learning in Agile Software Testing Environments",
    "year": 2019,
    "ML_Techniques": "ANN",
    "Category": "Testing",
    "Sub_category": "",
    "Venue": "ICST",
    "Link": "https://ieeexplore.ieee.org/document/8730163",
    "bibtex": "INPROCEEDINGS{Kahles2019_79,\n    author = \"{Kahles}, J. and {T\u00f6rr\u00f6nen}, J. and {Huuhtanen}, T. and {Jung}, A.\",\n    booktitle = \"2019 12th IEEE Conference on Software Testing, Validation and Verification (ICST)\",\n    title = \"Automating Root Cause Analysis via Machine Learning in Agile Software Testing Environments\",\n    year = \"2019\",\n    volume = \"\",\n    number = \"\",\n    pages = \"379-390\",\n    doi = \"10.1109/ICST.2019.00047\"\n}\n\n",
    "abstract": "We apply machine learning to automate the root cause analysis in agile software testing environments. In particular, we extract relevant features from raw log data after interviewing testing engineers (human experts). Initial efforts are put into clustering the unlabeled data, and despite obtaining weak correlations between several clusters and failure root causes, the vagueness in the rest of the clusters leads to the consideration of labeling. A new round of interviews with the testing engineers leads to the definition of five ground-truth categories. Using manually labeled data, we train artificial neural networks that either classify the data or pre-process it for clustering. The resulting method achieves an accuracy of 88.9%. The methodology of this paper serves as a prototype or baseline approach for the extraction of expert knowledge and its adaptation to machine learning techniques for root cause analysis in agile environments."
}, {
    "py/object": "data.DataClassPaper",
    "Title": "Back-to-Back Testing Framework Using a Machine Learning Method",
    "year": 2012,
    "ML_Techniques": "SVM",
    "Category": "Testing",
    "Sub_category": "Test data/case generation",
    "Venue": "SNPD",
    "Link": "https://link.springer.com/chapter/10.1007/978-3-642-32172-6_3",
    "bibtex": "InProceedings{Takagi2013_80,\n    author = \"Takagi, Tomohiko and Utsumi, Takeshi and Furukawa, Zengo\",\n    editor = \"Lee, Roger\",\n    title = \"Back-to-Back Testing Framework Using a Machine Learning Method\",\n    booktitle = \"Software Engineering, Artificial Intelligence, Networking and Parallel/Distributed Computing 2012\",\n    year = \"2013\",\n    publisher = \"Springer Berlin Heidelberg\",\n    address = \"Berlin, Heidelberg\",\n    pages = \"27--36\",\n    abstract = \"In back-to-back testing of software, expected outputs (test oracles) are generated from software that is similar to SUT (software under test), and are compared with test outputs from the SUT in order to reveal faults. The advantages of back-to-back testing are that one can automatically perform the creation of expected outputs that is one of the most costly processes in software testing, and one can obtain detailed expected outputs that are not limited to a specific aspect, such as state transitions. However, it is not easy to automatically classify the differences between the test outputs and the expected outputs into two groups, that is, one resulting from failures of the SUT and another resulting from intended functional differences between the SUT and the similar software. The manual classification is too costly and back-to-back testing can hardly be applied unless the functions of the similar software are exactly equal to the intended functions of the SUT. To solve this costly classification problem, this paper proposes a novel back-to-back testing framework in which a SVM (support vector machine) classifies them automatically.\",\n    isbn = \"978-3-642-32172-6\"\n}\n\n",
    "abstract": "In back-to-back testing of software, expected outputs (test oracles) are generated from software that is similar to SUT (software under test), and are compared with test outputs from the SUT in order to reveal faults. The advantages of back-to-back testing are that one can automatically perform the creation of expected outputs that is one of the most costly processes in software testing, and one can obtain detailed expected outputs that are not limited to a specific aspect, such as state transitions. However, it is not easy to automatically classify the differences between the test outputs and the expected outputs into two groups, that is, one resulting from failures of the SUT and another resulting from intended functional differences between the SUT and the similar software. The manual classification is too costly and back-to-back testing can hardly be applied unless the functions of the similar software are exactly equal to the intended functions of the SUT. To solve this costly classification problem, this paper proposes a novel back-to-back testing framework in which a SVM (support vector machine) classifies them automatically."
}, {
    "py/object": "data.DataClassPaper",
    "Title": "Comparative analysis of statistical and machine learning methods for predicting faulty modules",
    "year": 2014,
    "ML_Techniques": "DT, ANN, CCN, SVM, GEP",
    "Category": "Testing",
    "Sub_category": "Defect prediction",
    "Venue": "ASC",
    "Link": "https://www.sciencedirect.com/science/article/abs/pii/S1568494614001392",
    "bibtex": "article{Malhotra2014_81,\n    author = \"Malhotra, Ruchika\",\n    title = \"Comparative analysis of statistical and machine learning methods for predicting faulty modules\",\n    journal = \"Applied Soft Computing\",\n    volume = \"21\",\n    pages = \"286 - 297\",\n    year = \"2014\",\n    issn = \"1568-4946\",\n    doi = \"https://doi.org/10.1016/j.asoc.2014.03.032\",\n    url = \"http://www.sciencedirect.com/science/article/pii/S1568494614001392\",\n    keywords = \"Software quality, Static code metrics, Logistic regression, Machine learning, Receiver Operating Characteristic (ROC) curve\",\n    abstract = \"The demand for development of good quality software has seen rapid growth in the last few years. This is leading to increase in the use of the machine learning methods for analyzing and assessing public domain data sets. These methods can be used in developing models for estimating software quality attributes such as fault proneness, maintenance effort, testing effort. Software fault prediction in the early phases of software development can help and guide software practitioners to focus the available testing resources on the weaker areas during the software development. This paper analyses and compares the statistical and six machine learning methods for fault prediction. These methods (Decision Tree, Artificial Neural Network, Cascade Correlation Network, Support Vector Machine, Group Method of Data Handling Method, and Gene Expression Programming) are empirically validated to find the relationship between the static code metrics and the fault proneness of a module. In order to assess and compare the models predicted using the regression and the machine learning methods we used two publicly available data sets AR1 and AR6. We compared the predictive capability of the models using the Area Under the Curve (measured from the Receiver Operating Characteristic (ROC) analysis). The study confirms the predictive capability of the machine learning methods for software fault prediction. The results show that the Area Under the Curve of model predicted using the Decision Tree method is 0.8 and 0.9 (for AR1 and AR6 data sets, respectively) and is a better model than the model predicted using the logistic regression and other machine learning methods.\"\n}\n\n",
    "abstract": "The demand for development of good quality software has seen rapid growth in the last few years. This is leading to increase in the use of the machine learning methods for analyzing and assessing public domain data sets. These methods can be used in developing models for estimating software quality attributes such as fault proneness, maintenance effort, testing effort. Software fault prediction in the early phases of software development can help and guide software practitioners to focus the available testing resources on the weaker areas during the software development. This paper analyses and compares the statistical and six machine learning methods for fault prediction. These methods (Decision Tree, Artificial Neural Network, Cascade Correlation Network, Support Vector Machine, Group Method of Data Handling Method, and Gene Expression Programming) are empirically validated to find the relationship between the static code metrics and the fault proneness of a module. In order to assess and compare the models predicted using the regression and the machine learning methods we used two publicly available data sets AR1 and AR6. We compared the predictive capability of the models using the Area Under the Curve (measured from the Receiver Operating Characteristic (ROC) analysis). The study confirms the predictive capability of the machine learning methods for software fault prediction. The results show that the Area Under the Curve of model predicted using the Decision Tree method is 0.8 and 0.9 (for AR1 and AR6 data sets, respectively) and is a better model than the model predicted using the logistic regression and other machine learning methods."
}, {
    "py/object": "data.DataClassPaper",
    "Title": "Cross-Project Software Fault Prediction Using Data Leveraging Technique to Improve Software Quality",
    "year": 2020,
    "ML_Techniques": "LLR",
    "Category": "Testing",
    "Sub_category": "Defect prediction",
    "Venue": "EASE",
    "Link": "https://dl.acm.org/doi/10.1145/3383219.3383281",
    "bibtex": "inproceedings{Khan2020_82,\n    author = \"Khan, Bilal and Iqbal, Danish and Badshah, Sher\",\n    title = \"Cross-Project Software Fault Prediction Using Data Leveraging Technique to Improve Software Quality\",\n    year = \"2020\",\n    isbn = \"9781450377317\",\n    publisher = \"Association for Computing Machinery\",\n    address = \"New York, NY, USA\",\n    url = \"https://doi.org/10.1145/3383219.3383281\",\n    doi = \"10.1145/3383219.3383281\",\n    abstract = \"Software fault prediction is a process to detect bugs in software projects. Fault prediction in software engineering has attracted much attention from the last decade. The early prognostication of faults in software minimize the cost and effort of errors that come at later stages. Different machine learning techniques have been utilized for fault prediction, that is proven to be utilizable. Despite, the significance of fault prediction most of the companies do not consider fault prediction in practice and do not build useful models due to lack of data or lack of enough data to strengthen the power of fault predictors. However, models trained and tested on less amount of data are difficult to generalize, because they do not consider project size, project differences, and features selection. To overcome these issues, we proposed an instance-based transfer learning through data leveraging using logistic linear regression as a base proposed statistical methodology. In our study, we considered three software projects within the same domain. Finally, we performed a comparative analysis of three different experiments for building models (targeted project). The experimental results of the proposed approach show promising improvements in (SFP).\",\n    booktitle = \"Proceedings of the Evaluation and Assessment in Software Engineering\",\n    pages = \"434\u2013438\",\n    numpages = \"5\",\n    keywords = \"Instance-based learning, Software Quality, data leveraging, Cross-project, Software fault prediction, Machine learning\",\n    location = \"Trondheim, Norway\",\n    series = \"EASE '20\"\n}\n\n",
    "abstract": "Software fault prediction is a process to detect bugs in software projects. Fault prediction in software engineering has attracted much attention from the last decade. The early prognostication of faults in software minimize the cost and effort of errors that come at later stages. Different machine learning techniques have been utilized for fault prediction, that is proven to be utilizable. Despite, the significance of fault prediction most of the companies do not consider fault prediction in practice and do not build useful models due to lack of data or lack of enough data to strengthen the power of fault predictors. However, models trained and tested on less amount of data are difficult to generalize, because they do not consider project size, project differences, and features selection. To overcome these issues, we proposed an instance-based transfer learning through data leveraging using logistic linear regression as a base proposed statistical methodology. In our study, we considered three software projects within the same domain. Finally, we performed a comparative analysis of three different experiments for building models (targeted project). The experimental results of the proposed approach show promising improvements in (SFP)."
}, {
    "py/object": "data.DataClassPaper",
    "Title": "Deep Learning for Software Defect Prediction: A Survey",
    "year": 2020,
    "ML_Techniques": "",
    "Category": "Testing",
    "Sub_category": "Defect prediction",
    "Venue": "ICSE",
    "Link": "https://dl.acm.org/doi/10.1145/3387940.3391463",
    "bibtex": "inproceedings{Omri2020_83,\n    author = \"Omri, Safa and Sinz, Carsten\",\n    title = \"Deep Learning for Software Defect Prediction: A Survey\",\n    year = \"2020\",\n    isbn = \"9781450379632\",\n    publisher = \"Association for Computing Machinery\",\n    address = \"New York, NY, USA\",\n    url = \"https://doi.org/10.1145/3387940.3391463\",\n    doi = \"10.1145/3387940.3391463\",\n    abstract = \"Software fault prediction is an important and beneficial practice for improving software quality and reliability. The ability to predict which components in a large software system are most likely to contain the largest numbers of faults in the next release helps to better manage projects, including early estimation of possible release delays, and affordably guide corrective actions to improve the quality of the software. However, developing robust fault prediction models is a challenging task and many techniques have been proposed in the literature. Traditional software fault prediction studies mainly focus on manually designing features (e.g. complexity metrics), which are input into machine learning classifiers to identify defective code. However, these features often fail to capture the semantic and structural information of programs. Such information is needed for building accurate fault prediction models. In this survey, we discuss various approaches in fault prediction, also explaining how in recent studies deep learning algorithms for fault prediction help to bridge the gap between programs' semantics and fault prediction features and make accurate predictions.\",\n    booktitle = \"Proceedings of the IEEE/ACM 42nd International Conference on Software Engineering Workshops\",\n    pages = \"209\u2013214\",\n    numpages = \"6\",\n    keywords = \"software defect prediction, deep learning, machine learning, software testing, software quality assurance\",\n    location = \"Seoul, Republic of Korea\",\n    series = \"ICSEW'20\"\n}\n\n",
    "abstract": "Software fault prediction is an important and beneficial practice for improving software quality and reliability. The ability to predict which components in a large software system are most likely to contain the largest numbers of faults in the next release helps to better manage projects, including early estimation of possible release delays, and affordably guide corrective actions to improve the quality of the software. However, developing robust fault prediction models is a challenging task and many techniques have been proposed in the literature. Traditional software fault prediction studies mainly focus on manually designing features (e.g. complexity metrics), which are input into machine learning classifiers to identify defective code. However, these features often fail to capture the semantic and structural information of programs. Such information is needed for building accurate fault prediction models. In this survey, we discuss various approaches in fault prediction, also explaining how in recent studies deep learning algorithms for fault prediction help to bridge the gap between programs' semantics and fault prediction features and make accurate predictions."
}, {
    "py/object": "data.DataClassPaper",
    "Title": "DeepBugs: a learning approach to name-based bug detection",
    "year": 2018,
    "ML_Techniques": "Word2Vec",
    "Category": "Testing",
    "Sub_category": "Defect prediction",
    "Venue": "PACMPL",
    "Link": "https://dl.acm.org/doi/10.1145/3276517",
    "bibtex": "inproceedings{Omri2020_83,\n    author = \"Omri, Safa and Sinz, Carsten\",\n    title = \"Deep Learning for Software Defect Prediction: A Survey\",\n    year = \"2020\",\n    isbn = \"9781450379632\",\n    publisher = \"Association for Computing Machinery\",\n    address = \"New York, NY, USA\",\n    url = \"https://doi.org/10.1145/3387940.3391463\",\n    doi = \"10.1145/3387940.3391463\",\n    abstract = \"Software fault prediction is an important and beneficial practice for improving software quality and reliability. The ability to predict which components in a large software system are most likely to contain the largest numbers of faults in the next release helps to better manage projects, including early estimation of possible release delays, and affordably guide corrective actions to improve the quality of the software. However, developing robust fault prediction models is a challenging task and many techniques have been proposed in the literature. Traditional software fault prediction studies mainly focus on manually designing features (e.g. complexity metrics), which are input into machine learning classifiers to identify defective code. However, these features often fail to capture the semantic and structural information of programs. Such information is needed for building accurate fault prediction models. In this survey, we discuss various approaches in fault prediction, also explaining how in recent studies deep learning algorithms for fault prediction help to bridge the gap between programs' semantics and fault prediction features and make accurate predictions.\",\n    booktitle = \"Proceedings of the IEEE/ACM 42nd International Conference on Software Engineering Workshops\",\n    pages = \"209\u2013214\",\n    numpages = \"6\",\n    keywords = \"software defect prediction, deep learning, machine learning, software testing, software quality assurance\",\n    location = \"Seoul, Republic of Korea\",\n    series = \"ICSEW'20\"\n}\n\n",
    "abstract": "Natural language elements in source code, e.g., the names of variables and functions, convey useful information. However, most existing bug detection tools ignore this information and therefore miss some classes of bugs. The few existing name-based bug detection approaches reason about names on a syntactic level and rely on manually designed and tuned algorithms to detect bugs. This paper presents DeepBugs, a learning approach to name-based bug detection, which reasons about names based on a semantic representation and which automatically learns bug detectors instead of manually writing them. We formulate bug detection as a binary classification problem and train a classifier that distinguishes correct from incorrect code. To address the challenge that effectively learning a bug detector requires examples of both correct and incorrect code, we create likely incorrect code examples from an existing corpus of code through simple code transformations. A novel insight learned from our work is that learning from artificially seeded bugs yields bug detectors that are effective at finding bugs in real-world code. We implement our idea into a framework for learning-based and name-based bug detection. Three bug detectors built on top of the framework detect accidentally swapped function arguments, incorrect binary operators, and incorrect operands in binary operations. Applying the approach to a corpus of 150,000 JavaScript files yields bug detectors that have a high accuracy (between 89% and 95%), are very efficient (less than 20 milliseconds per analyzed file), and reveal 102 programming mistakes (with 68% true positive rate) in real-world code."
}, {
    "py/object": "data.DataClassPaper",
    "Title": "DeepFuzz: Automatic Generation of Syntax Valid C Programs for Fuzz Testing",
    "year": 2019,
    "ML_Techniques": "Seq2Seq",
    "Category": "Testing",
    "Sub_category": "Fuzzing",
    "Venue": "AAAI",
    "Link": "https://faculty.ist.psu.edu/wu/papers/DeepFuzz.pdf",
    "bibtex": "article{Liu2019_85,\n    author = \"Liu, Xiao and Li, Xiaoting and Prajapati, Rupesh and Wu, Dinghao\",\n    title = \"DeepFuzz: Automatic Generation of Syntax Valid C Programs for Fuzz Testing\",\n    volume = \"33\",\n    url = \"https://ojs.aaai.org/index.php/AAAI/article/view/3895\",\n    DOI = \"10.1609/aaai.v33i01.33011044\",\n    number = \"01\",\n    journal = \"Proceedings of the AAAI Conference on Artificial Intelligence\",\n    year = \"2019\",\n    month = \"Jul.\",\n    pages = \"1044-1051\"\n}\n\n",
    "abstract": "Compilers are among the most fundamental programming tools for building software. However, production compilers remain buggy. Fuzz testing is often leveraged with newlygenerated, or mutated inputs in order to find new bugs or security vulnerabilities. In this paper, we propose a grammarbased fuzzing tool called DEEPFUZZ. Based on a generative Sequence-to-Sequence model, DEEPFUZZ automatically and continuously generates well-formed C programs. We use this set of new C programs to fuzz off-the-shelf C compilers, e.g., GCC and Clang/LLVM. We present a detailed case study to analyze the success rate and coverage improvement of the generated C programs for fuzz testing. We analyze the performance of DEEPFUZZ with three types of sampling methods as well as three types of generation strategies. Consequently, DEEPFUZZ improved the testing efficacy in regards to the line, function, and branch coverage. In our preliminary study, we found and reported 8 bugs of GCC, all of which are actively being addressed by developers."
}, {
    "py/object": "data.DataClassPaper",
    "Title": "Determining Software Inter-Dependency Patterns for Integration Testing by applying Machine learning on Logs and Telemetry data",
    "year": 2020,
    "ML_Techniques": "",
    "Category": "Testing",
    "Sub_category": "",
    "Venue": "ICRITO",
    "Link": "https://ieeexplore.ieee.org/document/9197868",
    "bibtex": "INPROCEEDINGS{Rajaraman2020_86,\n    author = \"{Rajaraman}, R. and {Kapur}, P. K. and {Kumar}, D.\",\n    booktitle = \"2020 8th International Conference on Reliability, Infocom Technologies and Optimization (Trends and Future Directions) (ICRITO)\",\n    title = \"Determining Software Inter-Dependency Patterns for Integration Testing by applying Machine learning on Logs and Telemetry data\",\n    year = \"2020\",\n    volume = \"\",\n    number = \"\",\n    pages = \"1080-1084\",\n    doi = \"10.1109/ICRITO48877.2020.9197868\"\n}\n\n",
    "abstract": "Businesses running software applications are moving more towards vendor-agnostic approaches. Integration testing becoming more demanding and complex than ever. Determining integration testing requires a solid dependency pattern among different software applications. We would like to use here an NLP (Natural language processing) & Machine learning Classification model-based approach to identify the dependency graph between different component across applications. There are existing approaches eliciting about package dependencies and source code-based dependencies. In this paper, we would like to introduce an approach to understand the communication dependencies between products rather than just high-level package or install dependencies. The communication dependencies will be prioritized based on the frequency and criticality of usage. The prioritization helps us in determining the software inter-dependency patterns for Integration testing."
}, {
    "py/object": "data.DataClassPaper",
    "Title": "Empirical Assessment of Machine Learning based Software Defect Prediction Techniques",
    "year": 2008,
    "ML_Techniques": "LR, PR, SVR, NNC, SVLR, NND, LOG, NB",
    "Category": "Testing",
    "Sub_category": "Defect prediction",
    "Venue": "IJAIT",
    "Link": "https://www.worldscientific.com/doi/abs/10.1142/S0218213008003947",
    "bibtex": "INPROCEEDINGS{Rajaraman2020_86,\n    author = \"{Rajaraman}, R. and {Kapur}, P. K. and {Kumar}, D.\",\n    booktitle = \"2020 8th International Conference on Reliability, Infocom Technologies and Optimization (Trends and Future Directions) (ICRITO)\",\n    title = \"Determining Software Inter-Dependency Patterns for Integration Testing by applying Machine learning on Logs and Telemetry data\",\n    year = \"2020\",\n    volume = \"\",\n    number = \"\",\n    pages = \"1080-1084\",\n    doi = \"10.1109/ICRITO48877.2020.9197868\"\n}\n\n",
    "abstract": "The wide-variety of real-time software systems, including telecontrol/telepresence systems, robotic systems, and mission planning systems, can entail dynamic code synthesis based on runtime mission-specific requirements and operating conditions. This necessitates the need for dynamic dependability assessment to ensure that these systems perform as specified and not fail in catastrophic ways. One approach in achieving this is to dynamically assess the modules in the synthesized code using software defect prediction techniques. Statistical models; such as stepwise multi-linear regression models and multivariate models, and machine learning approaches, such as artificial neural networks, instance-based reasoning, Bayesian-belief networks, decision trees, and rule inductions, have been investigated for predicting software quality. However, there is still no consensus about the best predictor model for software defects. In this paper; we evaluate different predictor models on four different real-time software defect data sets. The results show that a combination of IR and instance-based learning along with the consistency-based subset evaluation technique provides a relatively better consistency in accuracy prediction compared to other models. The results also show that \"size\" and \"complexity\" metrics are not sufficient for accurately predicting real-time software defects."
}, {
    "py/object": "data.DataClassPaper",
    "Title": "Empirical comparison of machine learning algorithms for bug prediction in open source software",
    "year": 2017,
    "ML_Techniques": "SLP, MLP, ANN, SOM, AIS",
    "Category": "Testing",
    "Sub_category": "Defect prediction",
    "Venue": "ICBDAC",
    "Link": "https://ieeexplore.ieee.org/document/8070806",
    "bibtex": "INPROCEEDINGS{Malhotra2017_88,\n    author = \"{Malhotra}, R. and {Bahl}, L. and {Sehgal}, S. and {Priya}, P.\",\n    booktitle = \"2017 International Conference on Big Data Analytics and Computational Intelligence (ICBDAC)\",\n    title = \"Empirical comparison of machine learning algorithms for bug prediction in open source software\",\n    year = \"2017\",\n    volume = \"\",\n    number = \"\",\n    pages = \"40-45\",\n    doi = \"10.1109/ICBDACI.2017.8070806\"\n}\n\n",
    "abstract": "Bug tracking and analysis truly remains one of the most active areas of software engineering research. Bug tracking results may be employed by the software practitioners of large software projects effectively. The cost of detecting and correcting the defect becomes exponentially higher as we go from requirement analysis to the maintenance phase, where defects might even lead to loss of lives. Software metrics in conjunction with defect data can serve as basis for developing predictive models. Open source projects which encompass contributions from millions of people provide capacious dataset for testing. There have been diverse machine learning techniques proposed in the literature for analyzing complex relationships and extracting useful information from problems using optimal resources and time. However, more extensive research comparing these techniques is needed to establish superiority of one technique over another. This study aims at comparison of 14 ML techniques for development of effective defect prediction models. The issues addressed are 1) Construction of automated tool in Java to collect OO, inheritance and other metrics and detect bugs in classes extracted from open source repository, 2) Use of relevant performance measures to evaluate performance of predictive models to detect bugs in classes, 3) Statistical tests to compare predictive capability of different machine learning techniques, 4) Validation of defect prediction models. The results of the study show that Single Layer Perceptron is the best technique amongst all the techniques used in this study for development of defect prediction models. The conclusions drawn from this study can be used for practical applications by software practitioners to determine best technique for defect prediction and consequently carry out effective allocation of resources."
}, {
    "py/object": "data.DataClassPaper",
    "Title": "Feasibility of Machine Learning Algorithm for Test Partitioning",
    "year": 2019,
    "ML_Techniques": "SA, SVM",
    "Category": "Testing",
    "Sub_category": "",
    "Venue": "ITC-CSCC",
    "Link": "https://ieeexplore.ieee.org/document/8793328",
    "bibtex": "INPROCEEDINGS{Wang2019_89,\n    author = \"{Wang}, S. and {Al-Awadhi}, H. T. and {Aohagi}, M. and {Higami}, Y. and {Takahashi}, H.\",\n    booktitle = \"2019 34th International Technical Conference on Circuits/Systems, Computers and Communications (ITC-CSCC)\",\n    title = \"Feasibility of Machine Learning Algorithm for Test Partitioning\",\n    year = \"2019\",\n    volume = \"\",\n    number = \"\",\n    pages = \"1-4\",\n    doi = \"10.1109/ITC-CSCC.2019.8793328\"\n}\n\n",
    "abstract": "When a system is in idle/starting-up state, Field-Testing is a promising way to guarantee the reliability of an advanced system. However, the extremely limited test application time obstructs the implementation of field test. In this paper, we introduce a test pattern partitioning approach by using two well-known machine learning algorithms: Simulated Annealing (SA) and Support Vector Machines (SVM), to derive an optimal solution for pattern partitioning that minimizes the test latency for high reliability. From the experimental results on benchmark circuit we show that both SA and SVM based method can significantly improve the test latency of partition test, and SVM is much more efficient than SA. Those results confirm the feasibility of machine learning algorithm for the pattern partition problem."
}, {
    "py/object": "data.DataClassPaper",
    "Title": "Generating Test Input with Deep Reinforcement Learning",
    "year": 2018,
    "ML_Techniques": "DDQN",
    "Category": "Testing",
    "Sub_category": "Test data/case generation",
    "Venue": "SBST",
    "Link": "https://ieeexplore.ieee.org/document/8452812",
    "bibtex": "INPROCEEDINGS{Kim2018_90,\n    author = \"{Kim}, J. and {Kwon}, M. and {Yoo}, S.\",\n    booktitle = \"2018 IEEE/ACM 11th International Workshop on Search-Based Software Testing (SBST)\",\n    title = \"Generating Test Input with Deep Reinforcement Learning\",\n    year = \"2018\",\n    volume = \"\",\n    number = \"\",\n    pages = \"51-58\",\n    doi = \"\"\n}\n\n",
    "abstract": "Test data generation is a tedious and laborious process. Search-based Software Testing (SBST) automatically generates test data optimising structural test criteria using metaheuristic algorithms. In essence, metaheuristic algorithms are systematic trial-and-error based on the feedback of fitness function. This is similar to an agent of reinforcement learning which iteratively decides an action based on the current state to maximise the cumulative reward. Inspired by this analogy, this paper investigates the feasibility of employing reinforcement learning in SBST to replace human designed metaheuristic algorithms. We reformulate the software under test (SUT) as an environment of reinforcement learning. At the same time, we present GunPowder, a novel framework for SBST which extends SUT to the environment. We train a Double Deep Q-Networks (DDQN) agent with deep neural network and evaluate the effectiveness of our approach by conducting a small empirical study. Finally, we find that agents can learn metaheuristic algorithms for SBST, achieving 100% branch coverage for training functions. Our study sheds light on the future integration of deep neural network and SBST."
}, {
    "py/object": "data.DataClassPaper",
    "Title": "How high will it be? Using machine learning models to predict branch coverage in automated testing",
    "year": 2018,
    "ML_Techniques": "LR, SVR, MLP",
    "Category": "Testing",
    "Sub_category": "Test data/case generation",
    "Venue": "MaLTeSQuE",
    "Link": "https://ieeexplore.ieee.org/abstract/document/8368454",
    "bibtex": "INPROCEEDINGS{Grano2018_91,\n    author = \"{Grano}, G. and {Titov}, T. V. and {Panichella}, S. and {Gall}, H. C.\",\n    booktitle = \"2018 IEEE Workshop on Machine Learning Techniques for Software Quality Evaluation (MaLTeSQuE)\",\n    title = \"How high will it be? Using machine learning models to predict branch coverage in automated testing\",\n    year = \"2018\",\n    volume = \"\",\n    number = \"\",\n    pages = \"19-24\",\n    doi = \"10.1109/MALTESQUE.2018.8368454\"\n}\n\n",
    "abstract": "Software testing is a crucial component in modern continuous integration development environment. Ideally, at every commit, all the system's test cases should be executed and moreover, new test cases should be generated for the new code. This is especially true in a Continuous Test Generation (CTG) environment, where the automatic generation of test cases is integrated into the continuous integration pipeline. Furthermore, developers want to achieve a minimum level of coverage for every build of their systems. Since both executing all the test cases and generating new ones for all the classes at every commit is not feasible, they have to select which subset of classes has to be tested. In this context, knowing a priori the branch coverage that can be achieved with test data generation tools might give some useful indications for answering such a question. In this paper, we take the first steps towards the definition of machine learning models to predict the branch coverage achieved by test data generation tools. We conduct a preliminary study considering well known code metrics as a features. Despite the simplicity of these features, our results show that using machine learning to predict branch coverage in automated testing is a viable and feasible option."
}, {
    "py/object": "data.DataClassPaper",
    "Title": "Identifying and Generating Missing Tests using Machine Learning on Execution Traces",
    "year": 2020,
    "ML_Techniques": "RF, AB, KNN, NB, SVC, LOG",
    "Category": "Testing",
    "Sub_category": "Test data/case generation",
    "Venue": "AITest",
    "Link": "https://ieeexplore.ieee.org/document/9176745",
    "bibtex": "INPROCEEDINGS{Utting2020_92,\n    author = \"{Utting}, M. and {Legeard}, B. and {Dadeau}, F. and {Tamagnan}, F. and {Bouquet}, F.\",\n    booktitle = \"2020 IEEE International Conference On Artificial Intelligence Testing (AITest)\",\n    title = \"Identifying and Generating Missing Tests using Machine Learning on Execution Traces\",\n    year = \"2020\",\n    volume = \"\",\n    number = \"\",\n    pages = \"83-90\",\n    doi = \"10.1109/AITEST49225.2020.00020\"\n}\n\n",
    "abstract": "Testing IT systems has become a major bottleneck for many companies. Besides the growing complexity of such systems, shorter release cycles and increasing quality requirements have led to increased verification and validation costs. However, analysis of existing testing procedures reveals that not all artifacts are exploited to tame this cost increase. In particular, customer traces are usually ignored by validation engineers. In this paper, we use machine learning from execution traces (both customer traces and test execution traces) to identify test needs and to generate new tests in the context of web services and API testing. Log files of customer traces are split into smaller traces (user sessions) then encoded into Pandas DataFrames for data analysis and machine learning. Clustering algorithms are used to analyse the customer traces and compare them with existing system tests, and machine learning models are used to generate missing tests in the desired clusters. The tool-set is implemented in an open-source library called Agilkia."
}, {
    "py/object": "data.DataClassPaper",
    "Title": "Improved approach for software defect prediction using artificial neural networks",
    "year": 2016,
    "ML_Techniques": "ANN, FL",
    "Category": "Testing",
    "Sub_category": "Defect prediction",
    "Venue": "ICRITO",
    "Link": "https://ieeexplore.ieee.org/document/7785003",
    "bibtex": "INPROCEEDINGS{Sethi2016_93,\n    author = \"{Sethi}, T. and {Gagandeep}\",\n    booktitle = \"2016 5th International Conference on Reliability, Infocom Technologies and Optimization (Trends and Future Directions) (ICRITO)\",\n    title = \"Improved approach for software defect prediction using artificial neural networks\",\n    year = \"2016\",\n    volume = \"\",\n    number = \"\",\n    pages = \"480-485\",\n    doi = \"10.1109/ICRITO.2016.7785003\"\n}\n\n",
    "abstract": "Software defect prediction (SDP) is a most dynamic research area in software engineering. SDP is a process used to predict the deformities in the software. To identifying the defects before the arrival of item or aimed the software improvement, to make software dependable, defect prediction model is utilized. It is always desirable to predict the defects at early stages of life cycle. Hence to predict the defects before testing the SDP is done at end of each phase of SDLC. It helps to reduce the cost as well as time. To produce high quality software, the artificial neural network approach is applied to predict the defect. Nine metrics are applied to the multiple phases of SDLC and twenty genuine software projects are used. The software project data were collected from a team of organization and their responses were recorded in linguistic terms. For assessment of model the mean magnitude of relative error (MMRE) and balanced mean magnitude of relative error (BMMRE) measures are used. In this research work, the implementation of neural network based software defect prediction is compared with the results of fuzzy logic basic approach. In the proposed approach, it is found that the neural network based training model is providing better and effective results on multiple parameters.\n"
}, {
    "py/object": "data.DataClassPaper",
    "Title": "Improvement in Software Defect Prediction Outcome Using Principal Component Analysis and Ensemble Machine Learning Algorithms",
    "year": 2019,
    "ML_Techniques": "RF, AB, B",
    "Category": "Testing",
    "Sub_category": "Defect prediction",
    "Venue": "ICICI",
    "Link": "https://link.springer.com/chapter/10.1007/978-3-030-03146-6_44",
    "bibtex": "InProceedings{Dhamayanthi2019_94,\n    author = \"Dhamayanthi, N. and Lavanya, B.\",\n    editor = \"Hemanth, Jude and Fernando, Xavier and Lafata, Pavel and Baig, Zubair\",\n    title = \"Improvement in Software Defect Prediction Outcome Using Principal Component Analysis and Ensemble Machine Learning Algorithms\",\n    booktitle = \"International Conference on Intelligent Data Communication Technologies and Internet of Things (ICICI) 2018\",\n    year = \"2019\",\n    publisher = \"Springer International Publishing\",\n    address = \"Cham\",\n    pages = \"397--406\",\n    abstract = \"Improving customer experience is the focus of IT Industry. It is no longer about customer satisfaction, but it is about creating memorable experiences which will help build loyal customers. Hence it is extremely critical to release defect free software. While machine learning techniques were widely used for prediction modelling, creating a reliable predictor which can perform satisfactorily is always a challenge. In this paper, we have proposed a framework using PCA for feature selection and ensemble machine learning algorithms with stratified 10-fold cross validation for building the classification model. The proposed model is tested using 5 projects from NASA Metrics Data program and 4 ensemble machine learning algorithms. Our results show that the prediction accuracy is improved by 0.6{\\\\%} when the reduced dataset is used for classification than using the whole dataset. In comparison with previous research studies, our framework has shown an average of 4.2{\\\\%} increase in performance.\",\n    isbn = \"978-3-030-03146-6\"\n}\n\n",
    "abstract": "Improving customer experience is the focus of IT Industry. It is no longer about customer satisfaction, but it is about creating memorable experiences which will help build loyal customers. Hence it is extremely critical to release defect free software. While machine learning techniques were widely used for prediction modelling, creating a reliable predictor which can perform satisfactorily is always a challenge. In this paper, we have proposed a framework using PCA for feature selection and ensemble machine learning algorithms with stratified 10-fold cross validation for building the classification model. The proposed model is tested using 5 projects from NASA Metrics Data program and 4 ensemble machine learning algorithms. Our results show that the prediction accuracy is improved by 0.6% when the reduced dataset is used for classification than using the whole dataset. In comparison with previous research studies, our framework has shown an average of 4.2% increase in performance."
}, {
    "py/object": "data.DataClassPaper",
    "Title": "Improving bug detection and fixing via code representation learning",
    "year": 2020,
    "ML_Techniques": "CNN, RNN",
    "Category": "Testing",
    "Sub_category": "Program repair",
    "Venue": "ICSE",
    "Link": "https://dl.acm.org/doi/10.1145/3377812.3382172",
    "bibtex": "InProceedings{Dhamayanthi2019_94,\n    author = \"Dhamayanthi, N. and Lavanya, B.\",\n    editor = \"Hemanth, Jude and Fernando, Xavier and Lafata, Pavel and Baig, Zubair\",\n    title = \"Improvement in Software Defect Prediction Outcome Using Principal Component Analysis and Ensemble Machine Learning Algorithms\",\n    booktitle = \"International Conference on Intelligent Data Communication Technologies and Internet of Things (ICICI) 2018\",\n    year = \"2019\",\n    publisher = \"Springer International Publishing\",\n    address = \"Cham\",\n    pages = \"397--406\",\n    abstract = \"Improving customer experience is the focus of IT Industry. It is no longer about customer satisfaction, but it is about creating memorable experiences which will help build loyal customers. Hence it is extremely critical to release defect free software. While machine learning techniques were widely used for prediction modelling, creating a reliable predictor which can perform satisfactorily is always a challenge. In this paper, we have proposed a framework using PCA for feature selection and ensemble machine learning algorithms with stratified 10-fold cross validation for building the classification model. The proposed model is tested using 5 projects from NASA Metrics Data program and 4 ensemble machine learning algorithms. Our results show that the prediction accuracy is improved by 0.6{\\\\%} when the reduced dataset is used for classification than using the whole dataset. In comparison with previous research studies, our framework has shown an average of 4.2{\\\\%} increase in performance.\",\n    isbn = \"978-3-030-03146-6\"\n}\n\n",
    "abstract": "The software quality and reliability have been proved to be important during the program development. There are many existing studies trying to help improve it on bug detection and automated program repair processes. However, each of them has its own limitation and the overall performance still have some improvement space. In this paper, we proposed a deep learning framework to improve the software quality and reliability on these two detect-fix processes. We used advanced code modeling and AI models to have some improvements on the state-of-the-art approaches. The evaluation results show that our approach can have a relative improvement up to 206% in terms of F-1 score when comparing with baselines on bug detection and can have a relative improvement up to 19.8 times on the correct bug-fixing amount when comparing with baselines on automated program repair. These results can prove that our framework can have an outstanding performance on improving software quality and reliability in bug detection and automated program repair processes."
}, {
    "py/object": "data.DataClassPaper",
    "Title": "Improving bug detection via context-based code representation learning and attention-based neural networks",
    "year": 2019,
    "ML_Techniques": " Node2Vec",
    "Category": "Testing",
    "Sub_category": "Defect prediction",
    "Venue": "PACMPL",
    "Link": "https://dl.acm.org/doi/10.1145/3360588",
    "bibtex": "InProceedings{Dhamayanthi2019_94,\n    author = \"Dhamayanthi, N. and Lavanya, B.\",\n    editor = \"Hemanth, Jude and Fernando, Xavier and Lafata, Pavel and Baig, Zubair\",\n    title = \"Improvement in Software Defect Prediction Outcome Using Principal Component Analysis and Ensemble Machine Learning Algorithms\",\n    booktitle = \"International Conference on Intelligent Data Communication Technologies and Internet of Things (ICICI) 2018\",\n    year = \"2019\",\n    publisher = \"Springer International Publishing\",\n    address = \"Cham\",\n    pages = \"397--406\",\n    abstract = \"Improving customer experience is the focus of IT Industry. It is no longer about customer satisfaction, but it is about creating memorable experiences which will help build loyal customers. Hence it is extremely critical to release defect free software. While machine learning techniques were widely used for prediction modelling, creating a reliable predictor which can perform satisfactorily is always a challenge. In this paper, we have proposed a framework using PCA for feature selection and ensemble machine learning algorithms with stratified 10-fold cross validation for building the classification model. The proposed model is tested using 5 projects from NASA Metrics Data program and 4 ensemble machine learning algorithms. Our results show that the prediction accuracy is improved by 0.6{\\\\%} when the reduced dataset is used for classification than using the whole dataset. In comparison with previous research studies, our framework has shown an average of 4.2{\\\\%} increase in performance.\",\n    isbn = \"978-3-030-03146-6\"\n}\n\n",
    "abstract": "Bug detection has been shown to be an effective way to help developers in detecting bugs early, thus, saving much effort and time in software development process. Recently, deep learning-based bug detection approaches have gained successes over the traditional machine learning-based approaches, the rule-based program analysis approaches, and mining-based approaches. However, they are still limited in detecting bugs that involve multiple methods and suffer high rate of false positives. In this paper, we propose a combination approach with the use of contexts and attention neural network to overcome those limitations. We propose to use as the global context the Program Dependence Graph (PDG) and Data Flow Graph (DFG) to connect the method under investigation with the other relevant methods that might contribute to the buggy code. The global context is complemented by the local context extracted from the path on the AST built from the method\u2019s body. The use of PDG and DFG enables our model to reduce the false positive rate, while to complement for the potential reduction in recall, we make use of the attention neural network mechanism to put more weights on the buggy paths in the source code. That is, the paths that are similar to the buggy paths will be ranked higher, thus, improving the recall of our model. We have conducted several experiments to evaluate our approach on a very large dataset with +4.973M methods in 92 different project versions. The results show that our tool can have a relative improvement up to 160% on F-score when comparing with the state-of-the-art bug detection approaches. Our tool can detect 48 true bugs in the list of top 100 reported bugs, which is 24 more true bugs when comparing with the baseline approaches. We also reported that our representation is better suitable for bug detection and relatively improves over the other representations up to 206% in accuracy."
}, {
    "py/object": "data.DataClassPaper",
    "Title": "Integration Testing of Components Guided by Incremental State Machine Learning",
    "year": 2006,
    "ML_Techniques": "",
    "Category": "Testing",
    "Sub_category": "Test data/case generation",
    "Venue": "TAIC PART",
    "Link": "https://ieeexplore.ieee.org/abstract/document/1691670",
    "bibtex": "INPROCEEDINGS{KeqinLi2006_97,\n    author = \"{Keqin Li} and {Groz}, R. and {Shahbaz}, M.\",\n    booktitle = \"Testing: Academic Industrial Conference - Practice And Research Techniques (TAIC PART'06)\",\n    title = \"Integration Testing of Components Guided by Incremental State Machine Learning\",\n    year = \"2006\",\n    volume = \"\",\n    number = \"\",\n    pages = \"59-70\",\n    doi = \"10.1109/TAIC-PART.2006.15\"\n}\n\n",
    "abstract": "The design of complex systems, e.g., telecom services, is nowadays usually based on the integration of components (COTS), loosely coupled in distributed architectures. When components come from third party sources, their internal structure is usually unknown and the documentation is insufficient. Therefore, the system integrator faces the problem of providing a required system assembling COTS whose behaviour is barely specified and for which no model is usually available. In this paper, we address the problem of integration testing of COTS. It combines test generation techniques with machine learning algorithms. State-based models of components are built from observed behaviours. The models are alternatively used to generate tests and extended to take into account observed behaviour. This process is iterated until a satisfactory level of confidence in testing is achieved"
}, {
    "py/object": "data.DataClassPaper",
    "Title": "Investigating the Accuracy of Test Code Size Prediction using Use Case Metrics and Machine Learning Algorithms: An Empirical Study",
    "year": 2017,
    "ML_Techniques": "LR, KNN, NB, RF, MLP",
    "Category": "Testing",
    "Sub_category": ",Effort prediction",
    "Venue": "ICMLSC",
    "Link": "https://dl.acm.org/doi/10.1145/3036290.3036323",
    "bibtex": "INPROCEEDINGS{KeqinLi2006_97,\n    author = \"{Keqin Li} and {Groz}, R. and {Shahbaz}, M.\",\n    booktitle = \"Testing: Academic Industrial Conference - Practice And Research Techniques (TAIC PART'06)\",\n    title = \"Integration Testing of Components Guided by Incremental State Machine Learning\",\n    year = \"2006\",\n    volume = \"\",\n    number = \"\",\n    pages = \"59-70\",\n    doi = \"10.1109/TAIC-PART.2006.15\"\n}\n\n",
    "abstract": "Software testing plays a crucial role in software quality assurance. It is, however, a time and resource consuming process. It is, therefore, important to predict as soon as possible the effort required to test software, so that activities can be planned and resources can be optimally allocated. Test code size, in terms of Test Lines Of Code (TLOC), is an important testing effort indicator used in many empirical studies. In this paper, we investigate empirically the early prediction of TLOC for object-oriented software using use case metrics. We used different machine learning algorithms (linear regression, k-NN, Na\u00efve Bayes, C4.5, Random Forest, and Multilayer Perceptron) to build the prediction models. We performed an empirical study using data collected from five Java projects. The use case metrics have been compared to the well-known Use Case Points (UCP) method. Results show that the use case metrics-based approach gives a more accurate prediction of TLOC than the UCP method."
}, {
    "py/object": "data.DataClassPaper",
    "Title": "Learn&Fuzz: Machine learning for input fuzzing",
    "year": 2017,
    "ML_Techniques": "LSTM",
    "Category": "Testing",
    "Sub_category": "Fuzzing",
    "Venue": "ASE",
    "Link": "https://ieeexplore.ieee.org/abstract/document/8115618",
    "bibtex": "INPROCEEDINGS{KeqinLi2006_97,\n    author = \"{Keqin Li} and {Groz}, R. and {Shahbaz}, M.\",\n    booktitle = \"Testing: Academic Industrial Conference - Practice And Research Techniques (TAIC PART'06)\",\n    title = \"Integration Testing of Components Guided by Incremental State Machine Learning\",\n    year = \"2006\",\n    volume = \"\",\n    number = \"\",\n    pages = \"59-70\",\n    doi = \"10.1109/TAIC-PART.2006.15\"\n}\n\n",
    "abstract": "Fuzzing consists of repeatedly testing an application with modified, or fuzzed, inputs with the goal of finding security vulnerabilities in input-parsing code. In this paper, we show how to automate the generation of an input grammar suitable for input fuzzing using sample inputs and neural-network-based statistical machine-learning techniques. We present a detailed case study with a complex input format, namely PDF, and a large complex security-critical parser for this format, namely, the PDF parser embedded in Microsoft's new Edge browser. We discuss and measure the tension between conflicting learning and fuzzing goals: learning wants to capture the structure of well-formed inputs, while fuzzing wants to break that structure in order to cover unexpected code paths and find bugs. We also present a new algorithm for this learn&fuzz challenge which uses a learnt input probability distribution to intelligently guide where to fuzz inputs."
}, {
    "py/object": "data.DataClassPaper",
    "Title": "Lessons learned from using a deep tree-based model for software defect prediction in practice",
    "year": 2019,
    "ML_Techniques": "LTSM",
    "Category": "Testing",
    "Sub_category": "Defect prediction",
    "Venue": "MSR",
    "Link": "https://dl.acm.org/doi/10.1109/MSR.2019.00017",
    "bibtex": "INPROCEEDINGS{KeqinLi2006_97,\n    author = \"{Keqin Li} and {Groz}, R. and {Shahbaz}, M.\",\n    booktitle = \"Testing: Academic Industrial Conference - Practice And Research Techniques (TAIC PART'06)\",\n    title = \"Integration Testing of Components Guided by Incremental State Machine Learning\",\n    year = \"2006\",\n    volume = \"\",\n    number = \"\",\n    pages = \"59-70\",\n    doi = \"10.1109/TAIC-PART.2006.15\"\n}\n\n",
    "abstract": "Defects are common in software systems and cause many problems for software users. Different methods have been developed to make early prediction about the most likely defective modules in large codebases. Most focus on designing features (e.g. complexity metrics) that correlate with potentially defective code. Those approaches however do not sufficiently capture the syntax and multiple levels of semantics of source code, a potentially important capability for building accurate prediction models. In this paper, we report on our experience of deploying a new deep learning tree-based defect prediction model in practice. This model is built upon the tree-structured Long Short Term Memory network which directly matches with the Abstract Syntax Tree representation of source code. We discuss a number of lessons learned from developing the model and evaluating it on two datasets, one from open source projects contributed by our industry partner Samsung and the other from the public PROMISE repository."
}, {
    "py/object": "data.DataClassPaper",
    "Title": "Leveraging mutants for automatic prediction of metamorphic relations using machine learning",
    "year": 2019,
    "ML_Techniques": "SVM",
    "Category": "Testing",
    "Sub_category": ",Test data/case generation",
    "Venue": "MaLTeSQuE",
    "Link": "https://dl.acm.org/doi/abs/10.1145/3340482.3342741",
    "bibtex": "INPROCEEDINGS{KeqinLi2006_97,\n    author = \"{Keqin Li} and {Groz}, R. and {Shahbaz}, M.\",\n    booktitle = \"Testing: Academic Industrial Conference - Practice And Research Techniques (TAIC PART'06)\",\n    title = \"Integration Testing of Components Guided by Incremental State Machine Learning\",\n    year = \"2006\",\n    volume = \"\",\n    number = \"\",\n    pages = \"59-70\",\n    doi = \"10.1109/TAIC-PART.2006.15\"\n}\n\n",
    "abstract": "An oracle is used in software testing to derive the verdict (pass/fail) for a test case. Lack of precise test oracles is one of the major problems in software testing which can hinder judgements about quality. Metamorphic testing is an emerging technique which solves both the oracle problem and the test case generation problem by testing special forms of software requirements known as metamorphic requirements. However, manually deriving the metamorphic requirements for a given program requires a high level of domain expertise, is labor intensive and error prone. As an alternative, we consider the problem of automatic detection of metamorphic requirements using machine learning (ML). For this problem we can apply graph kernels and support vector machines (SVM). A significant problem for any ML approach is to obtain a large labeled training set of data (in this case programs) that generalises well. The main contribution of this paper is a general method to generate large volumes of synthetic training data which can improve ML assisted detection of metamorphic requirements. For training data synthesis we adopt mutation testing techniques. This research is the first to explore the area of data augmentation techniques for ML-based analysis of software code. We also have the goal to enhance black-box testing using white-box methodologies. Our results show that the mutants incorporated into the source code corpus not only efficiently scale the dataset size, but they can also improve the accuracy of classification models."
}, {
    "py/object": "data.DataClassPaper",
    "Title": "LSTM-based deep learning for spatial\u2013temporal software testing",
    "year": 2020,
    "ML_Techniques": "LSTM",
    "Category": "Testing",
    "Sub_category": ",Defect prediction",
    "Venue": "DPD",
    "Link": "https://link.springer.com/article/10.1007/s10619-020-07291-1",
    "bibtex": "article{Xiao2020_102,\n    author = \"Xiao, L. and Miao, HuaiKou and Shi, Tingting and Hong, Y.\",\n    title = \"LSTM-based deep learning for spatial\u2013temporal software testing\",\n    journal = \"Distributed and Parallel Databases\",\n    year = \"2020\",\n    pages = \"1-26\"\n}\n\n",
    "abstract": "Continuous integration (CI) software development practice has become more and more popular. Regression testing occurs very frequently in CI. Test case suites constantly change since new test cases are inserted and obsolete test case are removed in each cycle. The software developer hunts for quick-feedback of faults because of time constraint. An embedded software usually includes the spatial\u2013temporal data in CI. The efficiency of regression testing for the embedded software is related to the space\u2013time. To achieve ideal regression testing goals for the embedded software in CI, this paper proposes a novel test case prioritization approach using LSTM-Based (Long short-term memory) deep learning. LSTM is a time series prediction model. It can predict the probability of each test case detection fault in the next cycle according to the testing history information of all the previous CI cycles. The priority of test case can be obtained dynamically under the guidance of the probability. The experiments are conducted on two industrial data sets. The results verify that compared with some exiting test case prioritization approaches, our approach has better performance for embedded software as follows: (1) improve the prioritization effectiveness, (2) increase the fault detection rate in CI environment, and (3) decrease the testing execution time through automatic reduction the obsolete test cases.\n"
}, {
    "py/object": "data.DataClassPaper",
    "Title": "Machine Learning Applied to Software Testing: A Systematic Mapping Study",
    "year": 2019,
    "ML_Techniques": "",
    "Category": "Testing",
    "Sub_category": ",Test data/case generation",
    "Venue": "T-RL",
    "Link": "https://ieeexplore.ieee.org/abstract/document/8638573",
    "bibtex": "ARTICLE{Durelli2019_103,\n    author = \"{Durelli}, V. H. S. and {Durelli}, R. S. and {Borges}, S. S. and {Endo}, A. T. and {Eler}, M. M. and {Dias}, D. R. C. and {Guimar\u00e3es}, M. P.\",\n    journal = \"IEEE Transactions on Reliability\",\n    title = \"Machine Learning Applied to Software Testing: A Systematic Mapping Study\",\n    year = \"2019\",\n    volume = \"68\",\n    number = \"3\",\n    pages = \"1189-1212\",\n    doi = \"10.1109/TR.2019.2892517\"\n}\n\n",
    "abstract": "Software testing involves probing into the behavior of software systems to uncover faults. Most testing activities are complex and costly, so a practical strategy that has been adopted to circumvent these issues is to automate software testing. There has been a growing interest in applying machine learning (ML) to automate various software engineering activities, including testing-related ones. In this paper, we set out to review the state-of-the art of how ML has been explored to automate and streamline software testing and provide an overview of the research at the intersection of these two fields by conducting a systematic mapping study. We selected 48 primary studies. These selected studies were then categorized according to study type, testing activity, and ML algorithm employed to automate the testing activity. The results highlight the most widely used ML algorithms and identify several avenues for future research. We found that ML algorithms have been used mainly for test-case generation, refinement, and evaluation. Also, ML has been used to evaluate test oracle construction and to predict the cost of testing-related activities. The results of this paper outline the ML algorithms that are most commonly used to automate software-testing activities, helping researchers to understand the current state of research concerning ML applied to software testing. We also found that there is a need for better empirical studies examining how ML algorithms have been used to automate software-testing activities."
}, {
    "py/object": "data.DataClassPaper",
    "Title": "MACHINE LEARNING BASED METAMORPHIC TESTING FOR SOFTWARE QUALITY ASSESSMENT",
    "year": 2020,
    "ML_Techniques": "NB",
    "Category": "Testing",
    "Sub_category": ",Defect prediction,Test data/case generation,,Defect prediction",
    "Venue": "IJOR",
    "Link": "https://www.researchgate.net/publication/338867153_MACHINE_LEARNING_BASED_METAMORPHIC_TESTING_FOR_SOFTWARE_QUALITY_ASSESSMENT",
    "bibtex": "article{A.2020_104,\n    author = \"A., Josephine and Rao, Manjunatha Rao\",\n    year = \"2020\",\n    month = \"01\",\n    pages = \"\",\n    title = \"MACHINE LEARNING BASED METAMORPHIC TESTING FOR SOFTWARE QUALITY ASSESSMENT\",\n    journal = \"International Journal of Operational Research\"\n}\n\n",
    "abstract": "A software quality assessment is a disciplined examination of the software processes used by an organization, based on a process model. Metamorphic testing is used to verify the functional correctness of software in the absence of an ideal oracle. The ability to automatically detect failures and anomalies using MRs becomes difficult task in the day to day developing area. In this paper, the machine learning algorithm is introduced to automatically detect failures and anomalies using MRs can also provide hints for the construction of run-time self-correction mechanisms. The Naive bayes classification algorithm is used to improve the detection failures and anomalies to improve the self correction in the search engine results. The proposed technique acquires improved precision and recall when compared to conventional methods."
}, {
    "py/object": "data.DataClassPaper",
    "Title": "Machine learning based software fault prediction utilizing source code metrics",
    "year": 2018,
    "ML_Techniques": "DT, RF, NB, SVM, ANN, AB",
    "Category": "Testing",
    "Sub_category": "Defect prediction",
    "Venue": "ICCCS",
    "Link": "https://ieeexplore.ieee.org/document/8586805",
    "bibtex": "INPROCEEDINGS{Bhandari2018_105,\n    author = \"{Bhandari}, G. P. and {Gupta}, R.\",\n    booktitle = \"2018 IEEE 3rd International Conference on Computing, Communication and Security (ICCCS)\",\n    title = \"Machine learning based software fault prediction utilizing source code metrics\",\n    year = \"2018\",\n    volume = \"\",\n    number = \"\",\n    pages = \"40-45\",\n    doi = \"10.1109/CCCS.2018.8586805\"\n}\n\n",
    "abstract": "In the conventional techniques, it requires prior knowledge of faults or a special structure, which may not be realistic in practice while detecting the software faults. To deal with this problem, in this work, the proposed approach aims to predict the faults of the software utilizing the source code metrics. In addition, the purpose of this paper is to measure the capability of the software fault predictability in terms of accuracy, f-measure, precision, recall, Area Under ROC (Receiver Operating Characteristic) Curve (AUC). The study investigates the effect of the feature selection techniques for software fault prediction. As an experimental analysis, our proposed approach is validated from four publicly available datasets. The result predicted from Random Forest technique outperforms the other machine learning techniques in most of the cases. The effect of the feature selection techniques has increased the performance in few cases, however, in the maximum cases it is negligible or even the worse."
}, {
    "py/object": "data.DataClassPaper",
    "Title": "Machine learning for finding bugs: An initial report",
    "year": 2017,
    "ML_Techniques": "RF, RNN",
    "Category": "Testing",
    "Sub_category": ",Defect prediction",
    "Venue": "MaLTeSQuE",
    "Link": "https://ieeexplore.ieee.org/abstract/document/7882012",
    "bibtex": "INPROCEEDINGS{Chappelly2017_107,\n    author = \"{Chappelly}, T. and {Cifuentes}, C. and {Krishnan}, P. and {Gevay}, S.\",\n    booktitle = \"2017 IEEE Workshop on Machine Learning Techniques for Software Quality Evaluation (MaLTeSQuE)\",\n    title = \"Machine learning for finding bugs: An initial report\",\n    year = \"2017\",\n    volume = \"\",\n    number = \"\",\n    pages = \"21-26\",\n    doi = \"10.1109/MALTESQUE.2017.7882012\"\n}\n\n",
    "abstract": "Static program analysis is a technique to analyse code without executing it, and can be used to find bugs in source code. Many open source and commercial tools have been developed in this space over the past 20 years. Scalability and precision are of importance for the deployment of static code analysis tools - numerous false positives and slow runtime both make the tool hard to be used by development, where integration into a nightly build is the standard goal. This requires one to identify a suitable abstraction for the static analysis which is typically a manual process and can be expensive. In this paper we report our findings on using machine learning techniques to detect defects in C programs. We use three offthe- shelf machine learning techniques and use a large corpus of programs available for use in both the training and evaluation of the results. We compare the results produced by the machine learning technique against the Parfait static program analysis tool used internally at Oracle by thousands of developers. While on the surface the initial results were encouraging, further investigation suggests that the machine learning techniques we used are not suitable replacements for static program analysis tools due to low precision of the results. This could be due to a variety of reasons including not using domain knowledge such as the semantics of the programming language and lack of suitable data used in the training process."
}, {
    "py/object": "data.DataClassPaper",
    "Title": "Machine Learning in Value-Based Software Test Data Generation",
    "year": 2006,
    "ML_Techniques": "",
    "Category": "Testing",
    "Sub_category": "Test data/case generation",
    "Venue": "ICTAI",
    "Link": "https://ieeexplore.ieee.org/abstract/document/4031966",
    "bibtex": "INPROCEEDINGS{Zhang2006_108,\n    author = \"{Zhang}, D.\",\n    booktitle = \"2006 18th IEEE International Conference on Tools with Artificial Intelligence (ICTAI'06)\",\n    title = \"Machine Learning in Value-Based Software Test Data Generation\",\n    year = \"2006\",\n    volume = \"\",\n    number = \"\",\n    pages = \"732-736\",\n    doi = \"10.1109/ICTAI.2006.77\"\n}\n\n",
    "abstract": "Software engineering research and practice thus far are primarily conducted in a value-neutral setting where each artifact in software development such as requirement, use case, test case, and defect, is treated as equally important during a software system development process. There are a number of shortcomings of such value-neutral software engineering. Value-based software engineering is to integrate value considerations into the full range of existing and emerging software engineering principles and practices. Machine learning has been playing an increasingly important role in helping develop and maintain large and complex software systems. However, machine learning applications to software engineering have been largely confined to the value-neutral software engineering setting. In this paper, we advocate a shift to applying machine learning methods to value-based software engineering. We propose a framework for value-based software test data generation. The proposed framework incorporates some general principles in value-based software testing and can help improve return on investment"
}, {
    "py/object": "data.DataClassPaper",
    "Title": "Machine Learning Methods and Asymmetric Cost Function to Estimate Execution Effort of Software Testing",
    "year": 2010,
    "ML_Techniques": "ANN, SVM, LR, MLP",
    "Category": "Testing",
    "Sub_category": "Effort prediction",
    "Venue": "ICST",
    "Link": "https://ieeexplore.ieee.org/abstract/document/5477077",
    "bibtex": "INPROCEEDINGS{Silva2010_109,\n    author = \"e. {Silva}, D. G. and {Jino}, M. and d. {Abreu}, B. T.\",\n    booktitle = \"2010 Third International Conference on Software Testing, Verification and Validation\",\n    title = \"Machine Learning Methods and Asymmetric Cost Function to Estimate Execution Effort of Software Testing\",\n    year = \"2010\",\n    volume = \"\",\n    number = \"\",\n    pages = \"275-284\",\n    doi = \"10.1109/ICST.2010.46\"\n}\n\n",
    "abstract": "Planning and scheduling of testing activities play an important role for any independent test team that performs tests for different software systems, developed by different development teams. This work studies the application of machine learning tools and variable selection tools to solve the problem of estimating the execution effort of functional tests. An analysis of the test execution process is developed and experiments are performed on two real databases. The main contributions of this paper are the approach of selecting the significant variables for database synthesis and the use of an artificial neural network trained with an asymmetric cost function."
}, {
    "py/object": "data.DataClassPaper",
    "Title": "Machine Learning-based Software Testing: Towards a Classification Framework",
    "year": 2011,
    "ML_Techniques": "",
    "Category": "Testing",
    "Sub_category": ",Defect prediction",
    "Venue": "SEKE",
    "Link": "https://www.ee.ryerson.ca/~bagheri/papers/seke11.pdf",
    "bibtex": "inproceedings{Noorian2011_110,\n    author = \"Noorian, Mahdi and Bagheri, Ebrahim and Du, Wheichang\",\n    year = \"2011\",\n    month = \"01\",\n    pages = \"225-229\",\n    title = \"Machine Learning-based Software Testing: Towards a Classification Framework.\",\n    journal = \"SEKE 2011 - Proceedings of the 23rd International Conference on Software Engineering and Knowledge Engineering\"\n}\n\n",
    "abstract": "Software Testing (ST) processes attempt lo verify and validate the capability of a software system to meet Its required attributes and functionality. As software systems become more complex, the need for automated software testing methods emerges. Machine learning (ML) techniques have shown to be quite useful for this automation process. Various works have been presented In the Junction of ML and ST areas. The lack of general guidelines for applying appropriate learning methods for software testing purposes Is our major motivation In the current paper, in this paper, we Introduce a classification framework which can help to systematically review research work In the ML and ST domains. The proposed framework dimensions are defined using major characteristics of existing software testing and machine learning methods. Our framework am be used to effectively construct a concrete set of guidelines for choosing the most appropriate learning method and applying It to a distinct stage of the software testing life-cycle for automation purposes."
}, {
    "py/object": "data.DataClassPaper",
    "Title": "Near optimal machine learning based random test generation",
    "year": 2010,
    "ML_Techniques": "",
    "Category": "Testing",
    "Sub_category": "Test data/case generation",
    "Venue": "EWDTS",
    "Link": "https://ieeexplore.ieee.org/document/5742082",
    "bibtex": "INPROCEEDINGS{Shakeri2010_111,\n    author = \"{Shakeri}, N. and {Nemati}, N. and {Ahmadabadi}, M. N. and {Navabi}, Z.\",\n    booktitle = \"2010 East-West Design Test Symposium (EWDTS)\",\n    title = \"Near optimal machine learning based random test generation\",\n    year = \"2010\",\n    volume = \"\",\n    number = \"\",\n    pages = \"420-424\",\n    doi = \"10.1109/EWDTS.2010.5742082\"\n}\n\n",
    "abstract": "Optimized test generation techniques are required to overcome the ever increasing test cost of digital systems. In this work a near optimal machine learning based approach is proposed to improve the random test generation techniques. The improvements of the proposed method over previous works are exercised in an HDL environment and results for ISCAS benchmarks are reported."
}, {
    "py/object": "data.DataClassPaper",
    "Title": "Novel Applications of Machine Learning in Software Testing",
    "year": 2008,
    "ML_Techniques": "",
    "Category": "Testing",
    "Sub_category": "",
    "Venue": "SWQD",
    "Link": "https://ieeexplore.ieee.org/abstract/document/4601522",
    "bibtex": "INPROCEEDINGS{Briand2008_113,\n    author = \"{Briand}, L. C.\",\n    booktitle = \"2008 The Eighth International Conference on Quality Software\",\n    title = \"Novel Applications of Machine Learning in Software Testing\",\n    year = \"2008\",\n    volume = \"\",\n    number = \"\",\n    pages = \"3-10\",\n    doi = \"10.1109/QSIC.2008.29\"\n}\n\n",
    "abstract": "Machine learning techniques have long been used for various purposes in software engineering. This paper provides a brief overview of the state of the art and reports on a number of novel applications I was involved with in the area of software testing. Reflecting on this personal experience, I draw lessons learned and argue that more research should be performed in that direction as machine learning has the potential to significantly help in addressing some of the long-standing software testing problems."
}, {
    "py/object": "data.DataClassPaper",
    "Title": "On the Applicability of Machine LearningTechniques for Object Oriented SoftwareFault Prediction",
    "year": 2011,
    "ML_Techniques": "ANN, LB, RF, B, AB, NB, KS, LR",
    "Category": "Testing",
    "Sub_category": ",Defect prediction",
    "Venue": "SEIJ",
    "Link": "http://seij.dtu.ac.in/Paper%202.pdf",
    "bibtex": "INPROCEEDINGS{Briand2008_113,\n    author = \"{Briand}, L. C.\",\n    booktitle = \"2008 The Eighth International Conference on Quality Software\",\n    title = \"Novel Applications of Machine Learning in Software Testing\",\n    year = \"2008\",\n    volume = \"\",\n    number = \"\",\n    pages = \"3-10\",\n    doi = \"10.1109/QSIC.2008.29\"\n}\n\n",
    "abstract": "Software testing is a critical and essential part of software development that consumes maximum resources and effort. The construction of models to predict faulty classes can help and guide the testing community in predicting faulty classes in early phases of software development. It is important to analyze and compare the predictive accuracy of machine learning classifiers. The aim of this paper is to find the relation of object oriented metrics and fault proneness of a class. We have used seven machine learning and one logistic regression method in order to predict faulty classes. The results of our work are based on data set obtained from open source software. The results show that the predictive accuracy of machine learning technique LogitBoost is highest with AUC of 0.806."
}, {
    "py/object": "data.DataClassPaper",
    "Title": "Optimizing testing efforts based on change proneness through machine learning techniques",
    "year": 2014,
    "ML_Techniques": "LR, BN, NB, DT, RF, AB, B, KS",
    "Category": "Testing",
    "Sub_category": "Effort prediction",
    "Venue": "PIICON",
    "Link": "https://ieeexplore.ieee.org/document/7117742",
    "bibtex": "INPROCEEDINGS{Tripathi2014_115,\n    author = \"{Tripathi}, A. K. and {Sharma}, K.\",\n    booktitle = \"2014 6th IEEE Power India International Conference (PIICON)\",\n    title = \"Optimizing testing efforts based on change proneness through machine learning techniques\",\n    year = \"2014\",\n    volume = \"\",\n    number = \"\",\n    pages = \"1-4\",\n    doi = \"10.1109/POWERI.2014.7117742\"\n}\n\n",
    "abstract": "For any software organization, understanding the software quality is desirable in order to increase user experience of the software. When we talk about security software this factor becomes even more important. This paper aims to develop models for predicting the change proneness for object oriented system. The developed models may be used to predict the change prone classes at early phase of software development. Rigorous testing and allocation of some extra resources to those change prone classes may lead to better quality and it may also reduce our work at the maintenance phase. We apply one statistical and 10 machine learning techniques to predict the models. The results are analyzed from Receiver Operating Characteristics (ROC) analysis using Area under the Curve (AUC) obtained from ROC. Adaboost and Random forest method have shown the best result and hence, based on these results we can claim that quality models have a good relevance with Object Oriented systems."
}, {
    "py/object": "data.DataClassPaper",
    "Title": "PathPair2Vec: An AST path pair-based code representation method for defect prediction",
    "year": 2020,
    "ML_Techniques": "LSTM",
    "Category": "Testing",
    "Sub_category": "Defect prediction",
    "Venue": "COLA",
    "Link": "https://www.sciencedirect.com/science/article/pii/S2590118420300393",
    "bibtex": "article{Shi2020_116,\n    author = \"Shi, Ke and Lu, Yang and Chang, Jingfei and Wei, Zhen\",\n    title = \"PathPair2Vec: An AST path pair-based code representation method for defect prediction\",\n    journal = \"Journal of Computer Languages\",\n    volume = \"59\",\n    pages = \"100979\",\n    year = \"2020\",\n    issn = \"2590-1184\",\n    doi = \"https://doi.org/10.1016/j.cola.2020.100979\",\n    url = \"http://www.sciencedirect.com/science/article/pii/S2590118420300393\",\n    keywords = \"Defect prediction, AST path, Deep learning, Representation learning\",\n    abstract = \"Software project defect prediction (SDP) can predict the bug probability of software by their features and allocate their testing efforts. The existing software defect prediction methods can be divided into two categories: methods based on traditional handcrafted features and methods based on automatically made abstract features, especially those made by deep learning. The current research indicates that deep learning-based automatic features can achieve better performance than handcrafted features. Code2vec (Alon et al. 2019) is one of the best source code representation models, which leverages deep learning to learn automatic representations from code. In this paper, inspired by code2vec, we propose a new AST path pair-based source code representation method (PathPair2Vec) and apply it to software project defect prediction. We first propose the concept of the short path to describe each terminal node and its control logic. Then, we design a new sequence encoding method to code the different parts of the terminal node and its control logic. Finally, by pairs of short paths, we describe the semantic information of code and fuse them by an attention mechanism. Experiments on the PROMISE dataset show that our method improves the F1 score by 17.88\\% over the state-of-the-art SDP method, and the AST path pair-based source code representation can better identify the defect features of the source code.\"\n}\n\n",
    "abstract": "Software project defect prediction (SDP) can predict the bug probability of software by their features and allocate their testing efforts. The existing software defect prediction methods can be divided into two categories: methods based on traditional handcrafted features and methods based on automatically made abstract features, especially those made by deep learning. The current research indicates that deep learning-based automatic features can achieve better performance than handcrafted features.\n\nCode2vec (Alon et al. 2019) is one of the best source code representation models, which leverages deep learning to learn automatic representations from code. In this paper, inspired by code2vec, we propose a new AST path pair-based source code representation method (PathPair2Vec) and apply it to software project defect prediction. We first propose the concept of the short path to describe each terminal node and its control logic. Then, we design a new sequence encoding method to code the different parts of the terminal node and its control logic. Finally, by pairs of short paths, we describe the semantic information of code and fuse them by an attention mechanism. Experiments on the PROMISE dataset show that our method improves the F1 score by 17.88% over the state-of-the-art SDP method, and the AST path pair-based source code representation can better identify the defect features of the source code."
}, {
    "py/object": "data.DataClassPaper",
    "Title": "Predicting buggy changes inside an integrated development environment",
    "year": 2017,
    "ML_Techniques": "SVM",
    "Category": "Testing",
    "Sub_category": "Defect prediction",
    "Venue": "OOPSLA",
    "Link": "https://dl.acm.org/doi/10.1145/1328279.1328287",
    "bibtex": "article{Shi2020_116,\n    author = \"Shi, Ke and Lu, Yang and Chang, Jingfei and Wei, Zhen\",\n    title = \"PathPair2Vec: An AST path pair-based code representation method for defect prediction\",\n    journal = \"Journal of Computer Languages\",\n    volume = \"59\",\n    pages = \"100979\",\n    year = \"2020\",\n    issn = \"2590-1184\",\n    doi = \"https://doi.org/10.1016/j.cola.2020.100979\",\n    url = \"http://www.sciencedirect.com/science/article/pii/S2590118420300393\",\n    keywords = \"Defect prediction, AST path, Deep learning, Representation learning\",\n    abstract = \"Software project defect prediction (SDP) can predict the bug probability of software by their features and allocate their testing efforts. The existing software defect prediction methods can be divided into two categories: methods based on traditional handcrafted features and methods based on automatically made abstract features, especially those made by deep learning. The current research indicates that deep learning-based automatic features can achieve better performance than handcrafted features. Code2vec (Alon et al. 2019) is one of the best source code representation models, which leverages deep learning to learn automatic representations from code. In this paper, inspired by code2vec, we propose a new AST path pair-based source code representation method (PathPair2Vec) and apply it to software project defect prediction. We first propose the concept of the short path to describe each terminal node and its control logic. Then, we design a new sequence encoding method to code the different parts of the terminal node and its control logic. Finally, by pairs of short paths, we describe the semantic information of code and fuse them by an attention mechanism. Experiments on the PROMISE dataset show that our method improves the F1 score by 17.88\\% over the state-of-the-art SDP method, and the AST path pair-based source code representation can better identify the defect features of the source code.\"\n}\n\n",
    "abstract": "We present a tool that predicts whether the software under development inside an IDE has a bug. An IDE plugin performs this prediction, using the Change Classification technique to classify source code changes as buggy or clean during the editing session. Change Classification uses Support Vector Machines (SVM), a machine learning classifier algorithm, to classify changes to projects mined from their configuration management repository. This technique, besides being language independent and relatively accurate, can (a) classify a change immediately upon its completion and (b) use features extracted solely from the change delta (added, deleted) and the source code to predict buggy changes. Thus, integrating change classification within an IDE can predict potential bugs in the software as the developer edits the source code, ideally reducing the amount of time spent on fixing bugs later. To this end, we have developed a Change Classification plugin for Eclipse based on client-server architecture, described in this paper."
}, {
    "py/object": "data.DataClassPaper",
    "Title": "Predicting defect densities in source code files with decision tree learners",
    "year": 2006,
    "ML_Techniques": "DT",
    "Category": "Testing",
    "Sub_category": "Defect prediction",
    "Venue": "MSR",
    "Link": "https://dl.acm.org/doi/10.1145/1137983.1138012",
    "bibtex": "article{Shi2020_116,\n    author = \"Shi, Ke and Lu, Yang and Chang, Jingfei and Wei, Zhen\",\n    title = \"PathPair2Vec: An AST path pair-based code representation method for defect prediction\",\n    journal = \"Journal of Computer Languages\",\n    volume = \"59\",\n    pages = \"100979\",\n    year = \"2020\",\n    issn = \"2590-1184\",\n    doi = \"https://doi.org/10.1016/j.cola.2020.100979\",\n    url = \"http://www.sciencedirect.com/science/article/pii/S2590118420300393\",\n    keywords = \"Defect prediction, AST path, Deep learning, Representation learning\",\n    abstract = \"Software project defect prediction (SDP) can predict the bug probability of software by their features and allocate their testing efforts. The existing software defect prediction methods can be divided into two categories: methods based on traditional handcrafted features and methods based on automatically made abstract features, especially those made by deep learning. The current research indicates that deep learning-based automatic features can achieve better performance than handcrafted features. Code2vec (Alon et al. 2019) is one of the best source code representation models, which leverages deep learning to learn automatic representations from code. In this paper, inspired by code2vec, we propose a new AST path pair-based source code representation method (PathPair2Vec) and apply it to software project defect prediction. We first propose the concept of the short path to describe each terminal node and its control logic. Then, we design a new sequence encoding method to code the different parts of the terminal node and its control logic. Finally, by pairs of short paths, we describe the semantic information of code and fuse them by an attention mechanism. Experiments on the PROMISE dataset show that our method improves the F1 score by 17.88\\% over the state-of-the-art SDP method, and the AST path pair-based source code representation can better identify the defect features of the source code.\"\n}\n\n",
    "abstract": "With the advent of open source software repositories the data available for defect prediction in source files increased tremendously. Although traditional statistics turned out to derive reasonable results the sheer amount of data and the problem context of defect prediction demand sophisticated analysis such as provided by current data mining and machine learning techniques.In this work we focus on defect density prediction and present an approach that applies a decision tree learner on evolution data extracted from the Mozilla open source web browser project. The evolution data includes different source code, modification, and defect measures computed from seven recent Mozilla releases. Among the modification measures we also take into account the change coupling, a measure for the number of change-dependencies between source files. The main reason for choosing decision tree learners, instead of for example neural nets, was the goal of finding underlying rules which can be easily interpreted by humans. To find these rules, we set up a number of experiments to test common hypotheses regarding defects in software entities. Our experiments showed, that a simple tree learner can produce good results with various sets of input data."
}, {
    "py/object": "data.DataClassPaper",
    "Title": "Predicting metamorphic relations for testing scientific software: a machine learning approach using graph kernels",
    "year": 2016,
    "ML_Techniques": "SVM",
    "Category": "Testing",
    "Sub_category": "Defect prediction",
    "Venue": "STVR",
    "Link": "https://onlinelibrary.wiley.com/doi/abs/10.1002/stvr.1594",
    "bibtex": "article{Kanewala2016_120,\n    author = \"Kanewala, Upulee and Bieman, James M. and Ben-Hur, Asa\",\n    title = \"Predicting metamorphic relations for testing scientific software: a machine learning approach using graph kernels\",\n    journal = \"Software Testing, Verification and Reliability\",\n    volume = \"26\",\n    number = \"3\",\n    pages = \"245-269\",\n    keywords = \"metamorphic testing, metamorphic relations, graph kernels, support vector machines\",\n    doi = \"https://doi.org/10.1002/stvr.1594\",\n    url = \"https://onlinelibrary.wiley.com/doi/abs/10.1002/stvr.1594\",\n    eprint = \"https://onlinelibrary.wiley.com/doi/pdf/10.1002/stvr.1594\",\n    abstract = \"Summary Comprehensive, automated software testing requires an oracle to check whether the output produced by a test case matches the expected behaviour of the programme. But the challenges in creating suitable oracles limit the ability to perform automated testing in some programmes, and especially in scientific software. Metamorphic testing is a method for automating the testing process for programmes without test oracles. This technique operates by checking whether the programme behaves according to properties called metamorphic relations. A metamorphic relation describes the change in output when the input is changed in a prescribed way. Unfortunately, finding the metamorphic relations satisfied by a programme or function remains a labour-intensive task, which is generally performed by a domain expert or a programmer. In this work, we propose a machine learning approach for predicting metamorphic relations that uses a graph-based representation of a programme to represent control flow and data dependency information. In earlier work, we found that simple features derived from such graphs provide good performance. An analysis of the features used in this earlier work led us to explore the effectiveness of several representations of those graphs using the machine learning framework of graph kernels, which provide various ways of measuring similarity between graphs. Our results show that a graph kernel that evaluates the contribution of all paths in the graph has the best accuracy and that control flow information is more useful than data dependency information. The data used in this study are available for download at http://www.cs.colostate.edu/saxs/MRpred/functions.tar.gz to help researchers in further development of metamorphic relation prediction methods. Copyright \u00a9 2015 John Wiley \\\\& Sons, Ltd.\",\n    year = \"2016\"\n}\n\n",
    "abstract": "Comprehensive, automated software testing requires an oracle to check whether the output produced by a test case matches the expected behaviour of the programme. But the challenges in creating suitable oracles limit the ability to perform automated testing in some programmes, and especially in scientific software. Metamorphic testing is a method for automating the testing process for programmes without test oracles. This technique operates by checking whether the programme behaves according to properties called metamorphic relations. A metamorphic relation describes the change in output when the input is changed in a prescribed way. Unfortunately, finding the metamorphic relations satisfied by a programme or function remains a labour-intensive task, which is generally performed by a domain expert or a programmer. In this work, we propose a machine learning approach for predicting metamorphic relations that uses a graph-based representation of a programme to represent control flow and data dependency information. In earlier work, we found that simple features derived from such graphs provide good performance. An analysis of the features used in this earlier work led us to explore the effectiveness of several representations of those graphs using the machine learning framework of graph kernels, which provide various ways of measuring similarity between graphs. Our results show that a graph kernel that evaluates the contribution of all paths in the graph has the best accuracy and that control flow information is more useful than data dependency information. The data used in this study are available for download at http://www.cs.colostate.edu/saxs/MRpred/functions.tar.gz to help researchers in further development of metamorphic relation prediction methods. Copyright \u00a9 2015 John Wiley & Sons, Ltd."
}, {
    "py/object": "data.DataClassPaper",
    "Title": "Prediction & Assessment of Change Prone Classes Using Statistical & Machine Learning Techniques.",
    "year": 2017,
    "ML_Techniques": "LR, RF, AB, B, MLP, BN, NB, DT, LB",
    "Category": "Testing",
    "Sub_category": "Defect prediction",
    "Venue": "JIPS",
    "Link": "https://www.researchgate.net/publication/320045176_Prediction_Assessment_of_Change_Prone_Classes_Using_Statistical_Machine_Learning_Techniques",
    "bibtex": "article{Kanewala2016_120,\n    author = \"Kanewala, Upulee and Bieman, James M. and Ben-Hur, Asa\",\n    title = \"Predicting metamorphic relations for testing scientific software: a machine learning approach using graph kernels\",\n    journal = \"Software Testing, Verification and Reliability\",\n    volume = \"26\",\n    number = \"3\",\n    pages = \"245-269\",\n    keywords = \"metamorphic testing, metamorphic relations, graph kernels, support vector machines\",\n    doi = \"https://doi.org/10.1002/stvr.1594\",\n    url = \"https://onlinelibrary.wiley.com/doi/abs/10.1002/stvr.1594\",\n    eprint = \"https://onlinelibrary.wiley.com/doi/pdf/10.1002/stvr.1594\",\n    abstract = \"Summary Comprehensive, automated software testing requires an oracle to check whether the output produced by a test case matches the expected behaviour of the programme. But the challenges in creating suitable oracles limit the ability to perform automated testing in some programmes, and especially in scientific software. Metamorphic testing is a method for automating the testing process for programmes without test oracles. This technique operates by checking whether the programme behaves according to properties called metamorphic relations. A metamorphic relation describes the change in output when the input is changed in a prescribed way. Unfortunately, finding the metamorphic relations satisfied by a programme or function remains a labour-intensive task, which is generally performed by a domain expert or a programmer. In this work, we propose a machine learning approach for predicting metamorphic relations that uses a graph-based representation of a programme to represent control flow and data dependency information. In earlier work, we found that simple features derived from such graphs provide good performance. An analysis of the features used in this earlier work led us to explore the effectiveness of several representations of those graphs using the machine learning framework of graph kernels, which provide various ways of measuring similarity between graphs. Our results show that a graph kernel that evaluates the contribution of all paths in the graph has the best accuracy and that control flow information is more useful than data dependency information. The data used in this study are available for download at http://www.cs.colostate.edu/saxs/MRpred/functions.tar.gz to help researchers in further development of metamorphic relation prediction methods. Copyright \u00a9 2015 John Wiley \\\\& Sons, Ltd.\",\n    year = \"2016\"\n}\n\n",
    "abstract": "Software today has become an inseparable part of our life. In order to achieve the ever demanding needs of customers, it has to rapidly evolve and include a number of changes. In this paper, our aim is to study the relationship of object oriented metrics with change proneness attribute of a class. Prediction models based on this study can help us in identifying change prone classes of a software. We can then focus our efforts on these change prone classes during testing to yield a better quality software. Previously, researchers have used statistical methods for predicting change prone classes. But machine learning methods are rarely used for identification of change prone classes. In our study, we evaluate and compare the performances of ten machine learning methods with the statistical method. This evaluation is based on two open source software systems developed in Java language. We also validated the developed prediction models using other software data set in the same domain (3D modelling). The performance of the predicted models was evaluated using receiver operating characteristic analysis. The results indicate that the machine learning methods are at par with the statistical method for prediction of change prone classes. Another analysis showed that the models constructed for a software can also be used to predict change prone nature of classes of another software in the same domain. This study would help developers in performing effective regression testing at low cost and effort. It will also help the developers to design an effective model that results in less change prone classes, hence better maintenance."
}, {
    "py/object": "data.DataClassPaper",
    "Title": "Sample-based software defect prediction with active and semi-supervised learning",
    "year": 2012,
    "ML_Techniques": "CoForest-RF, DT, LOG, NB",
    "Category": "Testing",
    "Sub_category": "Defect prediction",
    "Venue": "ASE",
    "Link": "https://link.springer.com/article/10.1007/s10515-011-0092-1",
    "bibtex": "article{Li2011_124,\n    author = \"Li, M. and Zhang, H. and Wu, Rongxin and Zhou, Z.\",\n    title = \"Sample-based software defect prediction with active and semi-supervised learning\",\n    journal = \"Automated Software Engineering\",\n    year = \"2011\",\n    volume = \"19\",\n    pages = \"201-230\"\n}\n\n",
    "abstract": "Software defect prediction can help us better understand and control software quality. Current defect prediction techniques are mainly based on a sufficient amount of historical project data. However, historical data is often not available for new projects and for many organizations. In this case, effective defect prediction is difficult to achieve. To address this problem, we propose sample-based methods for software defect prediction. For a large software system, we can select and test a small percentage of modules, and then build a defect prediction model to predict defect-proneness of the rest of the modules. In this paper, we describe three methods for selecting a sample: random sampling with conventional machine learners, random sampling with a semi-supervised learner and active sampling with active semi-supervised learner. To facilitate the active sampling, we propose a novel active semi-supervised learning method ACoForest which is able to sample the modules that are most helpful for learning a good prediction model. Our experiments on PROMISE datasets show that the proposed methods are effective and have potential to be applied to industrial practice."
}, {
    "py/object": "data.DataClassPaper",
    "Title": "Shinobi: A Novel Approach for Context-Driven Testing (CDT) Using Heuristics and Machine Learning for Web Applications",
    "year": 2019,
    "ML_Techniques": "FR-CNN",
    "Category": "Testing",
    "Sub_category": ",Test data/case generation",
    "Venue": "INISCOM",
    "Link": "https://link.springer.com/chapter/10.1007/978-3-030-05873-9_8",
    "bibtex": "InProceedings{Nguyen2019_126,\n    author = \"Nguyen, Duc-Man and Do, Hoang-Nhat and Huynh, Quyet-Thang and Vo, Dinh-Thien and Ha, Nhu-Hang\",\n    editor = \"Duong, Trung Q and Vo, Nguyen-Son\",\n    title = \"Shinobi: A Novel Approach for Context-Driven Testing (CDT) Using Heuristics and Machine Learning for Web Applications\",\n    booktitle = \"Industrial Networks and Intelligent Systems\",\n    year = \"2019\",\n    publisher = \"Springer International Publishing\",\n    address = \"Cham\",\n    pages = \"86--102\",\n    abstract = \"Context-Driven Testing is widely used in the Agile World. It optimizes the testing value and provides an effective way to detect unexpected bugs. Context-driven testing requires the testing team to leverage the full knowledge and skills to solve the problem or to make a decision. In this paper, we propose an approach for Context-Driven Testing using Heuristics and Machine Learning for web applications with a framework called Shinobi. The framework can detect web controls, suggest a set of heuristic values, recognize the meaningful input data, and detect changes of application to recommend test ideas. In the context of improvising the testing performance, Shinobi is considered as Test Assistant for context-driven testers. Shinobi is a PoC to prove the idea of using Machine Learning to develop a Virtual Tester to improve the test quality and train junior testers as responsible testers. The framework is well integrated into all eCommerce projects at MeU Solutions which is a value-added advantage for testing.\",\n    isbn = \"978-3-030-05873-9\"\n}\n\n",
    "abstract": "Context-Driven Testing is widely used in the Agile World. It optimizes the testing value and provides an effective way to detect unexpected bugs. Context-driven testing requires the testing team to leverage the full knowledge and skills to solve the problem or to make a decision. In this paper, we propose an approach for Context-Driven Testing using Heuristics and Machine Learning for web applications with a framework called Shinobi. The framework can detect web controls, suggest a set of heuristic values, recognize the meaningful input data, and detect changes of application to recommend test ideas. In the context of improvising the testing performance, Shinobi is considered as Test Assistant for context-driven testers. Shinobi is a PoC to prove the idea of using Machine Learning to develop a Virtual Tester to improve the test quality and train junior testers as responsible testers. The framework is well integrated into all eCommerce projects at MeU Solutions which is a value-added advantage for testing."
}, {
    "py/object": "data.DataClassPaper",
    "Title": "Software Bug Prediction using Machine Learning Approach",
    "year": 2018,
    "ML_Techniques": "ANN, NB, DT",
    "Category": "Testing",
    "Sub_category": "Defect prediction",
    "Venue": "IJACSA",
    "Link": "https://www.researchgate.net/profile/Mustafa_Hammad/publication/323536716_Software_Bug_Prediction_using_Machine_Learning_Approach/links/5c17cdec92851c39ebf51720/Software-Bug-Prediction-using-Machine-Learning-Approach.pdf",
    "bibtex": "article{Hammouri2018_127,\n    author = \"Hammouri, Awni and Hammad, Mustafa and Alnabhan, Mohammad and Alsarayrah, Fatima\",\n    year = \"2018\",\n    month = \"01\",\n    pages = \"\",\n    title = \"Software Bug Prediction using Machine Learning Approach\",\n    volume = \"9\",\n    journal = \"International Journal of Advanced Computer Science and Applications\",\n    doi = \"10.14569/IJACSA.2018.090212\"\n}\n\n",
    "abstract": "Software Bug Prediction (SBP) is an important\nissue in software development and maintenance processes, which\nconcerns with the overall of software successes. This is because\npredicting the software faults in earlier phase improves the\nsoftware quality, reliability, efficiency and reduces the software\ncost. However, developing robust bug prediction model is a\nchallenging task and many techniques have been proposed in the\nliterature. This paper presents a software bug prediction model\nbased on machine learning (ML) algorithms. Three supervised\nML algorithms have been used to predict future software faults\nbased on historical data. These classifiers are Na\u00efve Bayes (NB),\nDecision Tree (DT) and Artificial Neural Networks (ANNs). The\nevaluation process showed that ML algorithms can be used\neffectively with high accuracy rate. Furthermore, a comparison\nmeasure is applied to compare the proposed prediction model\nwith other approaches. The collected results showed that the ML\napproach has a better performance."
}, {
    "py/object": "data.DataClassPaper",
    "Title": "Software code analysis using ensemble learning techniques",
    "year": 2019,
    "ML_Techniques": "GB, RF, B, V",
    "Category": "Testing",
    "Sub_category": ",Defect prediction",
    "Venue": "AISS",
    "Link": "https://dl.acm.org/doi/10.1145/3373477.3373486",
    "bibtex": "article{Hammouri2018_127,\n    author = \"Hammouri, Awni and Hammad, Mustafa and Alnabhan, Mohammad and Alsarayrah, Fatima\",\n    year = \"2018\",\n    month = \"01\",\n    pages = \"\",\n    title = \"Software Bug Prediction using Machine Learning Approach\",\n    volume = \"9\",\n    journal = \"International Journal of Advanced Computer Science and Applications\",\n    doi = \"10.14569/IJACSA.2018.090212\"\n}\n\n",
    "abstract": "Ensuing the advent of advancements in software systems, the probability of them containing high severity defects is exponentially on the rise. With each technological addition, the complexity of software is increasing. Reproduction and rectification of a defect requires time and effort. Current state of the art analysis tools cater to the investigation of static aspects of a production level code. However, it is imperative to assess the dynamic development process of a system so as to be able to timely detect erroneous components early on in the development life cycle of a software. A novel automated defect prediction feature enhancement is proposed that analyses the static structure of the current code and state of the software in past releases to extract relevant static and dynamic feature sets. Data generated is modelled for defect trends in the future release of the software by four ensemble classifiers. Results demonstrate the superiority of Voting algorithm for the problem of defect prediction.\n"
}, {
    "py/object": "data.DataClassPaper",
    "Title": "Software Defect Identification Using Machine Learning Techniques",
    "year": 2006,
    "ML_Techniques": "DT, MLP",
    "Category": "Testing",
    "Sub_category": ",Defect prediction",
    "Venue": "EUROMICRO",
    "Link": "https://ieeexplore.ieee.org/abstract/document/1690146",
    "bibtex": "INPROCEEDINGS{Ceylan2006_129,\n    author = \"{Ceylan}, E. and {Kutlubay}, F. O. and {Bener}, A. B.\",\n    booktitle = \"32nd EUROMICRO Conference on Software Engineering and Advanced Applications (EUROMICRO'06)\",\n    title = \"Software Defect Identification Using Machine Learning Techniques\",\n    year = \"2006\",\n    volume = \"\",\n    number = \"\",\n    pages = \"240-247\",\n    doi = \"10.1109/EUROMICRO.2006.56\"\n}\n\n",
    "abstract": "Software engineering is a tedious job that includes people, tight deadlines and limited budgets. Delivering what customer wants involves minimizing the defects in the programs. Hence, it is important to establish quality measures early on in the project life cycle. The main objective of this research is to analyze problems in software code and propose a model that will help catching those problems earlier in the project life cycle. Our proposed model uses machine learning methods. Principal component analysis is used for dimensionality reduction, and decision tree, multi layer perceptron and radial basis functions are used for defect prediction. The experiments in this research are carried out with different software metric datasets that are obtained from real-life projects of three big software companies in Turkey. We can say that, the improved method that we proposed brings out satisfactory results in terms of defect prediction"
}, {
    "py/object": "data.DataClassPaper",
    "Title": "Software defect prediction analysis using machine learning algorithms",
    "year": 2017,
    "ML_Techniques": "ANN, PSO, DT, NB, SVM",
    "Category": "Testing",
    "Sub_category": "Defect prediction",
    "Venue": "Confluence",
    "Link": "https://ieeexplore.ieee.org/abstract/document/7943255",
    "bibtex": "INPROCEEDINGS{Singh2017_130,\n    author = \"{Singh}, P. and {Chug}, A.\",\n    booktitle = \"2017 7th International Conference on Cloud Computing, Data Science Engineering - Confluence\",\n    title = \"Software defect prediction analysis using machine learning algorithms\",\n    year = \"2017\",\n    volume = \"\",\n    number = \"\",\n    pages = \"775-781\",\n    doi = \"10.1109/CONFLUENCE.2017.7943255\"\n}\n\n",
    "abstract": "Software Quality is the most important aspect of a software. Software Defect Prediction can directly affect quality and has achieved significant popularity in last few years. Defective software modules have a massive impact over software's quality leading to cost overruns, delayed timelines and much higher maintenance costs. In this paper we have analyzed the most popular and widely used Machine Learning algorithms - ANN (Artificial Neural Network), PSO(P article Swarm Optimization), DT (Decision Trees), NB(Naive Bayes) and LC (Linear classifier). The five algorithms were analyzed using KEEL tool and validated using k-fold cross validation technique. Datasets used in this research were obtained from open source NASA Promise dataset repository. Seven datasets were selected for defect prediction analysis. Classification was performed on these 7 datasets and validated using 10 fold cross validation. The results demonstrated the dominance of Linear Classifier over other algorithms in terms of defect prediction accuracy."
}, {
    "py/object": "data.DataClassPaper",
    "Title": "Software Defect Prediction Using Machine Learning Techniques",
    "year": 2020,
    "ML_Techniques": "NB, ANN, SVM, RF",
    "Category": "Testing",
    "Sub_category": "Defect prediction",
    "Venue": "ICOEI",
    "Link": "https://ieeexplore.ieee.org/document/9142909",
    "bibtex": "INPROCEEDINGS{Prabha2020_133,\n    author = \"{Prabha}, C. L. and {Shivakumar}, N.\",\n    booktitle = \"2020 4th International Conference on Trends in Electronics and Informatics (ICOEI)(48184)\",\n    title = \"Software Defect Prediction Using Machine Learning Techniques\",\n    year = \"2020\",\n    volume = \"\",\n    number = \"\",\n    pages = \"728-733\",\n    doi = \"10.1109/ICOEI48184.2020.9142909\"\n}\n\n",
    "abstract": "Software defect prediction provides development groups with observable outcomes while contributing to industrial results and development faults predicting defective code areas can help developers identify bugs and organize their test activities. The percentage of classification providing the proper prediction is essential for early identification. Moreover, software-defected data sets are supported and at least partially recognized due to their enormous dimension. This Problem is handled by hybridized approach that includes the PCA, randomforest, na\u00efve bayes and the SVM Software Framework, which as five datasets as PC3, MW1, KC1, PC4, and CM1, are listed in software analysis using the weka simulation tool. A systematic research analysis is conducted in which parameters of confusion, precision, recall, recognition accuracy, etc Are measured as well as compared with the prevailing schemes. The analytical analysis indicates that the proposed approach will provide more useful solutions for device defects prediction."
}, {
    "py/object": "data.DataClassPaper",
    "Title": "Software defect prediction using supervised learning algorithm and unsupervised learning algorithm",
    "year": 2013,
    "ML_Techniques": "DT, RF, KM, HC",
    "Category": "Testing",
    "Sub_category": "Defect prediction",
    "Venue": "JSEA",
    "Link": "https://ieeexplore.ieee.org/document/6832328",
    "bibtex": "INPROCEEDINGS{Chug2013_134,\n    author = \"{Chug}, A. and {Dhall}, S.\",\n    booktitle = \"Confluence 2013: The Next Generation Information Technology Summit (4th International Conference)\",\n    title = \"Software defect prediction using supervised learning algorithm and unsupervised learning algorithm\",\n    year = \"2013\",\n    volume = \"\",\n    number = \"\",\n    pages = \"173-179\",\n    doi = \"10.1049/cp.2013.2313\"\n}\n\n",
    "abstract": "Software defect prediction has recently attracted attention of many software quality researchers. One of the major areas in current project management software is to effectively utilize resources to make meaningful impact on time and cost. A pragmatic assessment of metrics is essential in order to comprehend the quality of software and to ensure corrective measures. Software defect prediction methods are majorly used to study the impact areas in software using different techniques which comprises of neural network (NN) techniques, clustering techniques, statistical method and machine learning methods. These techniques of Data mining are applied in building software defect prediction models which improve the software quality. The aim of this paper is to propose various classification and clustering methods with an objective to predict software defect. To predict software defect we analyzed classification and clustering techniques. The performance of three data mining classifier algorithms named J48, Random Forest, and Naive Bayesian Classifier (NBC) are evaluated based on various criteria like ROC, Precision, MAE, RAE etc. Clustering technique is then applied on the data set using k-means, Hierarchical Clustering and Make Density Based Clustering algorithm. Evaluation of results for clustering is based on criteria like Time Taken, Cluster Instance, Number of Iterations, Incorrectly Clustered Instance and Log Likelihood etc. A thorough exploration of ten real time defect datasets of NASA[1] software project, followed by various applications on them finally results in defect prediction."
}, {
    "py/object": "data.DataClassPaper",
    "Title": "Software Defect Prediction via Transformer",
    "year": 2020,
    "ML_Techniques": "LOG, TF",
    "Category": "Testing",
    "Sub_category": "Defect prediction",
    "Venue": "ITNEC",
    "Link": "https://ieeexplore.ieee.org/document/9084745",
    "bibtex": "INPROCEEDINGS{Zhang2020_135,\n    author = \"{Zhang}, Q. and {Wu}, B.\",\n    booktitle = \"2020 IEEE 4th Information Technology, Networking, Electronic and Automation Control Conference (ITNEC)\",\n    title = \"Software Defect Prediction via Transformer\",\n    year = \"2020\",\n    volume = \"1\",\n    number = \"\",\n    pages = \"874-879\",\n    doi = \"10.1109/ITNEC48623.2020.9084745\"\n}\n\n",
    "abstract": "In order to enhance software reliability, software defect prediction is used to predict potential defects and to improve efficiency of software examination. Traditional defect prediction methods mainly focus on design static code metrics, and building machine learning classifiers to predict pieces of code that potentially defective. However, these manual extracted features do not contain syntactic and semantic information of programs. These information is much more important than those metrics and can improve the accuracy of defect prediction. In this paper, we propose a framework called software defect prediction via transformer (DP-Transformer) which capture syntactic and semantic features from programs and use them to improve defect prediction. Specifically, we first parse source code into ASTs and then select representative nodes from ASTs to form token vectors. Then we employ mapping and word embedding to convert token vectors into numerical vectors and send the numerical vectors to transformer. Transformer will automatically extract syntactic and semantic features and eventually feed these features into a Logistic Regression classifier. We evaluate our method on seven open-source Java projects with certain labels and take F-measure as evaluation criteria. The experimental results show that averagely, the proposed DP-Transformer improves the state-of-art method by 8%."
}, {
    "py/object": "data.DataClassPaper",
    "Title": "Software fault classification using extreme learning machine: a cognitive approach",
    "year": 2018,
    "ML_Techniques": "ELM, SVM",
    "Category": "Testing",
    "Sub_category": ",Defect prediction",
    "Venue": "Evolutionary Intelligence",
    "Link": "https://link.springer.com/article/10.1007/s12065-018-0193-x",
    "bibtex": "article{Pandey2018_137,\n    author = \"Pandey, A. K. and Gupta, Manjari\",\n    title = \"Software fault classification using extreme learning machine: a cognitive approach\",\n    journal = \"Evolutionary Intelligence\",\n    year = \"2018\",\n    pages = \"1-8\"\n}\n\n",
    "abstract": "The software fault classification is very crucial in the development of reliable and high-quality software products. The fault classification allows determining and concentrating on fault software modules for early prediction of fault in time. As a result, it saves the time and money of the industry. Generally, various metrics are generated to represent the fault. But, selecting the dominant metrics from the available set is a challenge. Therefore, in this paper, a sequential forward search (SFS) with extreme learning machine (ELM) approach has used for fault classification. The number of features available in the metrics are selected to represent the fault using SFS and operated on ELM to verify the performance of software fault classification. Also, various activation functions of ELM have tested for the proposed work to identify the best model. The experimental result demonstrates that ELM with radial basis function achieves the good results compared to other activation function. Also, the proposed method has shown good results in comparison to support vector machine."
}, {
    "py/object": "data.DataClassPaper",
    "Title": "Software metrics for fault prediction using machine learning approaches: A literature review with PROMISE repository dataset",
    "year": 2017,
    "ML_Techniques": "",
    "Category": "Testing",
    "Sub_category": "Defect prediction",
    "Venue": "CyberneticsCom",
    "Link": "https://ieeexplore.ieee.org/abstract/document/8311708",
    "bibtex": "INPROCEEDINGS{Meiliana2017_138,\n    author = \"{Meiliana} and {Karim}, S. and {Warnars}, H. L. H. S. and {Gaol}, F. L. and {Abdurachman}, E. and {Soewito}, B.\",\n    booktitle = \"2017 IEEE International Conference on Cybernetics and Computational Intelligence (CyberneticsCom)\",\n    title = \"Software metrics for fault prediction using machine learning approaches: A literature review with PROMISE repository dataset\",\n    year = \"2017\",\n    volume = \"\",\n    number = \"\",\n    pages = \"19-23\",\n    doi = \"10.1109/CYBERNETICSCOM.2017.8311708\"\n}\n\n",
    "abstract": "Software testing is an important and critical phase of software development life cycle to find software faults or defects and then correct those faults. However, testing process is a time-consuming activity that requires good planning and a lot of resources. Therefore, technique and methodology for predicting the testing effort is important process prior the testing process to significantly increase efficiency of time, effort and cost usage. Correspond to software metric usage for measuring software quality, software metric can be used to identify the faulty modules in software. Furthermore, implementing machine learning technique will allow computer to \u201clearn\u201d and able to predict the fault prone modules. Research in this field has become a hot issue for more than ten years ago. However, considering the high importance of software quality with support of machine learning methods development, this research area is still being highlighted until this year. In this paper, a survey of various software metric used for predicting software fault by using machine learning algorithm is examined. According to our review, this is the first study of software fault prediction that focuses to PROMISE repository dataset usage. Some conducted experiments from PROMISE repository dataset are compared to contribute a consensus on what constitute effective software metrics and machine learning method in software fault prediction."
}, {
    "py/object": "data.DataClassPaper",
    "Title": "Software visualization and deep transfer learning for effective software defect prediction",
    "year": 2020,
    "ML_Techniques": "CNN",
    "Category": "Testing",
    "Sub_category": "Defect prediction",
    "Venue": "ICSE",
    "Link": "https://dl.acm.org/doi/10.1145/3377811.3380389",
    "bibtex": "INPROCEEDINGS{Meiliana2017_138,\n    author = \"{Meiliana} and {Karim}, S. and {Warnars}, H. L. H. S. and {Gaol}, F. L. and {Abdurachman}, E. and {Soewito}, B.\",\n    booktitle = \"2017 IEEE International Conference on Cybernetics and Computational Intelligence (CyberneticsCom)\",\n    title = \"Software metrics for fault prediction using machine learning approaches: A literature review with PROMISE repository dataset\",\n    year = \"2017\",\n    volume = \"\",\n    number = \"\",\n    pages = \"19-23\",\n    doi = \"10.1109/CYBERNETICSCOM.2017.8311708\"\n}\n\n",
    "abstract": "Software defect prediction aims to automatically locate defective code modules to better focus testing resources and human effort. Typically, software defect prediction pipelines are comprised of two parts: the first extracts program features, like abstract syntax trees, by using external tools, and the second applies machine learning-based classification models to those features in order to predict defective modules. Since such approaches depend on specific feature extraction tools, machine learning classifiers have to be custom-tailored to effectively build most accurate models.\n\nTo bridge the gap between deep learning and defect prediction, we propose an end-to-end framework which can directly get prediction results for programs without utilizing feature-extraction tools. To that end, we first visualize programs as images, apply the self-attention mechanism to extract image features, use transfer learning to reduce the difference in sample distributions between projects, and finally feed the image files into a pre-trained, deep learning model for defect prediction. Experiments with 10 open source projects from the PROMISE dataset show that our method can improve cross-project and within-project defect prediction. Our code and data pointers are available at https://zenodo.org/record/3373409#.XV0Oy5Mza35."
}, {
    "py/object": "data.DataClassPaper",
    "Title": "Structural Statistical Software Testing with Active Learning in a Graph",
    "year": 2008,
    "ML_Techniques": "VSL",
    "Category": "Testing",
    "Sub_category": ",Test data/case generation",
    "Venue": "ILP",
    "Link": "https://link.springer.com/chapter/10.1007/978-3-540-78469-2_9",
    "bibtex": "InProceedings{Baskiotis2008_141,\n    author = \"Baskiotis, Nicolas and Sebag, Michele\",\n    editor = \"Blockeel, Hendrik and Ramon, Jan and Shavlik, Jude and Tadepalli, Prasad\",\n    title = \"Structural Statistical Software Testing with Active Learning in a Graph\",\n    booktitle = \"Inductive Logic Programming\",\n    year = \"2008\",\n    publisher = \"Springer Berlin Heidelberg\",\n    address = \"Berlin, Heidelberg\",\n    pages = \"49--62\",\n    abstract = \"Structural Statistical Software Testing (SSST) exploits the control flow graph of the program being tested to construct test cases. Specifically, SSST exploits the feasible paths in the control flow graph, that is, paths which are actually exerted for some values of the program input; the limitation is that feasible paths are massively outnumbered by infeasible ones. Addressing this limitation, this paper presents an active learning algorithm aimed at sampling the feasible paths in the control flow graph. The difficulty comes from both the few feasible paths initially available and the nature of the feasible path concept, reflecting the long-range dependencies among the nodes of the control flow graph. The proposed approach is based on a frugal representation inspired from Parikh maps, and on the identification of the conjunctive subconcepts in the feasible path concept within a Disjunctive Version Space framework. Experimental validation on real-world and artificial problems demonstrates significant improvements compared to the state of the art.\",\n    isbn = \"978-3-540-78469-2\"\n}\n\n",
    "abstract": "Structural Statistical Software Testing (SSST) exploits the control flow graph of the program being tested to construct test cases. Specifically, SSST exploits the feasible paths in the control flow graph, that is, paths which are actually exerted for some values of the program input; the limitation is that feasible paths are massively outnumbered by infeasible ones. Addressing this limitation, this paper presents an active learning algorithm aimed at sampling the feasible paths in the control flow graph. The difficulty comes from both the few feasible paths initially available and the nature of the feasible path concept, reflecting the long-range dependencies among the nodes of the control flow graph. The proposed approach is based on a frugal representation inspired from Parikh maps, and on the identification of the conjunctive subconcepts in the feasible path concept within a Disjunctive Version Space framework. Experimental validation on real-world and artificial problems demonstrates significant improvements compared to the state of the art."
}, {
    "py/object": "data.DataClassPaper",
    "Title": "The State of Machine Learning Methodology in Software Fault Prediction",
    "year": 2012,
    "ML_Techniques": "",
    "Category": "Testing",
    "Sub_category": "Defect prediction",
    "Venue": "ICMLA",
    "Link": "https://ieeexplore.ieee.org/document/6406713",
    "bibtex": "INPROCEEDINGS{Hall2012_145,\n    author = \"{Hall}, T. and {Bowes}, D.\",\n    booktitle = \"2012 11th International Conference on Machine Learning and Applications\",\n    title = \"The State of Machine Learning Methodology in Software Fault Prediction\",\n    year = \"2012\",\n    volume = \"2\",\n    number = \"\",\n    pages = \"308-313\",\n    doi = \"10.1109/ICMLA.2012.226\"\n}\n\n",
    "abstract": "The aim of this paper is to investigate the quality of methodology in software fault prediction studies using machine learning. Over two hundred studies of fault prediction have been published in the last 10 years. There is evidence to suggest that the quality of methodology used in some of these studies does not allow us to have confidence in the predictions reported by them. We evaluate the machine learning methodology used in 21 fault prediction studies. All of these studies use NASA data sets. We score each study from 1 to 10 in terms of the quality of their machine learning methodology (e.g. whether or not studies report randomising their cross validation folds). Only 10 out of the 21 studies scored 5 or more out of 10. Furthermore 1 study scored only 1 out of 10. When we plot these scores over time there is no evidence that the quality of machine learning methodology is better in recent studies. Our results suggest that there remains much to be done by both researchers and reviewers to improve the quality of machine learning methodology used in software fault prediction. We conclude that the results reported in some studies need to be treated with caution."
}, {
    "py/object": "data.DataClassPaper",
    "Title": "Transfer Learning Code Vectorizer based Machine Learning Models for Software Defect Prediction",
    "year": 2020,
    "ML_Techniques": "SVM, RF, ANN, DT, GNB, LR, CNN",
    "Category": "Testing",
    "Sub_category": "Defect prediction",
    "Venue": "ComPE",
    "Link": "https://ieeexplore.ieee.org/document/9200076",
    "bibtex": "INPROCEEDINGS{Singh2020_146,\n    author = \"{Singh}, R. and {Singh}, J. and {Gill}, M. S. and {Malhotra}, R. and {Garima}\",\n    booktitle = \"2020 International Conference on Computational Performance Evaluation (ComPE)\",\n    title = \"Transfer Learning Code Vectorizer based Machine Learning Models for Software Defect Prediction\",\n    year = \"2020\",\n    volume = \"\",\n    number = \"\",\n    pages = \"497-502\",\n    doi = \"10.1109/ComPE49325.2020.9200076\"\n}\n\n",
    "abstract": "Software development life cycle comprises of planning, design, implementation, testing and eventually, deployment. Software defect prediction can be used in the initial stages of the development life cycle for identifying defective modules. Researchers have devised various methods that can be used for effective software defect prediction. The prediction of the presence of defects or bugs in a software module can facilitate the testing process as it would enable developers and testers to allocate their time and resources on modules that are prone to defects. Transfer learning can be used for transferring knowledge obtained from one domain into the other. In this paper, we propose Transfer Learning Code Vectorizer, a novel method that derives features from the text of the software source code itself and uses those features for defect prediction. We focus on the software code and convert it into vectors using a pre-trained deep learning language model. These code vectors are subsequently passed through machine and deep learning models. Further, we compare the results of using deep learning on the text of the software code versus the usage of software metrics for prediction of defects. In terms of weighted F1 scores, the experiments show that applying the proposed TLCV method outperforms the other machine learning techniques by 9.052%."
}, {
    "py/object": "data.DataClassPaper",
    "Title": "Transfer learning for cross-company software defect prediction",
    "year": 2012,
    "ML_Techniques": "NB, TNB, KNN",
    "Category": "Testing",
    "Sub_category": "Defect prediction",
    "Venue": "IST",
    "Link": "https://www.sciencedirect.com/science/article/abs/pii/S0950584911001996",
    "bibtex": "article{Ma2012_147,\n    author = \"Ma, Ying and Luo, Guangchun and Zeng, Xue and Chen, Aiguo\",\n    title = \"Transfer learning for cross-company software defect prediction\",\n    journal = \"Information and Software Technology\",\n    volume = \"54\",\n    number = \"3\",\n    pages = \"248 - 256\",\n    year = \"2012\",\n    issn = \"0950-5849\",\n    doi = \"https://doi.org/10.1016/j.infsof.2011.09.007\",\n    url = \"http://www.sciencedirect.com/science/article/pii/S0950584911001996\",\n    keywords = \"Machine learning, Software defect prediction, Transfer learning, Naive Bayes, Different distribution\",\n    abstract = \"Context Software defect prediction studies usually built models using within-company data, but very few focused on the prediction models trained with cross-company data. It is difficult to employ these models which are built on the within-company data in practice, because of the lack of these local data repositories. Recently, transfer learning has attracted more and more attention for building classifier in target domain using the data from related source domain. It is very useful in cases when distributions of training and test instances differ, but is it appropriate for cross-company software defect prediction? Objective In this paper, we consider the cross-company defect prediction scenario where source and target data are drawn from different companies. In order to harness cross company data, we try to exploit the transfer learning method to build faster and highly effective prediction model. Method Unlike the prior works selecting training data which are similar from the test data, we proposed a novel algorithm called Transfer Naive Bayes (TNB), by using the information of all the proper features in training data. Our solution estimates the distribution of the test data, and transfers cross-company data information into the weights of the training data. On these weighted data, the defect prediction model is built. Results This article presents a theoretical analysis for the comparative methods, and shows the experiment results on the data sets from different organizations. It indicates that TNB is more accurate in terms of AUC (The area under the receiver operating characteristic curve), within less runtime than the state of the art methods. Conclusion It is concluded that when there are too few local training data to train good classifiers, the useful knowledge from different-distribution training data on feature level may help. We are optimistic that our transfer learning method can guide optimal resource allocation strategies, which may reduce software testing cost and increase effectiveness of software testing process.\"\n}\n\n",
    "abstract": "Context\nSoftware defect prediction studies usually built models using within-company data, but very few focused on the prediction models trained with cross-company data. It is difficult to employ these models which are built on the within-company data in practice, because of the lack of these local data repositories. Recently, transfer learning has attracted more and more attention for building classifier in target domain using the data from related source domain. It is very useful in cases when distributions of training and test instances differ, but is it appropriate for cross-company software defect prediction?\n\nObjective\nIn this paper, we consider the cross-company defect prediction scenario where source and target data are drawn from different companies. In order to harness cross company data, we try to exploit the transfer learning method to build faster and highly effective prediction model.\n\nMethod\nUnlike the prior works selecting training data which are similar from the test data, we proposed a novel algorithm called Transfer Naive Bayes (TNB), by using the information of all the proper features in training data. Our solution estimates the distribution of the test data, and transfers cross-company data information into the weights of the training data. On these weighted data, the defect prediction model is built.\n\nResults\nThis article presents a theoretical analysis for the comparative methods, and shows the experiment results on the data sets from different organizations. It indicates that TNB is more accurate in terms of AUC (The area under the receiver operating characteristic curve), within less runtime than the state of the art methods.\n\nConclusion\nIt is concluded that when there are too few local training data to train good classifiers, the useful knowledge from different-distribution training data on feature level may help. We are optimistic that our transfer learning method can guide optimal resource allocation strategies, which may reduce software testing cost and increase effectiveness of software testing process."
}, {
    "py/object": "data.DataClassPaper",
    "Title": "Understanding machine learning software defect predictions",
    "year": 2020,
    "ML_Techniques": "LR, NB, KNN, SVM, NN, DT, RF ",
    "Category": "Testing",
    "Sub_category": "Defect prediction",
    "Venue": "ASE",
    "Link": "https://link.springer.com/article/10.1007/s10515-020-00277-4",
    "bibtex": "article{Santos2020_148,\n    author = \"dos Santos, Geanderson Esteves and Figueiredo, E. and Veloso, Adriano and Viggiato, Markos and Ziviani, N.\",\n    title = \"Understanding machine learning software defect predictions\",\n    journal = \"Autom. Softw. Eng.\",\n    year = \"2020\",\n    volume = \"27\",\n    pages = \"369-392\"\n}\n\n",
    "abstract": "Software defects are well-known in software development and might cause several problems for users and developers aside. As a result, researches employed distinct techniques to mitigate the impacts of these defects in the source code. One of the most notable techniques focuses on defect prediction using machine learning methods, which could support developers in handling these defects before they are introduced in the production environment. These studies provide alternative approaches to predict the likelihood of defects. However, most of these works concentrate on predicting defects from a vast set of software features. Another key issue with the current literature is the lack of a satisfactory explanation of the reasons that drive the software to a defective state. Specifically, we use a tree boosting algorithm (XGBoost) that receives as input a training set comprising records of easy-to-compute characteristics of each module and outputs whether the corresponding module is defect-prone. To exploit the link between predictive power and model explainability, we propose a simple model sampling approach that finds accurate models with the minimum set of features. Our principal idea is that features not contributing to increasing the predictive power should not be included in the model. Interestingly, the reduced set of features helps to increase model explainability, which is important to provide information to developers on features related to each module of the code which is more defect-prone. We evaluate our models on diverse projects within Jureczko datasets, and we show that (i) features that contribute most for finding best models may vary depending on the project and (ii) it is possible to find effective models that use few features leading to better understandability. We believe our results are useful to developers as we provide the specific software features that influence the defectiveness of selected projects."
}, {
    "py/object": "data.DataClassPaper",
    "Title": "Using Class Imbalance Learning for Software Defect Prediction",
    "year": 2013,
    "ML_Techniques": "AB, NB, RF, DT",
    "Category": "Testing",
    "Sub_category": "Defect prediction",
    "Venue": "T-RL",
    "Link": "https://ieeexplore.ieee.org/abstract/document/6509481",
    "bibtex": "ARTICLE{Wang2013_150,\n    author = \"{Wang}, S. and {Yao}, X.\",\n    journal = \"IEEE Transactions on Reliability\",\n    title = \"Using Class Imbalance Learning for Software Defect Prediction\",\n    year = \"2013\",\n    volume = \"62\",\n    number = \"2\",\n    pages = \"434-443\",\n    doi = \"10.1109/TR.2013.2259203\"\n}\n\n",
    "abstract": "To facilitate software testing, and save testing costs, a wide range of machine learning methods have been studied to predict defects in software modules. Unfortunately, the imbalanced nature of this type of data increases the learning difficulty of such a task. Class imbalance learning specializes in tackling classification problems with imbalanced distributions, which could be helpful for defect prediction, but has not been investigated in depth so far. In this paper, we study the issue of if and how class imbalance learning methods can benefit software defect prediction with the aim of finding better solutions. We investigate different types of class imbalance learning methods, including resampling techniques, threshold moving, and ensemble algorithms. Among those methods we studied, AdaBoost.NC shows the best overall performance in terms of the measures including balance, G-mean, and Area Under the Curve (AUC). To further improve the performance of the algorithm, and facilitate its use in software defect prediction, we propose a dynamic version of AdaBoost.NC, which adjusts its parameter automatically during training. Without the need to pre-define any parameters, it is shown to be more effective and efficient than the original AdaBoost.NC."
}, {
    "py/object": "data.DataClassPaper",
    "Title": "Using machine learning techniques to detect metamorphic relations for programs without test oracles",
    "year": 2013,
    "ML_Techniques": "DT, SVM",
    "Category": "Testing",
    "Sub_category": ",Defect prediction",
    "Venue": "ISSRE",
    "Link": "https://ieeexplore.ieee.org/abstract/document/6698899",
    "bibtex": "INPROCEEDINGS{Kanewala2013_151,\n    author = \"{Kanewala}, U. and {Bieman}, J. M.\",\n    booktitle = \"2013 IEEE 24th International Symposium on Software Reliability Engineering (ISSRE)\",\n    title = \"Using machine learning techniques to detect metamorphic relations for programs without test oracles\",\n    year = \"2013\",\n    volume = \"\",\n    number = \"\",\n    pages = \"1-10\",\n    doi = \"10.1109/ISSRE.2013.6698899\"\n}\n\n",
    "abstract": "Much software lacks test oracles, which limits automated testing. Metamorphic testing is one proposed method for automating the testing process for programs without test oracles. Unfortunately, finding the appropriate metamorphic relations required for use in metamorphic testing remains a labor intensive task, which is generally performed by a domain expert or a programmer. In this work we present a novel approach for automatically predicting metamorphic relations using machine learning techniques. Our approach uses a set of features developed using the control flow graph of a function for predicting likely metamorphic relations. We show the effectiveness of our method using a set of real world functions often used in scientific applications."
}, {
    "py/object": "data.DataClassPaper",
    "Title": "Using Machine Learning to Prioritize Automated Testing in an Agile Environment",
    "year": 2019,
    "ML_Techniques": "DT",
    "Category": "Testing",
    "Sub_category": ",Defect prediction",
    "Venue": "ICTAS",
    "Link": "https://ieeexplore.ieee.org/document/8703639",
    "bibtex": "INPROCEEDINGS{Butgereit2019_154,\n    author = \"{Butgereit}, L.\",\n    booktitle = \"2019 Conference on Information Communications Technology and Society (ICTAS)\",\n    title = \"Using Machine Learning to Prioritize Automated Testing in an Agile Environment\",\n    year = \"2019\",\n    volume = \"\",\n    number = \"\",\n    pages = \"1-6\",\n    doi = \"10.1109/ICTAS.2019.8703639\"\n}\n\n",
    "abstract": "Automated software testing is an integral part of most Agile methodologies. In the case of the Scrum Agile methodology, the definition of done includes the completion of tests. As a software project matures, however, the number of tests increases to such a point that the time required to run all the tests often hinders the speed in which artifacts can be deployed. This paper describes a technique of using machine learning to help prioritize automated testing to ensure that tests which have a higher probability of failing are executed early in the test run giving the programmers an early indication of problems. In order to do this, various metrics are collected about the software under test including Cyclomatic values, Halstead-based values, and Chidamber-Kemere values. In addition, the historical commit messages from the source code control system is accessed to see if there had been defects in the various source classes previously. From these two inputs, a data file can be created which contains various metrics and whether or not there had been defects in these source files previously. This data file can then be sent to Weka to create a decision tree indicating which measurements indicate potential defects. The model created by Weka can then then be used in future to attempt to predict where defects might be in the source files and then prioritize testing appropriately."
}, {
    "py/object": "data.DataClassPaper",
    "Title": "Using machine learning to refine Category-Partition test specifications and test suites",
    "year": 2009,
    "ML_Techniques": "DT",
    "Category": "Testing",
    "Sub_category": ",Test data/case generation",
    "Venue": "IST",
    "Link": "https://www.sciencedirect.com/science/article/abs/pii/S0950584909000974",
    "bibtex": "article{Briand2009_155,\n    author = \"Briand, Lionel C. and Labiche, Yvan and Bawar, Zaheer and Spido, Nadia Traldi\",\n    title = \"Using machine learning to refine Category-Partition test specifications and test suites\",\n    journal = \"Information and Software Technology\",\n    volume = \"51\",\n    number = \"11\",\n    pages = \"1551 - 1564\",\n    year = \"2009\",\n    note = \"Third IEEE International Workshop on Automation of Software Test (AST 2008) Eighth International Conference on Quality Software (QSIC 2008)\",\n    issn = \"0950-5849\",\n    doi = \"https://doi.org/10.1016/j.infsof.2009.06.006\",\n    url = \"http://www.sciencedirect.com/science/article/pii/S0950584909000974\",\n    keywords = \"Black box testing, Category-Partition, Machine learning, Test improvement\",\n    abstract = \"In the context of open source development or software evolution, developers often face test suites which have been developed with no apparent rationale and which may need to be augmented or refined to ensure sufficient dependability, or even reduced to meet tight deadlines. We refer to this process as the re-engineering of test suites. It is important to provide both methodological and tool support to help people understand the limitations of test suites and their possible redundancies, so as to be able to refine them in a cost effective manner. To address this problem in the case of black-box, Category-Partition testing, we propose a methodology and a tool based on machine learning that has shown promising results on a case study involving students as testers.\"\n}\n\n",
    "abstract": "In the context of open source development or software evolution, developers often face test suites which have been developed with no apparent rationale and which may need to be augmented or refined to ensure sufficient dependability, or even reduced to meet tight deadlines. We refer to this process as the re-engineering of test suites. It is important to provide both methodological and tool support to help people understand the limitations of test suites and their possible redundancies, so as to be able to refine them in a cost effective manner. To address this problem in the case of black-box, Category-Partition testing, we propose a methodology and a tool based on machine learning that has shown promising results on a case study involving students as testers.\n"
}, {
    "py/object": "data.DataClassPaper",
    "Title": "Using semi-supervised learning for predicting metamorphic relations",
    "year": 2018,
    "ML_Techniques": "SVM",
    "Category": "Testing",
    "Sub_category": ",Defect prediction",
    "Venue": "MET",
    "Link": "https://dl.acm.org/doi/10.1145/3193977.3193985",
    "bibtex": "article{Briand2009_155,\n    author = \"Briand, Lionel C. and Labiche, Yvan and Bawar, Zaheer and Spido, Nadia Traldi\",\n    title = \"Using machine learning to refine Category-Partition test specifications and test suites\",\n    journal = \"Information and Software Technology\",\n    volume = \"51\",\n    number = \"11\",\n    pages = \"1551 - 1564\",\n    year = \"2009\",\n    note = \"Third IEEE International Workshop on Automation of Software Test (AST 2008) Eighth International Conference on Quality Software (QSIC 2008)\",\n    issn = \"0950-5849\",\n    doi = \"https://doi.org/10.1016/j.infsof.2009.06.006\",\n    url = \"http://www.sciencedirect.com/science/article/pii/S0950584909000974\",\n    keywords = \"Black box testing, Category-Partition, Machine learning, Test improvement\",\n    abstract = \"In the context of open source development or software evolution, developers often face test suites which have been developed with no apparent rationale and which may need to be augmented or refined to ensure sufficient dependability, or even reduced to meet tight deadlines. We refer to this process as the re-engineering of test suites. It is important to provide both methodological and tool support to help people understand the limitations of test suites and their possible redundancies, so as to be able to refine them in a cost effective manner. To address this problem in the case of black-box, Category-Partition testing, we propose a methodology and a tool based on machine learning that has shown promising results on a case study involving students as testers.\"\n}\n\n",
    "abstract": " Software testing is difficult to automate, especially in programs which have no oracle, or method of determining which output is correct. Metamorphic testing is a solution this problem. Metamorphic testing uses metamorphic relations to define test cases and expected outputs. A large amount of time is needed for a domain expert to determine which metamorphic relations can be used to test a given program. Metamorphic relation prediction removes this need for such an expert. We propose a method using semi-supervised machine learning to detect which metamorphic relations are applicable to a given code base. We compare this semi-supervised model with a supervised model, and show that the addition of unlabeled data improves the classification accuracy of the MR prediction model."
}, {
    "py/object": "data.DataClassPaper",
    "Title": "Machine Learning Testing: Survey, Landscapes and Horizons",
    "year": 2020,
    "ML_Techniques": "",
    "Category": "Testing",
    "Sub_category": "",
    "Venue": "TSE",
    "Link": "https://ieeexplore.ieee.org/document/9000651",
    "bibtex": "ARTICLE{Zhang2020_157,\n    author = \"{Zhang}, J. M. and {Harman}, M. and {Ma}, L. and {Liu}, Y.\",\n    journal = \"IEEE Transactions on Software Engineering\",\n    title = \"Machine Learning Testing: Survey, Landscapes and Horizons\",\n    year = \"2020\",\n    volume = \"\",\n    number = \"\",\n    pages = \"1-1\",\n    doi = \"10.1109/TSE.2019.2962027\"\n}\n\n",
    "abstract": "This paper provides a comprehensive survey of Machine Learning Testing (ML testing) research. It covers 144 papers on testing properties (e.g., correctness, robustness, and fairness), testing components (e.g., the data, learning program, and framework), testing workflow (e.g., test generation and test evaluation), and application scenarios (e.g., autonomous driving, machine translation). The paper also analyses trends concerning datasets, research trends, and research focus, concluding with research challenges and promising research directions in ML testing."
}, {
    "py/object": "data.DataClassPaper",
    "Title": "Software Metrics for Fault Prediction Using Machine Learning Approaches A Literature Review with PROMISE Repository Dataset",
    "year": 2017,
    "ML_Techniques": "",
    "Category": "Testing",
    "Sub_category": "Defect prediction",
    "Venue": "CybermetricsCOM",
    "Link": "https://ieeexplore.ieee.org/document/8311708",
    "bibtex": "ARTICLE{Zhang2020_157,\n    author = \"{Zhang}, J. M. and {Harman}, M. and {Ma}, L. and {Liu}, Y.\",\n    journal = \"IEEE Transactions on Software Engineering\",\n    title = \"Machine Learning Testing: Survey, Landscapes and Horizons\",\n    year = \"2020\",\n    volume = \"\",\n    number = \"\",\n    pages = \"1-1\",\n    doi = \"10.1109/TSE.2019.2962027\"\n}\n\n",
    "abstract": "Software testing is an important and critical phase of software development life cycle to find software faults or defects and then correct those faults. However, testing process is a time-consuming activity that requires good planning and a lot of resources. Therefore, technique and methodology for predicting the testing effort is important process prior the testing process to significantly increase efficiency of time, effort and cost usage. Correspond to software metric usage for measuring software quality, software metric can be used to identify the faulty modules in software. Furthermore, implementing machine learning technique will allow computer to \u201clearn\u201d and able to predict the fault prone modules. Research in this field has become a hot issue for more than ten years ago. However, considering the high importance of software quality with support of machine learning methods development, this research area is still being highlighted until this year. In this paper, a survey of various software metric used for predicting software fault by using machine learning algorithm is examined. According to our review, this is the first study of software fault prediction that focuses to PROMISE repository dataset usage. Some conducted experiments from PROMISE repository dataset are compared to contribute a consensus on what constitute effective software metrics and machine learning method in software fault prediction."
}, {
    "py/object": "data.DataClassPaper",
    "Title": "A Novel Unsupervised Learning Approach for Assessing Web Services Refactoring",
    "year": 2019,
    "ML_Techniques": "KM, COBWEB, EM",
    "Category": "Refactoring",
    "Sub_category": "",
    "Venue": "IST",
    "Link": "https://link.springer.com/chapter/10.1007/978-3-030-30275-7_21",
    "bibtex": "InProceedings{Rodriguez2019_159,\n    author = \"Rodriguez, Guillermo and Mateos, Cristian and Listorti, Luciano and Hammer, Brian and Misra, Sanjay\",\n    editor = \"Dama{\\v{s}}evi{\\v{c}}ius, Robertas and Vasiljevien{\\.{e}}, Giedr{\\.{e}}\",\n    title = \"A Novel Unsupervised Learning Approach for Assessing Web Services Refactoring\",\n    booktitle = \"Information and Software Technologies\",\n    year = \"2019\",\n    publisher = \"Springer International Publishing\",\n    address = \"Cham\",\n    pages = \"273--284\",\n    abstract = \"During the last years, the development of Service-Oriented applications has become a trend. Given the characteristics and challenges posed by current systems, it has become essential to adopt this solution since it provides a great performance in distributed and heterogeneous environments. At the same time, the necessity of flexibility and great capacity of adaptation introduce a process of constant modifications and growth. Thus, developers easily make mistakes such as code duplication or unnecessary code, generating a negative impact on quality attributes such as performance and maintainability. Refactoring is considered a technique that greatly improves the quality of software and provides a solution to this issue. In this context, our work proposes an approach for comparing manual service groupings and automatic groupings that allows analyzing, evaluating and validating clustering techniques applied to improve service cohesion and fragmentation. We used V-Measure with homogeneity and completeness as the evaluation metrics. Additionally, we have performed improvements in existing clustering techniques of a previous work, VizSOC, that reach 20{\\\\%} of gain regarding the aforementioned metrics. Moreover, we added an implementation of the COBWEB clustering algorithm yielding fruitful results.\",\n    isbn = \"978-3-030-30275-7\"\n}\n\n",
    "abstract": "During the last years, the development of Service-Oriented\napplications has become a trend. Given the characteristics and challenges\nposed by current systems, it has become essential to adopt this solution\nsince it provides a great performance in distributed and heterogeneous\nenvironments. At the same time, the necessity of flexibility and great\ncapacity of adaptation introduce a process of constant modifications and\ngrowth. Thus, developers easily make mistakes such as code duplication\nor unnecessary code, generating a negative impact on quality attributes\nsuch as performance and maintainability. Refactoring is considered a\ntechnique that greatly improves the quality of software and provides a\nsolution to this issue. In this context, our work proposes an approach\nfor comparing manual service groupings and automatic groupings that\nallows analyzing, evaluating and validating clustering techniques applied\nto improve service cohesion and fragmentation. We used V-Measure with\nhomogeneity and completeness as the evaluation metrics. Additionally,\nwe have performed improvements in existing clustering techniques of a\nprevious work, VizSOC, that reach 20% of gain regarding the aforementioned\nmetrics. Moreover, we added an implementation of the COBWEB\nclustering algorithm yielding fruitful results."
}, {
    "py/object": "data.DataClassPaper",
    "Title": "An expert system for determining candidate software classes for refactoring",
    "year": 2009,
    "ML_Techniques": "NB",
    "Category": "Refactoring",
    "Sub_category": "",
    "Venue": "ESA",
    "Link": "https://www.sciencedirect.com/science/article/abs/pii/S0957417408009111",
    "bibtex": "article{Kosker2009_161,\n    author = \"Kosker, Yasemin and Turhan, Burak and Bener, Ayse\",\n    title = \"An expert system for determining candidate software classes for refactoring\",\n    journal = \"Expert Systems with Applications\",\n    volume = \"36\",\n    number = \"6\",\n    pages = \"10000 - 10003\",\n    year = \"2009\",\n    issn = \"0957-4174\",\n    doi = \"https://doi.org/10.1016/j.eswa.2008.12.066\",\n    url = \"http://www.sciencedirect.com/science/article/pii/S0957417408009111\",\n    keywords = \"Refactoring, Software metrics, Naive Bayes, Refactor prediction\",\n    abstract = \"In the lifetime of a software product, development costs are only the tip of the iceberg. Nearly 90\\% of the cost is maintenance due to error correction, adaptation and mainly enhancements. As Lehman and Belady [Lehman, M. M., \\& Belady, L. A. (1985). Program evolution: Processes of software change. Academic Press Professional.] state that software will become increasingly unstructured as it is changed. One way to overcome this problem is refactoring. Refactoring is an approach which reduces the software complexity by incrementally improving internal software quality. Our motivation in this research is to detect the classes that need to be rafactored by analyzing the code complexity. We propose a machine learning based model to predict classes to be refactored. We use Weighted Na\u00efve Bayes with InfoGain heuristic as the learner and we conducted experiments with metric data that we collected from the largest GSM operator in Turkey. Our results showed that we can predict 82\\% of the classes that need refactoring with 13\\% of manual inspection effort on the average.\"\n}\n\n",
    "abstract": "In the lifetime of a software product, development costs are only the tip of the iceberg. Nearly 90% of the\ncost is maintenance due to error correction, adaptation and mainly enhancements. As Lehman and Belady\n[Lehman, M. M., & Belady, L. A. (1985). Program evolution: Processes of software change. Academic Press\nProfessional.] state that software will become increasingly unstructured as it is changed. One way to\novercome this problem is refactoring. Refactoring is an approach which reduces the software complexity\nby incrementally improving internal software quality. Our motivation in this research is to detect the\nclasses that need to be rafactored by analyzing the code complexity. We propose a machine learning\nbased model to predict classes to be refactored. We use Weighted Na\u00efve Bayes with InfoGain heuristic\nas the learner and we conducted experiments with metric data that we collected from the largest GSM\noperator in Turkey. Our results showed that we can predict 82% of the classes that need refactoring with\n13% of manual inspection effort on the average."
}, {
    "py/object": "data.DataClassPaper",
    "Title": "Application of LSSVM and SMOTE on Seven Open Source Projects for Predicting Refactoring at Class Level",
    "year": 2017,
    "ML_Techniques": "SVM",
    "Category": "Refactoring",
    "Sub_category": "",
    "Venue": "APSEC",
    "Link": "https://ieeexplore.ieee.org/abstract/document/8305931",
    "bibtex": "INPROCEEDINGS{Kumar2017_162,\n    author = \"{Kumar}, L. and {Sureka}, A.\",\n    booktitle = \"2017 24th Asia-Pacific Software Engineering Conference (APSEC)\",\n    title = \"Application of LSSVM and SMOTE on Seven Open Source Projects for Predicting Refactoring at Class Level\",\n    year = \"2017\",\n    volume = \"\",\n    number = \"\",\n    pages = \"90-99\",\n    doi = \"10.1109/APSEC.2017.15\"\n}\n\n",
    "abstract": "Source code refactoring consisting of modifying the\nstructure of the source code without changing its functionality\nand external behavior.We present a method to predict refactoring\ncandidates at class level which can help developers in improving\ntheir design and structure of source code while preserving\nthe behavior. We propose a technique to predict refactoring\ncandidates based on the application of a machine learning based\nframework. We use Least Squares Support Vector Machines (LSSVM)\nas the learning algorithm, Principal Component Analysis\n(PCA) as a feature extraction technique and Synthetic Minority\nOver-sampling Technique (SMOTE) as a technique for handling\nimbalanced data.\nWe start with 102 source code metrics as input features which\nare then reduced to 31 features after removing irrelevant and\nredundant features through statistical tests. We conduct a series\nof experiments on publicly available software engineering dataset\nconsisting of seven open-source software systems in which the\nrefactored classes are manually validated. We apply LS-SVM\nwith three different functions: linear, polynomial and Radial Basis\nFunction (RBF). Statistical significance test demonstrate that\nRBF kernel outperforms linear and polynomial kernel but there is\nno statistically significant difference between the performance of\nlinear and polynomial kernel. Statistical significance test reveals\nthat with-SMOTE technique outperforms without-SMOTE and\nall metrics outperforms PCA based metrics. The mean value of\nArea Under Curve (AUC) for LS-SVM RBF kernel is 0.96."
}, {
    "py/object": "data.DataClassPaper",
    "Title": "Automated Recommendation of Software Refactorings Based on Feature Requests",
    "year": 2019,
    "ML_Techniques": "LOG, MNB, SVM, RF",
    "Category": "Refactoring",
    "Sub_category": "",
    "Venue": "RE",
    "Link": "https://ieeexplore.ieee.org/document/8920694",
    "bibtex": "INPROCEEDINGS{Nyamawe2019_163,\n    author = \"{Nyamawe}, A. S. and {Liu}, H. and {Niu}, N. and {Umer}, Q. and {Niu}, Z.\",\n    booktitle = \"2019 IEEE 27th International Requirements Engineering Conference (RE)\",\n    title = \"Automated Recommendation of Software Refactorings Based on Feature Requests\",\n    year = \"2019\",\n    volume = \"\",\n    number = \"\",\n    pages = \"187-198\",\n    doi = \"10.1109/RE.2019.00029\"\n}\n\n",
    "abstract": "During software evolution, developers often receive\nnew requirements expressed as feature requests. To implement\nthe requested features, developers have to perform necessary\nmodifications (refactorings) to prepare for new adaptation that\naccommodates the new requirements. Software refactoring is\na well-known technique that has been extensively used to improve\nsoftware quality such as maintainability and extensibility.\nHowever, it is often challenging to determine which kind of\nrefactorings should be applied. Consequently, several approaches\nbased on various heuristics have been proposed to recommend\nrefactorings. However, there is still lack of automated support\nto recommend refactorings given a feature request. To this end,\nin this paper, we propose a novel approach that recommends\nrefactorings based on the history of the previously requested\nfeatures and applied refactorings. First, we exploit the stateof-\nthe-art refactoring detection tools to identify the previous\nrefactorings applied to implement the past feature requests.\nSecond, we train a machine classifier with the history data of the\nfeature requests and refactorings applied on the commits that\nimplemented the corresponding feature requests. The machine\nclassifier is then used to predict refactorings for new feature\nrequests. We evaluate the proposed approach on the dataset\nof 43 open source Java projects and the results suggest that\nthe proposed approach can accurately recommend refactorings\n(average precision 73%)."
}, {
    "py/object": "data.DataClassPaper",
    "Title": "Automatic Clone Recommendation for Refactoring Based on the Present and the Past",
    "year": 2018,
    "ML_Techniques": "AB",
    "Category": "Refactoring",
    "Sub_category": "",
    "Venue": "ICSME",
    "Link": "https://ieeexplore.ieee.org/abstract/document/8530022",
    "bibtex": "INPROCEEDINGS{Yue2018_164,\n    author = \"{Yue}, R. and {Gao}, Z. and {Meng}, N. and {Xiong}, Y. and {Wang}, X. and {Morgenthaler}, J. D.\",\n    booktitle = \"2018 IEEE International Conference on Software Maintenance and Evolution (ICSME)\",\n    title = \"Automatic Clone Recommendation for Refactoring Based on the Present and the Past\",\n    year = \"2018\",\n    volume = \"\",\n    number = \"\",\n    pages = \"115-126\",\n    doi = \"10.1109/ICSME.2018.00021\"\n}\n\n",
    "abstract": "When many clones are detected in software programs,\nnot all clones are equally important to developers. To\nhelp developers refactor code and improve software quality,\nvarious tools were built to recommend clone-removal refactorings\nbased on the past and the present information, such as the\ncohesion degree of individual clones or the co-evolution relations\nof clone peers. The existence of these tools inspired us to\nbuild an approach that considers as many factors as possible\nto more accurately recommend clones. This paper introduces\nCREC, a learning-based approach that recommends clones by\nextracting features from the current status and past history of\nsoftware projects. Given a set of software repositories, CREC first\nautomatically extracts the clone groups historically refactored\n(R-clones) and those not refactored (NR-clones) to construct\nthe training set. CREC extracts 34 features to characterize the\ncontent and evolution behaviors of individual clones, as well as\nthe spatial, syntactical, and co-change relations of clone peers.\nWith these features, CREC trains a classifier that recommends\nclones for refactoring.\nWe designed the largest feature set thus far for clone recommendation,\nand performed an evaluation on six large projects.\nThe results show that our approach suggested refactorings\nwith 83% and 76% F-scores in the within-project and crossproject\nsettings. CREC significantly outperforms a state-of-theart\nsimilar approach on our data set, with the latter one achieving\n70% and 50% F-scores. We also compared the effectiveness of\ndifferent factors and different learning algorithms."
}, {
    "py/object": "data.DataClassPaper",
    "Title": "Method Level Refactoring Prediction on Five Open Source Java Projects using Machine Learning Techniques",
    "year": 2019,
    "ML_Techniques": "LR, LOG, NB, BN, MLP, RF, AB, LB, ANN",
    "Category": "Refactoring",
    "Sub_category": "",
    "Venue": "ISEC",
    "Link": "https://dl.acm.org/doi/abs/10.1145/3299771.3299777",
    "bibtex": "INPROCEEDINGS{Yue2018_164,\n    author = \"{Yue}, R. and {Gao}, Z. and {Meng}, N. and {Xiong}, Y. and {Wang}, X. and {Morgenthaler}, J. D.\",\n    booktitle = \"2018 IEEE International Conference on Software Maintenance and Evolution (ICSME)\",\n    title = \"Automatic Clone Recommendation for Refactoring Based on the Present and the Past\",\n    year = \"2018\",\n    volume = \"\",\n    number = \"\",\n    pages = \"115-126\",\n    doi = \"10.1109/ICSME.2018.00021\"\n}\n\n",
    "abstract": "Introduction : Identifying code segments in large and complex\nsystems in need of refactoring is non-trivial for software developers.\nOur research aim is to develop recommendation systems\nfor suggesting methods which require refactoring. Materials and\nMethods : Previous research shows that source code metrics for\nobject-oriented software systems are indicators of complexity of\na software system. We compute 25 different source code metrics\nat the method level and use it as features in a machine learning\nframework to predict the need of refactoring. We conduct a series\nof experiments on a publicly available annotated dataset of five\nsoftware systems to investigate the performance of our proposed\napproach. In this proposed solution, ten different machine learning\nclassifiers have been considered. In order to handle issues related\nto class imbalance, three different data sampling methods are also\nconsidered during implementation. Conclusion : Our analysis reveals\nthat the mean accuracy for the SMOTE and RUSBoost data\nsampling technique is 98.47% respectively. The mean accuracy for\nthe classifier AdaBoost is 98.16% and the mean accuracy for the\nclassifier ANN+GD is 98.17% respectively. Hypothesis testing results\nreveals that the performance of different classifiers and data\nsampling techniques are statistically significant in nature."
}, {
    "py/object": "data.DataClassPaper",
    "Title": "On the Use of Machine Learning and Search-Based Software Engineering for Ill-Defined Fitness Function: A Case Study on Software Refactoring",
    "year": 2014,
    "ML_Techniques": "ANN",
    "Category": "Refactoring",
    "Sub_category": "",
    "Venue": "SBSE",
    "Link": "https://link.springer.com/chapter/10.1007/978-3-319-09940-8_3",
    "bibtex": "InProceedings{Amal2014_170,\n    author = \"Amal, Boukhdhir and Kessentini, Marouane and Bechikh, Slim and Dea, Josselin and Said, Lamjed Ben\",\n    editor = \"Le Goues, Claire and Yoo, Shin\",\n    title = \"On the Use of Machine Learning and Search-Based Software Engineering for Ill-Defined Fitness Function: A Case Study on Software Refactoring\",\n    booktitle = \"Search-Based Software Engineering\",\n    year = \"2014\",\n    publisher = \"Springer International Publishing\",\n    address = \"Cham\",\n    pages = \"31--45\",\n    abstract = \"The most challenging step when adapting a search-based technique for a software engineering problem is the definition of the fitness function. For several software engineering problems, a fitness function is ill-defined, subjective, or difficult to quantify. For example, the evaluation of a software design is subjective. This paper introduces the use of a neural network-based fitness function for the problem of software refactoring. The software engineers evaluate manually the suggested refactoring solutions by a Genetic Algorithm (GA) for few iterations then an Artificial Neural Network (ANN) uses these training examples to evaluate the refactoring solutions for the remaining iterations. We evaluate the efficiency of our approach using six different open-source systems through an empirical study and compare the performance of our technique with several existing refactoring studies.\",\n    isbn = \"978-3-319-09940-8\"\n}\n\n",
    "abstract": "The most challenging step when adapting a search-based technique\nfor a software engineering problem is the definition of the fitness function. For\nseveral software engineering problems, a fitness function is ill-defined,\nsubjective, or difficult to quantify. For example, the evaluation of a software\ndesign is subjective. This paper introduces the use of a neural network-based\nfitness function for the problem of software refactoring. The software engineers\nevaluate manually the suggested refactoring solutions by a Genetic Algorithm\n(GA) for few iterations then an Artificial Neural Network (ANN) uses these\ntraining examples to evaluate the refactoring solutions for the remaining\niterations. We evaluate the efficiency of our approach using six different opensource\nsystems through an empirical study and compare the performance of our\ntechnique with several existing refactoring studies."
}, {
    "py/object": "data.DataClassPaper",
    "Title": "Prediction of Refactoring-Prone Classes Using Ensemble Learning",
    "year": 2019,
    "ML_Techniques": "ANN, SVM, BTW, MVE",
    "Category": "Refactoring",
    "Sub_category": "",
    "Venue": "NIP",
    "Link": "https://link.springer.com/chapter/10.1007/978-3-030-36802-9_27",
    "bibtex": "InProceedings{Aribandi2019_171,\n    author = \"Aribandi, Vamsi Krishna and Kumar, Lov and Bhanu Murthy Neti, Lalita and Krishna, Aneesh\",\n    editor = \"Gedeon, Tom and Wong, Kok Wai and Lee, Minho\",\n    title = \"Prediction of Refactoring-Prone Classes Using Ensemble Learning\",\n    booktitle = \"Neural Information Processing\",\n    year = \"2019\",\n    publisher = \"Springer International Publishing\",\n    address = \"Cham\",\n    pages = \"242--250\",\n    abstract = \"A considerable amount of software engineers' efforts go into maintaining code repositories, which involves identifying code whose structure can be improved. This often involves the identification of classes whose code requires refactoring. The early detection of refactoring-prone classes has the potential to reduce the costs and efforts that go into maintaining source code repositories. The purpose of this research is to develop prediction models using source code metrics for detecting patterns in object oriented source code, which are indicators of classes that are likely to be refactored in future iterations. In this study, four different sets of source code metrics have been considered as an input for refactoring prediction to evaluate the impact of these source code metrics on model performance. The impact of these source code metrics are evaluated using eleven different classification technique, and two different ensemble classes on seven different open source projects. Ensemble learning techniques have been shown to incorporate the diversity of patterns learnt by different classifiers, resulting in an augmented classifier that is more robust than any individual classifier. Our work also creates distinction between various sets of features for the task of predicting refactoring-prone classes.\",\n    isbn = \"978-3-030-36802-9\"\n}\n\n",
    "abstract": "A considerable amount of software engineers\u2019 efforts go into\nmaintaining code repositories, which involves identifying code whose\nstructure can be improved. This often involves the identification of classes\nwhose code requires refactoring. The early detection of refactoring-prone\nclasses has the potential to reduce the costs and efforts that go into\nmaintaining source code repositories. The purpose of this research is to\ndevelop prediction models using source code metrics for detecting patterns\nin object oriented source code, which are indicators of classes that\nare likely to be refactored in future iterations. In this study, four different\nsets of source code metrics have been considered as an input for\nrefactoring prediction to evaluate the impact of these source code metrics\non model performance. The impact of these source code metrics are\nevaluated using eleven different classification technique, and two different\nensemble classes on seven different open source projects. Ensemble\nlearning techniques have been shown to incorporate the diversity of patterns\nlearnt by different classifiers, resulting in an augmented classifier\nthat is more robust than any individual classifier. Our work also creates\ndistinction between various sets of features for the task of predicting\nrefactoring-prone classes."
}, {
    "py/object": "data.DataClassPaper",
    "Title": "Recommendation of Move Method Refactoring Using Path-Based Representation of Code",
    "year": 2020,
    "ML_Techniques": "SVM",
    "Category": "Refactoring",
    "Sub_category": "",
    "Venue": "ICSEW",
    "Link": "https://dl.acm.org/doi/10.1145/3387940.3392191",
    "bibtex": "inproceedings{Kurbatova2020_172,\n    author = \"Kurbatova, Zarina and Veselov, Ivan and Golubev, Yaroslav and Bryksin, Timofey\",\n    title = \"Recommendation of Move Method Refactoring Using Path-Based Representation of Code\",\n    year = \"2020\",\n    isbn = \"9781450379632\",\n    publisher = \"Association for Computing Machinery\",\n    address = \"New York, NY, USA\",\n    url = \"https://doi.org/10.1145/3387940.3392191\",\n    doi = \"10.1145/3387940.3392191\",\n    abstract = \"Software refactoring plays an important role in increasing code quality. One of the most popular refactoring types is the Move Method refactoring. It is usually applied when a method depends more on members of other classes than on its own original class. Several approaches have been proposed to recommend Move Method refactoring automatically. Most of them are based on heuristics and have certain limitations (e.g., they depend on the selection of metrics and manually-defined thresholds). In this paper, we propose an approach to recommend Move Method refactoring based on a path-based representation of code called code2vec that is able to capture the syntactic structure and semantic information of a code fragment. We use this code representation to train a machine learning classifier suggesting to move methods to more appropriate classes. We evaluate the approach on two publicly available datasets: a manually compiled dataset of well-known open-source projects and a synthetic dataset with automatically injected code smell instances. The results show that our approach is capable of recommending accurate refactoring opportunities and outperforms JDeodorant and JMove, which are state of the art tools in this field.\",\n    booktitle = \"Proceedings of the IEEE/ACM 42nd International Conference on Software Engineering Workshops\",\n    pages = \"315\u2013322\",\n    numpages = \"8\",\n    keywords = \"Feature Envy, Automatic Refactoring Recommendation, Code Smells, Path-based Representation, Move Method Refactoring\",\n    location = \"Seoul, Republic of Korea\",\n    series = \"ICSEW'20\"\n}\n\n",
    "abstract": "Software refactoring plays an important role in increasing code\nquality. One of the most popular refactoring types is the Move\nMethod refactoring. It is usually applied when a method depends\nmore on members of other classes than on its own original class. Several\napproaches have been proposed to recommend Move Method\nrefactoring automatically. Most of them are based on heuristics\nand have certain limitations (e.g., they depend on the selection of\nmetrics and manually-defined thresholds). In this paper, we propose\nan approach to recommend Move Method refactoring based\non a path-based representation of code called code2vec that is able\nto capture the syntactic structure and semantic information of a\ncode fragment. We use this code representation to train a machine\nlearning classifier suggesting to move methods to more appropriate\nclasses. We evaluate the approach on two publicly available\ndatasets: a manually compiled dataset of well-known open-source\nprojects and a synthetic dataset with automatically injected code\nsmell instances. The results show that our approach is capable of\nrecommending accurate refactoring opportunities and outperforms\nJDeodorant and JMove, which are state of the art tools in this field."
}, {
    "py/object": "data.DataClassPaper",
    "Title": "The Effectiveness of Supervised Machine Learning Algorithms in Predicting Software Refactoring",
    "year": 2020,
    "ML_Techniques": "LOG, NB,SVM, DT, RF, NN",
    "Category": "Refactoring",
    "Sub_category": "",
    "Venue": "TSE",
    "Link": "https://ieeexplore.ieee.org/document/9186715",
    "bibtex": "ARTICLE{Aniche2020_173,\n    author = \"{Aniche}, M. and {Maziero}, E. and {Durelli}, R. and {Durelli}, V.\",\n    journal = \"IEEE Transactions on Software Engineering\",\n    title = \"The Effectiveness of Supervised Machine Learning Algorithms in Predicting Software Refactoring\",\n    year = \"2020\",\n    volume = \"\",\n    number = \"\",\n    pages = \"1-1\",\n    doi = \"10.1109/TSE.2020.3021736\"\n}\n\n",
    "abstract": "Refactoring is the process of changing the internal structure of software to improve its quality without modifying its external\nbehavior. Empirical studies have repeatedly shown that refactoring has a positive impact on the understandability and maintainability of\nsoftware systems. However, before carrying out refactoring activities, developers need to identify refactoring opportunities. Currently,\nrefactoring opportunity identification heavily relies on developers\u2019 expertise and intuition. In this paper, we investigate the effectiveness of\nmachine learning algorithms in predicting software refactorings. More specifically, we train six different machine learning algorithms (i.e.,\nLogistic Regression, Naive Bayes, Support Vector Machine, Decision Trees, Random Forest, and Neural Network) with a dataset\ncomprising over two million refactorings from 11,149 real-world projects from the Apache, F-Droid, and GitHub ecosystems. The resulting\nmodels predict 20 different refactorings at class, method, and variable-levels with an accuracy often higher than 90%. Our results show\nthat (i) Random Forests are the best models for predicting software refactoring, (ii) process and ownership metrics seem to play a crucial\nrole in the creation of better models, and (iii) models generalize well in different contexts."
}, {
    "py/object": "data.DataClassPaper",
    "Title": "A large empirical assessment of the role of data balancing in machine-learning-based code smell detection",
    "year": 2020,
    "ML_Techniques": "CSC, OCC",
    "Category": "Quality assessment",
    "Sub_category": "Code smell detection",
    "Venue": "JSS",
    "Link": "https://www.sciencedirect.com/science/article/abs/pii/S0164121220301448",
    "bibtex": "article{Pecorelli2020_177,\n    author = \"Pecorelli, Fabiano and {Di Nucci}, Dario and {De Roover}, Coen and {De Lucia}, Andrea\",\n    title = \"A large empirical assessment of the role of data balancing in machine-learning-based code smell detection\",\n    journal = \"Journal of Systems and Software\",\n    volume = \"169\",\n    pages = \"110693\",\n    year = \"2020\",\n    issn = \"0164-1212\",\n    doi = \"https://doi.org/10.1016/j.jss.2020.110693\",\n    url = \"http://www.sciencedirect.com/science/article/pii/S0164121220301448\",\n    keywords = \"Code smells, Machine learning, Data balancing, Object oriented, Model view controller\",\n    abstract = \"Code smells can compromise software quality in the long term by inducing technical debt. For this reason, many approaches aimed at identifying these design flaws have been proposed in the last decade. Most of them are based on heuristics in which a set of metrics is used to detect smelly code components. However, these techniques suffer from subjective interpretations, a low agreement between detectors, and threshold dependability. To overcome these limitations, previous work applied Machine-Learning that can learn from previous datasets without needing any threshold definition. However, more recent work has shown that Machine-Learning is not always suitable for code smell detection due to the highly imbalanced nature of the problem. In this study, we investigate five approaches to mitigate data imbalance issues to understand their impact on Machine Learning-based approaches for code smell detection in Object-Oriented systems and those implementing the Model-View-Controller pattern. Our findings show that avoiding balancing does not dramatically impact accuracy. Existing data balancing techniques are inadequate for code smell detection leading to poor accuracy for Machine-Learning-based approaches. Therefore, new metrics to exploit different software characteristics and new techniques to effectively combine them are needed.\"\n}\n\n",
    "abstract": "Code smells can compromise software quality in the long term by inducing technical debt. For this\nreason, many approaches aimed at identifying these design flaws have been proposed in the last\ndecade. Most of them are based on heuristics in which a set of metrics is used to detect smelly\ncode components. However, these techniques suffer from subjective interpretations, a low agreement\nbetween detectors, and threshold dependability. To overcome these limitations, previous work applied\nMachine-Learning that can learn from previous datasets without needing any threshold definition.\nHowever, more recent work has shown that Machine-Learning is not always suitable for code smell\ndetection due to the highly imbalanced nature of the problem. In this study, we investigate five\napproaches to mitigate data imbalance issues to understand their impact on Machine Learning-based\napproaches for code smell detection in Object-Oriented systems and those implementing the Model-\nView-Controller pattern. Our findings show that avoiding balancing does not dramatically impact\naccuracy. Existing data balancing techniques are inadequate for code smell detection leading to poor\naccuracy for Machine-Learning-based approaches. Therefore, new metrics to exploit different software\ncharacteristics and new techniques to effectively combine them are needed."
}, {
    "py/object": "data.DataClassPaper",
    "Title": "A machine learning based framework for code clone validation",
    "year": 2020,
    "ML_Techniques": "NB, RF, BN, LOG, KS, DT",
    "Category": "Quality assessment",
    "Sub_category": "Clone detection",
    "Venue": "JSS",
    "Link": "https://www.sciencedirect.com/science/article/abs/pii/S0164121220301394",
    "bibtex": "article{Mostaeen2020_178,\n    author = \"Mostaeen, Golam and Roy, Banani and Roy, Chanchal K. and Schneider, Kevin and Svajlenko, Jeffrey\",\n    title = \"A machine learning based framework for code clone validation\",\n    journal = \"Journal of Systems and Software\",\n    volume = \"169\",\n    pages = \"110686\",\n    year = \"2020\",\n    issn = \"0164-1212\",\n    doi = \"https://doi.org/10.1016/j.jss.2020.110686\",\n    url = \"http://www.sciencedirect.com/science/article/pii/S0164121220301394\",\n    keywords = \"Code clones, Validation, Machine learning, Clone management\",\n    abstract = \"A code clone is a pair of code fragments, within or between software systems that are similar. Since code clones often negatively impact the maintainability of a software system, several code clone detection techniques and tools have been proposed and studied over the last decade. However, the clone detection tools are not always perfect and their clone detection reports often contain a number of false positives or irrelevant clones from specific project management or user perspective. To detect all possible similar source code patterns in general, the clone detection tools work on the syntax level while lacking user-specific preferences. This often means the clones must be manually inspected before analysis in order to remove those false positives from consideration. This manual clone validation effort is very time-consuming and often error-prone, in particular for large-scale clone detection. In this paper, we propose a machine learning approach for automating the validation process. First, a training dataset is built by taking code clones from several clone detection tools for different subject systems and then manually validating those clones. Second, several features are extracted from those clones to train the machine learning model by the proposed approach. The trained algorithm is then used to automatically validate clones without human inspection. Thus the proposed approach can be used to remove the false positive clones from the detection results, automatically evaluate the precision of any clone detectors for any given set of datasets, evaluate existing clone benchmark datasets, or even be used to build new clone benchmarks and datasets with minimum effort. In an experiment with clones detected by several clone detectors in several different software systems, we found our approach has an accuracy of up to 87.4\\% when compared against the manual validation by multiple expert judges. The proposed method also shows better results in several comparative studies with the existing related approaches for clone classification.\"\n}\n\n",
    "abstract": "A code clone is a pair of code fragments, within or between software systems that are similar. Since\ncode clones often negatively impact the maintainability of a software system, several code clone\ndetection techniques and tools have been proposed and studied over the last decade. However, the\nclone detection tools are not always perfect and their clone detection reports often contain a number\nof false positives or irrelevant clones from specific project management or user perspective. To detect\nall possible similar source code patterns in general, the clone detection tools work on the syntax level\nwhile lacking user-specific preferences. This often means the clones must be manually inspected before\nanalysis in order to remove those false positives from consideration. This manual clone validation effort\nis very time-consuming and often error-prone, in particular for large-scale clone detection. In this\npaper, we propose a machine learning approach for automating the validation process. First, a training\ndataset is built by taking code clones from several clone detection tools for different subject systems\nand then manually validating those clones. Second, several features are extracted from those clones\nto train the machine learning model by the proposed approach. The trained algorithm is then used\nto automatically validate clones without human inspection. Thus the proposed approach can be used\nto remove the false positive clones from the detection results, automatically evaluate the precision\nof any clone detectors for any given set of datasets, evaluate existing clone benchmark datasets, or\neven be used to build new clone benchmarks and datasets with minimum effort. In an experiment\nwith clones detected by several clone detectors in several different software systems, we found our\napproach has an accuracy of up to 87.4% when compared against the manual validation by multiple\nexpert judges. The proposed method also shows better results in several comparative studies with the\nexisting related approaches for clone classification."
}, {
    "py/object": "data.DataClassPaper",
    "Title": "A machine learning based tool for source code plagiarism detection",
    "year": 2011,
    "ML_Techniques": "NB, KNN, AB",
    "Category": "Quality assessment",
    "Sub_category": "Clone detection",
    "Venue": "IJMLC",
    "Link": "http://www.ijmlc.org/index.php?m=content&c=index&a=show&catid=25&id=242",
    "bibtex": "article{Mostaeen2020_178,\n    author = \"Mostaeen, Golam and Roy, Banani and Roy, Chanchal K. and Schneider, Kevin and Svajlenko, Jeffrey\",\n    title = \"A machine learning based framework for code clone validation\",\n    journal = \"Journal of Systems and Software\",\n    volume = \"169\",\n    pages = \"110686\",\n    year = \"2020\",\n    issn = \"0164-1212\",\n    doi = \"https://doi.org/10.1016/j.jss.2020.110686\",\n    url = \"http://www.sciencedirect.com/science/article/pii/S0164121220301394\",\n    keywords = \"Code clones, Validation, Machine learning, Clone management\",\n    abstract = \"A code clone is a pair of code fragments, within or between software systems that are similar. Since code clones often negatively impact the maintainability of a software system, several code clone detection techniques and tools have been proposed and studied over the last decade. However, the clone detection tools are not always perfect and their clone detection reports often contain a number of false positives or irrelevant clones from specific project management or user perspective. To detect all possible similar source code patterns in general, the clone detection tools work on the syntax level while lacking user-specific preferences. This often means the clones must be manually inspected before analysis in order to remove those false positives from consideration. This manual clone validation effort is very time-consuming and often error-prone, in particular for large-scale clone detection. In this paper, we propose a machine learning approach for automating the validation process. First, a training dataset is built by taking code clones from several clone detection tools for different subject systems and then manually validating those clones. Second, several features are extracted from those clones to train the machine learning model by the proposed approach. The trained algorithm is then used to automatically validate clones without human inspection. Thus the proposed approach can be used to remove the false positive clones from the detection results, automatically evaluate the precision of any clone detectors for any given set of datasets, evaluate existing clone benchmark datasets, or even be used to build new clone benchmarks and datasets with minimum effort. In an experiment with clones detected by several clone detectors in several different software systems, we found our approach has an accuracy of up to 87.4\\% when compared against the manual validation by multiple expert judges. The proposed method also shows better results in several comparative studies with the existing related approaches for clone classification.\"\n}\n\n",
    "abstract": "Source code plagiarism is a severe problem in\nacademia. In academia programming assignments are used to\nevaluate students in programming courses. Therefore checking\nprogramming assignments for plagiarism is essential. If a\ncourse consists of a large number of students, it is impractical to\ncheck each assignment by a human inspector. Therefore it is\nessential to have automated tools in order to assist detection of\nplagiarism in programming assignments.\nMajority of the current source code plagiarism detection\ntools are based on structured methods. Structural properties of\na plagiarized program and the original program differ\nsignificantly. Therefore it is hard to detect plagiarized\nprograms when plagiarism level is 4 or above by using tools\nwhich are based on structural methods.\nThis paper presents a new plagiarism detection method,\nwhich is based on machine learning techniques. We have\ntrained and tested three machine learning algorithms for\ndetecting source code plagiarism. Furthermore, we have\nutilized a meta-learning algorithm in order to improve the\naccuracy of our system."
}, {
    "py/object": "data.DataClassPaper",
    "Title": "A machine-learning based ensemble method for anti-patterns detection",
    "year": 2020,
    "ML_Techniques": "NN\n",
    "Category": "Quality assessment",
    "Sub_category": "Code smell detection",
    "Venue": "JSS",
    "Link": "https://www.sciencedirect.com/science/article/abs/pii/S0164121219302602",
    "bibtex": "article{Barbez2020_180,\n    author = \"Barbez, Antoine and Khomh, Foutse and Gu\u00e9h\u00e9neuc, Yann-Ga\u00ebl\",\n    title = \"A machine-learning based ensemble method for anti-patterns detection\",\n    journal = \"Journal of Systems and Software\",\n    volume = \"161\",\n    pages = \"110486\",\n    year = \"2020\",\n    issn = \"0164-1212\",\n    doi = \"https://doi.org/10.1016/j.jss.2019.110486\",\n    url = \"http://www.sciencedirect.com/science/article/pii/S0164121219302602\",\n    keywords = \"Software quality, Anti-patterns, Machine learning, Ensemble methods\",\n    abstract = \"Anti-patterns are poor solutions to recurring design problems. Several empirical studies have highlighted their negative impact on program comprehension, maintainability, as well as fault-proneness. A variety of detection approaches have been proposed to identify their occurrences in source code. However, these approaches can identify only a subset of the occurrences and report large numbers of false positives and misses. Furthermore, a low agreement is generally observed among different approaches. Recent studies have shown the potential of machine-learning models to improve this situation. However, such algorithms require large sets of manually-produced training-data, which often limits their application in practice. In this paper, we present SMAD (SMart Aggregation of Anti-patterns Detectors), a machine-learning based ensemble method to aggregate various anti-patterns detection approaches on the basis of their internal detection rules. Thus, our method uses several detection tools to produce an improved prediction from a reasonable number of training examples. We implemented SMAD for the detection of two well known anti-patterns: God Class and Feature Envy. With the results of our experiments conducted on eight java projects, we show that: (1) Our method clearly improves the so aggregated tools; (2) SMAD significantly outperforms other ensemble methods.\"\n}\n\n",
    "abstract": "Anti-patterns are poor solutions to recurring design problems. Several empirical studies have highlighted their negative impact on program comprehension, maintainability, as well as fault-proneness. A variety of detection approaches have been proposed to identify their occurrences in source code. However, these approaches can identify only a subset of the occurrences and report large numbers of false positives and misses. Furthermore, a low agreement is generally observed among different approaches. Recent studies have shown the potential of machine-learning models to improve this situation. However, such algorithms require large sets of manually-produced training-data, which often limits their application in practice. In this paper, we present SMAD (SMart Aggregation of Anti-patterns Detectors), a machine-learning based ensemble method to aggregate various anti-patterns detection approaches on the basis of their internal detection rules. Thus, our method uses several detection tools to produce an improved prediction from a reasonable number of training examples. We implemented SMAD for the detection of two well known anti-patterns: God Class and Feature Envy. With the results of our experiments conducted on eight java projects, we show that: (1) Our method clearly improves the so aggregated tools; (2) SMAD significantly outperforms other ensemble methods."
}, {
    "py/object": "data.DataClassPaper",
    "Title": "A preliminary study on the adequacy of static analysis warnings with respect to code smell prediction",
    "year": 2020,
    "ML_Techniques": "RF, DT, NB, SVM",
    "Category": "Quality assessment",
    "Sub_category": "Code smell detection",
    "Venue": "MaLTeSQuE",
    "Link": "https://dl.acm.org/doi/10.1145/3416505.3423559",
    "bibtex": "article{Barbez2020_180,\n    author = \"Barbez, Antoine and Khomh, Foutse and Gu\u00e9h\u00e9neuc, Yann-Ga\u00ebl\",\n    title = \"A machine-learning based ensemble method for anti-patterns detection\",\n    journal = \"Journal of Systems and Software\",\n    volume = \"161\",\n    pages = \"110486\",\n    year = \"2020\",\n    issn = \"0164-1212\",\n    doi = \"https://doi.org/10.1016/j.jss.2019.110486\",\n    url = \"http://www.sciencedirect.com/science/article/pii/S0164121219302602\",\n    keywords = \"Software quality, Anti-patterns, Machine learning, Ensemble methods\",\n    abstract = \"Anti-patterns are poor solutions to recurring design problems. Several empirical studies have highlighted their negative impact on program comprehension, maintainability, as well as fault-proneness. A variety of detection approaches have been proposed to identify their occurrences in source code. However, these approaches can identify only a subset of the occurrences and report large numbers of false positives and misses. Furthermore, a low agreement is generally observed among different approaches. Recent studies have shown the potential of machine-learning models to improve this situation. However, such algorithms require large sets of manually-produced training-data, which often limits their application in practice. In this paper, we present SMAD (SMart Aggregation of Anti-patterns Detectors), a machine-learning based ensemble method to aggregate various anti-patterns detection approaches on the basis of their internal detection rules. Thus, our method uses several detection tools to produce an improved prediction from a reasonable number of training examples. We implemented SMAD for the detection of two well known anti-patterns: God Class and Feature Envy. With the results of our experiments conducted on eight java projects, we show that: (1) Our method clearly improves the so aggregated tools; (2) SMAD significantly outperforms other ensemble methods.\"\n}\n\n",
    "abstract": "Code smells are poor implementation choices applied during software\nevolution that can affect source code maintainability. While\nseveral heuristic-based approaches have been proposed in the past,\nmachine learning solutions have recently gained attention since\nthey may potentially address some limitations of state-of-the-art\napproaches. Unfortunately, however, machine learning-based code\nsmell detectors still suffer from low accuracy. In this paper, we aim\nat advancing the knowledge in the field by investigating the role of\nstatic analysis warnings as features of machine learning models for\nthe detection of three code smell types.We first verify the potential\ncontribution given by these features. Then, we build code smell\nprediction models exploiting the most relevant features coming\nfrom the first analysis. The main finding of the study reports that\nthe warnings given by the considered tools lead the performance\nof code smell prediction models to drastically increase with respect\nto what reported by previous research in the field."
}, {
    "py/object": "data.DataClassPaper",
    "Title": "A Review of Machine Learning Techniques for Software Quality Prediction",
    "year": 2020,
    "ML_Techniques": "",
    "Category": "Quality assessment",
    "Sub_category": "Quality assessment/prediction,Quality prediction,Quality assessment/prediction,Quality assessment/prediction,Quality prediction,Quality assessment/prediction,Quality prediction",
    "Venue": "ACIE",
    "Link": "https://link.springer.com/chapter/10.1007/978-981-15-1483-8_45",
    "bibtex": "InProceedings{Cowlessur2020_182,\n    author = \"Cowlessur, Sanjeev K. and Pattnaik, Saumendra and Pattanayak, Binod Kumar\",\n    editor = \"Pati, Bibudhendu and Panigrahi, Chhabi Rani and Buyya, Rajkumar and Li, Kuan-Ching\",\n    title = \"A Review of Machine Learning Techniques for Software Quality Prediction\",\n    booktitle = \"Advanced Computing and Intelligent Engineering\",\n    year = \"2020\",\n    publisher = \"Springer Singapore\",\n    address = \"Singapore\",\n    pages = \"537--549\",\n    abstract = \"Successful implementation of a software product entirely depends on the quality of the software developed. However, prediction of the quality of a software product prior to its implementation in real-world applications presents significant challenges to the software developer during the process of development. A limited spectrum of research in this area has been reported in the literature as of today. Most of the researchers have concentrated their research work on software quality prediction using various machine learning techniques. Another aspect pertaining to software quality prediction is that the prediction must be achieved in the earlier stages of software development life cycle in order to reduce the amount of effort required by the developer in course of the development of a software product. In this paper, we carry out a comprehensive review of machine learning techniques which have been used to predict software quality.\",\n    isbn = \"978-981-15-1483-8\"\n}\n\n",
    "abstract": "Successful implementation of a software product entirely depends on the\nquality of the software developed. However, prediction of the quality of a software\nproduct prior to its implementation in real-world applications presents significant\nchallenges to the software developer during the process of development. A limited\nspectrum of research in this area has been reported in the literature as of today.\nMost of the researchers have concentrated their research work on software quality\nprediction using various machine learning techniques. Another aspect pertaining to\nsoftware quality prediction is that the predictionmust be achieved in the earlier stages\nof software development life cycle in order to reduce the amount of effort required\nby the developer in course of the development of a software product. In this paper,\nwe carry out a comprehensive review of machine learning techniques which have\nbeen used to predict software quality."
}, {
    "py/object": "data.DataClassPaper",
    "Title": "A Support Vector Machine Based Approach for Code Smell Detection",
    "year": 2017,
    "ML_Techniques": "SVM",
    "Category": "Quality assessment",
    "Sub_category": "Code smell detection",
    "Venue": "MLDS",
    "Link": "https://ieeexplore.ieee.org/abstract/document/8320252",
    "bibtex": "INPROCEEDINGS{Kaur2017_184,\n    author = \"{Kaur}, A. and {Jain}, S. and {Goel}, S.\",\n    booktitle = \"2017 International Conference on Machine Learning and Data Science (MLDS)\",\n    title = \"A Support Vector Machine Based Approach for Code Smell Detection\",\n    year = \"2017\",\n    volume = \"\",\n    number = \"\",\n    pages = \"9-14\",\n    doi = \"10.1109/MLDS.2017.8\"\n}\n\n",
    "abstract": "Code smells may be introduced in software due to\nmarket rivalry, work pressure deadline, improper functioning,\nskills or inexperience of software developers. Code smells indicate\nproblems in design or code which makes software hard to\nchange and maintain. Detecting code smells could reduce the\neffort of developers, resources and cost of the software. Many\nresearchers have proposed different techniques like DETEX for\ndetecting code smells which have limited precision and recall. To\novercome these limitations,a new technique named as SVMCSD\nhas been proposed for the detection of code smells, based on\nsupport vector machine learning technique. Four code smells are\nspecified namely God Class, Feature Envy,Data Class and Long\nMethod and the proposed technique is validated on two open\nsource systems namely ArgoUML and Xerces. The accuracy of\nSVMCSD is found to be better than DETEX in terms of two\nmetrics, precision and recall, when applied on a subset of a\nsystem. While considering the entire system, SVMCSD detect\nmore occurrences of code smells than DETEX."
}, {
    "py/object": "data.DataClassPaper",
    "Title": "A survey on machine learning techniques used for software quality prediction",
    "year": 2016,
    "ML_Techniques": "",
    "Category": "Quality assessment",
    "Sub_category": "Quality assessment/prediction,Quality prediction,Quality assessment/prediction,Quality assessment/prediction,Quality prediction,Quality assessment/prediction,Quality prediction",
    "Venue": "IJRIS",
    "Link": "https://www.inderscienceonline.com/doi/abs/10.1504/IJRIS.2016.080058",
    "bibtex": "article{Pattnaik2016_185,\n    author = \"Pattnaik, Saumendra and Pattanayak, Binod\",\n    year = \"2016\",\n    month = \"01\",\n    pages = \"3\",\n    title = \"A survey on machine learning techniques used for software quality prediction\",\n    volume = \"8\",\n    journal = \"International Journal of Reasoning-based Intelligent Systems\",\n    doi = \"10.1504/IJRIS.2016.080058\"\n}\n\n",
    "abstract": "In the present software development scenario, software quality prediction has become\nsignificantly important for successful implementation of the software in real world application\nand enhances the longevity of its functionality. Moreover, early identification of anticipated fault\nprone software modules in the process of development of software is crucial in saving efforts\ninvolved in this process. Machine learning techniques are considered to be the most appropriate\ntechniques for software quality prediction and a large spectrum of research work has been\nconducted in this direction by several authors. In this paper, we conduct an extensive survey on\nvarious machine learning techniques like fuzzy logic, neural network, and Bayesian model, etc.\nused for software quality prediction along with an analytical justification for each of the proposed\nsolutions."
}, {
    "py/object": "data.DataClassPaper",
    "Title": "A systematic literature review of machine learning techniques for software maintainability prediction",
    "year": 2020,
    "ML_Techniques": "",
    "Category": "Quality assessment",
    "Sub_category": "Quality assessment/prediction,Quality prediction,Quality assessment/prediction,Quality assessment/prediction,Quality prediction,Quality assessment/prediction,Quality prediction",
    "Venue": "IST",
    "Link": "https://www.sciencedirect.com/science/article/abs/pii/S0950584919302228",
    "bibtex": "article{Alsolai2020_186,\n    author = \"Alsolai, Hadeel and Roper, Marc\",\n    title = \"A systematic literature review of machine learning techniques for software maintainability prediction\",\n    journal = \"Information and Software Technology\",\n    volume = \"119\",\n    pages = \"106214\",\n    year = \"2020\",\n    issn = \"0950-5849\",\n    doi = \"https://doi.org/10.1016/j.infsof.2019.106214\",\n    url = \"http://www.sciencedirect.com/science/article/pii/S0950584919302228\",\n    keywords = \"Systematic literature review, Software maintainability prediction, Machine learning, Metric, Dataset\",\n    abstract = \"Context Software maintainability is one of the fundamental quality attributes of software engineering. The accurate prediction of software maintainability is a significant challenge for the effective management of the software maintenance process. Objective The major aim of this paper is to present a systematic review of studies related to the prediction of maintainability of object-oriented software systems using machine learning techniques. This review identifies and investigates a number of research questions to comprehensively summarize, analyse and discuss various viewpoints concerning software maintainability measurements, metrics, datasets, evaluation measures, individual models and ensemble models. Method The review uses the standard systematic literature review method applied to the most common computer science digital database libraries from January 1991 to July 2018. Results We survey 56 relevant studies in 35 journals and 21 conference proceedings. The results indicate that there is relatively little activity in the area of software maintainability prediction compared with other software quality attributes. CHANGE maintenance effort and the maintainability index were the most commonly used software measurements (dependent variables) employed in the selected primary studies, and most made use of class-level product metrics as the independent variables. Several private datasets were used in the selected studies, and there is a growing demand to publish datasets publicly. Most studies focused on regression problems and performed k-fold cross-validation. Individual prediction models were employed in the majority of studies, while ensemble models relatively rarely. Conclusion Based on the findings obtained in this systematic literature review, ensemble models demonstrated increased accuracy prediction over individual models, and have been shown to be useful models in predicting software maintainability. However, their application is relatively rare and there is a need to apply these, and other models to an extensive variety of datasets with the aim of improving the accuracy and consistency of results.\"\n}\n\n",
    "abstract": "Context: Software maintainability is one of the fundamental quality attributes of software engineering. The accurate prediction of software maintainability is a significant challenge for the effective management of the software maintenance process. Objective: The major aim of this paper is to present a systematic review of studies related to the prediction of maintainability of object-oriented software systems using machine learning techniques. This review identifies and investigates a number of research questions to comprehensively summarize, analyse and discuss various viewpoints concerning software maintainability measurements, metrics, datasets, evaluation measures, individual models and ensemble models. Method: The review uses the standard systematic literature review method applied to the most common computer science digital database libraries from January 1991 to July 2018. Results: We survey 56 relevant studies in 35 journals and 21 conference proceedings. The results indicate that there is relatively little activity in the area of software maintainability prediction compared with other software quality attributes. CHANGE maintenance effort and the maintainability index were the most commonly used software measurements (dependent variables) employed in the selected primary studies, and most made use of class-level product metrics as the independent variables. Several private datasets were used in the selected studies, and there is a growing demand to publish datasets publicly. Most studies focused on regression problems and performed k-fold cross-validation. Individual prediction models were employed in the majority of studies, while ensemble models relatively rarely. Conclusion: Based on the findings obtained in this systematic literature review, ensemble models demonstrated increased accuracy prediction over individual models, and have been shown to be useful models in predicting software maintainability. However, their application is relatively rare and there is a need to apply these, and other models to an extensive variety of datasets with the aim of improving the accuracy and consistency of results."
}, {
    "py/object": "data.DataClassPaper",
    "Title": "Adaptive on-line software aging prediction based on machine learning",
    "year": 2010,
    "ML_Techniques": "DT",
    "Category": "Quality assessment",
    "Sub_category": "Quality assessment/prediction,Quality prediction,Quality assessment/prediction,Quality assessment/prediction,Quality prediction,Quality assessment/prediction,Quality prediction",
    "Venue": "DSN",
    "Link": "https://ieeexplore.ieee.org/abstract/document/5544275",
    "bibtex": "INPROCEEDINGS{Alonso2010_188,\n    author = \"{Alonso}, J. and {Torres}, J. and {Berral}, J. L. and {Gavald\u00e0}, R.\",\n    booktitle = \"2010 IEEE/IFIP International Conference on Dependable Systems Networks (DSN)\",\n    title = \"Adaptive on-line software aging prediction based on machine learning\",\n    year = \"2010\",\n    volume = \"\",\n    number = \"\",\n    pages = \"507-516\",\n    doi = \"10.1109/DSN.2010.5544275\"\n}\n\n",
    "abstract": "The growing complexity of software systems is resulting\nin an increasing number of software faults. According\nto the literature, software faults are becoming one of\nthe main sources of unplanned system outages, and have\nan important impact on company benefits and image. For\nthis reason, a lot of techniques (such as clustering, fail-over\ntechniques, or server redundancy) have been proposed to\navoid software failures, and yet they still happen. Many\nsoftware failures are those due to the software aging phenomena.\nIn this work, first, we propose a new framework\nfor predicting in real time the time-until-crash of web applications\nwhich suffer from software aging, using machine\nlearning techniques. Our framework allows recovery of the\npotentially crashing server using a clean automatic recovery\nand avoiding losses of new and on-going user requests.\nSecond, we present a detailed evaluation of our chosen\nmachine learning prediction algorithm (M5P) in front of\ndynamic and non-deterministic software aging. We have\ntested our prediction model on a three-tier web J2EE application\nachieving acceptable prediction accuracy against\ncomplex scenarios with small training data sets. Furthermore,\nwe have found an interesting approach to help to determine\nthe root cause failure: The model generated by machine\nlearning algorithms."
}, {
    "py/object": "data.DataClassPaper",
    "Title": "An Empirical Analysis on Web Service Anti-pattern Detection Using a Machine Learning Framework",
    "year": 2018,
    "ML_Techniques": "RF, LOG, DT, LB, AB, B, MLP, NB",
    "Category": "Quality assessment",
    "Sub_category": "Code smell detection",
    "Venue": "COMPSAC",
    "Link": "https://ieeexplore.ieee.org/document/8377634",
    "bibtex": "INPROCEEDINGS{Kumar2018_189,\n    author = \"{Kumar}, L. and {Sureka}, A.\",\n    booktitle = \"2018 IEEE 42nd Annual Computer Software and Applications Conference (COMPSAC)\",\n    title = \"An Empirical Analysis on Web Service Anti-pattern Detection Using a Machine Learning Framework\",\n    year = \"2018\",\n    volume = \"01\",\n    number = \"\",\n    pages = \"2-11\",\n    doi = \"10.1109/COMPSAC.2018.00010\"\n}\n\n",
    "abstract": "Web Services are application components characterised\nby interoperability, extensibility, distributed application\ndevelopment and service oriented architecture. A complex distributed\napplication can be developed by combing several thirdparty\nweb-services. Anti-patterns are counter-productive and\npoor design and practices. Web-services suffer from a multitude\nof anti-patterns such as God object Web service and Fine grained\nWeb service. Our work is motivated by the need to build\ntechniques for automatically detecting common web-services antipatterns\nby static analysis of the source code implementing a webservice.\nOur approach is based on the premise that summary\nvalues of object oriented source code metrics computed at a\nweb-service level can be used as a predictor for anti-patterns.\nWe present an empirical analysis of 4 data sampling techniques\nto encounter the class imbalance problem, 5 feature ranking\ntechniques to identify the most informative and relevant features\nand 8 machine learning algorithms for predicting 5 different\ntypes of anti-patterns on 226 real-world web-services across\nseveral domains. We conclude that it is possible to predict antipatterns\nusing source code metrics and a machine learning framework.\nOur analysis reveals that the best performing classification\nalgorithm is Random Forest, best performing data sampling\ntechnique is SMOTE and the best performing feature ranking\nmethod is OneR."
}, {
    "py/object": "data.DataClassPaper",
    "Title": "An Empirical Framework for Code Smell Prediction using Extreme Learning Machine",
    "year": 2019,
    "ML_Techniques": "LOG, LR, DT, POLY",
    "Category": "Quality assessment",
    "Sub_category": "Code smell detection",
    "Venue": "IEMECON",
    "Link": "https://ieeexplore.ieee.org/document/8877082",
    "bibtex": "INPROCEEDINGS{Gupta2019_190,\n    author = \"{Gupta}, H. and {Kumar}, L. and {Neti}, L. B. M.\",\n    booktitle = \"2019 9th Annual Information Technology, Electromechanical Engineering and Microelectronics Conference (IEMECON)\",\n    title = \"An Empirical Framework for Code Smell Prediction using Extreme Learning Machine*\",\n    year = \"2019\",\n    volume = \"\",\n    number = \"\",\n    pages = \"189-195\",\n    doi = \"10.1109/IEMECONX.2019.8877082\"\n}\n\n",
    "abstract": "The software containing code smells indicates the violation of standard design and coding practices by developer during the development of the software system. Recent empirical studies observed that classes having code smells have higher probability of change proneness or fault proneness with respect to classes having no code smells [1]. The effort of removing bugs due to code smells increases exponentially if the smells are not identified during the earlier phases of software development. The code smell prediction using source code metrics can be used in starting phases of software development life cycle to reduce the maintenance and testing effort of software and also help in improving the quality of the software. The work in this paper empirically investigates and evaluates different classification techniques, feature selection techniques, and data sampling techniques to handle imbalance data in predicting 7 different types of code smell. The conclusion of this research is assessed over 629 application packages. The experimental finding confirms the estimating capability of different classifiers, feature selection, and data imbalance techniques for developing code smell prediction models. Our analysis also reveals that the models developed using one technique are superior than the models developed using other techniques."
}, {
    "py/object": "data.DataClassPaper",
    "Title": "Application of machine learning algorithms for code smell prediction using object-oriented software metrics",
    "year": 2020,
    "ML_Techniques": "DT, RF",
    "Category": "Quality assessment",
    "Sub_category": "Code smell detection",
    "Venue": "JSMS",
    "Link": "https://www.tandfonline.com/doi/abs/10.1080/09720510.2020.1799576",
    "bibtex": "article{Agnihotri2020_193,\n    author = \"Agnihotri, Mansi and Chug, Anuradha\",\n    title = \"Application of machine learning algorithms for code smell prediction using object-oriented software metrics\",\n    journal = \"Journal of Statistics and Management Systems\",\n    volume = \"23\",\n    number = \"7\",\n    pages = \"1159-1171\",\n    year = \"2020\",\n    publisher = \"Taylor \\& Francis\",\n    doi = \"10.1080/09720510.2020.1799576\",\n    URL = \"https://doi.org/10.1080/09720510.2020.1799576\",\n    eprint = \"https://doi.org/10.1080/09720510.2020.1799576\"\n}\n\n",
    "abstract": "Code smells are generally not considered as bugs; instead, they point out certain\nshortcomings in the software design or code. Identification of code smell is a necessary step\nfor improving the software quality and reducing the maintenance effort. In this study, we\nintroduce a bad smell prediction technique based on object- oriented software metrics that\nuse Decision Tree (DT) and Random Forest (RF) machine learning algorithm. An open-source\nproject, namely JHOTDRAW, was used as our dataset, for which values of object-oriented\nsoftware metrics were calculated. Two feature selection methods- Random Forest Importance\n(RFI) and Information Gain (IG) were applied to extract the most relevant attributes for the\nprediction of code smells, namely, Feature envy, Dispersed coupling, refused parent bequest,\nand God class. The random-search algorithm was used to tune the parameters of Random\nForest and Decision Tree. Results show that the best classification accuracy for Decision Tree\nwas obtained at 99.13% for refused parent bequest code smells. Results also show that after\nusing the Random Forest classifier, refused parent bequest smell was predicted with the best\naccuracy of 99.14%. Finally, in this research study, a set of code smell prediction rules were\nextracted using Decision Tree."
}, {
    "py/object": "data.DataClassPaper",
    "Title": "Applying Machine Learning in Technical Debt Management: Future Opportunities and Challenges",
    "year": 2020,
    "ML_Techniques": "",
    "Category": "Quality assessment",
    "Sub_category": "Technical debt identification",
    "Venue": "QICT",
    "Link": "https://link.springer.com/chapter/10.1007/978-3-030-58793-2_5",
    "bibtex": "InProceedings{Tsintzira2020_194,\n    author = \"Tsintzira, Angeliki-Agathi and Arvanitou, Elvira-Maria and Ampatzoglou, Apostolos and Chatzigeorgiou, Alexander\",\n    editor = \"Shepperd, Martin and Brito e Abreu, Fernando and Rodrigues da Silva, Alberto and P{\\'e}rez-Castillo, Ricardo\",\n    title = \"Applying Machine Learning in Technical Debt Management: Future Opportunities and Challenges\",\n    booktitle = \"Quality of Information and Communications Technology\",\n    year = \"2020\",\n    publisher = \"Springer International Publishing\",\n    address = \"Cham\",\n    pages = \"53--67\",\n    abstract = \"Technical Debt Management (TDM) is a fast-growing field that in the last years has attracted the attention of both academia and industry. TDM is a complex process, in the sense that it relies on multiple and heterogeneous data sources (e.g., source code, feature requests, bugs, developers' activity, etc.), which cannot be straightforwardly synthesized; leading the community to using mostly qualitative empirical methods. However, empirical studies that involve expert judgement are inherently biased, compared to automated or semi-automated approaches. To overcome this limitation, the broader (not TDM) software engineering community has started to employ machine learning (ML) technologies. Our goal is to investigate the opportunity of applying ML technologies for TDM, through a Systematic Literature Review (SLR) on the application of ML to software engineering problems (since ML applications on TDM are limited). Thus, we have performed a broader scope study, i.e., on machine learning for software engineering, and then synthesize the results so as to achieve our high-level goal (i.e., possible application of ML in TDM). Therefore, we have conducted a literature review, by browsing the research corpus published in five high-quality SE journals, with the goal of cataloging: (a) the software engineering practices in which ML is used; (b) the machine learning technologies that are used for solving them; and (c) the intersection of the two: developing a problem-solution mapping. The results are useful to both academics and industry, since the former can identify possible gaps, and interesting future research directions, whereas the latter can obtain benefits by adopting ML technologies.\",\n    isbn = \"978-3-030-58793-2\"\n}\n\n",
    "abstract": "Technical Debt Management (TDM) is a fast-growing field that in the last years has attracted the attention of both academia and industry. TDM is a complex process, in the sense that it relies on multiple and heterogeneous data sources (e.g., source code, feature requests, bugs, developers\u2019 activity, etc.), which cannot be straightforwardly synthesized; leading the community to using mostly qualitative empirical methods. However, empirical studies that involve expert judgement are inherently biased, compared to automated or semi-auto-mated approaches. To overcome this limitation, the broader (not TDM) software engineering community has started to employ machine learning (ML) technolo-gies. Our goal is to investigate the opportunity of applying ML technologies for TDM, through a Systematic Literature Review (SLR) on the application of ML to software engineering problems (since ML applications on TDM are limited). Thus, we have performed a broader scope study, i.e., on machine learning for software engineering, and then synthesize the results so as to achieve our high-level goal (i.e., possible application of ML in TDM). Therefore, we have con-ducted a literature review, by browsing the research corpus published in five high-quality SE journals, with the goal of cataloging: (a) the software engineering practices in which ML is used; (b) the machine learning technologies that are used for solving them; and (c) the intersection of the two: developing a problem-solution mapping. The results are useful to both academics and industry, since the former can identify possible gaps, and interesting future research directions, whereas the later can obtain benefits by adopting ML technologies."
}, {
    "py/object": "data.DataClassPaper",
    "Title": "Applying Machine Learning to Customized Smell Detection: A Multi-Project Study",
    "year": 2020,
    "ML_Techniques": "Ripper, RF, DT, OR, SVM, SMO, NB",
    "Category": "Quality assessment",
    "Sub_category": "Code smell detection",
    "Venue": "SBES",
    "Link": "https://www.researchgate.net/publication/345310750_Applying_Machine_Learning_to_Customized_Smell_Detection_A_Multi-Project_Study",
    "bibtex": "inproceedings{Oliveira2020_195,\n\tauthor = {Oliveira, Daniel and Assun\\c{c}\\~{a}o, Wesley K. G. and Souza, Leonardo and Oizumi, Willian and Garcia, Alessandro and Fonseca, Baldoino},\ntitle = {Applying Machine Learning to Customized Smell Detection: A Multi-Project Study},\nyear = {2020},\nisbn = {9781450387538},\npublisher = {Association for Computing Machinery},\naddress = {New York, NY, USA},\nurl = {https://doi.org/10.1145/3422392.3422427},\ndoi = {10.1145/3422392.3422427},\npages = {233\u2013242},\nnumpages = {10},\nkeywords = {code smell, software quality, code smell detection},\nlocation = {Natal, Brazil},\nseries = {SBES '20}\n}\n\n",
    "abstract": "Code smells are considered symptoms of poor implementation\nchoices, which may hamper the software maintainability. Hence,\ncode smells should be detected as early as possible to avoid software\nquality degradation. Unfortunately, detecting code smells is not a\ntrivial task. Some preliminary studies investigated and concluded\nthat machine learning (ML) techniques are a promising way to\nbetter support smell detection. However, these techniques are hard\nto be customized to promote an early and accurate detection of\nspecific smell types. Yet, ML techniques usually require numerous\ncode examples to be trained (composing a relevant dataset) in order\nto achieve satisfactory accuracy. Unfortunately, such a dependency\non a large validated dataset is impractical and leads to late detection\nof code smells. Thus, a prevailing challenge is the early customized\ndetection of code smells taking into account the typical limited\ntraining data. In this direction, this paper reports a study in which\nwe collected code smells, from ten active projects, that were actually\nrefactored by developers, differently from studies that rely on code\nsmells inferred by researchers. These smells were used for evaluating\nthe accuracy regarding early detection of code smells by using\nseven ML techniques. Once we take into account such smells that\nwere considered as important by developers, the ML techniques are\nable to customize the detection in order to focus on smells observed\nas relevant in the investigated systems. The results showed that\nall the analyzed techniques are sensitive to the type of smell and\nobtained good results for the majority of them, especially JRip and\nRandom Forest. We also observe that the ML techniques did not\nneed a high number of examples to reach their best accuracy results.\nThis finding implies that ML techniques can be successfully used\nfor early detection of smells without depending on the curation of\na large dataset."
}, {
    "py/object": "data.DataClassPaper",
    "Title": "Assessment of Code Smell for Predicting Class Change Proneness Using Machine Learning",
    "year": 2019,
    "ML_Techniques": "NB, MLP, LB, B, RF, DT",
    "Category": "Quality assessment",
    "Sub_category": "Code smell detection",
    "Venue": "IEEE Access",
    "Link": "https://ieeexplore.ieee.org/abstract/document/8667419",
    "bibtex": "ARTICLE{Pritam2019_196,\n    author = \"{Pritam}, N. and {Khari}, M. and {Hoang Son}, L. and {Kumar}, R. and {Jha}, S. and {Priyadarshini}, I. and {Abdel-Basset}, M. and {Viet Long}, H.\",\n    journal = \"IEEE Access\",\n    title = \"Assessment of Code Smell for Predicting Class Change Proneness Using Machine Learning\",\n    year = \"2019\",\n    volume = \"7\",\n    number = \"\",\n    pages = \"37414-37425\",\n    doi = \"10.1109/ACCESS.2019.2905133\"\n}\n\n",
    "abstract": "Assessment of code smell for predicting software change proneness is essential to ensure\nits signi cance in the area of software quality. While multiple studies have been conducted in this regard,\nthe number of systems studied and the methods used in this paper are quite different, thus, causing confusion\nfor understanding the best methodology. The objective of this paper is to approve the effect of code smell\non the change inclination of a speci c class in a product framework. This is the novelty and surplus of this\nwork against the others. Furthermore, this paper aims to validate code smell for predicting class change\nproneness to  nd an error in the prediction of change proneness using code smell. Six typical machine\nlearning algorithms (Naive Bayes Classi er, Multilayer Perceptron, LogitBoost, Bagging, Random Forest,\nand Decision Tree) have been used to predict change proneness using code smell from a set of 8200 Java\nclasses spanning 14 software systems. The experimental results suggest that code smell is indeed a powerful\npredictor of class change proneness with multilayer perceptron being the most effective technique. The\nsensitivity and speci city values for all the models are well over 70% with a few exceptions."
}, {
    "py/object": "data.DataClassPaper",
    "Title": "Bad Smell Detection Using Machine Learning Techniques: A Systematic Literature Review",
    "year": 2020,
    "ML_Techniques": "",
    "Category": "Quality assessment",
    "Sub_category": "Code smell detection",
    "Venue": "AJSE",
    "Link": "https://link.springer.com/article/10.1007/s13369-019-04311-w",
    "bibtex": "ARTICLE{Pritam2019_196,\n    author = \"{Pritam}, N. and {Khari}, M. and {Hoang Son}, L. and {Kumar}, R. and {Jha}, S. and {Priyadarshini}, I. and {Abdel-Basset}, M. and {Viet Long}, H.\",\n    journal = \"IEEE Access\",\n    title = \"Assessment of Code Smell for Predicting Class Change Proneness Using Machine Learning\",\n    year = \"2019\",\n    volume = \"7\",\n    number = \"\",\n    pages = \"37414-37425\",\n    doi = \"10.1109/ACCESS.2019.2905133\"\n}\n\n",
    "abstract": "Code smells are indicators of potential problems in software. They tend to have a negative impact on software quality. Several studies use machine learning techniques to detect bad smells. The objective of this study is to systematically review and analyze machine learning techniques used to detect code smells to provide interested research community with knowledge about the adopted techniques and practices for code smells detection. We use a systematic literature review approach to review studies that use machine learning techniques to detect code smells. Seventeen primary studies were identified. We found that 27 code smells were used in the identified studies; God Class and Long Method, Feature Envy, and Data Class are the most frequently detected code smells. In addition, we found that 16 machine learning algorithms were employed to detect code smells with acceptable prediction accuracy. Furthermore, we the results also indicate that support vector machine techniques were investigated the most. Moreover, we observed that J48 and Random Forest algorithms outperform the other algorithms. We also noticed that, in some cases, the use of boosting techniques on the models does not always enhance their performance. More studies are needed to consider the use of ensemble learning techniques, multiclassification, and feature selection technique for code smells detection. Thus, the application of machine learning algorithms to detect code smells in systems is still in its infancy and needs more research to facilitate the employment of machine learning algorithms in detecting code smells."
}, {
    "py/object": "data.DataClassPaper",
    "Title": "Bilateral Dependency Neural Networks for Cross-Language Algorithm Classification",
    "year": 2019,
    "ML_Techniques": "BiNN",
    "Category": "Quality assessment",
    "Sub_category": "Clone detection",
    "Venue": "SANER",
    "Link": "https://bdqnghi.github.io/files/SANER_2019_bilateral_dependency.pdf",
    "bibtex": "INPROCEEDINGS{Bui2019_200,\n    author = \"{Bui}, N. D. Q. and {Yu}, Y. and {Jiang}, L.\",\n    booktitle = \"2019 IEEE 26th International Conference on Software Analysis, Evolution and Reengineering (SANER)\",\n    title = \"Bilateral Dependency Neural Networks for Cross-Language Algorithm Classification\",\n    year = \"2019\",\n    volume = \"\",\n    number = \"\",\n    pages = \"422-433\",\n    doi = \"10.1109/SANER.2019.8667995\"\n}\n\n",
    "abstract": "Algorithm classification is to automatically identify\nthe classes of a program based on the algorithm(s) and/or data\nstructure(s) implemented in the program. It can be useful for\nvarious tasks, such as code reuse, code theft detection, and malware\ndetection. Code similarity metrics, on the basis of features\nextracted from syntax and semantics, have been used to classify\nprograms. Such features, however, often need manual selection\neffort and are specific to individual programming languages,\nlimiting the classifiers to programs in the same language.\nTo recognize the similarities and differences among algorithms\nimplemented in different languages, this paper describes a\nframework of Bilateral Neural Networks (Bi-NN) that builds a\nneural network on top of two underlying sub-networks, each of\nwhich encodes syntax and semantics of code in one language. A\nwhole Bi-NN can be trained with bilateral programs that implement\nthe same algorithms and/or data structures in different\nlanguages and then be applied to recognize algorithm classes\nacross languages.\nWe have instantiated the framework with several kinds of\ntoken-, tree- and graph-based neural networks that encode and\nlearn various kinds of information in code. We have applied\nthe instances of the framework to a code corpus collected from\nGitHub containing thousands of Java and C++ programs implementing\n50 different algorithms and data structures. Our evaluation\nresults show that the use of Bi-NN indeed produces promising\nalgorithm classification results both within one language and\nacross languages, and the encoding of dependencies from code\ninto the underlying neural networks helps improve algorithm\nclassification accuracy further. In particular, our custom-built\ndependency trees with tree-based convolutional neural networks\nachieve the highest classification accuracy among the different\ninstances of the framework that we have evaluated. Our study\npoints to a possible future research direction to tailor bilateral\nand multilateral neural networks that encode more relevant\nsemantics for code learning, mining and analysis tasks."
}, {
    "py/object": "data.DataClassPaper",
    "Title": "Classification model for code clones based on machine learning",
    "year": 2015,
    "ML_Techniques": "KM, COBWEB, EM",
    "Category": "Quality assessment",
    "Sub_category": "Clone detection",
    "Venue": "EMSE",
    "Link": "https://link.springer.com/article/10.1007/s10664-014-9316-x",
    "bibtex": "article{Yang2014_202,\n    author = \"Yang, Jiachen and Hotta, K. and Higo, Yoshiki and Igaki, H. and Kusumoto, S.\",\n    title = \"Classification model for code clones based on machine learning\",\n    journal = \"Empirical Software Engineering\",\n    year = \"2014\",\n    volume = \"20\",\n    pages = \"1095-1125\"\n}\n\n",
    "abstract": "Results from code clone detectors may contain plentiful useless code clones, but\njudging whether each code clone is useful varies from user to user based on a user\u2019s purpose\nfor the clone. In this research, we propose a classification model that applies machine learning\nto the judgments of each individual user regarding the code clones. To evaluate the proposed\nmodel, 32 participants completed an online survey to test its usability and accuracy. The result\nshowed several important observations on the characteristics of the true positives of code\nclones for the users. Our classification model showed more than 70% accuracy on average and\nmore than 90 % accuracy for some particular users and projects."
}, {
    "py/object": "data.DataClassPaper",
    "Title": "CloneCognition: machine learning based code clone validation tool",
    "year": 2019,
    "ML_Techniques": "ANN",
    "Category": "Quality assessment",
    "Sub_category": "Clone detection",
    "Venue": "FSE",
    "Link": "https://dl.acm.org/doi/10.1145/3338906.3341182",
    "bibtex": "article{Yang2014_202,\n    author = \"Yang, Jiachen and Hotta, K. and Higo, Yoshiki and Igaki, H. and Kusumoto, S.\",\n    title = \"Classification model for code clones based on machine learning\",\n    journal = \"Empirical Software Engineering\",\n    year = \"2014\",\n    volume = \"20\",\n    pages = \"1095-1125\"\n}\n\n",
    "abstract": "A code clone is a pair of similar code fragments, within or between\nsoftware systems. To detect each possible clone pair from\na software system while handling the complex code structures,\nthe clone detection tools undergo a lot of generalization of the\noriginal source codes. The generalization often results in returning\ncode fragments that are only coincidentally similar and not\nconsidered clones by users, and hence requires manual validation\nof the reported possible clones by users which is often both\ntime-consuming and challenging. In this paper, we propose a machine\nlearning based tool \u2018CloneCognition\u2019 (Open Source Codes:\nhttps://github.com/pseudoPixels/CloneCognition ; Video Demonstration:\nhttps://www.youtube.com/watch?v=KYQjmdr8rsw) to automate\nthe laborious manual validation process. The tool runs on\ntop of any code clone detection tools to facilitate the clone validation\nprocess. The tool shows promising clone classification performance\nwith an accuracy of up to 87.4%. The tool also exhibits significant\nimprovement in the results when compared with state-of-the-art\ntechniques for code clone validation."
}, {
    "py/object": "data.DataClassPaper",
    "Title": "Clonewise \u2013 Detecting Package-Level Clones Using Machine Learning",
    "year": 2013,
    "ML_Techniques": "NB, MLP, RF",
    "Category": "Quality assessment",
    "Sub_category": "Clone detection",
    "Venue": "SPCN",
    "Link": "https://link.springer.com/chapter/10.1007/978-3-319-04283-1_13",
    "bibtex": "article{Yang2014_202,\n    author = \"Yang, Jiachen and Hotta, K. and Higo, Yoshiki and Igaki, H. and Kusumoto, S.\",\n    title = \"Classification model for code clones based on machine learning\",\n    journal = \"Empirical Software Engineering\",\n    year = \"2014\",\n    volume = \"20\",\n    pages = \"1095-1125\"\n}\n\n",
    "abstract": "Developers sometimes maintain an internal copy of another software\nor fork development of an existing project. This practice can lead to software\nvulnerabilities when the embedded code is not kept up to date with upstream\nsources. We propose an automated solution to identify clones of packages\nwithout any prior knowledge of these relationships. We then correlate clones\nwith vulnerability information to identify outstanding security problems. This\napproach motivates software maintainers to avoid using cloned packages and\nlink against system wide libraries. We propose over 30 novel features that\nenable us to use to use pattern classification to accurately identify package-level\nclones. To our knowledge, we are the first to consider clone detection as a\nclassification problem. Our results show our system, Clonewise, compares well\nto manually tracked databases. Based on our work, over 30 unknown package\nclones and vulnerabilities have been identified and patched."
}, {
    "py/object": "data.DataClassPaper",
    "Title": "Code smell detection using multi-label classification approach",
    "year": 2020,
    "ML_Techniques": "BR, CC, LC",
    "Category": "Quality assessment",
    "Sub_category": "Code smell detection",
    "Venue": "SQJ",
    "Link": "https://link.springer.com/article/10.1007/s11219-020-09498-y",
    "bibtex": "article{Guggulothu2020_206,\n    author = \"Guggulothu, Thirupathi and Moiz, S. A.\",\n    title = \"Code smell detection using multi-label classification approach\",\n    journal = \"Software Quality Journal\",\n    year = \"2020\",\n    pages = \"1-24\"\n}\n\n",
    "abstract": "Code smells are characteristics of the software that indicates a code or design problem which\ncan make software hard to understand, evolve, and maintain. There are several code smell\ndetection tools proposed in the literature, but they produce different results. This is because\nsmells are informally defined or subjective in nature. Machine learning techniques help in\naddressing the issues of subjectivity, which can learn and distinguish the characteristics of\nsmelly and non-smelly source code elements (classes or methods). However, the existing\nmachine learning techniques can only detect a single type of smell in the code element that\ndoes not correspond to a real-world scenario as a single element can have multiple design\nproblems (smells). Further, the mechanisms proposed in the literature could not detect code\nsmells by considering the correlation (co-occurrence) among them. To address these shortcomings,\nwe propose and investigate the use of multi-label classification (MLC) methods to\ndetect whether the given code element is affected by multiple smells or not. In this proposal,\ntwo code smell datasets available in the literature are converted into a multi-label dataset\n(MLD). In the MLD, we found that there is a positive correlation between the two smells\n(long method and feature envy). In the classification phase, the two methods of MLC considered\nthe correlation among the smells and enhanced the performance (on average more\nthan 95% accuracy) for the 10-fold cross-validation with the ten iterations. The findings\nreported help the researchers and developers in prioritizing the critical code elements for\nrefactoring based on the number of code smells detected."
}, {
    "py/object": "data.DataClassPaper",
    "Title": "Code Smell Detection: Towards a Machine Learning-Based Approach",
    "year": 2013,
    "ML_Techniques": "DT, RF, NB, Ripper, SMO, SVM",
    "Category": "Quality assessment",
    "Sub_category": "Code smell detection",
    "Venue": "ICSME",
    "Link": "https://ieeexplore.ieee.org/document/6676916",
    "bibtex": "INPROCEEDINGS{Fontana2013_207,\n    author = \"{Fontana}, F. A. and {Zanoni}, M. and {Marino}, A. and {M\u00e4ntyl\u00e4}, M. V.\",\n    booktitle = \"2013 IEEE International Conference on Software Maintenance\",\n    title = \"Code Smell Detection: Towards a Machine Learning-Based Approach\",\n    year = \"2013\",\n    volume = \"\",\n    number = \"\",\n    pages = \"396-399\"\n}\n\n",
    "abstract": "Several code smells detection tools have been developed\nproviding different results, because smells can be subjectively\ninterpreted and hence detected in different ways. Usually\nthe detection techniques are based on the computation of different\nkinds of metrics, and other aspects related to the domain of the\nsystem under analysis, its size and other design features are not\ntaken into account. In this paper we propose an approach we are\nstudying based on machine learning techniques. We outline some\ncommon problems faced for smells detection and we describe the\ndifferent steps of our approach and the algorithms we use for\nthe classification."
}, {
    "py/object": "data.DataClassPaper",
    "Title": "Code Smell Prediction Employing Machine Learning Meets Emerging Java Language Constructs",
    "year": 2020,
    "ML_Techniques": "RF, NB, DT, Ripper",
    "Category": "Quality assessment",
    "Sub_category": "Code smell detection",
    "Venue": "Book",
    "Link": "https://link.springer.com/chapter/10.1007/978-3-030-34706-2_8",
    "bibtex": "Inbook{Grodzicka2020_208,\n    author = \"Grodzicka, Hanna and Ziobrowski, Arkadiusz and {\\L}akomiak, Zofia and Kawa, Micha{\\l} and Madeyski, Lech\",\n    editor = \"Poniszewska-Mara{\\'{n}}da, Aneta and Kryvinska, Natalia and Jarz{\\k{a}}bek, Stanis{\\l}aw and Madeyski, Lech\",\n    title = \"Code Smell Prediction Employing Machine Learning Meets Emerging Java Language Constructs\",\n    bookTitle = \"Data-Centric Business and Applications: Towards Software Development (Volume 4)\",\n    year = \"2020\",\n    publisher = \"Springer International Publishing\",\n    address = \"Cham\",\n    pages = \"137--167\",\n    abstract = \"Background: Defining code smell is not a trivial task. Their recognition tends to be highly subjective. Nevertheless some code smells detection tools have been proposed. Other recent approaches incline towards machine learning (ML) techniques to overcome disadvantages of using automatic detection tools. Objectives: We aim to develop a research infrastructure and reproduce the process of code smell prediction proposed by Arcelli Fontana et al. We investigate ML algorithms performance for samples including major modern Java language features. Those such as lambdas can shorten the code causing code smell presence not as obvious to detect and thus pose a challenge to both existing code smell detection tools and ML algorithms. Method: We extend the study with dataset consisting of 281 Java projects. For driving samples selection we define metrics considering lambdas and method reference, derived using custom JavaParser-based solution. Tagged samples with new constructions are used as an input for the utilized detection techniques. Results: Detection rules derived from the best performing algorithms like J48 and JRip incorporate newly introduced metrics. Conclusions: Presence of certain new Java language constructs may hide Long Method code smell or indicate a God Class. On the other hand, their absence or low number can suggest a Data Class.\",\n    isbn = \"978-3-030-34706-2\",\n    doi = \"10.1007/978-3-030-34706-2\\_8\",\n    url = \"https://doi.org/10.1007/978-3-030-34706-2\\_8\"\n}\n\n",
    "abstract": "Background: Defining code smell is not a trivial task. Their recognition tends to be highly\nsubjective. Nevertheless some code smells detection tools have been proposed. Other recent approaches incline\ntowards machine learning (ML) techniques to overcome disadvantages of using automatic detection tools.\nObjectives: We aim to develop a research infrastructure and reproduce the process of code smell prediction\nproposed by Arcelli Fontana et al. We investigate ML algorithms performance for samples including major\nmodern Java language features. Those such as lambdas can shorten the code causing code smell presence not\nas obvious to detect and thus pose a challenge to both existing code smell detection tools and ML algorithms.\nMethod: We extend the study with dataset consisting of 281 Java projects. For driving samples selection we\ndefine metrics considering lambdas and method reference, derived using custom JavaParser-based solution.\nTagged samples with new constructions are used as an input for the utilized detection techniques.\nResults: Detection rules derived from the best performing algorithms like J48 and JRip incorporate newly\nintroduced metrics.\nConclusions: Presence of certain new Java language constructs may hide Long Method code smell or indicate\na God Class. On the other hand, their absence or low number can suggest a Data Class"
}, {
    "py/object": "data.DataClassPaper",
    "Title": "Code smell severity classification using machine learning techniques",
    "year": 2017,
    "ML_Techniques": "SVM, SMO, NB, RF, Ripper, DT",
    "Category": "Quality assessment",
    "Sub_category": "Code smell detection",
    "Venue": "KBS",
    "Link": "https://www.sciencedirect.com/science/article/pii/S0950705117301880",
    "bibtex": "article{ArcelliFontana2017_209,\n    author = \"{Arcelli Fontana}, Francesca and Zanoni, Marco\",\n    title = \"Code smell severity classification using machine learning techniques\",\n    journal = \"Knowledge-Based Systems\",\n    volume = \"128\",\n    pages = \"43 - 58\",\n    year = \"2017\",\n    issn = \"0950-7051\",\n    doi = \"https://doi.org/10.1016/j.knosys.2017.04.014\",\n    url = \"http://www.sciencedirect.com/science/article/pii/S0950705117301880\",\n    keywords = \"Code smells detection, Machine learning, Code smell severity, Ordinal classification, Refactoring prioritization\"\n}\n\n",
    "abstract": "Several code smells detection tools have been developed providing different results, because smells can be subjectively interpreted and hence detected in different ways. Machine learning techniques have been used for different topics in software engineering, e.g., design pattern detection, code smell detection, bug prediction, recommending systems. In this paper, we focus our attention on the classification of code smell severity through the use of machine learning techniques in different experiments. The severity of code smells is an important factor to take into consideration when reporting code smell detection re- sults, since it allows the prioritization of refactoring efforts. In fact, code smells with high severity can be particularly large and complex, and create larger issues to the maintainability of software a system. In our experiments, we apply several machine learning models, spanning from multinomial classification to regression, plus a method to apply binary classifiers for ordinal classification. In fact, we model code smell severity as an ordinal variable. We take the baseline models from previous work, where we applied binary classification models for code smell detection with good results. We report and compare the per- formance of the models according to their accuracy and four different performance measures used for the evaluation of ordinal classification techniques. From our results, while the accuracy of the classification of severity is not high as in the binary classification of absence or presence of code smells, the ranking correlation of the actual and predicted severity for the best models reaches 0.88\u20130.96, measured through Spearman\u2019s \u03c1."
}, {
    "py/object": "data.DataClassPaper",
    "Title": "Comparing and experimenting machine learning techniques for code smell detection",
    "year": 2016,
    "ML_Techniques": "DT, Ripper, RF, NB, SMO, SVM",
    "Category": "Quality assessment",
    "Sub_category": "Code smell detection",
    "Venue": "EMSE",
    "Link": "https://link.springer.com/article/10.1007/s10664-015-9378-4",
    "bibtex": "article{Fontana2015_211,\n\ttitle={Comparing and experimenting machine learning techniques for code smell detection},\n\tauthor={F. Fontana and M. M{\\\"a}ntyl{\\\"a} and Marco Zanoni and Alessandro Marino},\n\tjournal={Empirical Software Engineering},\n\tyear={2015},\n\tvolume={21},\n\tpages={1143-1191}\n}\n\n",
    "abstract": "Several code smell detection tools have been developed providing different results,\nbecause smells can be subjectively interpreted, and hence detected, in different ways. In this\npaper, we perform the largest experiment of applying machine learning algorithms to code\nsmells to the best of our knowledge. We experiment 16 different machine-learning algorithms\non four code smells (Data Class, Large Class, Feature Envy, Long Method) and 74 software\nsystems, with 1986 manually validated code smell samples. We found that all algorithms\nachieved high performances in the cross-validation data set, yet the highest performances were\nobtained by J48 and Random Forest, while the worst performance were achieved by support\nvector machines. However, the lower prevalence of code smells, i.e., imbalanced data, in the\nentire data set caused varying performances that need to be addressed in the future studies. We\nconclude that the application of machine learning to the detection of these code smells can\nprovide high accuracy (>96 %), and only a hundred training examples are needed to reach at\nleast 95 % accuracy."
}, {
    "py/object": "data.DataClassPaper",
    "Title": "Comparing Heuristic and Machine Learning Approaches for Metric-Based Code Smell Detection",
    "year": 2019,
    "ML_Techniques": "DT, RF, NB, SVM, Ripper",
    "Category": "Quality assessment",
    "Sub_category": "Code smell detection",
    "Venue": "ICPC",
    "Link": "https://ieeexplore.ieee.org/document/8813271",
    "bibtex": "INPROCEEDINGS{Pecorelli2019_212,\n    author = \"{Pecorelli}, F. and {Palomba}, F. and {Di Nucci}, D. and {De Lucia}, A.\",\n    booktitle = \"2019 IEEE/ACM 27th International Conference on Program Comprehension (ICPC)\",\n    title = \"Comparing Heuristic and Machine Learning Approaches for Metric-Based Code Smell Detection\",\n    year = \"2019\",\n    volume = \"\",\n    number = \"\",\n    pages = \"93-104\"\n}\n\n",
    "abstract": "Code smells represent poor implementation choices\nperformed by developers when enhancing source code. Their\nnegative impact on source code maintainability and comprehensibility\nhas been widely shown in the past and several techniques\nto automatically detect them have been devised. Most of these\ntechniques are based on heuristics, namely they compute a set of\ncode metrics and combine them by creating detection rules; while\nthey have a reasonable accuracy, a recent trend is represented\nby the use of machine learning where code metrics are used as\npredictors of the smelliness of code artefacts. Despite the recent\nadvances in the field, there is still a noticeable lack of knowledge\nof whether machine learning can actually be more accurate than\ntraditional heuristic-based approaches. To fill this gap, in this\npaper we propose a large-scale study to empirically compare\nthe performance of heuristic-based and machine-learning-based\ntechniques for metric-based code smell detection. We consider\nfive code smell types and compare machine learning models with\nDECOR, a state-of-the-art heuristic-based approach. Key findings\nemphasize the need of further research aimed at improving the\neffectiveness of both machine learning and heuristic approaches\nfor code smell detection: while DECOR generally achieves better\nperformance than a machine learning baseline, its precision is\nstill too low to make it usable in practice."
}, {
    "py/object": "data.DataClassPaper",
    "Title": "Cross-Language Learning for Program Classification using Bilateral Tree-Based Convolutional Neural Networks",
    "year": 2018,
    "ML_Techniques": "",
    "Category": "Quality assessment",
    "Sub_category": "Clone detection",
    "Venue": "AAAI",
    "Link": "https://arxiv.org/abs/1710.06159v2",
    "bibtex": "inproceedings{Bui2018_214,\n    author = \"Bui, Nghi D. Q. and Jiang, Lingixao and Yu, Y.\",\n    title = \"Cross-Language Learning for Program Classification using Bilateral Tree-Based Convolutional Neural Networks\",\n    booktitle = \"AAAI Workshops\",\n    year = \"2018\"\n}\n\n",
    "abstract": "Towards the vision of translating code that implements an algorithm\nfrom one programming language into another, this\npaper proposes an approach for automated program classification\nusing bilateral tree-based convolutional neural networks\n(BiTBCNNs). It is layered on top of two tree-based\nconvolutional neural networks (TBCNNs), each of which recognizes\nthe algorithm of code written in an individual programming\nlanguage. The combination layer of the networks\nrecognizes the similarities and differences among code in different\nprogramming languages. The BiTBCNNs are trained\nusing the source code in different languages but known to\nimplement the same algorithms and/or functionalities. For\na preliminary evaluation, we use 3591 Java and 3534 C++\ncode snippets from 6 algorithms we crawled systematically\nfrom GitHub. We obtained over 90% accuracy in the crosslanguage\nbinary classification task to tell whether any given\ntwo code snippets implement a same algorithm. Also, for the\nalgorithm classification task, i.e., to predict which one of the\nsix algorithm labels is implemented by an arbitrary C++ code\nsnippet, we achieved over 80% precision."
}, {
    "py/object": "data.DataClassPaper",
    "Title": "Deep learning code fragments for code clone detection",
    "year": 2016,
    "ML_Techniques": "RNN, ReNN",
    "Category": "Quality assessment",
    "Sub_category": "Clone detection,,Clone detection,Clone detection,Clone detection,Clone detection,Clone detection,Clone detection,Clone detection,,Clone detection,Clone detection,Clone detection",
    "Venue": "ASE",
    "Link": "https://dl.acm.org/doi/10.1145/2970276.2970326",
    "bibtex": "inproceedings{Bui2018_214,\n    author = \"Bui, Nghi D. Q. and Jiang, Lingixao and Yu, Y.\",\n    title = \"Cross-Language Learning for Program Classification using Bilateral Tree-Based Convolutional Neural Networks\",\n    booktitle = \"AAAI Workshops\",\n    year = \"2018\"\n}\n\n",
    "abstract": "Code clone detection is an important problem for software\nmaintenance and evolution. Many approaches consider ei-\nther structure or identifiers, but none of the existing detec-\ntion techniques model both sources of information. These\ntechniques also depend on generic, handcrafted features to\nrepresent code fragments. We introduce learning-based de-\ntection techniques where everything for representing terms\nand fragments in source code is mined from the repository.\nOur code analysis supports a framework, which relies on\ndeep learning, for automatically linking patterns mined at\nthe lexical level with patterns mined at the syntactic level.\nWe evaluated our novel learning-based approach for code\nclone detection with respect to feasibility from the point\nof view of software maintainers. We sampled and manually\nevaluated 398 file- and 480 method-level pairs across eight\nreal-world Java systems; 93% of the file- and method-level\nsamples were evaluated to be true positives. Among the true\npositives, we found pairs mapping to all four clone types.We\ncompared our approach to a traditional structure-oriented\ntechnique and found that our learning-based approach de-\ntected clones that were either undetected or suboptimally\nreported by the prominent tool Deckard. Our results affirm\nthat our learning-based approach is suitable for clone detec-\ntion and a tenable technique for researchers."
}, {
    "py/object": "data.DataClassPaper",
    "Title": "DeepSim: deep learning code functional similarity",
    "year": 2018,
    "ML_Techniques": "DNN",
    "Category": "Quality assessment",
    "Sub_category": "Clone detection",
    "Venue": "FSE",
    "Link": "https://dl.acm.org/doi/10.1145/3236024.3236068",
    "bibtex": "inproceedings{Bui2018_214,\n    author = \"Bui, Nghi D. Q. and Jiang, Lingixao and Yu, Y.\",\n    title = \"Cross-Language Learning for Program Classification using Bilateral Tree-Based Convolutional Neural Networks\",\n    booktitle = \"AAAI Workshops\",\n    year = \"2018\"\n}\n\n",
    "abstract": "Measuring code similarity is fundamental for many software engineering\ntasks, e.g., code search, refactoring and reuse. However,\nmost existing techniques focus on code syntactical similarity only,\nwhile measuring code functional similarity remains a challenging\nproblem. In this paper, we propose a novel approach that encodes\ncode control flow and data flow into a semantic matrix in which\neach element is a high dimensional sparse binary feature vector,\nand we design a new deep learning model that measures code functional\nsimilarity based on this representation. By concatenating\nhidden representations learned from a code pair, this new model\ntransforms the problem of detecting functionally similar code to\nbinary classification, which can effectively learn patterns between\nfunctionally similar code with very different syntactics.\nWe have implemented our approach, DeepSim, for Java programs\nand evaluated its recall, precision and time performance on two\nlarge datasets of functionally similar code. The experimental results\nshow that DeepSim significantly outperforms existing state-of-theart\ntechniques, such as DECKARD, RtvNN, CDLH, and two baseline\ndeep neural networks models."
}, {
    "py/object": "data.DataClassPaper",
    "Title": "Design Flaws Prediction for Impact on Software Maintainability using Extreme Learning Machine",
    "year": 2020,
    "ML_Techniques": "ELM, LR, DT, PR, LOG",
    "Category": "Quality assessment",
    "Sub_category": "Code smell detection",
    "Venue": "JIC",
    "Link": "https://ieeexplore.ieee.org/document/9090717",
    "bibtex": "INPROCEEDINGS{Thongkum2020_217,\n    author = \"{Thongkum}, P. and {Mekruksavanich}, S.\",\n    booktitle = \"2020 Joint International Conference on Digital Arts, Media and Technology with ECTI Northern Section Conference on Electrical, Electronics, Computer and Telecommunications Engineering (ECTI DAMT NCON)\",\n    title = \"Design Flaws Prediction for Impact on Software Maintainability using Extreme Learning Machine\",\n    year = \"2020\",\n    volume = \"\",\n    number = \"\",\n    pages = \"79-82\",\n    doi = \"10.1109/ECTIDAMTNCON48261.2020.9090717\"\n}\n\n",
    "abstract": "The software that contains flaws in its design is\nan indication that the design and coding standards have been\nviolated by the developer during the software system\u2019s development.\nIt has been observed in recent empirical studies that\nclasses with flaws in the design flaws have a higher probability\nof change proneness or fault proneness when compared to\nclasses without flaws in the design. There is an exponential\nincrease in terms of the effort required to remove bugs due\nto design flaws in cases where the flaws are not detected in\nthe early stages of the development of the software. The use\nof source code metrics for the prediction of design flaws can\nbe implemented in the initial stages of the life cycle of the\nsoftware development for the reduction of the testing effort and\nthe maintenance of the software as well as the improvement of\nits quality. This empirical research study examines and assesses a\nvariety of techniques for classification, feature selection, and data\nsampling in order to deal with the imbalance data for prediction\nof several categories of design flaws. The assessment of more\nthan 20 application packages is the basis of the conclusions\nof this study. The results of the experiments indicate that the\nestimating capability of various classifiers, feature selection, and\ndata imbalance techniques for the development of prediction\nmodels for design flaws can be confirmed. In addition, it was\nalso revealed that the models that were developed through the\nuse of one particular technique were found to be superior to the\nmodels that were developed with the use of other techniques,\naccording to our analysis."
}, {
    "py/object": "data.DataClassPaper",
    "Title": "Detecting bad smells with machine learning algorithms: an empirical study",
    "year": 2020,
    "ML_Techniques": "NB, LR, DT, MLP, KNN, RF, GBM",
    "Category": "Quality assessment",
    "Sub_category": "Code smell detection",
    "Venue": "TechDebt",
    "Link": "https://dl.acm.org/doi/abs/10.1145/3387906.3388618",
    "bibtex": "INPROCEEDINGS{Thongkum2020_217,\n    author = \"{Thongkum}, P. and {Mekruksavanich}, S.\",\n    booktitle = \"2020 Joint International Conference on Digital Arts, Media and Technology with ECTI Northern Section Conference on Electrical, Electronics, Computer and Telecommunications Engineering (ECTI DAMT NCON)\",\n    title = \"Design Flaws Prediction for Impact on Software Maintainability using Extreme Learning Machine\",\n    year = \"2020\",\n    volume = \"\",\n    number = \"\",\n    pages = \"79-82\",\n    doi = \"10.1109/ECTIDAMTNCON48261.2020.9090717\"\n}\n\n",
    "abstract": "Bad smells are symptoms of bad design choices implemented on the source code. They are one of the key indicators of technical debts, specifically, design debt. To manage this kind of debt, it is important to be aware of bad smells and refactor them whenever possible. Therefore, several bad smell detection tools and techniques have been proposed over the years. These tools and techniques present different strategies to perform detections. More recently, machine learning algorithms have also been proposed to support bad smell detection. However, we lack empirical evidence on the accuracy and efficiency of these machine learning based techniques. In this paper, we present an evaluation of seven different machine learning algorithms on the task of detecting four types of bad smells. We also provide an analysis of the impact of software metrics for bad smell detection using a unified approach for interpreting the models' decisions. We found that with the right optimization, machine learning algorithms can achieve good performance (F1 score) for two bad smells: God Class (0.86) and Refused Parent Bequest (0.67). We also uncovered which metrics play fundamental roles for detecting each bad smell."
}, {
    "py/object": "data.DataClassPaper",
    "Title": "Detecting code smells using machine learning techniques: are we there yet?",
    "year": 2018,
    "ML_Techniques": "DT, Ripper, RF, NB, SMO, SVM",
    "Category": "Quality assessment",
    "Sub_category": "Code smell detection",
    "Venue": "SANER",
    "Link": "https://ieeexplore.ieee.org/document/8330266",
    "bibtex": "INPROCEEDINGS{Thongkum2020_217,\n    author = \"{Thongkum}, P. and {Mekruksavanich}, S.\",\n    booktitle = \"2020 Joint International Conference on Digital Arts, Media and Technology with ECTI Northern Section Conference on Electrical, Electronics, Computer and Telecommunications Engineering (ECTI DAMT NCON)\",\n    title = \"Design Flaws Prediction for Impact on Software Maintainability using Extreme Learning Machine\",\n    year = \"2020\",\n    volume = \"\",\n    number = \"\",\n    pages = \"79-82\",\n    doi = \"10.1109/ECTIDAMTNCON48261.2020.9090717\"\n}\n\n",
    "abstract": "Code smells are symptoms of poor design and implementation\nchoices weighing heavily on the quality of produced\nsource code. During the last decades several code smell detection\ntools have been proposed. However, the literature shows that\nthe results of these tools can be subjective and are intrinsically\ntied to the nature and approach of the detection. In a recent\nwork the use of Machine-Learning (ML) techniques for code\nsmell detection has been proposed, possibly solving the issue\nof tool subjectivity giving to a learner the ability to discern\nbetween smelly and non-smelly source code elements. While this\nwork opened a new perspective for code smell detection, it only\nconsidered the case where instances affected by a single type\nsmell are contained in each dataset used to train and test the\nmachine learners. In this work we replicate the study with a\ndifferent dataset configuration containing instances of more than\none type of smell. The results reveal that with this configuration\nthe machine learning techniques reveal critical limitations in the\nstate of the art which deserve further research."
}, {
    "py/object": "data.DataClassPaper",
    "Title": "Detection of Memory Leaks in C/C++ Code via Machine Learning",
    "year": 2017,
    "ML_Techniques": "DT",
    "Category": "Quality assessment",
    "Sub_category": "Quality assessment/prediction,Static or dynamic quality assessment,Quality assessment/prediction,Quality assessment/prediction,Static or dynamic quality assessment,Quality assessment/prediction,Static or dynamic quality assessment",
    "Venue": "ISSREW",
    "Link": "https://ieeexplore.ieee.org/abstract/document/8109292",
    "bibtex": "INPROCEEDINGS{Andrzejak2017_221,\n    author = \"{Andrzejak}, A. and {Eichler}, F. and {Ghanavati}, M.\",\n    booktitle = \"2017 IEEE International Symposium on Software Reliability Engineering Workshops (ISSREW)\",\n    title = \"Detection of Memory Leaks in C/C++ Code via Machine Learning\",\n    year = \"2017\",\n    volume = \"\",\n    number = \"\",\n    pages = \"252-258\",\n    doi = \"10.1109/ISSREW.2017.72\"\n}\n\n",
    "abstract": "Memory leaks are one of the primary causes of\nsoftware aging. Despite of recent countermeasures in C/C++ such\nas smart pointers, leak-related defects remain a troublesome issue\nin C/C++ code, especially in legacy applications.\nWe propose an approach for automatic detection of memory leaks\nin C/C++ programs based on characterizing memory allocation\nsites via the age distribution of the non-disposed memory chunks\nallocated by such a site (the so-called GenCount-technique introduced\nfor Java by Vladimir \u0160or). We instrument malloc and\nfree calls in C/C++ and collect for each allocation site data on\nthe number of allocated memory fragments, their lifetimes, and\nsizes. Based on this data we compute feature vectors and train\na machine learning classifier to differentiate between leaky and\ndefect-free allocation sites.\nOur evaluation uses applications from SPEC CPU2006 suite with\ninjected memory leaks resembling real leaks. The results show\nthat even out-of-the-box classification algorithms can achieve\nhigh accuracy, with precision and recall values of 0.93 and 0.88,\nrespectively."
}, {
    "py/object": "data.DataClassPaper",
    "Title": "Experience report: Evaluating the effectiveness of decision trees for detecting code smells",
    "year": 2015,
    "ML_Techniques": "DT",
    "Category": "Quality assessment",
    "Sub_category": "Code smell detection",
    "Venue": "ISSRE",
    "Link": "https://ieeexplore.ieee.org/abstract/document/7381819",
    "bibtex": "INPROCEEDINGS{Amorim2015_223,\n    author = \"{Amorim}, L. and {Costa}, E. and {Antunes}, N. and {Fonseca}, B. and {Ribeiro}, M.\",\n    booktitle = \"2015 IEEE 26th International Symposium on Software Reliability Engineering (ISSRE)\",\n    title = \"Experience report: Evaluating the effectiveness of decision trees for detecting code smells\",\n    year = \"2015\",\n    volume = \"\",\n    number = \"\",\n    pages = \"261-269\",\n    doi = \"10.1109/ISSRE.2015.7381819\"\n}\n\n",
    "abstract": "Developers continuously maintain software systems\nto adapt to new requirements and to fix bugs. Due to the complexity\nof maintenance tasks and the time-to-market, developers\nmake poor implementation choices, also known as code smells.\nStudies indicate that code smells hinder comprehensibility, and\npossibly increase change- and fault-proneness. Therefore, they\nmust be identified to enable the application of corrections. The\nchallenge is that the inaccurate definitions of code smells make\ndevelopers disagree whether a piece of code is a smell or not,\nconsequently, making difficult creation of a universal detection\nsolution able to recognize smells in different software projects.\nSeveral works have been proposed to identify code smells but\nthey still report inaccurate results and use techniques that do\nnot present to developers a comprehensive explanation how these\nresults have been obtained. In this experimental report we study\nthe effectiveness of the Decision Tree algorithm to recognize code\nsmells. For this, it was applied in a dataset containing 4 open\nsource projects and the results were compared with the manual\noracle, with existing detection approaches and with other machine\nlearning algorithms. The results showed that the approach was\nable to effectively learn rules for the detection of the code smells\nstudied. The results were even better when genetic algorithms\nare used to pre-select the metrics to use."
}, {
    "py/object": "data.DataClassPaper",
    "Title": "Functional code clone detection with syntax and semantics fusion learning",
    "year": 2020,
    "ML_Techniques": "DNN",
    "Category": "Quality assessment",
    "Sub_category": "Clone detection",
    "Venue": "ISSTA",
    "Link": "https://dl.acm.org/doi/10.1145/3395363.3397362",
    "bibtex": "INPROCEEDINGS{Amorim2015_223,\n    author = \"{Amorim}, L. and {Costa}, E. and {Antunes}, N. and {Fonseca}, B. and {Ribeiro}, M.\",\n    booktitle = \"2015 IEEE 26th International Symposium on Software Reliability Engineering (ISSRE)\",\n    title = \"Experience report: Evaluating the effectiveness of decision trees for detecting code smells\",\n    year = \"2015\",\n    volume = \"\",\n    number = \"\",\n    pages = \"261-269\",\n    doi = \"10.1109/ISSRE.2015.7381819\"\n}\n\n",
    "abstract": "Clone detection of source code is among the most fundamental\nsoftware engineering techniques. Despite intensive research in the\npast decade, existing techniques are still unsatisfactory in detecting\n\"functional\" code clones. In particular, existing techniques cannot\nefficiently extract syntax and semantics information from source\ncode. In this paper, we propose a novel joint code representation\nthat applies fusion embedding techniques to learn hidden syntactic\nand semantic features of source codes. Besides, we introduce a\nnew granularity for functional code clone detection. Our approach\nregards the connected methods with caller-callee relationships as a\nfunctionality and the method without any caller-callee relationship\nwith other methods represents a single functionality. Then we train\na supervised deep learning model to detect functional code clones.\nWe conduct evaluations on a large dataset of C++ programs and\nthe experimental results show that fusion learning can significantly\noutperform the state-of-the-art techniques in detecting functional\ncode clones."
}, {
    "py/object": "data.DataClassPaper",
    "Title": "Investigating Non-Usually Employed Features in the Identification of Architectural Smells: A Machine Learning-Based Approach",
    "year": 2020,
    "ML_Techniques": "NB, NN, KNN, B, AB, RF, SVM, DT",
    "Category": "Quality assessment",
    "Sub_category": "Code smell detection",
    "Venue": "BSSCAR",
    "Link": "https://dl.acm.org/doi/abs/10.1145/3425269.3425281",
    "bibtex": "INPROCEEDINGS{Amorim2015_223,\n    author = \"{Amorim}, L. and {Costa}, E. and {Antunes}, N. and {Fonseca}, B. and {Ribeiro}, M.\",\n    booktitle = \"2015 IEEE 26th International Symposium on Software Reliability Engineering (ISSRE)\",\n    title = \"Experience report: Evaluating the effectiveness of decision trees for detecting code smells\",\n    year = \"2015\",\n    volume = \"\",\n    number = \"\",\n    pages = \"261-269\",\n    doi = \"10.1109/ISSRE.2015.7381819\"\n}\n\n",
    "abstract": "Architectural smells (ASs) negatively affect the maintenance and evolution of software at the architectural level. Most of the current approaches for ASs identification rely on the same small and well-known set of usually employed metrics (UE-Ms) with fixed thresholds. Machine learning (ML) is a promising technique for smell identification as algorithms can learn from a rich set of metrics/features, covering several characteristics of the software and incorporating a certain degree of subjectivity. This has been explored by building datasets with a robust and rich set of features, including not only the UE-Ms but also other non-usually employed metrics (NUE-Ms). However, usually the UE-Ms determine the output of the algorithms, obfuscating other metrics that have the potential to improve the classification. This also leads to inflated and difficult to maintain datasets. In this paper, we investigate the accuracy of some ML algorithms employing only NUE-Ms. We scoped our study in the classification of two smells: God Component and Unstable Dependency. This investigation revealed a set of NUE-Ms that can be also used to identify these smells and the contribution of each one for the classification. Based on this information, software engineers can then build a final dataset just with the potential features. We also briefly present our tool, called InSet, that was used by academics and practitioners to identify smells in their systems. The feedback of them was used as the oracle to compare our tool to other approaches and good results were reached."
}, {
    "py/object": "data.DataClassPaper",
    "Title": "Keep it simple: Is deep learning good for linguistic smell detection?",
    "year": 2018,
    "ML_Techniques": "RF, SVM, DT, NB, CNN",
    "Category": "Quality assessment",
    "Sub_category": "Code smell detection",
    "Venue": "SANER",
    "Link": "https://ieeexplore.ieee.org/document/8330265",
    "bibtex": "INPROCEEDINGS{Fakhoury2018_232,\n    author = \"{Fakhoury}, S. and {Arnaoudova}, V. and {Noiseux}, C. and {Khomh}, F. and {Antoniol}, G.\",\n    booktitle = \"2018 IEEE 25th International Conference on Software Analysis, Evolution and Reengineering (SANER)\",\n    title = \"Keep it simple: Is deep learning good for linguistic smell detection?\",\n    year = \"2018\",\n    volume = \"\",\n    number = \"\",\n    pages = \"602-611\",\n    doi = \"10.1109/SANER.2018.8330265\"\n}\n\n",
    "abstract": "Deep neural networks is a popular technique that\nhas been applied successfully to domains such as image processing,\nsentiment analysis, speech recognition, and computational\nlinguistic. Deep neural networks are machine learning algorithms\nthat, in general, require a labeled set of positive and negative\nexamples that are used to tune hyper-parameters and adjust\nmodel coefficients to learn a prediction function. Recently, deep\nneural networks have also been successfully applied to certain\nsoftware engineering problem domains (e.g., bug prediction),\nhowever, results are shown to be outperformed by traditional\nmachine learning approaches in other domains (e.g., recovering\nlinks between entries in a discussion forum).\nIn this paper, we report our experience in building an automatic\nLinguistic Antipattern Detector (LAPD) using deep neural\nnetworks. We manually build and validate an oracle of around\n1,700 instances and create binary classification models using traditional\nmachine learning approaches and Convolutional Neural\nNetworks. Our experience is that, considering the size of the\noracle, the available hardware and software, as well as the theory\nto interpret results, deep neural networks are outperformed by\ntraditional machine learning algorithms in terms of all evaluation\nmetrics we used and resources (time and memory).\nTherefore, although deep learning is reported to produce results\ncomparable and even superior to human experts for certain\ncomplex tasks, it does not seem to be a good fit for simple classification\ntasks like smell detection. Researchers and practitioners\nshould be careful when selecting machine learning models for\nthe problem at hand."
}, {
    "py/object": "data.DataClassPaper",
    "Title": "Learning a classifier for false positive error reports emitted by static code analysis tools",
    "year": 2017,
    "ML_Techniques": "NB, LSTM",
    "Category": "Quality assessment",
    "Sub_category": "Quality assessment/prediction,Static or dynamic quality assessment,Quality assessment/prediction,Quality assessment/prediction,Static or dynamic quality assessment,Quality assessment/prediction,Static or dynamic quality assessment",
    "Venue": "MAPL",
    "Link": "https://dl.acm.org/doi/abs/10.1145/3088525.3088675",
    "bibtex": "INPROCEEDINGS{Fakhoury2018_232,\n    author = \"{Fakhoury}, S. and {Arnaoudova}, V. and {Noiseux}, C. and {Khomh}, F. and {Antoniol}, G.\",\n    booktitle = \"2018 IEEE 25th International Conference on Software Analysis, Evolution and Reengineering (SANER)\",\n    title = \"Keep it simple: Is deep learning good for linguistic smell detection?\",\n    year = \"2018\",\n    volume = \"\",\n    number = \"\",\n    pages = \"602-611\",\n    doi = \"10.1109/SANER.2018.8330265\"\n}\n\n",
    "abstract": "The large scale and high complexity of modern software systems\nmake perfectly precise static code analysis (SCA) infeasible. Therefore\nSCA tools often over-approximate, so not to miss any real\nproblems. This, however, comes at the expense of raising false\nalarms, which, in practice, reduces the usability of these tools.\nTo partially address this problem, we propose a novel learning\nprocess whose goal is to discover program structures that cause\na given SCA tool to emit false error reports, and then to use this\ninformation to predict whether a new error report is likely to be a\nfalse positive as well. To do this, we first preprocess code to isolate\nthe locations that are related to the error report. Then, we apply\nmachine learning techniques to the preprocessed code to discover\ncorrelations and to learn a classifier.\nWe evaluated this approach in an initial case study of a widelyused\nSCA tool for Java. Our results showed that for our dataset\nwe could accurately classify a large majority of false positive error\nreports. Moreover, we identified some common coding patterns that\nled to false positive errors. We believe that SCA developers may be\nable to redesign their methods to address these patterns and reduce\nfalse positive error reports."
}, {
    "py/object": "data.DataClassPaper",
    "Title": "Machine Learning Approach for Reliability Assessment of Open Source Software",
    "year": 2019,
    "ML_Techniques": "NB, DT, RF, SVM, ANN, PNN",
    "Category": "Quality assessment",
    "Sub_category": "Quality assessment/prediction,Static or dynamic quality assessment,Quality assessment/prediction,Quality assessment/prediction,Static or dynamic quality assessment,Quality assessment/prediction,Static or dynamic quality assessment",
    "Venue": "ICCSA",
    "Link": "https://link.springer.com/chapter/10.1007/978-3-030-24305-0_35",
    "bibtex": "InProceedings{Behera2019_235,\n    author = \"Behera, Ranjan Kumar and Rath, Santanu Kumar and Misra, Sanjay and Leon, Marcelo and Adewumi, Adewole\",\n    editor = \"Misra, Sanjay and Gervasi, Osvaldo and Murgante, Beniamino and Stankova, Elena and Korkhov, Vladimir and Torre, Carmelo and Rocha, Ana Maria A.C. and Taniar, David and Apduhan, Bernady O. and Tarantino, Eufemia\",\n    title = \"Machine Learning Approach for Reliability Assessment of Open Source Software\",\n    booktitle = \"Computational Science and Its Applications -- ICCSA 2019\",\n    year = \"2019\",\n    publisher = \"Springer International Publishing\",\n    address = \"Cham\",\n    pages = \"472--482\",\n    abstract = \"Some of the quality parameters for any successful open source software may be attributed to affordability, availability of source code, re-distributability, and modifiability etc. Quality of software can be further improvised subsequently by either users or associated developers by constantly monitoring some of the reliability aspects. Since multiple users are allowed to modify the code there is a potential threat for security, which might degrade the reliability of software. Bug tracking systems are often considered to monitor various software faults, detected mostly in open source software projects. Various authors have made research in this direction by applying different techniques in order to improve the reliability of open source software projects. In this work, an various machine learning models have been implemented to examine the reliability of the software. An extensive numerical illustration has also been presented for bug data recorded on bug tracking system. The effectiveness of machine learning models for estimating the level of faults associated with the systems has been verified by comparing it with similar approaches as available in the literature.\",\n    isbn = \"978-3-030-24305-0\"\n}\n\n",
    "abstract": "Some of the quality parameters for any successful open source\nsoftware may be attributed to a ordability, availability of source code,\nre-distributability, and modi ability etc. Quality of software can be fur-\nther improvised subsequently by either users or associated developers by\nconstantly monitoring some of the reliability aspects. Since multiple users\nare allowed to modify the code there is a potential threat for security,\nwhich might degrade the reliability of software. Bug tracking systems\nare often considered to monitor various software faults, detected mostly\nin open source software projects. Various authors have made research in\nthis direction by applying di erent techniques in order to improve the\nreliability of open source software projects. In this work, an various ma-\nchine learning models have been implemented to examine the reliability\nof the software. An extensive numerical illustration has also been pre-\nsented for bug data recorded on bug tracking system. The e ectiveness of\nmachine learning models for estimating the level of faults associated with\nthe systems has been veri ed by comparing it with similar approaches\nas available in the literature."
}, {
    "py/object": "data.DataClassPaper",
    "Title": "Machine learning techniques for code smell detection: A systematic literature review and meta-analysis",
    "year": 2019,
    "ML_Techniques": "",
    "Category": "Quality assessment",
    "Sub_category": "Code smell detection",
    "Venue": "IST",
    "Link": "https://www.worldscientific.com/doi/abs/10.1142/S021819401950013X",
    "bibtex": "article{Azeem2019_240,\n    author = \"Azeem, Muhammad Ilyas and Palomba, Fabio and Shi, Lin and Wang, Qing\",\n    title = \"Machine learning techniques for code smell detection: A systematic literature review and meta-analysis\",\n    journal = \"Information and Software Technology\",\n    volume = \"108\",\n    pages = \"115 - 138\",\n    year = \"2019\",\n    issn = \"0950-5849\",\n    doi = \"https://doi.org/10.1016/j.infsof.2018.12.009\",\n    url = \"http://www.sciencedirect.com/science/article/pii/S0950584918302623\",\n    keywords = \"Code smells, Machine learning, Systematic literature review\"\n}\n\n",
    "abstract": "Background : Code smells indicate suboptimal design or implementation choices in the source code that often lead it to be more change- and fault-prone. Researchers defined dozens of code smell detectors, which exploit different sources of information to support developers when diagnosing design flaws. Despite their good accuracy, previous work pointed out three important limitations that might preclude the use of code smell detectors in practice: (i) subjectiveness of developers with respect to code smells detected by such tools, (ii) scarce agreement between different detectors, and (iii) difficulties in finding good thresholds to be used for detection. To overcome these limitations, the use of machine learning techniques represents an ever increasing research area. Objective : While the research community carefully studied the methodologies applied by researchers when defin- ing heuristic-based code smell detectors, there is still a noticeable lack of knowledge on how machine learning approaches have been adopted for code smell detection and whether there are points of improvement to allow a better detection of code smells. Our goal is to provide an overview and discuss the usage of machine learning approaches in the field of code smells. Method : This paper presents a Systematic Literature Review (SLR) on Machine Learning Techniques for Code Smell Detection. Our work considers papers published between 2000 and 2017. Starting from an initial set of 2456 papers, we found that 15 of them actually adopted machine learning approaches. We studied them under four different perspectives: (i) code smells considered, (ii) setup of machine learning approaches, (iii) design of the evaluation strategies, and (iv) a meta-analysis on the performance achieved by the models proposed so far. Results : The analyses performed show that God Class, Long Method, Functional Decomposition , and Spaghetti Code have been heavily considered in the literature. Decision Trees and Support Vector Machines are the most commonly used machine learning algorithms for code smell detection. Models based on a large set of independent variables have performed well. JRip and Random Forest are the most effective classifiers in terms of perfor- mance. The analyses also reveal the existence of several open issues and challenges that the research community should focus on in the future. Conclusion : Based on our findings, we argue that there is still room for the improvement of machine learning techniques in the context of code smell detection. The open issues emerged in this study can represent the input for researchers interested in developing more powerful techniques."
}, {
    "py/object": "data.DataClassPaper",
    "Title": "Machine learning techniques for code smells detection: an empirical experiment on a highly imbalanced setup",
    "year": 2019,
    "ML_Techniques": "RF, NN, KNN, NB, DT, B",
    "Category": "Quality assessment",
    "Sub_category": "Code smell detection",
    "Venue": "SBSI",
    "Link": "https://dl.acm.org/doi/abs/10.1145/3330204.3330275",
    "bibtex": "article{Azeem2019_240,\n    author = \"Azeem, Muhammad Ilyas and Palomba, Fabio and Shi, Lin and Wang, Qing\",\n    title = \"Machine learning techniques for code smell detection: A systematic literature review and meta-analysis\",\n    journal = \"Information and Software Technology\",\n    volume = \"108\",\n    pages = \"115 - 138\",\n    year = \"2019\",\n    issn = \"0950-5849\",\n    doi = \"https://doi.org/10.1016/j.infsof.2018.12.009\",\n    url = \"http://www.sciencedirect.com/science/article/pii/S0950584918302623\",\n    keywords = \"Code smells, Machine learning, Systematic literature review\"\n}\n\n",
    "abstract": "NO Abs"
}, {
    "py/object": "data.DataClassPaper",
    "Title": "Machine-learning-guided selectively unsound static analysis",
    "year": 2017,
    "ML_Techniques": "SVM",
    "Category": "Quality assessment",
    "Sub_category": "Quality assessment/prediction,Static or dynamic quality assessment,Quality assessment/prediction,Quality assessment/prediction,Static or dynamic quality assessment,Quality assessment/prediction,Static or dynamic quality assessment",
    "Venue": "ICSE",
    "Link": "https://dl.acm.org/doi/10.1109/ICSE.2017.54",
    "bibtex": "article{Azeem2019_240,\n    author = \"Azeem, Muhammad Ilyas and Palomba, Fabio and Shi, Lin and Wang, Qing\",\n    title = \"Machine learning techniques for code smell detection: A systematic literature review and meta-analysis\",\n    journal = \"Information and Software Technology\",\n    volume = \"108\",\n    pages = \"115 - 138\",\n    year = \"2019\",\n    issn = \"0950-5849\",\n    doi = \"https://doi.org/10.1016/j.infsof.2018.12.009\",\n    url = \"http://www.sciencedirect.com/science/article/pii/S0950584918302623\",\n    keywords = \"Code smells, Machine learning, Systematic literature review\"\n}\n\n",
    "abstract": "We present a machine-learning-based technique for\nselectively applying unsoundness in static analysis. Existing bugfinding\nstatic analyzers are unsound in order to be precise and\nscalable in practice. However, they are uniformly unsound and\nhence at the risk of missing a large amount of real bugs. By being\nsound, we can improve the detectability of the analyzer but it\noften suffers from a large number of false alarms. Our approach\naims to strike a balance between these two approaches by\nselectively allowing unsoundness only when it is likely to reduce\nfalse alarms, while retaining true alarms. We use an anomalydetection\ntechnique to learn such harmless unsoundness. We\nimplemented our technique in two static analyzers for full C. One\nis for a taint analysis for detecting format-string vulnerabilities,\nand the other is for an interval analysis for buffer-overflow\ndetection. The experimental results show that our approach\nsignificantly improves the recall of the original unsound analysis\nwithout sacrificing the precision."
}, {
    "py/object": "data.DataClassPaper",
    "Title": "Measuring Software Reliability: A Trend Using Machine Learning Techniques",
    "year": 2015,
    "ML_Techniques": "SVR",
    "Category": "Quality assessment",
    "Sub_category": "Quality assessment/prediction,Static or dynamic quality assessment,Quality assessment/prediction,Quality assessment/prediction,Static or dynamic quality assessment,Quality assessment/prediction,Static or dynamic quality assessment",
    "Venue": "Book",
    "Link": "https://link.springer.com/chapter/10.1007/978-3-319-12883-2_28",
    "bibtex": "Inbook{Kumar2015_247,\n    author = \"Kumar, Nishikant and Banerjee, Soumya\",\n    editor = \"Zhu, Quanmin and Azar, Ahmad Taher\",\n    title = \"Measuring Software Reliability: A Trend Using Machine Learning Techniques\",\n    bookTitle = \"Complex System Modelling and Control Through Intelligent Soft Computations\",\n    year = \"2015\",\n    publisher = \"Springer International Publishing\",\n    address = \"Cham\",\n    pages = \"807--829\",\n    abstract = \"It has become inevitable for every software developer to understand, to follow that how and why software fails, and to express reliability in quantitative terms. This has led to a proliferation of software reliability models to estimate and predict reliability. The basic approach is to model past failure data to predict future behavior. Most of the models have three major components: assumptions, factors and a mathematical function, usually high order exponential or logarithmic used to relate factors to reliability. Software reliability models are used to forecast the curve of failure rate by statistical evidence available during testing phase. They also can indicate about the extra time required to carry out the test procedure in order to meet the specifications and deliver desired functionality with minimum number of defects. Therefore there are challenges whether, autonomous or machine learning techniques like other predictive methods could be able to forecast the reliability measures for a specific software application. This chapter contemplates reliability issue through a generic Machine Learning paradigm while referring the most common aspects of Support Vector Machine scenario. Couples of customized simulation and experimental results have been presented to support the proposed reliability measures and strategies.\",\n    isbn = \"978-3-319-12883-2\",\n    doi = \"10.1007/978-3-319-12883-2\\_28\",\n    url = \"https://doi.org/10.1007/978-3-319-12883-2\\_28\"\n}\n\n",
    "abstract": "It has become inevitable for every software developer to understand, to follow that how and why software fails, and to express reliability in quantitative terms. This has led to a proliferation of software reliability models to estimate and predict reliability. The basic approach is to model past failure data to predict future behavior. Most of the models have three major components: assumptions, factors and a mathematical function, usually high order exponential or logarithmic used to relate factors to reliability. Software reliability models are used to forecast the curve of failure rate by statistical evidence available during testing phase. They also can indicate about the extra time required to carry out the test procedure in order to meet the specifications and deliver desired functionality with minimum number of defects. Therefore there are challenges whether, autonomous or machine learning techniques like other predictive methods could be able to forecast the reliability measures for a specific software application. This chapter contemplates reliability issue through a generic Machine Learning paradigm while referring the most common aspects of Support Vector Machine scenario. Couples of customized simulation and experimental results have been presented to support the proposed reliability measures and strategies."
}, {
    "py/object": "data.DataClassPaper",
    "Title": "Mobile-Sandbox: combining static and dynamic analysis with machine-learning techniques",
    "year": 2015,
    "ML_Techniques": "SVM",
    "Category": "Vulnerability analysis",
    "Sub_category": "",
    "Venue": "IJIS",
    "Link": "https://link.springer.com/article/10.1007/s10207-014-0250-0#citeas",
    "bibtex": "article{Spreitzenbarth2014_248,\n    author = \"Spreitzenbarth, Michael and Schreck, Thomas and Echtler, F. and Arp, D. and Hoffmann, Johannes\",\n    title = \"Mobile-Sandbox: combining static and dynamic analysis with machine-learning techniques\",\n    journal = \"International Journal of Information Security\",\n    year = \"2014\",\n    volume = \"14\",\n    pages = \"141-153\"\n}\n\n",
    "abstract": "Smartphones in general and Android in particular are increasingly shifting into the focus of cyber criminals. For understanding the threat to security and privacy, it is important for security researchers to analyze malicious software written for these systems. The exploding number of Android malware calls for automation in the analysis. In this paper, we present Mobile-Sandbox, a system designed to automatically analyze Android applications in novel ways: First, it combines static and dynamic analysis, i.e., results of static analysis are used to guide dynamic analysis and extend coverage of executed code. Additionally, it uses specific techniques to log calls to native (i.e., \u201cnon-Java\u201d) APIs, and last but not least it combines these results with machine-learning techniques to cluster the analyzed samples into benign and malicious ones. We evaluated the system on more than 69,000 applications from Asian third-party mobile markets and found that about 21 % of them actually use native calls in their code."
}, {
    "py/object": "data.DataClassPaper",
    "Title": "On the role of data balancing for machine learning-based code smell detection",
    "year": 2019,
    "ML_Techniques": "CCS, OCC",
    "Category": "Quality assessment",
    "Sub_category": "Code smell detection",
    "Venue": "MALTeSQuE",
    "Link": "https://dl.acm.org/doi/10.1145/3340482.3342744",
    "bibtex": "article{Spreitzenbarth2014_248,\n    author = \"Spreitzenbarth, Michael and Schreck, Thomas and Echtler, F. and Arp, D. and Hoffmann, Johannes\",\n    title = \"Mobile-Sandbox: combining static and dynamic analysis with machine-learning techniques\",\n    journal = \"International Journal of Information Security\",\n    year = \"2014\",\n    volume = \"14\",\n    pages = \"141-153\"\n}\n\n",
    "abstract": "Code smells can compromise software quality in the long term by\ninducing technical debt. For this reason, many approaches aimed\nat identifying these design flaws have been proposed in the last\ndecade. Most of them are based on heuristics in which a set of\nmetrics (e.g., code metrics, process metrics) is used to detect smelly\ncode components. However, these techniques suffer of subjective\ninterpretation, low agreement between detectors, and threshold\ndependability. To overcome these limitations, previouswork applied\nMachine Learning techniques that can learn from previous datasets\nwithout needing any threshold definition. However, more recent\nwork has shown that Machine Learning is not always suitable for\ncode smell detection due to the highly unbalanced nature of the\nproblem. In this study we investigate several approaches able to\nmitigate data unbalancing issues to understand their impact on MLbased\napproaches for code smell detection. Our findings highlight\na number of limitations and open issues with respect to the usage\nof data balancing in ML-based code smell detection."
}, {
    "py/object": "data.DataClassPaper",
    "Title": "On the Use of Machine Learning Techniques Towards the Design of Cloud Based Automatic Code Clone Validation Tools",
    "year": 2018,
    "ML_Techniques": "DT, RF, RT, NB, BN, LR, KS, ANN",
    "Category": "Quality assessment",
    "Sub_category": "Clone detection",
    "Venue": "SCAM",
    "Link": "https://ieeexplore.ieee.org/document/8530729",
    "bibtex": "INPROCEEDINGS{Mostaeen2018_251,\n    author = \"{Mostaeen}, G. and {Svajlenko}, J. and {Roy}, B. and {Roy}, C. K. and {Schneider}, K. A.\",\n    booktitle = \"2018 IEEE 18th International Working Conference on Source Code Analysis and Manipulation (SCAM)\",\n    title = \"[Research Paper] On the Use of Machine Learning Techniques Towards the Design of Cloud Based Automatic Code Clone Validation Tools\",\n    year = \"2018\",\n    volume = \"\",\n    number = \"\",\n    pages = \"155-164\",\n    doi = \"10.1109/SCAM.2018.00025\"\n}\n\n",
    "abstract": "A code clone is a pair of code fragments, within\nor between software systems that are similar. Since code clones\noften negatively impact the maintainability of a software system,\na great many numbers of code clone detection techniques and\ntools have been proposed and studied over the last decade. To\ndetect all possible similar source code patterns in general, the\nclone detection tools work on syntax level (such as texts, tokens,\nAST and so on) while lacking user-specific preferences. This often\nmeans the reported clones must be manually validated prior to\nany analysis in order to filter out the true positive clones from\ntask or user-specific considerations. This manual clone validation\neffort is very time-consuming and often error-prone, in particular\nfor large-scale clone detection. In this paper, we propose a\nmachine learning based approach for automating the validation\nprocess. In an experiment with clones detected by several clone\ndetectors in several different software systems, we found our\napproach has an accuracy of up to 87.4% when compared against\nthe manual validation by multiple expert judges. The proposed\nmethod shows promising results in several comparative studies\nwith the existing related approaches for automatic code clone\nvalidation. We also present our experimental results in terms of\ndifferent code clone detection tools, machine learning algorithms\nand open source software systems."
}, {
    "py/object": "data.DataClassPaper",
    "Title": "Predicting Code Smells and Analysis of Predictions: Using Machine Learning Techniques and Software Metrics",
    "year": 2020,
    "ML_Techniques": "RF, GBT, DT, SVM, MLP",
    "Category": "Quality assessment",
    "Sub_category": "Code smell detection",
    "Venue": "JCST",
    "Link": "https://link.springer.com/article/10.1007/s11390-020-0323-7",
    "bibtex": "article{Mhawish2020_252,\n    author = \"Mhawish, Mohammad Y. and Gupta, Manjari\",\n    title = \"Predicting Code Smells and Analysis of Predictions: Using Machine Learning Techniques and Software Metrics\",\n    journal = \"J. Comput. Sci. Technol.\",\n    year = \"2020\",\n    volume = \"35\",\n    pages = \"1428-1445\"\n}\n\n",
    "abstract": "Code smell detection is essential to improve software quality, enhancing software maintainability, and decrease\nthe risk of faults and failures in the software system. In this paper, we proposed a code smell prediction approach based on\nmachine learning techniques and software metrics. The local interpretable model-agnostic explanations (LIME) algorithm\nwas further used to explain the machine learning model\u2019s predictions and interpretability. The datasets obtained from\nFontana et al. were reformed and used to build binary-label and multi-label datasets. The results of 10-fold cross-validation\nshow that the performance of tree-based algorithms (mainly Random Forest) is higher compared with kernel-based and\nnetwork-based algorithms. The genetic algorithm based feature selection methods enhance the accuracy of these machine\nlearning algorithms by selecting the most relevant features in each dataset. Moreover, the parameter optimization techniques\nbased on the grid search algorithm significantly enhance the accuracy of all these algorithms. Finally, machine learning\ntechniques have high potential in predicting the code smells, which contribute to detect these smells and enhance the\nsoftware\u2019s quality."
}, {
    "py/object": "data.DataClassPaper",
    "Title": "Prediction of Web Service Anti-patterns Using Aggregate Software Metrics and Machine Learning Techniques",
    "year": 2020,
    "ML_Techniques": "LOG, DT, ANN, SVM, ELM, MVE, BTE",
    "Category": "Quality assessment",
    "Sub_category": "Code smell detection",
    "Venue": "ISEC",
    "Link": "https://dl.acm.org/doi/10.1145/3385032.3385042",
    "bibtex": "article{Mhawish2020_252,\n    author = \"Mhawish, Mohammad Y. and Gupta, Manjari\",\n    title = \"Predicting Code Smells and Analysis of Predictions: Using Machine Learning Techniques and Software Metrics\",\n    journal = \"J. Comput. Sci. Technol.\",\n    year = \"2020\",\n    volume = \"35\",\n    pages = \"1428-1445\"\n}\n\n",
    "abstract": "Service-Oriented Architecture(SOA) can be characterized as an approximately coupled engineering intended to meet the business needs of an association/organization. Service-Based Systems (SBSs) are inclined to continually change to enjoy new client necessities and adjust the execution settings, similar to some other huge and complex frameworks. These changes may lead to the evolution of designs/products with poor Quality of Service (QoS), resulting in the bad practiced solutions, commonly known as Anti-patterns. Anti-patterns makes the evolution and maintenance of the software systems hard and complex. Early identification of modules, classes, or source code regions where anti-patterns are more likely to occur can help in amending and maneuvering testing efforts leading to the improvement of software quality. In this work, we investigate the application of three sampling techniques, three feature selection techniques, and sixteen different classification techniques to develop the models for web service anti-pattern detection. We report the results of an empirical study by evaluating the approach proposed, on a data set of 226 Web Service Description Language(i.e., WSDL)files, a variety of five types of web-service anti-patterns. Experimental results demonstrated that SMOTE is the best performing data sampling techniques. The experimental results also reveal that the model developed by considering Uncorrelated Significant Predictors(SUCP) as the input obtained better performance compared to the model developed by other metrics. Experimental results also show that the Least Square Support Vector Machine with Linear(LSLIN) function has outperformed all other classifier techniques."
}, {
    "py/object": "data.DataClassPaper",
    "Title": "Ranking warnings from multiple source code static analyzers via ensemble learning",
    "year": 2019,
    "ML_Techniques": "AB",
    "Category": "Quality assessment",
    "Sub_category": "Quality assessment/prediction,Static or dynamic quality assessment,Quality assessment/prediction,Quality assessment/prediction,Static or dynamic quality assessment,Quality assessment/prediction,Static or dynamic quality assessment",
    "Venue": "OpenSym",
    "Link": "https://dl.acm.org/doi/10.1145/3306446.3340828",
    "bibtex": "article{Mhawish2020_252,\n    author = \"Mhawish, Mohammad Y. and Gupta, Manjari\",\n    title = \"Predicting Code Smells and Analysis of Predictions: Using Machine Learning Techniques and Software Metrics\",\n    journal = \"J. Comput. Sci. Technol.\",\n    year = \"2020\",\n    volume = \"35\",\n    pages = \"1428-1445\"\n}\n\n",
    "abstract": "While there is a wide variety of both open source and proprietary\nsource code static analyzers available in the market,\neach of them usually performs better in a small set of problems,\nmaking it hard to choose one single tool to rely on when\nexamining a program looking for bugs in the source code.\nCombining the analysis of different tools may reduce the number\nof false negatives, but yields a corresponding increase in\nthe absolute number of false positives (which is already high\nfor many tools). A possible solution, then, is to filter these\nresults to identify the issues least likely to be false positives. In\nthis study, we post-analyze the reports generated by three tools\non synthetic test cases provided by the US National Institute of\nStandards and Technology. In order to make our technique as\ngeneral as possible, we limit our data to the reports themselves,\nexcluding other information such as change histories or code\nmetrics. The features extracted from these reports are used to\ntrain a set of decision trees using AdaBoost to create a stronger\nclassifier, achieving 0.8 classification accuracy (the combined\nfalse positive rate from the used tools was 0.61). Finally, we\nuse this classifier to rank static analyzer alarms based on the\nprobability of a given alarm being an actual bug in the source\ncode."
}, {
    "py/object": "data.DataClassPaper",
    "Title": "Recognizing lines of code violating company-specific coding guidelines using machine learning",
    "year": 2020,
    "ML_Techniques": "CART, RF",
    "Category": "Quality assessment",
    "Sub_category": "Code smell detection",
    "Venue": "EMSE",
    "Link": "https://link.springer.com/article/10.1007/s10664-019-09769-8",
    "bibtex": "article{Ochodek2019_257,\n    author = \"Ochodek, Miroslaw and Hebig, Regina and Meding, Wilhelm and Frost, Gert and Staron, Miroslaw\",\n    title = \"Recognizing lines of code violating company-specific coding guidelines using machine learning\",\n    journal = \"Empirical Software Engineering\",\n    year = \"2019\",\n    volume = \"25\",\n    pages = \"220-265\"\n}\n\n",
    "abstract": "Software developers in big and medium-size companies are working with millions of lines\nof code in their codebases. Assuring the quality of this code has shifted from simple defect\nmanagement to proactive assurance of internal code quality. Although static code analysis\nand code reviews have been at the forefront of research and practice in this area, code\nreviews are still an effort-intensive and interpretation-prone activity. The aim of this research\nis to support code reviews by automatically recognizing company-specific code guidelines\nviolations in large-scale, industrial source code. In our action research project, we constructed\na machine-learning-based tool for code analysis where software developers and\narchitects in big and medium-sized companies can use a few examples of source code lines\nviolating code/design guidelines (up to 700 lines of code) to train decision-tree classifiers to\nfind similar violations in their codebases (up to 3 million lines of code). Our action research\nproject consisted of (i) understanding the challenges of two large software development\ncompanies, (ii) applying the machine-learning-based tool to detect violations of Sun\u2019s and\nGoogle\u2019s coding conventions in the code of three large open source projects implemented\nin Java, (iii) evaluating the tool on evolving industrial codebase, and (iv) finding the best\nlearning strategies to reduce the cost of training the classifiers. We were able to achieve\nthe average accuracy of over 99% and the average F-score of 0.80 for open source projects\nwhen using ca. 40K lines for training the tool.We obtained a similar average F-score of 0.78\nfor the industrial code but this time using only up to 700 lines of code as a training dataset.\nFinally, we observed the tool performed visibly better for the rules requiring to understand a\nsingle line of code or the context of a few lines (often allowing to reach the F-score of 0.90\nor higher). Based on these results, we could observe that this approach can provide modern\nsoftware development companies with the ability to use examples to teach an algorithm\nto recognize violations of code/design guidelines and thus increase the number of reviews\nconducted before the product release. This, in turn, leads to the increased quality of the final\nsoftware."
}, {
    "py/object": "data.DataClassPaper",
    "Title": "Risky Module Estimation in Safety-Critical Software",
    "year": 2009,
    "ML_Techniques": "SVM",
    "Category": "Quality assessment",
    "Sub_category": "Quality assessment/prediction,Static or dynamic quality assessment,Quality assessment/prediction,Quality assessment/prediction,Static or dynamic quality assessment,Quality assessment/prediction,Static or dynamic quality assessment",
    "Venue": "ACIS",
    "Link": "https://ieeexplore.ieee.org/document/5223201/keywords#keywords",
    "bibtex": "INPROCEEDINGS{Kim2009_259,\n    author = \"{Kim}, Y. and {Jeong}, C. and {Jeong}, A. and {Kim}, H. S.\",\n    booktitle = \"2009 Eighth IEEE/ACIS International Conference on Computer and Information Science\",\n    title = \"Risky Module Estimation in Safety-Critical Software\",\n    year = \"2009\",\n    volume = \"\",\n    number = \"\",\n    pages = \"967-970\",\n    doi = \"10.1109/ICIS.2009.83\"\n}\n\n",
    "abstract": "Software used in safety-critical system must have\nhigh dependability. Software testing and V&V (Verification\nand Validation) activities are very important for assuring high\nsoftware quality. If we can predict the risky modules in safetycritical\nsoftware, testing activities and regulation activities can\nbe applied to them more intensively. In this paper, we classify\nthe estimated risk classes which can be used for deep testing\nand V&V. We predict the risk class for each module using\nsupport vector machines. We can consider that the modules\nclassified to risk class 5 or 4 are more risky than others\nrelatively. For all classification error rates, we expect that the\nresults can be useful and practical for software testing, V&V,\nand activities for regulatory reviews. In the future works, to\nimprove the practicality, we will have to investigate other\nmachine learning algorithms and datasets."
}, {
    "py/object": "data.DataClassPaper",
    "Title": "Semantic Clone Detection Using Machine Learning",
    "year": 2016,
    "ML_Techniques": "SVM, LDA, KS, DT, NB, MLP, B, LB",
    "Category": "Quality assessment",
    "Sub_category": "Clone detection",
    "Venue": "ICMLA",
    "Link": "https://ieeexplore.ieee.org/abstract/document/7838289",
    "bibtex": "INPROCEEDINGS{Sheneamer2016_260,\n    author = \"{Sheneamer}, A. and {Kalita}, J.\",\n    booktitle = \"2016 15th IEEE International Conference on Machine Learning and Applications (ICMLA)\",\n    title = \"Semantic Clone Detection Using Machine Learning\",\n    year = \"2016\",\n    volume = \"\",\n    number = \"\",\n    pages = \"1024-1028\",\n    doi = \"10.1109/ICMLA.2016.0185\"\n}\n\n",
    "abstract": "If two fragments of source code are identical to\neach other, they are called code clones. Code clones introduce\ndifficulties in software maintenance and cause bug propagation.\nIn this paper, we present a machine learning framework to\nautomatically detect clones in software, which is able to detect\nTypes-3 and the most complicated kind of clones, Type-4 clones.\nPreviously used traditional features are often weak in detecting\nthe semantic clones The novel aspects of our approach are the\nextraction of features from abstract syntax trees (AST) and\nprogram dependency graphs (PDG), representation of a pair\nof code fragments as a vector and the use of classification\nalgorithms. The key benefit of this approach is that our approach\ncan find both syntactic and semantic clones extremely well. Our\nevaluation indicates that using our new AST and PDG features\nis a viable methodology, since they improve detecting clones on\nthe IJaDataset2.0."
}, {
    "py/object": "data.DataClassPaper",
    "Title": "SP-J48: a novel optimization and machine-learning-based approach for solving complex problems: special application in software engineering for detecting code smells",
    "year": 2020,
    "ML_Techniques": "DT",
    "Category": "Quality assessment",
    "Sub_category": "Code smell detection",
    "Venue": "NCA",
    "Link": "https://link.springer.com/article/10.1007/s00521-019-04175-z",
    "bibtex": "article{Kaur2019_264,\n    author = \"Kaur, Amandeep and Jain, Sushma and Goel, S.\",\n    title = \"SP-J48: a novel optimization and machine-learning-based approach for solving complex problems: special application in software engineering for detecting code smells\",\n    journal = \"Neural Computing and Applications\",\n    year = \"2019\",\n    volume = \"32\",\n    pages = \"7009-7027\"\n}\n\n",
    "abstract": "This paper presents a novel hybrid algorithm based on optimization and machine-learning approaches for solving real-life complex problems. The optimization algorithm is inspired from the searching and attacking behaviors of sandpipers, called as Sandpiper Optimization Algorithm (SPOA). These two behaviors are modeled and implemented computationally to emphasize intensification and diversification in the search space. A comparison of the proposed SPOA algorithm is performed with nine competing optimization algorithms over 23 benchmark test functions. The proposed SPOA is further hybridized with B-J48 pruned machine-learning approach for efficiently detecting the code smells from the data set. The results reveal that the proposed technique is able to solve challenging problems and outperforms the other well-known approaches."
}, {
    "py/object": "data.DataClassPaper",
    "Title": "Using Machine Learning and Information Retrieval Techniques to Improve Software Maintainability",
    "year": 2013,
    "ML_Techniques": "",
    "Category": "Quality assessment",
    "Sub_category": "Clone detection",
    "Venue": "TESESDK",
    "Link": "https://link.springer.com/chapter/10.1007/978-3-642-45260-4_9",
    "bibtex": "InProceedings{Corazza2013_267,\n    author = \"Corazza, Anna and Di Martino, Sergio and Maggio, Valerio and Moschitti, Alessandro and Passerini, Andrea and Scanniello, Giuseppe and Silvestri, Fabrizio\",\n    editor = \"Moschitti, Alessandro and Plank, Barbara\",\n    title = \"Using Machine Learning and Information Retrieval Techniques to Improve Software Maintainability\",\n    booktitle = \"Trustworthy Eternal Systems via Evolving Software, Data and Knowledge\",\n    year = \"2013\",\n    publisher = \"Springer Berlin Heidelberg\",\n    address = \"Berlin, Heidelberg\",\n    pages = \"117--134\",\n    abstract = \"In this paper, we investigate some ideas based on Machine Learning, Natural Language Processing, and Information Retrieval to outline possible research directions in the field of software architecture recovery and clone detection. In particular, after presenting an extensive related work, we illustrate two proposals for addressing these two issues, that represent hot topics in the field of Software Maintenance. Both proposals use Kernel Methods for exploiting structural representation of source code and to automate the detection of clones and the recovery of the actually implemented architecture in a subject software system.\",\n    isbn = \"978-3-642-45260-4\"\n}\n\n",
    "abstract": "In this paper, we investigate some ideas based on Machine Learning, Natural Language Processing, and Information Retrieval to outline possible research directions in the field of software architecture recovery and clone detection. In particular, after presenting an extensive related work, we illustrate two proposals for addressing these two issues, that represent hot topics in the field of Software Maintenance. Both proposals use Kernel Methods for exploiting structural representation of source code and to automate the detection of clones and the recovery of the actually implemented architecture in a subject software system."
}, {
    "py/object": "data.DataClassPaper",
    "Title": "Using Machine Learning Techniques to Classify and Predict Static Code Analysis Tool Warnings",
    "year": 2018,
    "ML_Techniques": "RF, SVM, KNN, Ripper",
    "Category": "Quality assessment",
    "Sub_category": "Quality assessment/prediction,Quality prediction,Quality assessment/prediction,Quality assessment/prediction,Quality prediction,Quality assessment/prediction,Quality prediction",
    "Venue": "AICCSA",
    "Link": "https://ieeexplore.ieee.org/abstract/document/8612819",
    "bibtex": "INPROCEEDINGS{Alikhashashneh2018_268,\n    author = \"{Alikhashashneh}, E. A. and {Raje}, R. R. and {Hill}, J. H.\",\n    booktitle = \"2018 IEEE/ACS 15th International Conference on Computer Systems and Applications (AICCSA)\",\n    title = \"Using Machine Learning Techniques to Classify and Predict Static Code Analysis Tool Warnings\",\n    year = \"2018\",\n    volume = \"\",\n    number = \"\",\n    pages = \"1-8\",\n    doi = \"10.1109/AICCSA.2018.8612819\"\n}\n\n",
    "abstract": "This paper discusses our work on using software\nengineering metrics (i.e., source code metrics) to classify an error\nmessage generated by a Static Code Analysis (SCA) tool as\na true-positive, false-positive, or false-negative. Specifically, we\ncompare the performance of Support Vector Machine (SVM),\nK-Nearest Neighbor (KNN), Random Forests, and Repeated\nIncremental Pruning to Produce Error Reduction (RIPPER) over\neight datasets. The performance of the techniques is assessed by\ncomputing the F-measure metric, which is defined as the weighted\nharmonic mean of the precision and recall of the predicted model.\nThe overall results of the study show that the F-measure value of\nthe predicted model, which is generated using Random Forests\ntechnique, ranges from 83% to 98%. Additionally, the Random\nForests technique outperforms the other techniques. Lastly, our\nresults indicate that the complexity and coupling metrics have the\nmost impact on whether a SCA tool with generate a false-positive\nwarning or not."
}, {
    "py/object": "data.DataClassPaper",
    "Title": "A New Word Embedding Approach to Evaluate Potential Fixes for Automated Program Repair",
    "year": 2018,
    "ML_Techniques": "Word2Vec",
    "Category": "Program synthesis",
    "Sub_category": "Program repair",
    "Venue": "IJCNN",
    "Link": "https://ieeexplore.ieee.org/abstract/document/8489079",
    "bibtex": "INPROCEEDINGS{Amorim2018_272,\n    author = \"{Amorim}, L. A. and {Freitas}, M. F. and {Dantas}, A. and {de Souza}, E. F. and {Camilo-Junior}, C. G. and {Martins}, W. S.\",\n    booktitle = \"2018 International Joint Conference on Neural Networks (IJCNN)\",\n    title = \"A New Word Embedding Approach to Evaluate Potential Fixes for Automated Program Repair\",\n    year = \"2018\",\n    volume = \"\",\n    number = \"\",\n    pages = \"1-8\",\n    doi = \"10.1109/IJCNN.2018.8489079\"\n}\n\n",
    "abstract": "Debugging is frequently a manual and costly task. Some work recently presented automated program repair methods aiming to reduce debugging time. Despite different approaches, the process of evaluating source code patches (potential fixes) is crucial for most of them, e.g., generate-and-validate systems. The evaluation is a complex task given that patches with different syntaxes might share the same semantics, behaving equally for typically limited specifications. Hence, many approaches fail to better explore the search space of patches, leading them to not reach the patch that fixes the bug. Some research points that a buggy code is more entropic, i.e., less natural than its fixed version. So, this work proposes applying Word2vec, a word embedding model, to improve the repair evaluation process based on the naturalness obtained from a corpus of known fixes. Word2vec captures co-occurrence relationships between words in a given context and then predicts the contextual words of a given word. This technique has been applied to deal with richer semantic relationships in a text. Word2vec evaluates patches according to distances of document vectors and a softmax output layer. We analyze the performance of our proposal with mutated patches created from correct source codes and we simulate potential fixes generated by automated program repair approaches. Thus, the main contribution of this paper is a new method to evaluate patches used in automated program repair methods. The results show that Word2vec-based metrics are capable of analyzing source code naturalness and be used to evaluate source code patches."
}, {
    "py/object": "data.DataClassPaper",
    "Title": "A Syntactic Neural Model for General-Purpose Code Generation",
    "year": 2017,
    "ML_Techniques": "EN-DE",
    "Category": "Program synthesis",
    "Sub_category": "",
    "Venue": "ACL",
    "Link": "https://arxiv.org/abs/1704.01696v1",
    "bibtex": "inproceedings{Yin2017_275,\n    author = \"Yin, Pengcheng and Neubig, Graham\",\n    title = \"A Syntactic Neural Model for General-Purpose Code Generation\",\n    booktitle = \"Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)\",\n    month = \"July\",\n    year = \"2017\",\n    address = \"Vancouver, Canada\",\n    publisher = \"Association for Computational Linguistics\",\n    url = \"https://www.aclweb.org/anthology/P17-1041\",\n    doi = \"10.18653/v1/P17-1041\",\n    pages = \"440--450\",\n    abstract = \"We consider the problem of parsing natural language descriptions into source code written in a general-purpose programming language like Python. Existing data-driven methods treat this problem as a language generation task without considering the underlying syntax of the target programming language. Informed by previous work in semantic parsing, in this paper we propose a novel neural architecture powered by a grammar model to explicitly capture the target syntax as prior knowledge. Experiments find this an effective way to scale up to generation of complex programs from natural language descriptions, achieving state-of-the-art results that well outperform previous code generation and semantic parsing approaches.\"\n}\n\n",
    "abstract": "We consider the problem of parsing natural language descriptions into source code written in a general-purpose programming language like Python. Existing data-driven methods treat this problem as a language generation task without considering the underlying syntax of the target programming language. Informed by previous work in semantic parsing, in this paper we propose a novel neural architecture powered by a grammar model to explicitly capture the target syntax as prior knowledge. Experiments find this an effective way to scale up to generation of complex programs from natural language descriptions, achieving state-of-the-art results that well outperform previous code generation and semantic parsing approaches."
}, {
    "py/object": "data.DataClassPaper",
    "Title": "Abstract Syntax Networks for Code Generation and Semantic Parsing",
    "year": 2017,
    "ML_Techniques": "EN-DE",
    "Category": "Program synthesis",
    "Sub_category": "",
    "Venue": "ACL",
    "Link": "https://arxiv.org/abs/1704.07535v1",
    "bibtex": "inproceedings{Rabinovich2017_276,\n    author = \"Rabinovich, Maxim and Stern, Mitchell and Klein, Dan\",\n    title = \"Abstract Syntax Networks for Code Generation and Semantic Parsing\",\n    booktitle = \"Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)\",\n    month = \"July\",\n    year = \"2017\",\n    address = \"Vancouver, Canada\",\n    publisher = \"Association for Computational Linguistics\",\n    url = \"https://www.aclweb.org/anthology/P17-1105\",\n    doi = \"10.18653/v1/P17-1105\",\n    pages = \"1139--1149\",\n    abstract = \"Tasks like code generation and semantic parsing require mapping unstructured (or partially structured) inputs to well-formed, executable outputs. We introduce abstract syntax networks, a modeling framework for these problems. The outputs are represented as abstract syntax trees (ASTs) and constructed by a decoder with a dynamically-determined modular structure paralleling the structure of the output tree. On the benchmark Hearthstone dataset for code generation, our model obtains 79.2 BLEU and 22.7{\\\\%} exact match accuracy, compared to previous state-of-the-art values of 67.1 and 6.1{\\\\%}. Furthermore, we perform competitively on the Atis, Jobs, and Geo semantic parsing datasets with no task-specific engineering.\"\n}\n\n",
    "abstract": "Tasks like code generation and semantic parsing require mapping unstructured (or partially structured) inputs to well-formed, executable outputs. We introduce abstract syntax networks, a modeling framework for these problems. The outputs are represented as abstract syntax trees (ASTs) and constructed by a decoder with a dynamically-determined modular structure paralleling the structure of the output tree. On the benchmark Hearthstone dataset for code generation, our model obtains 79.2 BLEU and 22.7% exact match accuracy, compared to previous state-of-the-art values of 67.1 and 6.1%. Furthermore, we perform competitively on the Atis, Jobs, and Geo semantic parsing datasets with no task-specific engineering."
}, {
    "py/object": "data.DataClassPaper",
    "Title": "Accelerating search-based program synthesis using learned probabilistic models",
    "year": 2018,
    "ML_Techniques": "",
    "Category": "Program synthesis",
    "Sub_category": "",
    "Venue": "PLDI",
    "Link": "https://dl.acm.org/doi/10.1145/3192366.3192410",
    "bibtex": "inproceedings{Rabinovich2017_276,\n    author = \"Rabinovich, Maxim and Stern, Mitchell and Klein, Dan\",\n    title = \"Abstract Syntax Networks for Code Generation and Semantic Parsing\",\n    booktitle = \"Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)\",\n    month = \"July\",\n    year = \"2017\",\n    address = \"Vancouver, Canada\",\n    publisher = \"Association for Computational Linguistics\",\n    url = \"https://www.aclweb.org/anthology/P17-1105\",\n    doi = \"10.18653/v1/P17-1105\",\n    pages = \"1139--1149\",\n    abstract = \"Tasks like code generation and semantic parsing require mapping unstructured (or partially structured) inputs to well-formed, executable outputs. We introduce abstract syntax networks, a modeling framework for these problems. The outputs are represented as abstract syntax trees (ASTs) and constructed by a decoder with a dynamically-determined modular structure paralleling the structure of the output tree. On the benchmark Hearthstone dataset for code generation, our model obtains 79.2 BLEU and 22.7{\\\\%} exact match accuracy, compared to previous state-of-the-art values of 67.1 and 6.1{\\\\%}. Furthermore, we perform competitively on the Atis, Jobs, and Geo semantic parsing datasets with no task-specific engineering.\"\n}\n\n",
    "abstract": "A key challenge in program synthesis concerns how to efficiently search for the desired program in the space of possible programs. We propose a general approach to accelerate search-based program synthesis by biasing the search towards likely programs. Our approach targets a standard formulation, syntax-guided synthesis (SyGuS), by extending the grammar of possible programs with a probabilistic model dictating the likelihood of each program. We develop a weighted search algorithm to efficiently enumerate programs in order of their likelihood. We also propose a method based on transfer learning that enables to effectively learn a powerful model, called probabilistic higher-order grammar, from known solutions in a domain. We have implemented our approach in a tool called Euphony and evaluate it on SyGuS benchmark problems from a variety of domains. We show that Euphony can learn good models using easily obtainable solutions, and achieves significant performance gains over existing general-purpose as well as domain-specific synthesizers."
}, {
    "py/object": "data.DataClassPaper",
    "Title": "An Empirical Study on Learning Bug-Fixing Patches in the Wild via Neural Machine Translation",
    "year": 2019,
    "ML_Techniques": "NMT",
    "Category": "Program synthesis",
    "Sub_category": "Program repair",
    "Venue": "TOSEM",
    "Link": "https://dl.acm.org/doi/10.1145/3340544",
    "bibtex": "article{Tufano2019_279,\n    author = \"Tufano, Michele and Watson, Cody and Bavota, Gabriele and Penta, Massimiliano Di and White, Martin and Poshyvanyk, Denys\",\n    title = \"An Empirical Study on Learning Bug-Fixing Patches in the Wild via Neural Machine Translation\",\n    year = \"2019\",\n    issue_date = \"October 2019\",\n    publisher = \"Association for Computing Machinery\",\n    address = \"New York, NY, USA\",\n    volume = \"28\",\n    number = \"4\",\n    issn = \"1049-331X\",\n    url = \"https://doi.org/10.1145/3340544\",\n    doi = \"10.1145/3340544\",\n    abstract = \"Millions of open source projects with numerous bug fixes are available in code repositories. This proliferation of software development histories can be leveraged to learn how to fix common programming bugs. To explore such a potential, we perform an empirical study to assess the feasibility of using Neural Machine Translation techniques for learning bug-fixing patches for real defects. First, we mine millions of bug-fixes from the change histories of projects hosted on GitHub in order to extract meaningful examples of such bug-fixes. Next, we abstract the buggy and corresponding fixed code, and use them to train an Encoder-Decoder model able to translate buggy code into its fixed version. In our empirical investigation, we found that such a model is able to fix thousands of unique buggy methods in the wild. Overall, this model is capable of predicting fixed patches generated by developers in 9--50\\% of the cases, depending on the number of candidate patches we allow it to generate. Also, the model is able to emulate a variety of different Abstract Syntax Tree operations and generate candidate patches in a split second.\",\n    journal = \"ACM Trans. Softw. Eng. Methodol.\",\n    month = \"September\",\n    articleno = \"19\",\n    numpages = \"29\",\n    keywords = \"Neural machine translation, bug-fixes\"\n}\n\n",
    "abstract": "Millions of open-source projects with numerous bug fixes are available in code repositories. This proliferation of software development histories can be leveraged to learn how to fix common programming bugs. To explore such a potential, we perform an empirical study to assess the feasibility of using Neural Machine Translation techniques for learning bug-fixing patches for real defects. First, we mine millions of bug-fixes from the change histories of projects hosted on GitHub, in order to extract meaningful examples of such bug-fixes. Next, we abstract the buggy and corresponding fixed code, and use them to train an Encoder-Decoder model able to translate buggy code into its fixed version. In our empirical investigation we found that such a model is able to fix thousands of unique buggy methods in the wild. Overall, this model is capable of predicting fixed patches generated by developers in 9-50% of the cases, depending on the number of candidate patches we allow it to generate. Also, the model is able to emulate a variety of different Abstract Syntax Tree operations and generate candidate patches in a split second."
}, {
    "py/object": "data.DataClassPaper",
    "Title": "Automated Large Program Repair based on Big Code",
    "year": 2018,
    "ML_Techniques": "",
    "Category": "Program synthesis",
    "Sub_category": "Program repair",
    "Venue": "SoICT",
    "Link": "https://dl.acm.org/doi/abs/10.1145/3287921.3287958",
    "bibtex": "article{Tufano2019_279,\n    author = \"Tufano, Michele and Watson, Cody and Bavota, Gabriele and Penta, Massimiliano Di and White, Martin and Poshyvanyk, Denys\",\n    title = \"An Empirical Study on Learning Bug-Fixing Patches in the Wild via Neural Machine Translation\",\n    year = \"2019\",\n    issue_date = \"October 2019\",\n    publisher = \"Association for Computing Machinery\",\n    address = \"New York, NY, USA\",\n    volume = \"28\",\n    number = \"4\",\n    issn = \"1049-331X\",\n    url = \"https://doi.org/10.1145/3340544\",\n    doi = \"10.1145/3340544\",\n    abstract = \"Millions of open source projects with numerous bug fixes are available in code repositories. This proliferation of software development histories can be leveraged to learn how to fix common programming bugs. To explore such a potential, we perform an empirical study to assess the feasibility of using Neural Machine Translation techniques for learning bug-fixing patches for real defects. First, we mine millions of bug-fixes from the change histories of projects hosted on GitHub in order to extract meaningful examples of such bug-fixes. Next, we abstract the buggy and corresponding fixed code, and use them to train an Encoder-Decoder model able to translate buggy code into its fixed version. In our empirical investigation, we found that such a model is able to fix thousands of unique buggy methods in the wild. Overall, this model is capable of predicting fixed patches generated by developers in 9--50\\% of the cases, depending on the number of candidate patches we allow it to generate. Also, the model is able to emulate a variety of different Abstract Syntax Tree operations and generate candidate patches in a split second.\",\n    journal = \"ACM Trans. Softw. Eng. Methodol.\",\n    month = \"September\",\n    articleno = \"19\",\n    numpages = \"29\",\n    keywords = \"Neural machine translation, bug-fixes\"\n}\n\n",
    "abstract": "The task of automatic program repair is to automatically localize and generate the correct patches for the bugs. A prominent approach is to produce a space of candidate patches, then find and validate candidates on test case sets. However, searching for the correct candidates is really challenging, since the search space is dominated by incorrect patches and its size is huge.\n\nThis paper presents several methods to improve the automated program repair system Prophet, called Prophet+. Our approach contributes three improvements over Prophet: 1) extract twelve relations of statements and blocks for Bi-gram model using Big code, 2) prune the search space, 3) develop an algorithm to re-rank candidate patches in the search space. The experimental results show that our proposed system enhances the performance of Prophet, recognized as the state-of-the-art system, significantly. Specifically, for the top 1, our system generates the correct patches for 17 over 69 bugs while the number achieved by Prophet is 15."
}, {
    "py/object": "data.DataClassPaper",
    "Title": "Automated program repair",
    "year": 2019,
    "ML_Techniques": "",
    "Category": "Program synthesis",
    "Sub_category": "Program repair",
    "Venue": "CACM",
    "Link": "https://dl.acm.org/doi/abs/10.1145/3318162",
    "bibtex": "article{Goues2019_281,\n    author = \"Goues, Claire Le and Pradel, Michael and Roychoudhury, Abhik\",\n    title = \"Automated Program Repair\",\n    year = \"2019\",\n    issue_date = \"December 2019\",\n    publisher = \"Association for Computing Machinery\",\n    address = \"New York, NY, USA\",\n    volume = \"62\",\n    number = \"12\",\n    issn = \"0001-0782\",\n    url = \"https://doi.org/10.1145/3318162\",\n    doi = \"10.1145/3318162\",\n    abstract = \"Automated program repair can relieve programmers from the burden of manually fixing the ever-increasing number of programming mistakes.\",\n    journal = \"Commun. ACM\",\n    month = \"November\",\n    pages = \"56\u201365\",\n    numpages = \"10\"\n}\n\n",
    "abstract": "Automated program repair can relieve programmers from the burden of manually fixing the ever-increasing number of programming mistakes."
}, {
    "py/object": "data.DataClassPaper",
    "Title": "Automated support for diagnosis and repair",
    "year": 2015,
    "ML_Techniques": "",
    "Category": "Program synthesis",
    "Sub_category": "Program repair",
    "Venue": "CACM",
    "Link": "https://dl.acm.org/doi/fullHtml/10.1145/2658986",
    "bibtex": "article{Goues2019_281,\n    author = \"Goues, Claire Le and Pradel, Michael and Roychoudhury, Abhik\",\n    title = \"Automated Program Repair\",\n    year = \"2019\",\n    issue_date = \"December 2019\",\n    publisher = \"Association for Computing Machinery\",\n    address = \"New York, NY, USA\",\n    volume = \"62\",\n    number = \"12\",\n    issn = \"0001-0782\",\n    url = \"https://doi.org/10.1145/3318162\",\n    doi = \"10.1145/3318162\",\n    abstract = \"Automated program repair can relieve programmers from the burden of manually fixing the ever-increasing number of programming mistakes.\",\n    journal = \"Commun. ACM\",\n    month = \"November\",\n    pages = \"56\u201365\",\n    numpages = \"10\"\n}\n\n",
    "abstract": "Model checking and logic-based learning together deliver automated support, especially in adaptive and autonomous systems."
}, {
    "py/object": "data.DataClassPaper",
    "Title": "Automatic B-model repair using model checking and machine learning",
    "year": 2019,
    "ML_Techniques": "ResNet, RF, CART ",
    "Category": "Program synthesis",
    "Sub_category": "Program repair",
    "Venue": "ASE",
    "Link": "https://link.springer.com/article/10.1007/s10515-019-00264-4",
    "bibtex": "article{Cai2019_284,\n    author = {Cai, Cheng-Hao and Sun, Jing and Dobbie, Gillian},\n    title = {Automatic B-model repair using model checking and machine learning},\n    year = {2019},\n    publisher = {Springer},\n    address = {},\n    volume = {26},\n    number = {3},\n    issn = {1573-7535},\n    doi = {10.1007/s10515-019-00264-4},\n    journal = {Automated Software Engineering},\n    month = jan,\n    pages = {},\n    numpages = {}\n}\n\n",
    "abstract": "The B-method, which provides automated verification for the design of software systems, still requires users to manually repair faulty models. This paper proposes B-repair, an approach that supports automated repair of faulty models written in the B formal specification language. After discovering a fault in a model using the B-method, B-repair is able to suggest possible repairs for the fault, estimate the quality of suggested repairs and use a suitable repair to revise the model. The suggestion of repairs is produced using the Isolation method, which suggests changing the pre-conditions of operations, and the Revision method, which suggests changing the post-conditions of operations. The estimation of repair quality makes use of machine learning techniques that can learn the features of state transitions. After estimating the quality of suggested repairs, the repairs are ranked, and a best repair is selected according to the result of ranking and is used to revise the model. This approach has been evaluated using a set of finite state machines seeded with faults and a case study. The evaluation has revealed that B-repair is able to repair a large number of faults, including invariant violations, assertion violations and deadlock states, and gain high accuracies of repair. Using the combination of model checking and machine learning-guided techniques, B-repair saves development time by finding and repairing faults automatically during design."
}, {
    "py/object": "data.DataClassPaper",
    "Title": "Automatic patch generation by learning correct code",
    "year": 2016,
    "ML_Techniques": "",
    "Category": "Program synthesis",
    "Sub_category": "Program repair",
    "Venue": "POPL",
    "Link": "https://dl.acm.org/doi/10.1145/2837614.2837617",
    "bibtex": "article{Cai2019_284,\n    author = {Cai, Cheng-Hao and Sun, Jing and Dobbie, Gillian},\n    title = {Automatic B-model repair using model checking and machine learning},\n    year = {2019},\n    publisher = {Springer},\n    address = {},\n    volume = {26},\n    number = {3},\n    issn = {1573-7535},\n    doi = {10.1007/s10515-019-00264-4},\n    journal = {Automated Software Engineering},\n    month = jan,\n    pages = {},\n    numpages = {}\n}\n\n",
    "abstract": "We present Prophet, a novel patch generation system that works with a set of successful human patches obtained from open- source software repositories to learn a probabilistic, application-independent model of correct code. It generates a space of candidate patches, uses the model to rank the candidate patches in order of likely correctness, and validates the ranked patches against a suite of test cases to find correct patches. Experimental results show that, on a benchmark set of 69 real-world defects drawn from eight open-source projects, Prophet significantly outperforms the previous state-of-the-art patch generation system."
}, {
    "py/object": "data.DataClassPaper",
    "Title": "CoCoNuT: combining context-aware neural translation models using ensemble for program repair",
    "year": 2020,
    "ML_Techniques": "NMT, CNN",
    "Category": "Program synthesis",
    "Sub_category": "Program repair",
    "Venue": "ISSTA",
    "Link": "https://dl.acm.org/doi/abs/10.1145/3395363.3397369",
    "bibtex": "article{Cai2019_284,\n    author = {Cai, Cheng-Hao and Sun, Jing and Dobbie, Gillian},\n    title = {Automatic B-model repair using model checking and machine learning},\n    year = {2019},\n    publisher = {Springer},\n    address = {},\n    volume = {26},\n    number = {3},\n    issn = {1573-7535},\n    doi = {10.1007/s10515-019-00264-4},\n    journal = {Automated Software Engineering},\n    month = jan,\n    pages = {},\n    numpages = {}\n}\n\n",
    "abstract": "Automated generate-and-validate (GV) program repair techniques (APR) typically rely on hard-coded rules, thus only fixing bugs following specific fix patterns. These rules require a significant amount of manual effort to discover and it is hard to adapt these rules to different programming languages.\n\nTo address these challenges, we propose a new G&V technique\u2014CoCoNuT, which uses ensemble learning on the combination of convolutional neural networks (CNNs) and a new context-aware neural machine translation (NMT) architecture to automatically fix bugs in multiple programming languages. To better represent the context of a bug, we introduce a new context-aware NMT architecture that represents the buggy source code and its surrounding context separately. CoCoNuT uses CNNs instead of recurrent neural networks (RNNs), since CNN layers can be stacked to extract hierarchical features and better model source code at different granularity levels (e.g., statements and functions). In addition, CoCoNuT takes advantage of the randomness in hyperparameter tuning to build multiple models that fix different bugs and combines these models using ensemble learning to fix more bugs.\n\nOur evaluation on six popular benchmarks for four programming languages (Java, C, Python, and JavaScript) shows that CoCoNuT correctly fixes (i.e., the first generated patch is semantically equivalent to the developer\u2019s patch) 509 bugs, including 309 bugs that are fixed by none of the 27 techniques with which we compare."
}, {
    "py/object": "data.DataClassPaper",
    "Title": "Code Naturalness to Assist Search Space Exploration in Search-Based Program Repair Methods",
    "year": 2019,
    "ML_Techniques": "Doc2vec, LSTM",
    "Category": "Program synthesis",
    "Sub_category": "Program repair",
    "Venue": "SSBSE",
    "Link": "https://link.springer.com/chapter/10.1007/978-3-030-27455-9_12",
    "bibtex": "InProceedings{Dantas2019_289,\n    author = \"Dantas, Altino and de Souza, Eduardo F. and Souza, Jerffeson and Camilo-Junior, Celso G.\",\n    editor = \"Nejati, Shiva and Gay, Gregory\",\n    title = \"Code Naturalness to Assist Search Space Exploration in Search-Based Program Repair Methods\",\n    booktitle = \"Search-Based Software Engineering\",\n    year = \"2019\",\n    publisher = \"Springer International Publishing\",\n    address = \"Cham\",\n    pages = \"164--170\",\n    abstract = \"Automated Program Repair (APR) is a research field that has recently gained attention due to its advances in proposing methods to fix buggy programs without human intervention. Search-Based Program Repair methods have difficulties to traverse the search space, mainly, because it is challenging and costly to evaluate each variant. Therefore, aiming to improve each program's variant evaluation through providing more information to the fitness function, we propose the combination of two techniques, Doc2vec and LSTM, to capture high-level differences among variants and to capture the dependence between source code statements in the fault localization region. The experiments performed with the IntroClass benchmark show that our approach captures differences between variants according to the level of changes they received, and the resulting information is useful to balance the search between the exploration and exploitation steps. Besides, the proposal might be promising to filter program variants that are adequate to the suspicious portion of the code.\",\n    isbn = \"978-3-030-27455-9\"\n}\n\n",
    "abstract": "Automated Program Repair (APR) is a research field that has recently gained attention due to its advances in proposing methods to fix buggy programs without human intervention. Search-Based Program Repair methods have difficulties to traverse the search space, mainly, because it is challenging and costly to evaluate each variant. Therefore, aiming to improve each program\u2019s variant evaluation through providing more information to the fitness function, we propose the combination of two techniques, Doc2vec and LSTM, to capture high-level differences among variants and to capture the dependence between source code statements in the fault localization region. The experiments performed with the IntroClass benchmark show that our approach captures differences between variants according to the level of changes they received, and the resulting information is useful to balance the search between the exploration and exploitation steps. Besides, the proposal might be promising to filter program variants that are adequate to the suspicious portion of the code."
}, {
    "py/object": "data.DataClassPaper",
    "Title": "CODIT: Code Editing with Tree-Based Neural Machine Translation",
    "year": 2020,
    "ML_Techniques": "NMT",
    "Category": "Program synthesis",
    "Sub_category": "Program translation",
    "Venue": "TSE",
    "Link": "https://arxiv.org/pdf/1810.00314.pdf",
    "bibtex": "InProceedings{Dantas2019_289,\n    author = \"Dantas, Altino and de Souza, Eduardo F. and Souza, Jerffeson and Camilo-Junior, Celso G.\",\n    editor = \"Nejati, Shiva and Gay, Gregory\",\n    title = \"Code Naturalness to Assist Search Space Exploration in Search-Based Program Repair Methods\",\n    booktitle = \"Search-Based Software Engineering\",\n    year = \"2019\",\n    publisher = \"Springer International Publishing\",\n    address = \"Cham\",\n    pages = \"164--170\",\n    abstract = \"Automated Program Repair (APR) is a research field that has recently gained attention due to its advances in proposing methods to fix buggy programs without human intervention. Search-Based Program Repair methods have difficulties to traverse the search space, mainly, because it is challenging and costly to evaluate each variant. Therefore, aiming to improve each program's variant evaluation through providing more information to the fitness function, we propose the combination of two techniques, Doc2vec and LSTM, to capture high-level differences among variants and to capture the dependence between source code statements in the fault localization region. The experiments performed with the IntroClass benchmark show that our approach captures differences between variants according to the level of changes they received, and the resulting information is useful to balance the search between the exploration and exploitation steps. Besides, the proposal might be promising to filter program variants that are adequate to the suspicious portion of the code.\",\n    isbn = \"978-3-030-27455-9\"\n}\n\n",
    "abstract": "The way developers edit day-to-day code tends to be repetitive, often using existing code elements. Many researchers have tried to automate repetitive code changes by learning from specific change templates which are applied to limited scope. The advancement of Neural Machine Translation (NMT) and the availability of vast open-source evolutionary data opens up the possibility of automatically learning those templates from the wild. However, unlike natural languages, for which NMT techniques were originally devised, source code and its changes have certain properties. For instance, compared to natural language, source code vocabulary can be significantly larger. Further, good changes in code do not break its syntactic structure. Thus, deploying state-of-the-art NMT models without adapting the methods to the source code domain yields sub-optimal results.\n\nTo this end, we propose a novel Tree based NMT system to model source code changes and learn code change patterns from the wild. We realize our model with a change suggestion engine: Codit and train the model with more than 30k real-world changes and evaluate it on 6k patches. Our evaluation shows the effectiveness of Codit in learning and suggesting patches. Codit also shows promise generating bug fix patches."
}, {
    "py/object": "data.DataClassPaper",
    "Title": "Common Statement Kind Changes to Inform Automatic Program Repair",
    "year": 2018,
    "ML_Techniques": "ARM",
    "Category": "Program synthesis",
    "Sub_category": "Program repair",
    "Venue": "MSR",
    "Link": "https://ieeexplore.ieee.org/abstract/document/8595190",
    "bibtex": "INPROCEEDINGS{Soto2018_292,\n    author = \"{Soto}, M. and {Le Goues}, C.\",\n    booktitle = \"2018 IEEE/ACM 15th International Conference on Mining Software Repositories (MSR)\",\n    title = \"Common Statement Kind Changes to Inform Automatic Program Repair\",\n    year = \"2018\",\n    volume = \"\",\n    number = \"\",\n    pages = \"102-105\",\n    doi = \"\"\n}\n\n",
    "abstract": "The search space for automatic program repair approaches is vast and the search for mechanisms to help restrict this search are increasing. We make a granular analysis based on statement kinds to find which statements are more likely to be modified than others when fixing an error. We construct a corpus for analysis by delimiting debugging regions in the provided dataset and recursively analyze the differences between the Simplified Syntax Trees associated with EditEvent's. We build a distribution of statement kinds with their corresponding likelihood of being modified and we validate the usage of this distribution to guide the statement selection. We then build association rules with different confidence thresholds to describe statement kinds commonly modified together for multi-edit patch creation. Finally we evaluate association rule coverage over a held out test set and find that when using a 95% confidence threshold we can create less and more accurate rules that fully cover 93.8% of the testing instances."
}, {
    "py/object": "data.DataClassPaper",
    "Title": "Compilation error repair: for the student programs, from the student programs",
    "year": 2018,
    "ML_Techniques": "RNN",
    "Category": "Program synthesis",
    "Sub_category": "Program repair",
    "Venue": "ICSE",
    "Link": "https://dl.acm.org/doi/abs/10.1145/3183377.3183383",
    "bibtex": "INPROCEEDINGS{Soto2018_292,\n    author = \"{Soto}, M. and {Le Goues}, C.\",\n    booktitle = \"2018 IEEE/ACM 15th International Conference on Mining Software Repositories (MSR)\",\n    title = \"Common Statement Kind Changes to Inform Automatic Program Repair\",\n    year = \"2018\",\n    volume = \"\",\n    number = \"\",\n    pages = \"102-105\",\n    doi = \"\"\n}\n\n",
    "abstract": "Compile-time errors pose a major learning hurdle for students of introductory programming courses. Compiler error messages, while accurate, are targeted at seasoned programmers, and seem cryptic to beginners. In this work, we address this problem of pedagogically-inspired program repair and report TRACER (Targeted RepAir of Compilation ERrors), a system for performing repairs on compilation errors, aimed at introductory programmers.\n\nTRACER invokes a novel combination of tools from programming language theory and deep learning and offers repairs that not only enable successful compilation, but repairs that are very close to those actually performed by students on similar errors. The ability to offer such targeted corrections, rather than just code that compiles, makes TRACER more relevant in offering real-time feedback to students in lab or tutorial sessions, as compared to existing works that merely offer a certain compilation success rate.\n\nIn an evaluation on 4500 erroneous C programs written by students of a freshman year programming course, TRACER recommends a repair exactly matching the one expected by the student for 68% of the cases, and in 79.27% of the cases, produces a compilable repair. On a further set of 6971 programs that require errors to be fixed on multiple lines, TRACER enjoyed a success rate of 44% compared to the 27% success rate offered by the state-of-the-art technique DeepFix."
}, {
    "py/object": "data.DataClassPaper",
    "Title": "Data-guided repair of selection statements",
    "year": 2014,
    "ML_Techniques": "SVM, DT",
    "Category": "Program synthesis",
    "Sub_category": "Program repair",
    "Venue": "ICSE",
    "Link": "https://dl.acm.org/doi/10.1145/2568225.2568303",
    "bibtex": "INPROCEEDINGS{Soto2018_292,\n    author = \"{Soto}, M. and {Le Goues}, C.\",\n    booktitle = \"2018 IEEE/ACM 15th International Conference on Mining Software Repositories (MSR)\",\n    title = \"Common Statement Kind Changes to Inform Automatic Program Repair\",\n    year = \"2018\",\n    volume = \"\",\n    number = \"\",\n    pages = \"102-105\",\n    doi = \"\"\n}\n\n",
    "abstract": "Database-centric programs form the backbone of many enterprise systems. Fixing defects in such programs takes much human effort due to the interplay between imperative code and database-centric logic. This paper presents a novel data-driven approach for automated fixing of bugs in the selection condition of database statements (e.g., WHERE clause of SELECT statements) \u2013 a common form of bugs in such programs. Our key observation is that in real-world data, there is information latent in the distribution of data that can be useful to repair selection conditions efficiently. Given a faulty database program and input data, only a part of which induces the defect, our novelty is in determining the correct behavior for the defect-inducing data by taking advantage of the information revealed by the rest of the data. We accomplish this by employing semi-supervised learning to predict the correct behavior for defect-inducing data and by patching up any inaccuracies in the prediction by a SAT-based combinatorial search. Next, we learn a compact decision tree for the correct behavior, including the correct behavior on the defect-inducing data. This tree suggests a plausible fix to the selection condition. We demonstrate the feasibility of our approach on seven realworld examples."
}, {
    "py/object": "data.DataClassPaper",
    "Title": "Deep Learning for Source Code Modeling and Generation: Models, Applications, and Challenges",
    "year": 2020,
    "ML_Techniques": "NMT",
    "Category": "Program synthesis",
    "Sub_category": ",Program translation",
    "Venue": "CSUR",
    "Link": "https://dl.acm.org/doi/10.1145/3383458",
    "bibtex": "article{Le2020_297,\n    author = \"Le, Triet H. M. and Chen, Hao and Babar, Muhammad Ali\",\n    title = \"Deep Learning for Source Code Modeling and Generation: Models, Applications, and Challenges\",\n    year = \"2020\",\n    issue_date = \"June 2020\",\n    publisher = \"Association for Computing Machinery\",\n    address = \"New York, NY, USA\",\n    volume = \"53\",\n    number = \"3\",\n    issn = \"0360-0300\",\n    url = \"https://doi.org/10.1145/3383458\",\n    doi = \"10.1145/3383458\",\n    journal = \"ACM Comput. Surv.\",\n    month = \"June\",\n    articleno = \"62\",\n    numpages = \"38\",\n    keywords = \"Deep learning, source code modeling, source code generation, big code\"\n}\n\n",
    "abstract": "Deep Learning (DL) techniques for Natural Language Processing have been evolving remarkably fast. Recently, the DL advances in language modeling, machine translation and paragraph understanding are so prominent that the potential of DL in Software Engineering cannot be overlooked, especially in the field of program learning. To facilitate further research and applications of DL in this field, we provide a comprehensive review to categorize and investigate existing DL methods for source code modeling and generation. To address the limitations of the traditional source code models, we formulate common program learning tasks under an encoder-decoder framework. After that, we introduce recent DL mechanisms suitable to solve such problems. Then, we present the state-of-the-art practices and discuss their challenges with some recommendations for practitioners and researchers as well."
}, {
    "py/object": "data.DataClassPaper",
    "Title": "Deep Reinforcement Learning for Syntactic Error Repair in Student Programs",
    "year": 2019,
    "ML_Techniques": "LSTM, A3C",
    "Category": "Program synthesis",
    "Sub_category": "Program repair",
    "Venue": "AAAI",
    "Link": "https://ojs.aaai.org//index.php/AAAI/article/view/3882",
    "bibtex": "article{Gupta2019_298,\n    author = \"Gupta, Rahul and Kanade, Aditya and Shevade, Shirish\",\n    year = \"2019\",\n    month = \"07\",\n    pages = \"930-937\",\n    title = \"Deep Reinforcement Learning for Syntactic Error Repair in Student Programs\",\n    volume = \"33\",\n    journal = \"Proceedings of the AAAI Conference on Artificial Intelligence\",\n    doi = \"10.1609/aaai.v33i01.3301930\"\n}\n\n",
    "abstract": "Novice programmers often struggle with the formal syntax of programming languages. In the traditional classroom setting, they can make progress with the help of real time feedback from their instructors which is often impossible to get in the massive open online course (MOOC) setting. Syntactic error repair techniques have huge potential to assist them at scale. Towards this, we design a novel programming language correction framework amenable to reinforcement learning. The framework allows an agent to mimic human actions for text navigation and editing. We demonstrate that the agent can be trained through self-exploration directly from the raw input, that is, program text itself, without either supervision or any prior knowledge of the formal syntax of the programming language. We evaluate our technique on a publicly available dataset containing 6975 erroneous C programs with typographic errors, written by students during an introductory programming course. Our technique fixes 1699 (24.4%) programs completely and 1310 (18.8%) program partially, outperforming DeepFix, a state-of-the-art syntactic error repair technique, which uses a fully supervised neural machine translation approach."
}, {
    "py/object": "data.DataClassPaper",
    "Title": "DeepCoder: Learning to Write Programs",
    "year": 2016,
    "ML_Techniques": "EN-DE",
    "Category": "Program synthesis",
    "Sub_category": "",
    "Venue": "CoRR",
    "Link": "https://arxiv.org/abs/1611.01989",
    "bibtex": "article{Balog2016_299,\n    author = \"Balog, Matej and Gaunt, Alexander L. and Brockschmidt, Marc and Nowozin, Sebastian and Tarlow, Daniel\",\n    title = \"DeepCoder: Learning to Write Programs\",\n    journal = \"CoRR\",\n    volume = \"abs/1611.01989\",\n    year = \"2016\",\n    url = \"http://arxiv.org/abs/1611.01989\",\n    archivePrefix = \"arXiv\",\n    eprint = \"1611.01989\",\n    timestamp = \"Mon, 13 Aug 2018 16:47:48 +0200\",\n    biburl = \"https://dblp.org/rec/journals/corr/BalogGBNT16.bib\",\n    bibsource = \"dblp computer science bibliography, https://dblp.org\"\n}\n\n",
    "abstract": "We develop a first line of attack for solving programming competition-style problems from input-output examples using deep learning. The approach is to train a neural network to predict properties of the program that generated the outputs from the inputs. We use the neural network's predictions to augment search techniques from the programming languages community, including enumerative search and an SMT-based solver. Empirically, we show that our approach leads to an order of magnitude speedup over the strong non-augmented baselines and a Recurrent Neural Network approach, and that we are able to solve problems of difficulty comparable to the simplest problems on programming competition websites."
}, {
    "py/object": "data.DataClassPaper",
    "Title": "DeepDelta: learning to repair compilation errors",
    "year": 2019,
    "ML_Techniques": "NMT",
    "Category": "Program synthesis",
    "Sub_category": "Program repair",
    "Venue": "FSE",
    "Link": "https://dl.acm.org/doi/10.1145/3338906.3340455",
    "bibtex": "article{Balog2016_299,\n    author = \"Balog, Matej and Gaunt, Alexander L. and Brockschmidt, Marc and Nowozin, Sebastian and Tarlow, Daniel\",\n    title = \"DeepCoder: Learning to Write Programs\",\n    journal = \"CoRR\",\n    volume = \"abs/1611.01989\",\n    year = \"2016\",\n    url = \"http://arxiv.org/abs/1611.01989\",\n    archivePrefix = \"arXiv\",\n    eprint = \"1611.01989\",\n    timestamp = \"Mon, 13 Aug 2018 16:47:48 +0200\",\n    biburl = \"https://dblp.org/rec/journals/corr/BalogGBNT16.bib\",\n    bibsource = \"dblp computer science bibliography, https://dblp.org\"\n}\n\n",
    "abstract": "Programmers spend a substantial amount of time manually repairing code that does not compile. We observe that the repairs for any particular error class typically follow a pattern and are highly mechanical. We propose a novel approach that automatically learns these patterns with a deep neural network and suggests program repairs for the most costly classes of build-time compilation failures. We describe how we collect all build errors and the human-authored, in-progress code changes that cause those failing builds to transition to successful builds at Google. We generate an AST diff from the textual code changes and transform it into a domain-specific language called Delta that encodes the change that must be made to make the code compile. We then feed the compiler diagnostic information (as source) and the Delta changes that resolved the diagnostic (as target) into a Neural Machine Translation network for training. For the two most prevalent and costly classes of Java compilation errors, namely missing symbols and mismatched method signatures, our system called DeepDelta, generates the correct repair changes for 19,314 out of 38,788 (50%) of unseen compilation errors. The correct changes are in the top three suggested fixes 86% of the time on average."
}, {
    "py/object": "data.DataClassPaper",
    "Title": "DeeperCoder: Code Generation Using Machine Learning",
    "year": 2020,
    "ML_Techniques": "NN",
    "Category": "Program synthesis",
    "Sub_category": "",
    "Venue": "CCWC",
    "Link": "https://ieeexplore.ieee.org/document/9031149",
    "bibtex": "article{Balog2016_299,\n    author = \"Balog, Matej and Gaunt, Alexander L. and Brockschmidt, Marc and Nowozin, Sebastian and Tarlow, Daniel\",\n    title = \"DeepCoder: Learning to Write Programs\",\n    journal = \"CoRR\",\n    volume = \"abs/1611.01989\",\n    year = \"2016\",\n    url = \"http://arxiv.org/abs/1611.01989\",\n    archivePrefix = \"arXiv\",\n    eprint = \"1611.01989\",\n    timestamp = \"Mon, 13 Aug 2018 16:47:48 +0200\",\n    biburl = \"https://dblp.org/rec/journals/corr/BalogGBNT16.bib\",\n    bibsource = \"dblp computer science bibliography, https://dblp.org\"\n}\n\n",
    "abstract": "In this paper, we present a program generation system based on input and output specification. The system is developed based on a programming-by-example technique used in program synthesis. The system can generate computer programs that satisfies user requirements based on inputs and outputs. We created a simple Domain Specific Language (DSL) which will be used in program synthesis. We trained our neural network with a large set of input space and store corresponding sample training programs. To get the final output which satisfies all the user specifications, we used inductive program synthesis and machine learning. We also experimented with different deep learning models to obtain the desired results with reduced number of steps and execution time. Finally, we show three layers of neural networks with LeakyReLU achieves the best performance when compared to other approaches."
}, {
    "py/object": "data.DataClassPaper",
    "Title": "DLFix: context-based code transformation learning for automated program repair",
    "year": 2020,
    "ML_Techniques": "RNN",
    "Category": "Program synthesis",
    "Sub_category": "Program repair",
    "Venue": "ICSE",
    "Link": "https://dl.acm.org/doi/abs/10.1145/3377811.3380345",
    "bibtex": "article{Balog2016_299,\n    author = \"Balog, Matej and Gaunt, Alexander L. and Brockschmidt, Marc and Nowozin, Sebastian and Tarlow, Daniel\",\n    title = \"DeepCoder: Learning to Write Programs\",\n    journal = \"CoRR\",\n    volume = \"abs/1611.01989\",\n    year = \"2016\",\n    url = \"http://arxiv.org/abs/1611.01989\",\n    archivePrefix = \"arXiv\",\n    eprint = \"1611.01989\",\n    timestamp = \"Mon, 13 Aug 2018 16:47:48 +0200\",\n    biburl = \"https://dblp.org/rec/journals/corr/BalogGBNT16.bib\",\n    bibsource = \"dblp computer science bibliography, https://dblp.org\"\n}\n\n",
    "abstract": "Automated Program Repair (APR) is very useful in helping developers in the process of software development and maintenance. Despite recent advances in deep learning (DL), the DL-based APR approaches still have limitations in learning bug-fixing code changes and the context of the surrounding source code of the bug-fixing code changes. These limitations lead to incorrect fixing locations or fixes. In this paper, we introduce DLFix, a two-tier DL model that treats APR as code transformation learning from the prior bug fixes and the surrounding code contexts of the fixes. The first layer is a tree-based RNN model that learns the contexts of bug fixes and its result is used as an additional weighting input for the second layer designed to learn the bug-fixing code transformations.\n\nWe conducted several experiments to evaluate DLFix in two benchmarks: Defect4j and Bugs.jar, and a newly built bug datasets with a total of +20K real-world bugs in eight projects. We compared DLFix against a total of 13 state-of-the-art pattern-based APR tools. Our results show that DLFix can auto-fix more bugs than 11 of them, and is comparable and complementary to the top two pattern-based APR tools in which there are 7 and 11 unique bugs that they cannot detect, respectively, but we can. Importantly, DLFix is fully automated and data-driven, and does not require hard-coding of bug-fixing patterns as in those tools. We compared DLFix against 4 state-of-the-art deep learning based APR models. DLFix is able to fix 2.5 times more bugs than the best performing baseline."
}, {
    "py/object": "data.DataClassPaper",
    "Title": "Dynamic Neural Program Embedding for Program Repair",
    "year": 2017,
    "ML_Techniques": "RNN",
    "Category": "Program synthesis",
    "Sub_category": "Program repair",
    "Venue": "ICLR",
    "Link": "https://arxiv.org/abs/1711.07163",
    "bibtex": "article{Wang2017_304,\n    author = \"Wang, Ke and Singh, Rishabh and Su, Zhendong\",\n    year = \"2017\",\n    month = \"11\",\n    pages = \"\",\n    title = \"Dynamic Neural Program Embedding for Program Repair\"\n}\n\n",
    "abstract": "Neural program embeddings have shown much promise recently for a variety of program analysis tasks, including program synthesis, program repair, fault localization, etc. However, most existing program embeddings are based on syntactic features of programs, such as raw token sequences or abstract syntax trees. Unlike images and text, a program has an unambiguous semantic meaning that can be difficult to capture by only considering its syntax (i.e. syntactically similar pro- grams can exhibit vastly different run-time behavior), which makes syntax-based program embeddings fundamentally limited. This paper proposes a novel semantic program embedding that is learned from program execution traces. Our key insight is that program states expressed as sequential tuples of live variable values not only captures program semantics more precisely, but also offer a more natural fit for Recurrent Neural Networks to model. We evaluate different syntactic and semantic program embeddings on predicting the types of errors that students make in their submissions to an introductory programming class and two exercises on the CodeHunt education platform. Evaluation results show that our new semantic program embedding significantly outperforms the syntactic program embeddings based on token sequences and abstract syntax trees. In addition, we augment a search-based program repair system with the predictions obtained from our se- mantic embedding, and show that search efficiency is also significantly improved."
}, {
    "py/object": "data.DataClassPaper",
    "Title": "Elixir: Effective object-oriented program repair",
    "year": 2017,
    "ML_Techniques": "LOG",
    "Category": "Program synthesis",
    "Sub_category": "Program repair",
    "Venue": "ASE",
    "Link": "https://ieeexplore.ieee.org/abstract/document/8115675",
    "bibtex": "INPROCEEDINGS{Saha2017_306,\n    author = \"{Saha}, R. K. and {Lyu}, Y. and {Yoshida}, H. and {Prasad}, M. R.\",\n    booktitle = \"2017 32nd IEEE/ACM International Conference on Automated Software Engineering (ASE)\",\n    title = \"Elixir: Effective object-oriented program repair\",\n    year = \"2017\",\n    volume = \"\",\n    number = \"\",\n    pages = \"648-659\",\n    doi = \"10.1109/ASE.2017.8115675\"\n}\n\n",
    "abstract": "This work is motivated by the pervasive use of method invocations in object-oriented (OO) programs, and indeed their prevalence in patches of OO-program bugs. We propose a generate-and-validate repair technique, called ELIXIR designed to be able to generate such patches. ELIXIR aggressively uses method calls, on par with local variables, fields, or constants, to construct more expressive repair-expressions, that go into synthesizing patches. The ensuing enlargement of the repair space, on account of the wider use of method calls, is effectively tackled by using a machine-learnt model to rank concrete repairs. The machine-learnt model relies on four features derived from the program context, i.e., the code surrounding the potential repair location, and the bug report. We implement ELIXIR and evaluate it on two datasets, the popular Defects4J dataset and a new dataset Bugs.jar created by us, and against 2 baseline versions of our technique, and 5 other techniques representing the state of the art in program repair. Our evaluation shows that ELIXIR is able to increase the number of correctly repaired bugs in Defects4J by 85% (from 14 to 26) and by 57% in Bugs.jar (from 14 to 22), while also significantly out-performing other state-of-the-art repair techniques including ACS, HD-Repair, NOPOL, PAR, and jGenProg."
}, {
    "py/object": "data.DataClassPaper",
    "Title": "Enabling Machine Learning on Resource Constrained Devices by Source Code Generation of the Learned Models",
    "year": 2018,
    "ML_Techniques": "NB, DT, MLP",
    "Category": "Program synthesis",
    "Sub_category": "",
    "Venue": "ICCS",
    "Link": "https://link.springer.com/chapter/10.1007/978-3-319-93701-4_54",
    "bibtex": "InProceedings{Szydlo2018_307,\n    author = \"Szydlo, Tomasz and Sendorek, Joanna and Brzoza-Woch, Robert\",\n    editor = \"Shi, Yong and Fu, Haohuan and Tian, Yingjie and Krzhizhanovskaya, Valeria V. and Lees, Michael Harold and Dongarra, Jack and Sloot, Peter M. A.\",\n    title = \"Enabling Machine Learning on Resource Constrained Devices by Source Code Generation of the Learned Models\",\n    booktitle = \"Computational Science -- ICCS 2018\",\n    year = \"2018\",\n    publisher = \"Springer International Publishing\",\n    address = \"Cham\",\n    pages = \"682--694\",\n    abstract = \"Due to the development of IoT solutions, we can observe the constantly growing number of these devices in almost every aspect of our lives. The machine learning may improve increase their intelligence and smartness. Unfortunately, the highly regarded programming libraries consume to much resources to be ported to the embedded processors. Thus, in the paper the concept of source code generation of machine learning models is presented as well as the generation algorithms for commonly used machine learning methods. The concept has been proven in the use cases.\",\n    isbn = \"978-3-319-93701-4\"\n}\n\n",
    "abstract": "Due to the development of IoT solutions, we can observe the constantly growing number of these devices in almost every aspect of our lives. The machine learning may improve increase their intelligence and smartness. Unfortunately, the highly regarded programming libraries consume to much resources to be ported to the embedded processors. Thus, in the paper the concept of source code generation of machine learning models is presented as well as the generation algorithms for commonly used machine learning methods. The concept has been proven in the use cases."
}, {
    "py/object": "data.DataClassPaper",
    "Title": "Evaluating Representation Learning of Code Changes for Predicting Patch Correctness in Program Repair",
    "year": 2020,
    "ML_Techniques": "BERT, LOG, NN",
    "Category": "Program synthesis",
    "Sub_category": "Program repair",
    "Venue": "ASE",
    "Link": "https://ieeexplore.ieee.org/abstract/document/9286101",
    "bibtex": "INPROCEEDINGS{Tian2020_309,\n    author = \"{Tian}, H. and {Liu}, K. and {Kabor\u00e9}, A. K. and {Koyuncu}, A. and {Li}, L. and {Klein}, J. and {Bissyand\u00e9}, T. F.\",\n    booktitle = \"2020 35th IEEE/ACM International Conference on Automated Software Engineering (ASE)\",\n    title = \"Evaluating Representation Learning of Code Changes for Predicting Patch Correctness in Program Repair\",\n    year = \"2020\",\n    volume = \"\",\n    number = \"\",\n    pages = \"981-992\",\n    doi = \"\"\n}\n\n",
    "abstract": "A large body of the literature of automated program repair develops approaches where patches are generated to be validated against an oracle (e.g., a test suite). Because such an oracle can be imperfect, the generated patches, although validated by the oracle, may actually be incorrect. While the state of the art explore research directions that require dynamic information or rely on manually-crafted heuristics, we study the benefit of learning code representations to learn deep features that may encode the properties of patch correctness. Our work mainly investigates different representation learning approaches for code changes to derive embeddings that are amenable to similarity computations. We report on findings based on embeddings produced by pre-trained and re-trained neural networks. Experimental results demonstrate the potential of embeddings to empower learning algorithms in reasoning about patch correctness: a machine learning predictor with BERT transformer-based embeddings associated with logistic regression yielded an AUC value of about 0.8 in predicting patch correctness on a deduplicated dataset of 1000 labeled patches. Our study shows that learned representations can lead to reasonable performance when comparing against the state-of-the-art, PATCH-SIM, which relies on dynamic information. These representations may further be complementary to features that were carefully (manually) engineered in the literature."
}, {
    "py/object": "data.DataClassPaper",
    "Title": "EXECUTION-GUIDED NEURAL PROGRAM SYNTHESIS",
    "year": 2019,
    "ML_Techniques": "EN-DE",
    "Category": "Program synthesis",
    "Sub_category": "",
    "Venue": "ICLR",
    "Link": "https://openreview.net/forum?id=H1gfOiAqYm",
    "bibtex": "INPROCEEDINGS{Tian2020_309,\n    author = \"{Tian}, H. and {Liu}, K. and {Kabor\u00e9}, A. K. and {Koyuncu}, A. and {Li}, L. and {Klein}, J. and {Bissyand\u00e9}, T. F.\",\n    booktitle = \"2020 35th IEEE/ACM International Conference on Automated Software Engineering (ASE)\",\n    title = \"Evaluating Representation Learning of Code Changes for Predicting Patch Correctness in Program Repair\",\n    year = \"2020\",\n    volume = \"\",\n    number = \"\",\n    pages = \"981-992\",\n    doi = \"\"\n}\n\n",
    "abstract": "Neural program synthesis from input-output examples has attracted an increasing interest from both the machine learning and the programming language community. Most existing neural program synthesis approaches employ an encoder-decoder architecture, which uses an encoder to compute the embedding of the given input-output examples, as well as a decoder to generate the program from the embedding following a given syntax. Although such approaches achieve a reasonable performance on simple tasks such as FlashFill, on more complex tasks such as Karel, the state-of-the-art approach can only achieve an accuracy of around 77%. We observe that the main drawback of existing approaches is that the semantic information is greatly under-utilized. In this work, we propose two simple yet principled techniques to better leverage the semantic information, which are execution-guided synthesis and synthesizer ensemble. These techniques are general enough to be combined with any existing encoder-decoder-style neural program synthesizer. Applying our techniques to the Karel dataset, we can boost the accuracy from around 77% to more than 90%."
}, {
    "py/object": "data.DataClassPaper",
    "Title": "Exploring Paraphrasing Techniques on Formal Language for Generating Semantics Preserving Source Code Transformations",
    "year": 2020,
    "ML_Techniques": "GAN",
    "Category": "Program synthesis",
    "Sub_category": ",Refactoring",
    "Venue": "ICSC",
    "Link": "https://ieeexplore.ieee.org/document/9031503",
    "bibtex": "INPROCEEDINGS{Stein2020_311,\n    author = \"{Stein}, A. J. and {Kapllani}, L. and {Mancoridis}, S. and {Greenstadt}, R.\",\n    booktitle = \"2020 IEEE 14th International Conference on Semantic Computing (ICSC)\",\n    title = \"Exploring Paraphrasing Techniques on Formal Language for Generating Semantics Preserving Source Code Transformations\",\n    year = \"2020\",\n    volume = \"\",\n    number = \"\",\n    pages = \"242-248\",\n    doi = \"10.1109/ICSC.2020.00051\"\n}\n\n",
    "abstract": "Automatically identifying and generating equivalent semantic content to a word, phrase, or sentence is an important part of natural language processing (NLP). The research done so far in paraphrases in NLP has been focused exclusively on textual data, but has significant potential if it is applied to formal languages like source code. In this paper, we present a novel technique for generating source code transformations via the use of paraphrases. We explore how to extract and validate source code paraphrases. The transformations can be used for stylometry tasks and processes like refactoring. A machine learning method of identifying valid transformations has the advantage of avoiding the generation of transformations by hand and is more likely to have more valid transformations. Our dataset is comprised by 27,300 C++ source code files, consisting of 273topics each with 10 parallel files. This generates approximately152,000 paraphrases. Of these paraphrases, 11% yield valid code transformations. We then train a random forest classifier that can identify valid transformations with 83% accuracy. In this paper we also discuss some of the observed relationships betweenlinked paraphrase transformations. We depict the relationshipsthat emerge between alternative equivalent code transformationsin a graph formalism"
}, {
    "py/object": "data.DataClassPaper",
    "Title": "Getafix: learning to fix bugs automatically",
    "year": 2019,
    "ML_Techniques": "HC",
    "Category": "Program synthesis",
    "Sub_category": "Program repair",
    "Venue": "OOPSLA",
    "Link": "https://dl.acm.org/doi/10.1145/3360585",
    "bibtex": "INPROCEEDINGS{Stein2020_311,\n    author = \"{Stein}, A. J. and {Kapllani}, L. and {Mancoridis}, S. and {Greenstadt}, R.\",\n    booktitle = \"2020 IEEE 14th International Conference on Semantic Computing (ICSC)\",\n    title = \"Exploring Paraphrasing Techniques on Formal Language for Generating Semantics Preserving Source Code Transformations\",\n    year = \"2020\",\n    volume = \"\",\n    number = \"\",\n    pages = \"242-248\",\n    doi = \"10.1109/ICSC.2020.00051\"\n}\n\n",
    "abstract": "Static analyzers help find bugs early by warning about recurring bug categories. While fixing these bugs still remains a mostly manual task in practice, we observe that fixes for a specific bug category often are repetitive. This paper addresses the problem of automatically fixing instances of common bugs by learning from past fixes. We present Getafix, an approach that produces human-like fixes while being fast enough to suggest fixes in time proportional to the amount of time needed to obtain static analysis results in the first place.\n\nGetafix is based on a novel hierarchical clustering algorithm that summarizes fix patterns into a hierarchy ranging from general to specific patterns. Instead of an expensive exploration of a potentially large space of candidate fixes, Getafix uses a simple yet effective ranking technique that uses the context of a code change to select the most appropriate fix for a given bug.\n\nOur evaluation applies Getafix to 1,268 bug fixes for six bug categories reported by popular static analyzers for Java, including null dereferences, incorrect API calls, and misuses of particular language constructs. The approach predicts exactly the human-written fix as the top-most suggestion between 12% and 91% of the time, depending on the bug category. The top-5 suggestions contain fixes for 526 of the 1,268 bugs. Moreover, we report on deploying the approach within Facebook, where it contributes to the reliability of software used by billions of people. To the best of our knowledge, Getafix is the first industrially-deployed automated bug-fixing tool that learns fix patterns from past, human-written fixes to produce human-like fixes."
}, {
    "py/object": "data.DataClassPaper",
    "Title": "Glass-Box Program Synthesis: A Machine Learning Approach",
    "year": 2017,
    "ML_Techniques": "LOG",
    "Category": "Program synthesis",
    "Sub_category": "",
    "Venue": "AAAI",
    "Link": "https://arxiv.org/abs/1709.08669v1",
    "bibtex": "inproceedings{Christakopoulou2018_313,\n    author = \"Christakopoulou, Konstantina and Kalai, A.\",\n    title = \"Glass-Box Program Synthesis: A Machine Learning Approach\",\n    booktitle = \"AAAI\",\n    year = \"2018\"\n}\n\n",
    "abstract": "Recently proposed models which learn to write computer programs from data use either input/output examples or rich execution traces. Instead, we argue that a novel alternative is to use a glass-box loss function, given as a program itself that can be directly inspected. Glass-box optimization covers a wide range of problems, from computing the greatest common divisor of two integers, to learning-to-learn problems.\nIn this paper, we present an intelligent search system which learns, given the partial program and the glass-box problem, the probabilities over the space of programs. We empirically demonstrate that our informed search procedure leads to significant improvements compared to brute-force program search, both in terms of accuracy and time. For our experiments we use rich context free grammars inspired by number theory, text processing, and algebra. Our results show that (i) performing 4 rounds of our framework typically solves about 70% of the target problems, (ii) our framework can improve itself even in domain agnostic scenarios, and (iii) it can solve problems that would be otherwise too slow to solve with brute-force search."
}, {
    "py/object": "data.DataClassPaper",
    "Title": "Harnessing Evolution for Multi-Hunk Program Repair",
    "year": 2019,
    "ML_Techniques": "",
    "Category": "Program synthesis",
    "Sub_category": "Program repair",
    "Venue": "ICSE",
    "Link": "https://ieeexplore.ieee.org/abstract/document/8812131",
    "bibtex": "INPROCEEDINGS{Saha2019_315,\n    author = \"{Saha}, S. and k. {Saha}, R. and r. {Prasad}, M.\",\n    booktitle = \"2019 IEEE/ACM 41st International Conference on Software Engineering (ICSE)\",\n    title = \"Harnessing Evolution for Multi-Hunk Program Repair\",\n    year = \"2019\",\n    volume = \"\",\n    number = \"\",\n    pages = \"13-24\",\n    doi = \"10.1109/ICSE.2019.00020\"\n}\n\n",
    "abstract": "Despite significant advances in automatic program repair (APR) techniques over the past decade, practical deployment remains an elusive goal. One of the important challenges in this regard is the general inability of current APR techniques to produce patches that require edits in multiple locations, i.e., multi-hunk patches. In this work, we present a novel APR technique that generalizes single-hunk repair techniques to include an important class of multi-hunk bugs, namely bugs that may require applying a substantially similar patch at a number of locations. We term such sets of repair locations as evolutionary siblings - similar looking code, instantiated in similar contexts, that are expected to undergo similar changes. At the heart of our proposed method is an analysis to accurately identify a set of evolutionary siblings, for a given bug. This analysis leverages three distinct sources of information, namely the test-suite spectrum, a novel code similarity analysis, and the revision history of the project. The discovered siblings are then simultaneously repaired in a similar fashion. We instantiate this technique in a tool called Hercules and demonstrate that it is able to correctly fix 46 bugs in the Defects4J dataset, the highest of any individual APR technique to date. This includes 15 multi-hunk bugs and overall 11 bugs which have not been fixed by any other technique so far."
}, {
    "py/object": "data.DataClassPaper",
    "Title": "How Different Is It Between Machine-Generated and Developer-Provided Patches? : An Empirical Study on the Correct Patches Generated by Automated Program Repair Techniques",
    "year": 2019,
    "ML_Techniques": "",
    "Category": "Program synthesis",
    "Sub_category": "Program repair",
    "Venue": "ESEM",
    "Link": "https://ieeexplore.ieee.org/abstract/document/8870172",
    "bibtex": "INPROCEEDINGS{Wang2019_316,\n    author = \"{Wang}, S. and {Wen}, M. and {Chen}, L. and {Yi}, X. and {Mao}, X.\",\n    booktitle = \"2019 ACM/IEEE International Symposium on Empirical Software Engineering and Measurement (ESEM)\",\n    title = \"How Different Is It Between Machine-Generated and Developer-Provided Patches? : An Empirical Study on the Correct Patches Generated by Automated Program Repair Techniques\",\n    year = \"2019\",\n    volume = \"\",\n    number = \"\",\n    pages = \"1-12\",\n    doi = \"10.1109/ESEM.2019.8870172\"\n}\n\n",
    "abstract": "Background: Over the years, Automated Program Repair (APR) has attracted much attention from both academia and industry since it can reduce the costs in fixing bugs. However, how to assess the patch correctness remains to be an open challenge. Two widely adopted ways to approach this challenge, including manually checking and validating using automated generated tests, are biased (i.e., suffering from subjectivity and low precision respectively). Aim: To address this concern, we propose to conduct an empirical study towards understanding the correct patches that are generated by existing state-of-the-art APR techniques, aiming at providing guidelines for future assessment of patches. Method: To this end, we first present a Literature Review (LR) on the reported correct patches generated by recent techniques on the Defects 4J benchmark and collect 177 correct patches after a process of sanity check. We investigate how these machine-generated correct patches achieve semantic equivalence, but syntactic difference compared with developer-provided ones, how these patches distribute in different projects and APR techniques, and how the characteristics of a bug affect the patches generated for it. Results: Our main findings include: 1) we do not need to fix bugs exactly like how developers do since we observe that 25.4% (45/177) of the correct patches generated by APR techniques are syntactically different from developer-provided ones; 2) the distribution of machine-generated correct patches diverges for the aspects of Defects 4J projects and APR techniques; and 3) APR techniques tend to generate patches that are different from those by developers for bugs with large patch sizes. Conclusion: Our study not only verifies the conclusions from previous studies but also highlights implications for future study towards assessing patch correctness."
}, {
    "py/object": "data.DataClassPaper",
    "Title": "Human-In-The-Loop Automatic Program Repair",
    "year": 2020,
    "ML_Techniques": "",
    "Category": "Program synthesis",
    "Sub_category": "Program repair",
    "Venue": "ICST",
    "Link": "https://arxiv.org/abs/1912.07758",
    "bibtex": "INPROCEEDINGS{B\u00f6hme2020_317,\n    author = \"{B\u00f6hme}, M. and {Geethal}, C. and {Pham}, V. -T.\",\n    booktitle = \"2020 IEEE 13th International Conference on Software Testing, Validation and Verification (ICST)\",\n    title = \"Human-In-The-Loop Automatic Program Repair\",\n    year = \"2020\",\n    volume = \"\",\n    number = \"\",\n    pages = \"274-285\",\n    doi = \"10.1109/ICST46399.2020.00036\"\n}\n\n",
    "abstract": "We introduce Learn2fix, the first human-in-the-loop, semi-automatic repair technique when no bug oracle--except for the user who is reporting the bug--is available. Our approach negotiates with the user the condition under which the bug is observed. Only when a budget of queries to the user is exhausted, it attempts to repair the bug. A query can be thought of as the following question: \"When executing this alternative test input, the program produces the following output; is the bug observed\"? Through systematic queries, Learn2fix trains an automatic bug oracle that becomes increasingly more accurate in predicting the user's response. Our key challenge is to maximize the oracle's accuracy in predicting which tests are bug-exposing given a small budget of queries. From the alternative tests that were labeled by the user, test-driven automatic repair produces the patch.\nOur experiments demonstrate that Learn2fix learns a sufficiently accurate automatic oracle with a reasonably low labeling effort (lt. 20 queries). Given Learn2fix's test suite, the GenProg test-driven repair tool produces a higher-quality patch (i.e., passing a larger proportion of validation tests) than using manual test suites provided with the repair benchmark."
}, {
    "py/object": "data.DataClassPaper",
    "Title": "Improving automated program repair using two-layer tree-based neural networks",
    "year": 2020,
    "ML_Techniques": "EN-DE, CNN",
    "Category": "Program synthesis",
    "Sub_category": "Program repair",
    "Venue": "ICSE",
    "Link": "https://dl.acm.org/doi/10.1145/3377812.3390896",
    "bibtex": "INPROCEEDINGS{B\u00f6hme2020_317,\n    author = \"{B\u00f6hme}, M. and {Geethal}, C. and {Pham}, V. -T.\",\n    booktitle = \"2020 IEEE 13th International Conference on Software Testing, Validation and Verification (ICST)\",\n    title = \"Human-In-The-Loop Automatic Program Repair\",\n    year = \"2020\",\n    volume = \"\",\n    number = \"\",\n    pages = \"274-285\",\n    doi = \"10.1109/ICST46399.2020.00036\"\n}\n\n",
    "abstract": "We present DLFix, a two-layer tree-based model learning bug-fixing code changes and their surrounding code context to improve Automated Program Repair (APR). The first layer learns the surrounding code context of a fix and uses it as weights for the second layer that is used to learn the bug-fixing code transformation. Our empirical results on Defect4J show that DLFix can fix 30 bugs and its results are comparable and complementary to the best performing pattern-based APR tools. Furthermore, DLFix can fix 2.5 times more bugs than the best performing deep learning baseline."
}, {
    "py/object": "data.DataClassPaper",
    "Title": "Improving performance of automatic program repair using learned heuristics",
    "year": 2017,
    "ML_Techniques": "RF",
    "Category": "Program synthesis",
    "Sub_category": "Program repair",
    "Venue": "FSE",
    "Link": "https://dl.acm.org/doi/abs/10.1145/3106237.3121281",
    "bibtex": "INPROCEEDINGS{B\u00f6hme2020_317,\n    author = \"{B\u00f6hme}, M. and {Geethal}, C. and {Pham}, V. -T.\",\n    booktitle = \"2020 IEEE 13th International Conference on Software Testing, Validation and Verification (ICST)\",\n    title = \"Human-In-The-Loop Automatic Program Repair\",\n    year = \"2020\",\n    volume = \"\",\n    number = \"\",\n    pages = \"274-285\",\n    doi = \"10.1109/ICST46399.2020.00036\"\n}\n\n",
    "abstract": "Automatic program repair offers the promise of significant reduction in debugging time, but still faces challenges in making the process efficient, accurate, and generalizable enough for practical application. Recent efforts such as Prophet demonstrate that machine learning can be used to develop heuristics about which patches are likely to be correct, reducing overfitting problems and improving speed of repair. SearchRepair takes a different approach to accuracy, using blocks of human-written code as patches to better constrain repairs and avoid overfitting. This project combines Prophet's learning techniques with SearchRepair's larger block size to create a method that is both fast and accurate, leading to higher-quality repairs. We propose a novel first-pass filter to substantially reduce the number of candidate patches in SearchRepair and demonstrate 85% reduction in runtime over standard SearchRepair on the IntroClass dataset."
}, {
    "py/object": "data.DataClassPaper",
    "Title": "IntelliCode compose: code generation using transformer",
    "year": 2020,
    "ML_Techniques": "GPT-C",
    "Category": "Program synthesis",
    "Sub_category": "",
    "Venue": "FSE",
    "Link": "https://dl.acm.org/doi/10.1145/3368089.3417058",
    "bibtex": "INPROCEEDINGS{B\u00f6hme2020_317,\n    author = \"{B\u00f6hme}, M. and {Geethal}, C. and {Pham}, V. -T.\",\n    booktitle = \"2020 IEEE 13th International Conference on Software Testing, Validation and Verification (ICST)\",\n    title = \"Human-In-The-Loop Automatic Program Repair\",\n    year = \"2020\",\n    volume = \"\",\n    number = \"\",\n    pages = \"274-285\",\n    doi = \"10.1109/ICST46399.2020.00036\"\n}\n\n",
    "abstract": "In software development through integrated development environments (IDEs), code completion is one of the most widely used features. Nevertheless, majority of integrated development environments only support completion of methods and APIs, or arguments.\n\nIn this paper, we introduce IntelliCode Compose \u2013 a general-purpose multilingual code completion tool which is capable of predicting sequences of code tokens of arbitrary types, generating up to entire lines of syntactically correct code. It leverages state-of-the-art generative transformer model trained on 1.2 billion lines of source code in Python, C#, JavaScript and TypeScript programming languages. IntelliCode Compose is deployed as a cloud-based web service. It makes use of client-side tree-based caching, efficient parallel implementation of the beam search decoder, and compute graph optimizations to meet edit-time completion suggestion requirements in the Visual Studio Code IDE and Azure Notebook.\n\nOur best model yields an average edit similarity of 86.7% and a perplexity of 1.82 for Python programming language."
}, {
    "py/object": "data.DataClassPaper",
    "Title": "Latent Attention For If-Then Program Synthesis",
    "year": 2016,
    "ML_Techniques": "Bi-LSTM",
    "Category": "Program synthesis",
    "Sub_category": "",
    "Venue": "NIPS",
    "Link": "https://arxiv.org/abs/1611.01867v1",
    "bibtex": "INPROCEEDINGS{B\u00f6hme2020_317,\n    author = \"{B\u00f6hme}, M. and {Geethal}, C. and {Pham}, V. -T.\",\n    booktitle = \"2020 IEEE 13th International Conference on Software Testing, Validation and Verification (ICST)\",\n    title = \"Human-In-The-Loop Automatic Program Repair\",\n    year = \"2020\",\n    volume = \"\",\n    number = \"\",\n    pages = \"274-285\",\n    doi = \"10.1109/ICST46399.2020.00036\"\n}\n\n",
    "abstract": "Automatic translation from natural language descriptions into programs is a longstanding challenging problem. In this work, we consider a simple yet important sub-problem: translation from textual descriptions to If-Then programs. We devise a novel neural network architecture for this task which we train end-to-end. Specifically, we introduce Latent Attention, which computes multiplicative weights for the words in the description in a two-stage process with the goal of better leveraging the natural language structures that indicate the relevant parts for predicting program elements. Our architecture reduces the error rate by 28.57% compared to prior art. We also propose a one-shot learning scenario of If-Then program synthesis and simulate it with our existing dataset. We demonstrate a variation on the training procedure for this scenario that outperforms the original procedure, significantly closing the gap to the model trained with all data."
}, {
    "py/object": "data.DataClassPaper",
    "Title": "Latent Predictor Networks for Code Generation",
    "year": 2016,
    "ML_Techniques": "",
    "Category": "Program synthesis",
    "Sub_category": "",
    "Venue": "ACL",
    "Link": "https://arxiv.org/abs/1603.06744",
    "bibtex": "inproceedings{Ling2016_324,\n    author = \"Ling, Wang and Blunsom, Phil and Grefenstette, Edward and Hermann, Karl Moritz and Ko{\\v{c}}isk{\\'y}, Tom{\\'a}{\\v{s}} and Wang, Fumin and Senior, Andrew\",\n    title = \"Latent Predictor Networks for Code Generation\",\n    booktitle = \"Proceedings of the 54th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)\",\n    month = \"August\",\n    year = \"2016\",\n    address = \"Berlin, Germany\",\n    publisher = \"Association for Computational Linguistics\",\n    url = \"https://www.aclweb.org/anthology/P16-1057\",\n    doi = \"10.18653/v1/P16-1057\",\n    pages = \"599--609\"\n}\n\n",
    "abstract": "Many language generation tasks require the production of text conditioned on both structured and unstructured inputs. We present a novel neural network architecture which generates an output sequence conditioned on an arbitrary number of input functions. Crucially, our approach allows both the choice of conditioning context and the granularity of generation, for example characters or tokens, to be marginalised, thus permitting scalable and effective training. Using this framework, we address the problem of generating programming code from a mixed natural language and structured specification. We create two new data sets for this paradigm derived from the collectible trading card games Magic the Gathering and Hearthstone. On these, and a third preexisting corpus, we demonstrate that marginalising multiple predictors allows our model to outperform strong benchmarks."
}, {
    "py/object": "data.DataClassPaper",
    "Title": "Learning to Generate Pseudo-Code from Source Code Using Statistical Machine Translation",
    "year": 2015,
    "ML_Techniques": "SMT",
    "Category": "Program synthesis",
    "Sub_category": "Program translation",
    "Venue": "ASE",
    "Link": "https://ieeexplore.ieee.org/abstract/document/7372045",
    "bibtex": "INPROCEEDINGS{Oda2015_325,\n    author = \"{Oda}, Y. and {Fudaba}, H. and {Neubig}, G. and {Hata}, H. and {Sakti}, S. and {Toda}, T. and {Nakamura}, S.\",\n    booktitle = \"2015 30th IEEE/ACM International Conference on Automated Software Engineering (ASE)\",\n    title = \"Learning to Generate Pseudo-Code from Source Code Using Statistical Machine Translation\",\n    year = \"2015\",\n    volume = \"\",\n    number = \"\",\n    pages = \"574-584\",\n    doi = \"10.1109/ASE.2015.36\"\n}\n\n",
    "abstract": "Pseudo-code written in natural language can aid the comprehension of source code in unfamiliar programming languages. However, the great majority of source code has no corresponding pseudo-code, because pseudo-code is redundant and laborious to create. If pseudo-code could be generated automatically and instantly from given source code, we could allow for on-demand production of pseudo-code without human effort. In this paper, we propose a method to automatically generate pseudo-code from source code, specifically adopting the statistical machine translation (SMT) framework. SMT, which was originally designed to translate between two natural languages, allows us to automatically learn the relationship between source code/pseudo-code pairs, making it possible to create a pseudo-code generator with less human effort. In experiments, we generated English or Japanese pseudo-code from Python statements using SMT, and find that the generated pseudo-code is largely accurate, and aids code understanding."
}, {
    "py/object": "data.DataClassPaper",
    "Title": "Learning to Represent Programs with Graphs",
    "year": 2017,
    "ML_Techniques": "GGNN",
    "Category": "Program synthesis",
    "Sub_category": "",
    "Venue": "ICLR",
    "Link": "https://arxiv.org/abs/1711.00740v1",
    "bibtex": "inproceedings{Allamanis2018_326,\n    author = \"Allamanis, Miltiadis and Brockschmidt, Marc and Khademi, Mahmoud\",\n    title = \"Learning to Represent Programs with Graphs\",\n    booktitle = \"International Conference on Learning Representations\",\n    year = \"2018\",\n    url = \"https://openreview.net/forum?id=BJOFETxR-\"\n}\n\n",
    "abstract": "Learning tasks on source code (i.e., formal languages) have been considered recently, but most work has tried to transfer natural language methods and does not capitalize on the unique opportunities offered by code's known syntax. For example, long-range dependencies induced by using the same variable or function in distant locations are often not considered. We propose to use graphs to represent both the syntactic and semantic structure of code and use graph-based deep learning methods to learn to reason over program structures.\nIn this work, we present how to construct graphs from source code and how to scale Gated Graph Neural Networks training to such large graphs. We evaluate our method on two tasks: VarNaming, in which a network attempts to predict the name of a variable given its usage, and VarMisuse, in which the network learns to reason about selecting the correct variable that should be used at a given program location. Our comparison to methods that use less structured program representations shows the advantages of modeling known structure, and suggests that our models learn to infer meaningful names and to solve the VarMisuse task in many cases. Additionally, our testing showed that VarMisuse identifies a number of bugs in mature open-source projects."
}, {
    "py/object": "data.DataClassPaper",
    "Title": "Learning to synthesize",
    "year": 2018,
    "ML_Techniques": "GBT",
    "Category": "Program synthesis",
    "Sub_category": "",
    "Venue": "GI",
    "Link": "https://dl.acm.org/doi/10.1145/3194810.3194816",
    "bibtex": "inproceedings{Allamanis2018_326,\n    author = \"Allamanis, Miltiadis and Brockschmidt, Marc and Khademi, Mahmoud\",\n    title = \"Learning to Represent Programs with Graphs\",\n    booktitle = \"International Conference on Learning Representations\",\n    year = \"2018\",\n    url = \"https://openreview.net/forum?id=BJOFETxR-\"\n}\n\n",
    "abstract": "In many scenarios we need to find the most likely program under a local context, where the local context can be an incomplete program, a partial specification, natural language description, etc. We call such problem program estimations. In this paper we propose an abstract framework, learning to synthesis, or L2S in short, to address this problem. L2S combines four tools to achieve this: rewriting rules are used to define the search space and search steps, constraint solving is used to prune off invalid candidates at each search step, machine learning is used to estimate conditional probabilities for the candidates at each search step, and search algorithms are used to find the best possible solution. The main goal of L2S is to lay out the design space to motivate the research on program estimation.\n\nWe have performed a preliminary evaluation by instantiating this framework for synthesizing conditions of an automated program repair (APR) system. The training data are from the project itself and related JDK packages. Compared to ACS, a state-of-the-art condition synthesis system for program repair, our approach could deal with a larger search space such that we fixed 4 additional bugs outside the search space of ACS, and relies only the source code of the current projects."
}, {
    "py/object": "data.DataClassPaper",
    "Title": "Machine Learning-Driven Automatic Program Transformation to Increase Performance in Heterogeneous Architectures",
    "year": 2017,
    "ML_Techniques": "RL",
    "Category": "Program synthesis",
    "Sub_category": "Refactoring",
    "Venue": "HPC",
    "Link": "https://link.springer.com/chapter/10.1007/978-3-319-56702-0_7",
    "bibtex": "InProceedings{Tamarit2017_328,\n    author = \"Tamarit, Salvador and Vigueras, Guillermo and Carro, Manuel and Mari{\\\\textasciitilde {n}}o, Julio\",\n    editor = {Niethammer, Christoph and Gracia, Jos{\\'e} and Hilbrich, Tobias and Kn{\\\"u}pfer, Andreas and Resch, Michael M. and Nagel, Wolfgang E.},\n    title = \"Machine Learning-Driven Automatic Program Transformation to Increase Performance in Heterogeneous Architectures\",\n    booktitle = \"Tools for High Performance Computing 2016\",\n    year = \"2017\",\n    publisher = \"Springer International Publishing\",\n    address = \"Cham\",\n    pages = \"115--140\",\n    abstract = \"We present a program transformation approach to convert procedural code into functionally equivalent code adapted to a given platform. Our framework is based on the application of guarded transformation rules that capture semantic conditions to ensure the soundness of their application. Our goal is to determine a sequence of rule applications which transform some initial code into final code which optimizes some non-functional properties. The code to be transformed is adorned with semantic annotations, either provided by the user or by external analysis tools. These annotations give information to decide whether applying a transformation rule is or is not sound. In general, there are several rules applicable at several program points and, besides, transformation sequences do not monotonically change the optimization function. Therefore, we face a search problem that grows exponentially with the length of the transformation sequence. In our experience with even small examples, that becomes impractical very quickly. In order to effectively deal with this issue, we have adopted a machine-learning approach using classification trees and reinforcement learning. It learns from successful transformation sequences and produces encodings of strategies which can provide long-term rewards for a given characteristic, avoiding local minima. We have evaluated the proposed technique in a series of benchmarks, adapting standard C code to GPU execution via OpenCL. We have found the automatically produced code to be as efficient as hand-written code generated by an expert human programmer.\",\n    isbn = \"978-3-319-56702-0\"\n}\n\n",
    "abstract": "We present a program transformation approach to convert procedural code into functionally equivalent code adapted to a given platform. Our framework is based on the application of guarded transformation rules that capture semantic conditions to ensure the soundness of their application. Our goal is to determine a sequence of rule applications which transform some initial code into final code which optimizes some non-functional properties. The code to be transformed is adorned with semantic annotations, either provided by the user or by external analysis tools. These annotations give information to decide whether applying a transformation rule is or is not sound. In general, there are several rules applicable at several program points and, besides, transformation sequences do not monotonically change the optimization function. Therefore, we face a search problem that grows exponentially with the length of the transformation sequence. In our experience with even small examples, that becomes impractical very quickly. In order to effectively deal with this issue, we have adopted a machine-learning approach using classification trees and reinforcement learning. It learns from successful transformation sequences and produces encodings of strategies which can provide long-term rewards for a given characteristic, avoiding local minima. We have evaluated the proposed technique in a series of benchmarks, adapting standard C code to GPU execution via OpenCL. We have found the automatically produced code to be as efficient as hand-written code generated by an expert human programmer."
}, {
    "py/object": "data.DataClassPaper",
    "Title": "MAKING NEURAL PROGRAMMING ARCHITECTURES GENERALIZE VIA RECURSION",
    "year": 2017,
    "ML_Techniques": "LSTM",
    "Category": "Program synthesis",
    "Sub_category": "",
    "Venue": "CoRR",
    "Link": "https://arxiv.org/abs/1704.06611v1",
    "bibtex": "InProceedings{Tamarit2017_328,\n    author = \"Tamarit, Salvador and Vigueras, Guillermo and Carro, Manuel and Mari{\\\\textasciitilde {n}}o, Julio\",\n    editor = {Niethammer, Christoph and Gracia, Jos{\\'e} and Hilbrich, Tobias and Kn{\\\"u}pfer, Andreas and Resch, Michael M. and Nagel, Wolfgang E.},\n    title = \"Machine Learning-Driven Automatic Program Transformation to Increase Performance in Heterogeneous Architectures\",\n    booktitle = \"Tools for High Performance Computing 2016\",\n    year = \"2017\",\n    publisher = \"Springer International Publishing\",\n    address = \"Cham\",\n    pages = \"115--140\",\n    abstract = \"We present a program transformation approach to convert procedural code into functionally equivalent code adapted to a given platform. Our framework is based on the application of guarded transformation rules that capture semantic conditions to ensure the soundness of their application. Our goal is to determine a sequence of rule applications which transform some initial code into final code which optimizes some non-functional properties. The code to be transformed is adorned with semantic annotations, either provided by the user or by external analysis tools. These annotations give information to decide whether applying a transformation rule is or is not sound. In general, there are several rules applicable at several program points and, besides, transformation sequences do not monotonically change the optimization function. Therefore, we face a search problem that grows exponentially with the length of the transformation sequence. In our experience with even small examples, that becomes impractical very quickly. In order to effectively deal with this issue, we have adopted a machine-learning approach using classification trees and reinforcement learning. It learns from successful transformation sequences and produces encodings of strategies which can provide long-term rewards for a given characteristic, avoiding local minima. We have evaluated the proposed technique in a series of benchmarks, adapting standard C code to GPU execution via OpenCL. We have found the automatically produced code to be as efficient as hand-written code generated by an expert human programmer.\",\n    isbn = \"978-3-319-56702-0\"\n}\n\n",
    "abstract": "Empirically, neural networks that attempt to learn programs from data have exhibited poor generalizability. Moreover, it has traditionally been difficult to reason about the behavior of these models beyond a certain level of input complexity. In order to address these issues, we propose augmenting neural architectures with a key abstraction: recursion. As an application, we implement recursion in the Neural Programmer-Interpreter framework on four tasks: grade-school addition, bubble sort, topological sort, and quicksort. We demonstrate superior generalizability and interpretability with small amounts of training data. Recursion divides the problem into smaller pieces and drastically reduces the domain of each neural network component, making it tractable to prove guarantees about the overall system's behavior. Our experience suggests that in order for neural architectures to robustly learn program semantics, it is necessary to incorporate a concept like recursion."
}, {
    "py/object": "data.DataClassPaper",
    "Title": "Neural Program Meta-Induction",
    "year": 2017,
    "ML_Techniques": "EN-DE",
    "Category": "Program synthesis",
    "Sub_category": "",
    "Venue": "NIPS",
    "Link": "https://arxiv.org/abs/1710.04157v1",
    "bibtex": "inproceedings{Devlin2017_332,\n    author = \"Devlin, Jacob and Bunel, Rudy and Singh, Rishabh and Hausknecht, Matthew and Kohli, Pushmeet\",\n    title = \"Neural Program Meta-Induction\",\n    year = \"2017\",\n    isbn = \"9781510860964\",\n    publisher = \"Curran Associates Inc.\",\n    address = \"Red Hook, NY, USA\",\n    abstract = \"Most recently proposed methods for Neural Program Induction work under the assumption of having a large set of input/output (I/O) examples for learning any underlying input-output mapping. This paper aims to address the problem of data and computation efficiency of program induction by leveraging information from related tasks. Specifically, we propose two approaches for cross-task knowledge transfer to improve program induction in limited-data scenarios. In our first proposal, portfolio adaptation, a set of induction models is pretrained on a set of related tasks, and the best model is adapted towards the new task using transfer learning. In our second approach, meta program induction, a k-shot learning approach is used to make a model generalize to new tasks without additional training. To test the efficacy of our methods, we constructed a new benchmark of programs written in the Karel programming language [17]. Using an extensive experimental evaluation on the Karel benchmark, we demonstrate that our proposals dramatically outperform the baseline induction method that does not use knowledge transfer. We also analyze the relative performance of the two approaches and study conditions in which they perform best. In particular, meta induction outperforms all existing approaches under extreme data sparsity (when a very small number of examples are available), i.e., fewer than ten. As the number of available I/O examples increase (i.e. a thousand or more), portfolio adapted program induction becomes the best approach. For intermediate data sizes, we demonstrate that the combined method of adapted meta program induction has the strongest performance.\",\n    booktitle = \"Proceedings of the 31st International Conference on Neural Information Processing Systems\",\n    pages = \"2077\u20132085\",\n    numpages = \"9\",\n    location = \"Long Beach, California, USA\",\n    series = \"NIPS'17\"\n}\n\n",
    "abstract": "Most recently proposed methods for Neural Program Induction work under the assumption of having a large set of input/output (I/O) examples for learning any underlying input-output mapping. This paper aims to address the problem of data and computation efficiency of program induction by leveraging information from related tasks. Specifically, we propose two approaches for cross-task knowledge transfer to improve program induction in limited-data scenarios. In our first proposal, portfolio adaptation, a set of induction models is pretrained on a set of related tasks, and the best model is adapted towards the new task using transfer learning. In our second approach, meta program induction, a k-shot learning approach is used to make a model generalize to new tasks without additional training. To test the efficacy of our methods, we constructed a new benchmark of programs written in the Karel programming language [17]. Using an extensive experimental evaluation on the Karel benchmark, we demonstrate that our proposals dramatically outperform the baseline induction method that does not use knowledge transfer. We also analyze the relative performance of the two approaches and study conditions in which they perform best. In particular, meta induction outperforms all existing approaches under extreme data sparsity (when a very small number of examples are available), i.e., fewer than ten. As the number of available I/O examples increase (i.e. a thousand or more), portfolio adapted program induction becomes the best approach. For intermediate data sizes, we demonstrate that the combined method of adapted meta program induction has the strongest performance."
}, {
    "py/object": "data.DataClassPaper",
    "Title": "Neural Program Repair by Jointly Learning to Localize and Repair",
    "year": 2019,
    "ML_Techniques": "LSTM",
    "Category": "Program synthesis",
    "Sub_category": "Program repair",
    "Venue": "ICLR",
    "Link": "https://arxiv.org/abs/1904.01720",
    "bibtex": "unknown{Vasic2019_333,\n    author = \"Vasic, Marko and Kanade, Aditya and Maniatis, Petros and Bieber, David and Singh, Rishabh\",\n    year = \"2019\",\n    month = \"04\",\n    pages = \"\",\n    title = \"Neural Program Repair by Jointly Learning to Localize and Repair\"\n}\n\n",
    "abstract": "Due to its potential to improve programmer productivity and software quality, automated program repair has been an active topic of research. Newer techniques harness neural networks to learn directly from examples of buggy programs and their fixes. In this work, we consider a recently identified class of bugs called variable-misuse bugs. The state-of-the-art solution for variable misuse enumerates potential fixes for all possible bug locations in a program, before selecting the best prediction. We show that it is beneficial to train a model that jointly and directly localizes and repairs variable-misuse bugs. We present multi-headed pointer networks for this purpose, with one head each for localization and repair. The experimental results show that the joint model significantly outperforms an enumerative solution that uses a pointer based model for repair alone."
}, {
    "py/object": "data.DataClassPaper",
    "Title": "Neural Programming by Example",
    "year": 2017,
    "ML_Techniques": "DNN",
    "Category": "Program synthesis",
    "Sub_category": "",
    "Venue": "CoRR",
    "Link": "https://arxiv.org/abs/1703.04990v1",
    "bibtex": "article{Shu2017_334,\n    author = \"Shu, Chengxun and Zhang, Hongyu\",\n    title = \"Neural Programming by Example\",\n    journal = \"CoRR\",\n    volume = \"abs/1703.04990\",\n    year = \"2017\",\n    url = \"http://arxiv.org/abs/1703.04990\",\n    archivePrefix = \"arXiv\",\n    eprint = \"1703.04990\",\n    timestamp = \"Sun, 06 Oct 2019 12:45:50 +0200\",\n    biburl = \"https://dblp.org/rec/journals/corr/ShuZ17.bib\",\n    bibsource = \"dblp computer science bibliography, https://dblp.org\"\n}\n\n",
    "abstract": "Programming by Example (PBE) targets at automatically inferring a computer program for accomplishing a certain task from sample input and output. In this paper, we propose a deep neural networks (DNN) based PBE model called Neural Programming by Example (NPBE), which can learn from input-output strings and induce programs that solve the string manipulation problems. Our NPBE model has four neural network based components: a string encoder, an input-output analyzer, a program generator, and a symbol selector. We demonstrate the effectiveness of NPBE by training it end-to-end to solve some common string manipulation problems in spreadsheet systems. The results show that our model can induce string manipulation programs effectively. Our work is one step towards teaching DNN to generate computer programs.\n"
}, {
    "py/object": "data.DataClassPaper",
    "Title": "Neural Sketch Learning for Conditional Program Generation",
    "year": 2017,
    "ML_Techniques": "GED",
    "Category": "Program synthesis",
    "Sub_category": "",
    "Venue": "ICLR",
    "Link": "https://arxiv.org/abs/1703.05698",
    "bibtex": "inproceedings{Murali2018_335,\n    author = \"Murali, Vijayaraghavan and Qi, Letao and Chaudhuri, S. and Jermaine, C.\",\n    title = \"Neural Sketch Learning for Conditional Program Generation\",\n    booktitle = \"ICLR\",\n    year = \"2018\"\n}\n\n",
    "abstract": "We study the problem of generating source code in a strongly typed, Java-like programming language, given a label (for example a set of API calls or types) carrying a small amount of information about the code that is desired. The generated programs are expected to respect a \"realistic\" relationship between programs and labels, as exemplified by a corpus of labeled programs available during training.\nTwo challenges in such conditional program generation are that the generated programs must satisfy a rich set of syntactic and semantic constraints, and that source code contains many low-level features that impede learning. We address these problems by training a neural generator not on code but on program sketches, or models of program syntax that abstract out names and operations that do not generalize across programs. During generation, we infer a posterior distribution over sketches, then concretize samples from this distribution into type-safe programs using combinatorial techniques. We implement our ideas in a system for generating API-heavy Java code, and show that it can often predict the entire body of a method given just a few API calls or data types that appear in the method."
}, {
    "py/object": "data.DataClassPaper",
    "Title": "Neural Symbolic Machines: Learning Semantic Parsers on Freebase with Weak Supervision (Short Version)",
    "year": 2016,
    "ML_Techniques": "EN-DE",
    "Category": "Program synthesis",
    "Sub_category": "",
    "Venue": "ACL",
    "Link": "https://arxiv.org/abs/1612.01197",
    "bibtex": "inproceedings{Murali2018_335,\n    author = \"Murali, Vijayaraghavan and Qi, Letao and Chaudhuri, S. and Jermaine, C.\",\n    title = \"Neural Sketch Learning for Conditional Program Generation\",\n    booktitle = \"ICLR\",\n    year = \"2018\"\n}\n\n",
    "abstract": "Extending the success of deep neural networks to natural language understanding and symbolic reasoning requires complex operations and external memory. Recent neural program induction approaches have attempted to address this problem, but are typically limited to differentiable memory, and consequently cannot scale beyond small synthetic tasks. In this work, we propose the Manager-Programmer-Computer framework, which integrates neural networks with non-differentiable memory to support abstract, scalable and precise operations through a friendly neural computer interface. Specifically, we introduce a Neural Symbolic Machine, which contains a sequence-to-sequence neural \"programmer\", and a non-differentiable \"computer\" that is a Lisp interpreter with code assist. To successfully apply REINFORCE for training, we augment it with approximate gold programs found by an iterative maximum likelihood training process. NSM is able to learn a semantic parser from weak supervision over a large knowledge base. It achieves new state-of-the-art performance on WebQuestionsSP, a challenging semantic parsing dataset, with weak supervision. Compared to previous approaches, NSM is end-to-end, therefore does not rely on feature engineering or domain specific knowledge."
}, {
    "py/object": "data.DataClassPaper",
    "Title": "Neuro-symbolic program corrector for introductory programming assignments",
    "year": 2018,
    "ML_Techniques": "RNN",
    "Category": "Program synthesis",
    "Sub_category": "Program repair",
    "Venue": "ICSE",
    "Link": "https://dl.acm.org/doi/10.1145/3180155.3180219",
    "bibtex": "inproceedings{Murali2018_335,\n    author = \"Murali, Vijayaraghavan and Qi, Letao and Chaudhuri, S. and Jermaine, C.\",\n    title = \"Neural Sketch Learning for Conditional Program Generation\",\n    booktitle = \"ICLR\",\n    year = \"2018\"\n}\n\n",
    "abstract": "Automatic correction of programs is a challenging problem with numerous real world applications in security, verification, and education. One application that is becoming increasingly important is the correction of student submissions in online courses for providing feedback. Most existing program repair techniques analyze Abstract Syntax Trees (ASTs) of programs, which are unfortunately unavailable for programs with syntax errors. In this paper, we propose a novel Neuro-symbolic approach that combines neural networks with constraint-based reasoning. Specifically, our method first uses a Recurrent Neural Network (RNN) to perform syntax repairs for the buggy programs; subsequently, the resulting syntactically-fixed programs are repaired using constraint-based techniques to ensure functional correctness. The RNNs are trained using a corpus of syntactically correct submissions for a given programming assignment, and are then queried to fix syntax errors in an incorrect programming submission by replacing or inserting the predicted tokens at the error location. We evaluate our technique on a dataset comprising of over 14,500 student submissions with syntax errors. Our method is able to repair syntax errors in 60% (8689) of submissions, and finds functionally correct repairs for 23.8% (3455) submissions."
}, {
    "py/object": "data.DataClassPaper",
    "Title": "Program Synthesis and Semantic Parsing with Learned Code Idioms",
    "year": 2019,
    "ML_Techniques": "EN-DE",
    "Category": "Program synthesis",
    "Sub_category": "",
    "Venue": "NeurIPS",
    "Link": "https://papers.nips.cc/paper/2019/file/cff34ad343b069ea6920464ad17d4bcf-Paper.pdf",
    "bibtex": "inproceedings{Murali2018_335,\n    author = \"Murali, Vijayaraghavan and Qi, Letao and Chaudhuri, S. and Jermaine, C.\",\n    title = \"Neural Sketch Learning for Conditional Program Generation\",\n    booktitle = \"ICLR\",\n    year = \"2018\"\n}\n\n",
    "abstract": "Program synthesis of general-purpose source code from natural language specifications is challenging due to the need to reason about high-level patterns in the target program and low-level implementation details at the same time. In this work, we present PATOIS, a system that allows a neural program synthesizer to explicitly interleave high-level and low-level reasoning at every generation step. It accomplishes this by automatically mining common code idioms from a given corpus, incorporating them into the underlying language for neural synthesis, and training a tree-based neural synthesizer to use these idioms during code generation. We evaluate PATOIS on two complex semantic parsing datasets and show that using learned code idioms improves the synthesizer's accuracy."
}, {
    "py/object": "data.DataClassPaper",
    "Title": "PROGRAM SYNTHESIS FOR CHARACTER LEVEL LANGUAGE MODELING",
    "year": 2017,
    "ML_Techniques": "LSTM",
    "Category": "Program synthesis",
    "Sub_category": "",
    "Venue": "ICLR",
    "Link": "https://files.sri.inf.ethz.ch/website/papers/charmodel-iclr2017.pdf",
    "bibtex": "inproceedings{Murali2018_335,\n    author = \"Murali, Vijayaraghavan and Qi, Letao and Chaudhuri, S. and Jermaine, C.\",\n    title = \"Neural Sketch Learning for Conditional Program Generation\",\n    booktitle = \"ICLR\",\n    year = \"2018\"\n}\n\n",
    "abstract": "We propose a statistical model applicable to character level language modeling and show that it is a good fit for both, program source code and English text. The model is parameterized by a program from a domain-specific language (DSL) that allows expressing non-trivial data dependencies. Learning is done in two phases: (i) we synthesize a program from the DSL, essentially learning a good representation for the data, and (ii) we learn parameters from the training data - the process is done via counting, as in simple language models such as n-gram.\n\nOur experiments show that the precision of our model is comparable to that of neural networks while sharing a number of advantages with n-gram models such as fast query time and the capability to quickly add and remove training data samples. Further, the model is parameterized by a program that can be manually inspected, understood and updated, addressing a major problem of neural networks."
}, {
    "py/object": "data.DataClassPaper",
    "Title": "Repairing Intricate Faults in Code Using Machine Learning and Path Exploration",
    "year": 2016,
    "ML_Techniques": "SVM, DT",
    "Category": "Program synthesis",
    "Sub_category": "Program repair",
    "Venue": "ICSME",
    "Link": "https://ieeexplore.ieee.org/abstract/document/7816493",
    "bibtex": "INPROCEEDINGS{Gopinath2016_348,\n    author = \"{Gopinath}, D. and {Wang}, K. and {Hua}, J. and {Khurshid}, S.\",\n    booktitle = \"2016 IEEE International Conference on Software Maintenance and Evolution (ICSME)\",\n    title = \"Repairing Intricate Faults in Code Using Machine Learning and Path Exploration\",\n    year = \"2016\",\n    volume = \"\",\n    number = \"\",\n    pages = \"453-457\",\n    doi = \"10.1109/ICSME.2016.75\"\n}\n\n",
    "abstract": "Debugging remains costly and tedious, especially for code that performs intricate operations that are conceptually complex to reason about. We present MLR, a novel approach for repairing faults in such operations, specifically in the context of complex data structures. Our focus is on faults in conditional statements. Our insight is that an integrated approach based on machine learning and systematic path exploration can provide effective repairs. MLR mines the data-spectra of the passing and failing executions of conditional branches to prune the search space for repair and generate patches that are likely valid beyond the existing test-suite. We apply MLR to repair faults in small but complex data structure subjects to demonstrate its efficacy. Experimental results show that MLR has the potential to repair this fault class more effectively than state-of-the-art repair tools."
}, {
    "py/object": "data.DataClassPaper",
    "Title": "SEQUENCER: Sequence-to-Sequence Learning for End-to-End Program Repair",
    "year": 2019,
    "ML_Techniques": "EN-DE",
    "Category": "Program synthesis",
    "Sub_category": "Program repair",
    "Venue": "TSE",
    "Link": "https://ieeexplore.ieee.org/abstract/document/8827954",
    "bibtex": "ARTICLE{Chen2019_350,\n    author = \"{Chen}, Z. and {Kommrusch}, S. J. and {Tufano}, M. and {Pouchet}, L. and {Poshyvanyk}, D. and {Monperrus}, M.\",\n    journal = \"IEEE Transactions on Software Engineering\",\n    title = \"SEQUENCER: Sequence-to-Sequence Learning for End-to-End Program Repair\",\n    year = \"2019\",\n    volume = \"\",\n    number = \"\",\n    pages = \"1-1\",\n    doi = \"10.1109/TSE.2019.2940179\"\n}\n\n",
    "abstract": "This paper presents a novel end-to-end approach to program repair based on sequence-to-sequence learning. We devise, implement, and evaluate a system, called SequenceR, for fixing bugs based on sequence-to-sequence learning on source code. This approach uses the copy mechanism to overcome the unlimited vocabulary problem that occurs with big code. Our system is data-driven; we train it on 35,578 samples, carefully curated from commits to open-source repositories. We evaluate it on 4,711 independent real bug fixes, as well on the Defects4J benchmark used in program repair research. SequenceR is able to perfectly predict the fixed line for 950/4711 testing samples, and find correct patches for 14 bugs in Defects4J. It captures a wide range of repair operators without any domain-specific top-down design."
}, {
    "py/object": "data.DataClassPaper",
    "Title": "Should fixing these failures be delegated to automated program repair?",
    "year": 2015,
    "ML_Techniques": "RF",
    "Category": "Program synthesis",
    "Sub_category": "Program repair",
    "Venue": "ISSRE",
    "Link": "https://ieeexplore.ieee.org/abstract/document/7381836",
    "bibtex": "INPROCEEDINGS{Le2015_352,\n    author = \"{Le}, X. D. and {Le}, T. B. and {Lo}, D.\",\n    booktitle = \"2015 IEEE 26th International Symposium on Software Reliability Engineering (ISSRE)\",\n    title = \"Should fixing these failures be delegated to automated program repair?\",\n    year = \"2015\",\n    volume = \"\",\n    number = \"\",\n    pages = \"427-437\",\n    doi = \"10.1109/ISSRE.2015.7381836\"\n}\n\n",
    "abstract": "Program repair constitutes one of the major components of software maintenance that usually incurs a significant cost in software production. Automated program repair is supposed to help in reducing the software maintenance cost by automatically fixing software defects. Despite the recent advances in automated software repair, it is still very costly to wait for repair tools to produce valid repairs of defects. This paper addresses the following question: \"Will an automated program repair technique find a repair for a defect within a reasonable time?\". To answer this question, we build an oracle that can predict whether fixing a failure should be delegated to an automated repair technique. If the repair technique is predicted to take too long to produce a repair, the bug fixing process should rather be assigned to a developer or other appropriate techniques available. Our oracle is built for genetic-programming-based automated program repair approaches, which have recently received considerable attention due to their capability to automatically fix real-world bugs. These approaches search for a valid repair over a large number of variants that are syntactically mutated from the original program. At an early stage of running a repair tool, we extract a number of features that are potentially related to the effectiveness of the tool. Leveraging advances in machine learning, we process the values of these features to learn a discriminative model that is able to predict whether continuing a genetic programming search will lead to a repair within a desired time limit. We perform experiments to evaluate the ability of our approach to predict the effectiveness of GenProg, a well-known genetic-programming-based automated program repair approach, in fixing 105 real bugs. Our experiments show that our approach can identify effective cases from ineffective ones (i.e., bugs for which GenProg cannot produce correct fixes after a long period of time) with a precision, recall, F-measure, and AUC of 72%, 74%, 73%, and 76% respectively."
}, {
    "py/object": "data.DataClassPaper",
    "Title": "SLDeep: Statement-level software defect prediction using deep-learning model on static code features",
    "year": 2020,
    "ML_Techniques": "LSTM",
    "Category": "Program synthesis",
    "Sub_category": "Program repair",
    "Venue": "ESA",
    "Link": "https://www.sciencedirect.com/science/article/abs/pii/S0957417419308735",
    "bibtex": "INPROCEEDINGS{Le2015_352,\n    author = \"{Le}, X. D. and {Le}, T. B. and {Lo}, D.\",\n    booktitle = \"2015 IEEE 26th International Symposium on Software Reliability Engineering (ISSRE)\",\n    title = \"Should fixing these failures be delegated to automated program repair?\",\n    year = \"2015\",\n    volume = \"\",\n    number = \"\",\n    pages = \"427-437\",\n    doi = \"10.1109/ISSRE.2015.7381836\"\n}\n\n",
    "abstract": "Software defect prediction (SDP) seeks to estimate fault-prone areas of the code to focus testing activities on more suspicious portions. Consequently, high-quality software is released with less time and effort. The current SDP techniques however work at coarse-grained units, such as a module or a class, putting some burden on the developers to locate the fault. To address this issue, we propose a new technique called as Statement-Level software defect prediction using Deep-learning model (SLDeep). The significance of SLDeep for intelligent and expert systems is that it demonstrates a novel use of deep-learning models to the solution of a practical problem faced by software developers. To reify our proposal, we defined a suite of 32 statement-level metrics, such as the number of binary and unary operators used in a statement. Then, we applied as learning model, long short-term memory (LSTM). We conducted experiments using 119,989 C/C++ programs within Code4Bench. The programs comprise 2,356,458 lines of code of which 292,064 lines are faulty. The benchmark comprises a diverse set of programs and versions, written by thousands of developers. Therefore, it tends to give a model that can be used for cross-project SDP. In the experiments, our trained model could successfully classify the unseen data (that is, fault-proneness of new statements) with average performance measures 0.979, 0.570, and 0.702 in terms of recall, precision, and accuracy, respectively. These experimental results suggest that SLDeep is effective for statement-level SDP. The impact of this work is twofold. Working at statement-level further alleviates developer's burden in pinpointing the fault locations. Second, cross-project feature of SLDeep helps defect prediction research become more industrially-viable."
}, {
    "py/object": "data.DataClassPaper",
    "Title": "Structured Generative Models of Natural Source Code",
    "year": 2014,
    "ML_Techniques": "GD",
    "Category": "Program synthesis",
    "Sub_category": "",
    "Venue": "ICML",
    "Link": "https://arxiv.org/abs/1401.0514",
    "bibtex": "inproceedings{Maddison2014_355,\n    author = \"Maddison, Chris J. and Tarlow, Daniel\",\n    title = \"Structured Generative Models of Natural Source Code\",\n    year = \"2014\",\n    publisher = \"JMLR.org\",\n    abstract = \"We study the problem of building generative models of natural source code (NSC); that is, source code written by humans and meant to be understood by humans. Our primary contribution is to describe new generative models that are tailored to NSC. The models are based on probabilistic context free grammars (PCFGs) and neuro-probabilistic language models (Mnih \\&amp; Teh, 2012), which are extended to incorporate additional source code-specific structure. These models can be efficiently trained on a corpus of source code and outperform a variety of less structured baselines in terms of predictive log likelihoods on held-out data.\",\n    booktitle = \"Proceedings of the 31st International Conference on International Conference on Machine Learning - Volume 32\",\n    pages = \"II\u2013649\u2013II\u2013657\",\n    numpages = \"9\",\n    location = \"Beijing, China\",\n    series = \"ICML'14\"\n}\n\n",
    "abstract": "We study the problem of building generative models of natural source code (NSC); that is, source code written by humans and meant to be understood by humans. Our primary contribution is to describe new generative models that are tailored to NSC. The models are based on probabilistic context free grammars (PCFGs) and neuro-probabilistic language models (Mnih & Teh, 2012), which are extended to incorporate additional source code-specific structure. These models can be efficiently trained on a corpus of source code and outperform a variety of less structured baselines in terms of predictive log likelihoods on held-out data."
}, {
    "py/object": "data.DataClassPaper",
    "Title": "Syntax and Sensibility:Using language models to detect and correctsyntax errors",
    "year": 2018,
    "ML_Techniques": "LSTM",
    "Category": "Program synthesis",
    "Sub_category": "Program repair",
    "Venue": "SANER",
    "Link": "https://softwareprocess.es/pubs/santos2018SANER-syntax.pdf",
    "bibtex": "inproceedings{Maddison2014_355,\n    author = \"Maddison, Chris J. and Tarlow, Daniel\",\n    title = \"Structured Generative Models of Natural Source Code\",\n    year = \"2014\",\n    publisher = \"JMLR.org\",\n    abstract = \"We study the problem of building generative models of natural source code (NSC); that is, source code written by humans and meant to be understood by humans. Our primary contribution is to describe new generative models that are tailored to NSC. The models are based on probabilistic context free grammars (PCFGs) and neuro-probabilistic language models (Mnih \\&amp; Teh, 2012), which are extended to incorporate additional source code-specific structure. These models can be efficiently trained on a corpus of source code and outperform a variety of less structured baselines in terms of predictive log likelihoods on held-out data.\",\n    booktitle = \"Proceedings of the 31st International Conference on International Conference on Machine Learning - Volume 32\",\n    pages = \"II\u2013649\u2013II\u2013657\",\n    numpages = \"9\",\n    location = \"Beijing, China\",\n    series = \"ICML'14\"\n}\n\n",
    "abstract": "Syntax errors are made by novice and experienced programmers alike; however, novice programmers lack the years of experience that help them quickly resolve these frustrating errors. Standard LR parsers are of little help, typically resolving syntax errors and their precise location poorly. We propose a methodology that locates where syntax errors occur, and suggests possible changes to the token stream that can fix the error identified. This methodology finds syntax errors by using language models trained on correct source code to find tokens that seem out of place. Fixes are synthesized by consulting the language models to determine what tokens are more likely at the estimated error location. We compare n-gram and LSTM (long short-term memory) language models for this task, each trained on a large corpus of Java code collected from GitHub. Unlike prior work, our methodology does not rely that the problem source code comes from the same domain as the training data. We evaluated against a repository of real student mistakes. Our tools are able to find a syntactically-valid fix within its top-2 suggestions, often producing the exact fix that the student used to resolve the error. The results show that this tool and methodology can locate and suggest corrections for syntax errors. Our methodology is of practical use to all programmers, but will be especially useful to novices frustrated with incomprehensible syntax errors"
}, {
    "py/object": "data.DataClassPaper",
    "Title": "Synthesizing Benchmarks for Predictive Modeling",
    "year": 2017,
    "ML_Techniques": "LSTM",
    "Category": "Program synthesis",
    "Sub_category": "",
    "Venue": "CGO",
    "Link": "https://ieeexplore.ieee.org/document/7863731",
    "bibtex": "inproceedings{Maddison2014_355,\n    author = \"Maddison, Chris J. and Tarlow, Daniel\",\n    title = \"Structured Generative Models of Natural Source Code\",\n    year = \"2014\",\n    publisher = \"JMLR.org\",\n    abstract = \"We study the problem of building generative models of natural source code (NSC); that is, source code written by humans and meant to be understood by humans. Our primary contribution is to describe new generative models that are tailored to NSC. The models are based on probabilistic context free grammars (PCFGs) and neuro-probabilistic language models (Mnih \\&amp; Teh, 2012), which are extended to incorporate additional source code-specific structure. These models can be efficiently trained on a corpus of source code and outperform a variety of less structured baselines in terms of predictive log likelihoods on held-out data.\",\n    booktitle = \"Proceedings of the 31st International Conference on International Conference on Machine Learning - Volume 32\",\n    pages = \"II\u2013649\u2013II\u2013657\",\n    numpages = \"9\",\n    location = \"Beijing, China\",\n    series = \"ICML'14\"\n}\n\n",
    "abstract": "Predictive modeling using machine learning is an effective method for building compiler heuristics, but there is a shortage of benchmarks. Typical machine learning experiments outside of the compilation field train over thousands or millions of examples. In machine learning for compilers, however, there are typically only a few dozen common benchmarks available. This limits the quality of learned models, as they have very sparse training data for what are often high-dimensional feature spaces. What is needed is a way to generate an unbounded number of training programs that finely cover the feature space. At the same time the generated programs must be similar to the types of programs that human developers actually write, otherwise the learning will target the wrong parts of the feature space. We mine open source repositories for program fragments and apply deep learning techniques to automatically construct models for how humans write programs. We sample these models to generate an unbounded number of runnable training programs. The quality of the programs is such that even human developers struggle to distinguish our generated programs from hand-written code. We use our generator for OpenCL programs, CLgen, to automatically synthesize thousands of programs and show that learning over these improves the performance of a state of the art predictive model by 1.27x. In addition, the fine covering of the feature space automatically exposes weaknesses in the feature design which are invisible with the sparse training examples from existing benchmark suites. Correcting these weaknesses further increases performance by 4.30x."
}, {
    "py/object": "data.DataClassPaper",
    "Title": "Synthetic Datasets for Neural Program Synthesis",
    "year": 2019,
    "ML_Techniques": "",
    "Category": "Program synthesis",
    "Sub_category": "",
    "Venue": "LR",
    "Link": "https://openreview.net/forum?id=ryeOSnAqYm",
    "bibtex": "inproceedings{Shin2019_362,\n    author = \"Shin, Richard and Kant, Neel and Gupta, Kavi and Bender, Chris and Trabucco, Brandon and Singh, Rishabh and Song, Dawn\",\n    title = \"Synthetic Datasets for Neural Program Synthesis\",\n    booktitle = \"International Conference on Learning Representations\",\n    year = \"2019\",\n    url = \"https://openreview.net/forum?id=ryeOSnAqYm\"\n}\n\n",
    "abstract": "The goal of program synthesis is to automatically generate programs in a particular language from corresponding specifications, e.g. input-output behavior. Many current approaches achieve impressive results after training on randomly generated I/O examples in limited domain-specific languages (DSLs), as with string transformations in RobustFill. However, we empirically discover that applying test input generation techniques for languages with control flow and rich input space causes deep networks to generalize poorly to certain data distributions; to correct this, we propose a new methodology for controlling and evaluating the bias of synthetic data distributions over both programs and specifications. We demonstrate, using the Karel DSL and a small Calculator DSL, that training deep networks on these distributions leads to improved cross-distribution generalization performance."
}, {
    "py/object": "data.DataClassPaper",
    "Title": "Towards Synthesizing Complex Programs from Input-Output Example",
    "year": 2017,
    "ML_Techniques": "LSTM",
    "Category": "Program synthesis",
    "Sub_category": "",
    "Venue": "ICLR",
    "Link": "https://arxiv.org/abs/1706.01284v3",
    "bibtex": "misc{Chen2018_365,\n    author = \"Chen, Xinyun and Liu, Chang and Song, Dawn\",\n    title = \"Towards Synthesizing Complex Programs from Input-Output Examples\",\n    year = \"2018\",\n    eprint = \"1706.01284\",\n    archivePrefix = \"arXiv\",\n    primaryClass = \"cs.LG\"\n}\n\n",
    "abstract": "In recent years, deep learning techniques have been developed to improve the performance of program synthesis from input-output examples. Albeit its significant progress, the programs that can be synthesized by state-of-the-art approaches are still simple in terms of their complexity. In this work, we move a significant step forward along this direction by proposing a new class of challenging tasks in the domain of program synthesis from input-output examples: learning a context-free parser from pairs of input programs and their parse trees. We show that this class of tasks are much more challenging than previously studied tasks, and the test accuracy of existing approaches is almost 0%.\nWe tackle the challenges by developing three novel techniques inspired by three novel observations, which reveal the key ingredients of using deep learning to synthesize a complex program. First, the use of a non-differentiable machine is the key to effectively restrict the search space. Thus our proposed approach learns a neural program operating a domain-specific non-differentiable machine. Second, recursion is the key to achieve generalizability. Thus, we bake-in the notion of recursion in the design of our non-differentiable machine. Third, reinforcement learning is the key to learn how to operate the non-differentiable machine, but it is also hard to train the model effectively with existing reinforcement learning algorithms from a cold boot. We develop a novel two-phase reinforcement learning-based search algorithm to overcome this issue. In our evaluation, we show that using our novel approach, neural parsing programs can be learned to achieve 100% test accuracy on test inputs that are 500x longer than the training samples."
}, {
    "py/object": "data.DataClassPaper",
    "Title": "Type error feedback via analytic program repair",
    "year": 2020,
    "ML_Techniques": "DNN, MLP",
    "Category": "Program synthesis",
    "Sub_category": "Program repair",
    "Venue": "PLDI",
    "Link": "https://dl.acm.org/doi/abs/10.1145/3385412.3386005",
    "bibtex": "misc{Chen2018_365,\n    author = \"Chen, Xinyun and Liu, Chang and Song, Dawn\",\n    title = \"Towards Synthesizing Complex Programs from Input-Output Examples\",\n    year = \"2018\",\n    eprint = \"1706.01284\",\n    archivePrefix = \"arXiv\",\n    primaryClass = \"cs.LG\"\n}\n\n",
    "abstract": "We introduce Analytic Program Repair, a data-driven strategy for providing feedback for type-errors via repairs for the erroneous program. Our strategy is based on insight that similar errors have similar repairs. Thus, we show how to use a training dataset of pairs of ill-typed programs and their fixed versions to: (1) learn a collection of candidate repair templates by abstracting and partitioning the edits made in the training set into a representative set of templates; (2) predict the appropriate template from a given error, by training multi-class classifiers on the repair templates used in the training set; (3) synthesize a concrete repair from the template by enumerating and ranking correct (e.g. well-typed) terms matching the predicted template. We have implemented our approach in Rite: a type error reporting tool for OCaml programs. We present an evaluation of the accuracy and efficiency of Rite on a corpus of 4,500 ill-typed Ocaml programs drawn from two instances of an introductory programming course, and a user-study of the quality of the generated error messages that shows the locations and final repair quality to be better than the state-of-the-art tool in a statistically-significant manner."
}, {
    "py/object": "data.DataClassPaper",
    "Title": "An Application of Latent Dirichlet Allocation to Analyzing Software Evolution",
    "year": 2008,
    "ML_Techniques": "unsupervised statistical topic models",
    "Category": "Program comprehension",
    "Sub_category": "Entity identification/recommendation",
    "Venue": "ICMLA",
    "Link": "https://ieeexplore.ieee.org/document/4725072",
    "bibtex": "INPROCEEDINGS{Linstead2008_371,\n    author = \"{Linstead}, E. and {Lopes}, C. and {Baldi}, P.\",\n    booktitle = \"2008 Seventh International Conference on Machine Learning and Applications\",\n    title = \"An Application of Latent Dirichlet Allocation to Analyzing Software Evolution\",\n    year = \"2008\",\n    volume = \"\",\n    number = \"\",\n    pages = \"813-818\",\n    doi = \"10.1109/ICMLA.2008.47\"\n}\n\n",
    "abstract": "We develop and apply unsupervised statistical topic models, in particular latent Dirichlet allocation, to identify functional components of source code and study their evolution over multiple project versions. We present results for two large, open source Java projects, Eclipse and Argo UML, which are well-known and well-studied within the software mining community. Our results demonstrate the effectiveness of probabilistic topic models in automatically summarizing the temporal dynamics of software concerns, with direct application to project management and program understanding. In addition to detecting the emergence of topics on the release timeline which represent integration points for key source code functionality, our techniques can also be used to pinpoint refactoring events in the underlying software design, as well as to identify general programming concepts whose prevalence is dependent only of the size of the code base to be analyzed. Complete results are available from our supplementary materials website at http://sourcerer.ics.uci.edu/icmla2008/software_evolution.html."
}, {
    "py/object": "data.DataClassPaper",
    "Title": "Automatic classification of software artifacts in open-source applications",
    "year": 2018,
    "ML_Techniques": "",
    "Category": "Program comprehension",
    "Sub_category": "Program classification",
    "Venue": "MSR",
    "Link": "https://dl.acm.org/doi/10.1145/3196398.3196446",
    "bibtex": "INPROCEEDINGS{Linstead2008_371,\n    author = \"{Linstead}, E. and {Lopes}, C. and {Baldi}, P.\",\n    booktitle = \"2008 Seventh International Conference on Machine Learning and Applications\",\n    title = \"An Application of Latent Dirichlet Allocation to Analyzing Software Evolution\",\n    year = \"2008\",\n    volume = \"\",\n    number = \"\",\n    pages = \"813-818\",\n    doi = \"10.1109/ICMLA.2008.47\"\n}\n\n",
    "abstract": "With the increasing popularity of open-source software development, there is a tremendous growth of software artifacts that provide insight into how people build software. Researchers are always looking for large-scale and representative software artifacts to produce systematic and unbiased validation of novel and existing techniques. For example, in the domain of software requirements traceability, researchers often use software applications with multiple types of artifacts, such as requirements, system elements, verifications, or tasks to develop and evaluate their traceability analysis techniques. However, the manual identification of rich software artifacts is very labor-intensive. In this work, we first conduct a large-scale study to identify which types of software artifacts are produced by a wide variety of open-source projects at different levels of granularity. Then we propose an automated approach based on Machine Learning techniques to identify various types of software artifacts. Through a set of experiments, we report and compare the performance of these algorithms when applied to software artifacts."
}, {
    "py/object": "data.DataClassPaper",
    "Title": "Change Prediction through Coding Rules Violations",
    "year": 2017,
    "ML_Techniques": "DT, RF, NB",
    "Category": "Program comprehension",
    "Sub_category": "Change analysis",
    "Venue": "EASE",
    "Link": "https://dl.acm.org/doi/10.1145/3084226.3084282",
    "bibtex": "inproceedings{Tollin2017_374,\n    author = \"Tollin, Irene and Fontana, Francesca Arcelli and Zanoni, Marco and Roveda, Riccardo\",\n    title = \"Change Prediction through Coding Rules Violations\",\n    year = \"2017\",\n    isbn = \"9781450348041\",\n    publisher = \"Association for Computing Machinery\",\n    address = \"New York, NY, USA\",\n    url = \"https://doi.org/10.1145/3084226.3084282\",\n    doi = \"10.1145/3084226.3084282\",\n    abstract = \"Static source code analysis is an increasingly important activity to manage software project quality, and is often found as a part of the development process. A widely adopted way of checking code quality is through the detection of violations to specific sets of rules addressing good programming practices. SonarQube is a platform able to detect these violations, called Issues. In this paper we described an empirical study performend on two industrial projects, where we used Issues extracted on different versions of the projects to predict changes in code through a set of machine learning models. We achieved good detection performances, especially when predicting changes in the next version. This result paves the way for future investigations of the interest in an industrial setting towards the prioritization of Issues management according to their impact on change-proneness.\",\n    booktitle = \"Proceedings of the 21st International Conference on Evaluation and Assessment in Software Engineering\",\n    pages = \"61\u201364\",\n    numpages = \"4\",\n    keywords = \"change prediction, machine learning, issues, software quality\",\n    location = \"Karlskrona, Sweden\",\n    series = \"EASE'17\"\n}\n\n",
    "abstract": "Static source code analysis is an increasingly important activity to manage software project quality, and is often found as a part of the development process. A widely adopted way of checking code quality is through the detection of violations to specific sets of rules addressing good programming practices. SonarQube is a platform able to detect these violations, called Issues. In this paper we described an empirical study performend on two industrial projects, where we used Issues extracted on different versions of the projects to predict changes in code through a set of machine learning models. We achieved good detection performances, especially when predicting changes in the next version. This result paves the way for future investigations of the interest in an industrial setting towards the prioritization of Issues management according to their impact on change-proneness."
}, {
    "py/object": "data.DataClassPaper",
    "Title": "Classifying Software Changes: Clean or Buggy?",
    "year": 2008,
    "ML_Techniques": "SVM",
    "Category": "Testing",
    "Sub_category": "",
    "Venue": "TSE",
    "Link": "https://ieeexplore.ieee.org/document/4408585",
    "bibtex": "ARTICLE{Kim2008_375,\n    author = \"{Kim}, S. and {Whitehead,}, E. J. and {Zhang}, Y.\",\n    journal = \"IEEE Transactions on Software Engineering\",\n    title = \"Classifying Software Changes: Clean or Buggy?\",\n    year = \"2008\",\n    volume = \"34\",\n    number = \"2\",\n    pages = \"181-196\",\n    doi = \"10.1109/TSE.2007.70773\"\n}\n\n",
    "abstract": "This paper introduces a new technique for predicting latent software bugs, called change classification. Change classification uses a machine learning classifier to determine whether a new software change is more similar to prior buggy changes or clean changes. In this manner, change classification predicts the existence of bugs in software changes. The classifier is trained using features (in the machine learning sense) extracted from the revision history of a software project stored in its software configuration management repository. The trained classifier can classify changes as buggy or clean, with a 78 percent accuracy and a 60 percent buggy change recall on average. Change classification has several desirable qualities: 1) The prediction granularity is small (a change to a single file), 2) predictions do not require semantic information about the source code, 3) the technique works for a broad array of project types and programming languages, and 4) predictions can be made immediately upon the completion of a change. Contributions of this paper include a description of the change classification approach, techniques for extracting features from the source code and change histories, a characterization of the performance of change classification across 12 open source projects, and an evaluation of the predictive power of different groups of features."
}, {
    "py/object": "data.DataClassPaper",
    "Title": "Code Authorship Attribution: Methods and Challenges",
    "year": 2019,
    "ML_Techniques": "",
    "Category": "Program comprehension",
    "Sub_category": "Entity identification/recommendation",
    "Venue": "CSUR",
    "Link": "https://dl.acm.org/doi/10.1145/3292577",
    "bibtex": "article{Kalgutkar2019_376,\n    author = \"Kalgutkar, Vaibhavi and Kaur, Ratinder and Gonzalez, Hugo and Stakhanova, Natalia and Matyukhina, Alina\",\n    title = \"Code Authorship Attribution: Methods and Challenges\",\n    year = \"2019\",\n    issue_date = \"February 2019\",\n    publisher = \"Association for Computing Machinery\",\n    address = \"New York, NY, USA\",\n    volume = \"52\",\n    number = \"1\",\n    issn = \"0360-0300\",\n    url = \"https://doi.org/10.1145/3292577\",\n    doi = \"10.1145/3292577\",\n    abstract = \"Code authorship attribution is the process of identifying the author of a given code. With increasing numbers of malware and advanced mutation techniques, the authors of malware are creating a large number of malware variants. To better deal with this problem, methods for examining the authorship of malicious code are necessary. Code authorship attribution techniques can thus be utilized to identify and categorize the authors of malware. This information can help predict the types of tools and techniques that the author of a specific malware uses, as well as the manner in which the malware spreads and evolves. In this article, we present the first comprehensive review of research on code authorship attribution. The article summarizes various methods of authorship attribution and highlights challenges in the field.\",\n    journal = \"ACM Comput. Surv.\",\n    month = \"February\",\n    articleno = \"3\",\n    numpages = \"36\",\n    keywords = \"Authorship analysis, programming style, malware attribution, software forensics\"\n}\n\n",
    "abstract": "Code authorship attribution is the process of identifying the author of a given code. With increasing numbers of malware and advanced mutation techniques, the authors of malware are creating a large number of malware variants. To better deal with this problem, methods for examining the authorship of malicious code are necessary. Code authorship attribution techniques can thus be utilized to identify and categorize the authors of malware. This information can help predict the types of tools and techniques that the author of a specific malware uses, as well as the manner in which the malware spreads and evolves. In this article, we present the first comprehensive review of research on code authorship attribution. The article summarizes various methods of authorship attribution and highlights challenges in the field."
}, {
    "py/object": "data.DataClassPaper",
    "Title": "CommtPst: Deep learning source code for commenting positions prediction",
    "year": 2020,
    "ML_Techniques": "",
    "Category": "Program comprehension",
    "Sub_category": "Entity identification/recommendation",
    "Venue": "JSS",
    "Link": "https://www.sciencedirect.com/science/article/abs/pii/S0164121220301758",
    "bibtex": "article{Huang2020_377,\n    author = \"Huang, Yuan and Hu, Xinyu and Jia, Nan and Chen, Xiangping and Zheng, Zibin and Luo, Xiapu\",\n    title = \"CommtPst: Deep learning source code for commenting positions prediction\",\n    journal = \"Journal of Systems and Software\",\n    volume = \"170\",\n    pages = \"110754\",\n    year = \"2020\",\n    issn = \"0164-1212\",\n    doi = \"https://doi.org/10.1016/j.jss.2020.110754\",\n    url = \"http://www.sciencedirect.com/science/article/pii/S0164121220301758\",\n    keywords = \"Comment position, LSTM, Code syntax, Code semantics, Comment generation\",\n    abstract = \"Existing techniques for automatic code commenting assume that the code snippet to be commented has been identified, thus requiring users to provide the code snippet in advance. A smarter commenting approach is desired to first self-determine where to comment in a given source code and then generate comments for the code snippets that need comments. To achieve the first step of this goal, we propose a novel method, CommtPst, to automatically find the appropriate commenting positions in the source code. Since commenting is closely related to the code syntax and semantics, we adopt neural language model (word embeddings) to capture the code semantic information, and analyze the abstract syntax trees to capture code syntactic information. Then, we employ LSTM (long short term memory) to model the long-term logical dependency of code statements over the fused semantic and syntactic information and learn the commenting patterns on the code sequence. We evaluated CommtPst using large data sets from dozens of open-source software systems in GitHub. The experimental results show that the precision, recall and F-Measure values achieved by CommtPst are 0.792, 0.602 and 0.684, respectively, which outperforms the traditional machine learning method with 11.4\\% improvement on F-measure.\"\n}\n\n",
    "abstract": "Existing techniques for automatic code commenting assume that the code snippet to be commented has been identified, thus requiring users to provide the code snippet in advance. A smarter commenting approach is desired to first self-determine where to comment in a given source code and then generate comments for the code snippets that need comments. To achieve the first step of this goal, we propose a novel method, CommtPst, to automatically find the appropriate commenting positions in the source code. Since commenting is closely related to the code syntax and semantics, we adopt neural language model (word embeddings) to capture the code semantic information, and analyze the abstract syntax trees to capture code syntactic information. Then, we employ LSTM (long short term memory) to model the long-term logical dependency of code statements over the fused semantic and syntactic information and learn the commenting patterns on the code sequence. We evaluated CommtPst using large data sets from dozens of open-source software systems in GitHub. The experimental results show that the precision, recall and F-Measure values achieved by CommtPst are 0.792, 0.602 and 0.684, respectively, which outperforms the traditional machine learning method with 11.4% improvement on F-measure."
}, {
    "py/object": "data.DataClassPaper",
    "Title": "Deep Learning Type Inference",
    "year": 2018,
    "ML_Techniques": "Bi-RNN",
    "Category": "Program comprehension",
    "Sub_category": "Entity identification/recommendation",
    "Venue": "FSE",
    "Link": "http://vhellendoorn.github.io/PDF/fse2018-j2t.pdf",
    "bibtex": "inproceedings{Hellendoorn2018_378,\n    author = \"Hellendoorn, Vincent J. and Bird, Christian and Barr, Earl T. and Allamanis, Miltiadis\",\n    title = \"Deep Learning Type Inference\",\n    year = \"2018\",\n    isbn = \"9781450355735\",\n    publisher = \"Association for Computing Machinery\",\n    address = \"New York, NY, USA\",\n    url = \"https://doi.org/10.1145/3236024.3236051\",\n    doi = \"10.1145/3236024.3236051\",\n    pages = \"152\u2013162\",\n    numpages = \"11\",\n    keywords = \"Deep Learning, Naturalness, Type Inference\",\n    location = \"Lake Buena Vista, FL, USA\",\n    series = \"ESEC/FSE 2018\"\n}\n\n",
    "abstract": "Dynamically typed languages such as JavaScript and Python are increasingly popular, yet static typing has not been totally eclipsed: Python now supports type annotations and languages like TypeScript offer a middle-ground for JavaScript: a strict superset of JavaScript, to which it transpiles, coupled with a type system that permits partially typed programs. However, static typing has a cost: adding annotations, reading the added syntax, and wrestling with the type system to fix type errors. Type inference can ease the transition to more statically typed code and unlock the benefits of richer compile-time information, but is limited in languages like JavaScript as it cannot soundly handle duck-typing or runtime evaluation via eval. We propose DeepTyper, a deep learning model that understands which types naturally occur in certain contexts and relations and can provide type suggestions, which can often be verified by the type checker, even if it could not infer the type initially. DeepTyper, leverages an automatically aligned corpus of tokens and types to accurately predict thousands of variable and function type annotations. Furthermore, we demonstrate that context is key in accurately assigning these types and introduce a technique to reduce overfitting on local cues while highlighting the need for further improvements. Finally, we show that our model can interact with a compiler to provide more than 4,000 additional type annotations with over 95% precision that could not be inferred without the aid of DeepTyper."
}, {
    "py/object": "data.DataClassPaper",
    "Title": "Detecting Design Patterns in Object-Oriented Program Source Code by Using Metrics and Machine Learning",
    "year": 2014,
    "ML_Techniques": "DNN",
    "Category": "Program comprehension",
    "Sub_category": "Entity identification/recommendation",
    "Venue": "JSEA",
    "Link": "https://www.scirp.org/html/2-9301797_51394.htm",
    "bibtex": "article{Uchiyama2014_379,\n    author = \"Uchiyama, S. and Kubo, A. and Washizaki, H. and Fukazawa, Y.\",\n    title = \"Detecting Design Patterns in Object-Oriented Program Source Code by Using Metrics and Machine Learning\",\n    journal = \"Journal of Software Engineering and Applications\",\n    year = \"2014\",\n    volume = \"07\",\n    pages = \"983-998\"\n}\n\n",
    "abstract": "Detecting well-known design patterns in object-oriented program source code can help maintainers understand the design of a program. Through the detection, the understandability, maintainability, and reusability of object-oriented programs can be improved. There are automated detection techniques; however, many existing techniques are based on static analysis and use strict conditions composed on class structure data. Hence, it is difficult for them to detect and distinguish design patterns in which the class structures are similar. Moreover, it is difficult for them to deal with diversity in design pattern applications. To solve these problems in existing techniques, we propose a design pattern detection technique using source code metrics and machine learning. Our technique judges candidates for the roles that compose design patterns by using machine learning and measurements of several metrics, and it detects design patterns by analyzing the relations between candidates. It suppresses false negatives and distinguishes patterns in which the class structures are similar. As a result of experimental evaluations with a set of programs, we confirmed that our technique is more accurate than two conventional techniques."
}, {
    "py/object": "data.DataClassPaper",
    "Title": "Embedding Java Classes with code2vec: Improvements from Variable Obfuscation",
    "year": 2020,
    "ML_Techniques": "Code2Vec",
    "Category": "Program comprehension",
    "Sub_category": "",
    "Venue": "MSR",
    "Link": "https://dl.acm.org/doi/10.1145/3379597.3387445",
    "bibtex": "article{Uchiyama2014_379,\n    author = \"Uchiyama, S. and Kubo, A. and Washizaki, H. and Fukazawa, Y.\",\n    title = \"Detecting Design Patterns in Object-Oriented Program Source Code by Using Metrics and Machine Learning\",\n    journal = \"Journal of Software Engineering and Applications\",\n    year = \"2014\",\n    volume = \"07\",\n    pages = \"983-998\"\n}\n\n",
    "abstract": "Automatic source code analysis in key areas of software engineering, such as code security, can benefit from Machine Learning (ML). However, many standard ML approaches require a numeric representation of data and cannot be applied directly to source code. Thus, to enable ML, we need to embed source code into numeric feature vectors while maintaining the semantics of the code as much as possible. code2vec is a recently released embedding approach that uses the proxy task of method name prediction to map Java methods to feature vectors. However, experimentation with code2vec shows that it learns to rely on variable names for prediction, causing it to be easily fooled by typos or adversarial attacks. Moreover, it is only able to embed individual Java methods and cannot embed an entire collection of methods such as those present in a typical Java class, making it difficult to perform predictions at the class level (e.g., for the identification of malicious Java classes). Both shortcomings are addressed in the research presented in this paper. We investigate the effect of obfuscating variable names during the training of a code2vec model to force it to rely on the structure of the code rather than specific names and consider a simple approach to creating class-level embeddings by aggregating sets of method embeddings. Our results, obtained on a challenging new collection of source-code classification problems, indicate that obfuscating variable names produces an embedding model that is both impervious to variable naming and more accurately reflects code semantics. The datasets, models, and code are shared for further ML research on source code."
}, {
    "py/object": "data.DataClassPaper",
    "Title": "Identifying Auto-Generated Code by Using Machine Learning Techniques",
    "year": 2016,
    "ML_Techniques": "DT, RF, NB, SVM",
    "Category": "Program comprehension",
    "Sub_category": "Program classification",
    "Venue": "IWESEP",
    "Link": "https://ieeexplore.ieee.org/document/7464547",
    "bibtex": "INPROCEEDINGS{Shimonaka2016_381,\n    author = \"{Shimonaka}, K. and {Sumi}, S. and {Higo}, Y. and {Kusumoto}, S.\",\n    booktitle = \"2016 7th International Workshop on Empirical Software Engineering in Practice (IWESEP)\",\n    title = \"Identifying Auto-Generated Code by Using Machine Learning Techniques\",\n    year = \"2016\",\n    volume = \"\",\n    number = \"\",\n    pages = \"18-23\",\n    doi = \"10.1109/IWESEP.2016.18\"\n}\n\n",
    "abstract": "Recently, many researchers have conducted mining source code repositories to retrieve useful information about software development. Source code repositories often include auto-generated code, and auto-generated code is usually removed in a preprocessing phase because the presence of auto-generated code is harmful to source code analysis. A usual way to remove auto-generated code is searching particular comments which exist among auto-generated code. However, we cannot identify auto-generated code automatically with such a way if comments have disappeared. In addition, it takes too much time to identify auto-generated code manually. Therefore, we propose a technique to identify auto-generated code automatically by using machine learning techniques. In our proposed technique, we can identify whether source code is auto-generated code or not by utilizing syntactic information of source code. In order to evaluate the proposed technique, we conducted experiments on source code generated by four kinds of code generators. As a result, we confirmed that the proposed technique was able to identify auto-generated code with high accuracy."
}, {
    "py/object": "data.DataClassPaper",
    "Title": "Identifying Supplementary Bug-fix Commits",
    "year": 2018,
    "ML_Techniques": "SVM",
    "Category": "Program comprehension",
    "Sub_category": "Program classification",
    "Venue": "COMPSAC",
    "Link": "https://ieeexplore.ieee.org/document/8377655",
    "bibtex": "INPROCEEDINGS{Ji2018_382,\n    author = \"{Ji}, T. and {Pan}, J. and {Chen}, L. and {Mao}, X.\",\n    booktitle = \"2018 IEEE 42nd Annual Computer Software and Applications Conference (COMPSAC)\",\n    title = \"Identifying Supplementary Bug-fix Commits\",\n    year = \"2018\",\n    volume = \"01\",\n    number = \"\",\n    pages = \"184-193\",\n    doi = \"10.1109/COMPSAC.2018.00031\"\n}\n\n",
    "abstract": "Real-world bugs and the bug-fix activities are essential in many fields such as bug prediction and automatic program repair. Identifying bug-fix commits from version histories has received much recent attention. Linking commits to bug reports and analyzing the commits individually are common practice. However, considering the one-to-many relationship between the bug report and the bug-fix commits, analyzing commits individually will miss the relevance between commits, since several commits might fix the same bug together. In addition, some supplementary bug-fix commits which supplement or correct the identified bug-fix commit may be neglected. For empirical studies on bug-fix commits, it is important to study all the relevant commits as a whole, otherwise we will fail to understand the complete real bug-fix activities. In this paper, we investigate the relevance between bug-fix commits that are linked to the same bug-fix pull request, and utilize machine learning techniques to determine supplementary bug-fix commits for an identified bug-fix commit. Experimental results show that there indeed exist supplementary bug-fix commits (i.e., 19.8% on average) that are neglected when analyzing commits individually. The performance of our tool SupBCFinder is much better than that of using a sliding window of one hour and that of analyzing the local change. Moreover, inspired by our learning-based approach and extracted features, we propose one effective heuristic as an alternative for the cases when there are not enough pull requests for training."
}, {
    "py/object": "data.DataClassPaper",
    "Title": "Large-Scale and Language-Oblivious Code Authorship Identification",
    "year": 2017,
    "ML_Techniques": "RNN",
    "Category": "Program comprehension",
    "Sub_category": "Entity identification/recommendation",
    "Venue": "CCS",
    "Link": "https://dl.acm.org/doi/10.1145/3243734.3243738",
    "bibtex": "inproceedings{Abuhamad2018_383,\n    author = \"Abuhamad, Mohammed and AbuHmed, Tamer and Mohaisen, Aziz and Nyang, DaeHun\",\n    title = \"Large-Scale and Language-Oblivious Code Authorship Identification\",\n    year = \"2018\",\n    isbn = \"9781450356930\",\n    publisher = \"Association for Computing Machinery\",\n    address = \"New York, NY, USA\",\n    url = \"https://doi.org/10.1145/3243734.3243738\",\n    doi = \"10.1145/3243734.3243738\",\n    abstract = \"Efficient extraction of code authorship attributes is key for successful identification. However, the extraction of such attributes is very challenging, due to various programming language specifics, the limited number of available code samples per author, and the average code lines per file, among others. To this end, this work proposes a Deep Learning-based Code Authorship Identification System (DL-CAIS) for code authorship attribution that facilitates large-scale, language-oblivious, and obfuscation-resilient code authorship identification. The deep learning architecture adopted in this work includes TF-IDF-based deep representation using multiple Recurrent Neural Network (RNN) layers and fully-connected layers dedicated to authorship attribution learning. The deep representation then feeds into a random forest classifier for scalability to de-anonymize the author. Comprehensive experiments are conducted to evaluate DL-CAIS over the entire Google Code Jam (GCJ) dataset across all years (from 2008 to 2016) and over real-world code samples from 1987 public repositories on GitHub. The results of our work show the high accuracy despite requiring a smaller number of files per author. Namely, we achieve an accuracy of 96\\% when experimenting with 1,600 authors for GCJ, and 94.38\\% for the real-world dataset for 745 C programmers. Our system also allows us to identify 8,903 authors, the largest-scale dataset used by far, with an accuracy of 92.3\\%. Moreover, our technique is resilient to language-specifics, and thus it can identify authors of four programming languages (e.g. C, C++, Java, and Python), and authors writing in mixed languages (e.g. Java/C++, Python/C++). Finally, our system is resistant to sophisticated obfuscation (e.g. using C Tigress) with an accuracy of 93.42\\% for a set of 120 authors.\",\n    booktitle = \"Proceedings of the 2018 ACM SIGSAC Conference on Computer and Communications Security\",\n    pages = \"101\u2013114\",\n    numpages = \"14\",\n    keywords = \"deep learning identification, software forensics, program features, code authorship identification\",\n    location = \"Toronto, Canada\",\n    series = \"CCS '18\"\n}\n\n",
    "abstract": "Efficient extraction of code authorship attributes is key for successful identification. However, the extraction of such attributes is very challenging, due to various programming language specifics, the limited number of available code samples per author, and the average code lines per file, among others. To this end, this work proposes a Deep Learning-based Code Authorship Identification System (DL-CAIS) for code authorship attribution that facilitates large-scale, language-oblivious, and obfuscation-resilient code authorship identification. The deep learning architecture adopted in this work includes TF-IDF-based deep representation using multiple Recurrent Neural Network (RNN) layers and fully-connected layers dedicated to authorship attribution learning. The deep representation then feeds into a random forest classifier for scalability to de-anonymize the author. Comprehensive experiments are conducted to evaluate DL-CAIS over the entire Google Code Jam (GCJ) dataset across all years (from 2008 to 2016) and over real-world code samples from 1987 public repositories on GitHub. The results of our work show the high accuracy despite requiring a smaller number of files per author. Namely, we achieve an accuracy of 96% when experimenting with 1,600 authors for GCJ, and 94.38% for the real-world dataset for 745 C programmers. Our system also allows us to identify 8,903 authors, the largest-scale dataset used by far, with an accuracy of 92.3%. Moreover, our technique is resilient to language-specifics, and thus it can identify authors of four programming languages (e.g. C, C++, Java, and Python), and authors writing in mixed languages (e.g. Java/C++, Python/C++). Finally, our system is resistant to sophisticated obfuscation (e.g. using C Tigress) with an accuracy of 93.42% for a set of 120 authors."
}, {
    "py/object": "data.DataClassPaper",
    "Title": "Machine learning based recommendation of method names: how far are we",
    "year": 2019,
    "ML_Techniques": "",
    "Category": "Program comprehension",
    "Sub_category": "Entity identification/recommendation",
    "Venue": "ASE",
    "Link": "https://dl.acm.org/doi/10.1109/ASE.2019.00062",
    "bibtex": "inproceedings{Abuhamad2018_383,\n    author = \"Abuhamad, Mohammed and AbuHmed, Tamer and Mohaisen, Aziz and Nyang, DaeHun\",\n    title = \"Large-Scale and Language-Oblivious Code Authorship Identification\",\n    year = \"2018\",\n    isbn = \"9781450356930\",\n    publisher = \"Association for Computing Machinery\",\n    address = \"New York, NY, USA\",\n    url = \"https://doi.org/10.1145/3243734.3243738\",\n    doi = \"10.1145/3243734.3243738\",\n    abstract = \"Efficient extraction of code authorship attributes is key for successful identification. However, the extraction of such attributes is very challenging, due to various programming language specifics, the limited number of available code samples per author, and the average code lines per file, among others. To this end, this work proposes a Deep Learning-based Code Authorship Identification System (DL-CAIS) for code authorship attribution that facilitates large-scale, language-oblivious, and obfuscation-resilient code authorship identification. The deep learning architecture adopted in this work includes TF-IDF-based deep representation using multiple Recurrent Neural Network (RNN) layers and fully-connected layers dedicated to authorship attribution learning. The deep representation then feeds into a random forest classifier for scalability to de-anonymize the author. Comprehensive experiments are conducted to evaluate DL-CAIS over the entire Google Code Jam (GCJ) dataset across all years (from 2008 to 2016) and over real-world code samples from 1987 public repositories on GitHub. The results of our work show the high accuracy despite requiring a smaller number of files per author. Namely, we achieve an accuracy of 96\\% when experimenting with 1,600 authors for GCJ, and 94.38\\% for the real-world dataset for 745 C programmers. Our system also allows us to identify 8,903 authors, the largest-scale dataset used by far, with an accuracy of 92.3\\%. Moreover, our technique is resilient to language-specifics, and thus it can identify authors of four programming languages (e.g. C, C++, Java, and Python), and authors writing in mixed languages (e.g. Java/C++, Python/C++). Finally, our system is resistant to sophisticated obfuscation (e.g. using C Tigress) with an accuracy of 93.42\\% for a set of 120 authors.\",\n    booktitle = \"Proceedings of the 2018 ACM SIGSAC Conference on Computer and Communications Security\",\n    pages = \"101\u2013114\",\n    numpages = \"14\",\n    keywords = \"deep learning identification, software forensics, program features, code authorship identification\",\n    location = \"Toronto, Canada\",\n    series = \"CCS '18\"\n}\n\n",
    "abstract": "High quality method names are critical for the readability and maintainability of programs. However, constructing concise and consistent method names is often challenging, especially for inexperienced developers. To this end, advanced machine learning techniques have been recently leveraged to recommend method names automatically for given method bodies/implementation. Recent large-scale evaluations also suggest that such approaches are accurate. However, little is known about where and why such approaches work or don't work. To figure out the state of the art as well as the rationale for the success/failure, in this paper we conduct an empirical study on the state-of-the-art approach code2vec. We assess code2vec on a new dataset with more realistic settings. Our evaluation results suggest that although switching to new dataset does not significantly influence the performance, more realistic settings do significantly reduce the performance of code2vec. Further analysis on the successfully recommended method names also reveals the following findings: 1) around half (48.3%) of the accepted recommendations are made on getter/setter methods; 2) a large portion (19.2%) of the successfully recommended method names could be copied from the given bodies. To further validate its usefulness, we ask developers to manually score the difficulty in naming methods they developed. Code2vec is then applied to such manually scored methods to evaluate how often it works in need. Our evaluation results suggest that code2vec rarely works when it is really needed. Finally, to intuitively reveal the state of the art and to investigate the possibility of designing simple and straightforward alternative approaches, we propose a heuristics based approach to recommending method names. Evaluation results on large-scale dataset suggest that this simple heuristics-based approach significantly outperforms the state-of-the-art machine learning based approach, improving precision and recall by 65.25% and 22.45%, respectively. The comparison suggests that machine learning based recommendation of method names may still have a long way to go."
}, {
    "py/object": "data.DataClassPaper",
    "Title": "Metadata recovery from obfuscated programs using machine learning",
    "year": 2016,
    "ML_Techniques": "",
    "Category": "Program comprehension",
    "Sub_category": "Entity identification/recommendation",
    "Venue": "SSPREW",
    "Link": "https://dl.acm.org/doi/10.1145/3015135.3015136",
    "bibtex": "inproceedings{Abuhamad2018_383,\n    author = \"Abuhamad, Mohammed and AbuHmed, Tamer and Mohaisen, Aziz and Nyang, DaeHun\",\n    title = \"Large-Scale and Language-Oblivious Code Authorship Identification\",\n    year = \"2018\",\n    isbn = \"9781450356930\",\n    publisher = \"Association for Computing Machinery\",\n    address = \"New York, NY, USA\",\n    url = \"https://doi.org/10.1145/3243734.3243738\",\n    doi = \"10.1145/3243734.3243738\",\n    abstract = \"Efficient extraction of code authorship attributes is key for successful identification. However, the extraction of such attributes is very challenging, due to various programming language specifics, the limited number of available code samples per author, and the average code lines per file, among others. To this end, this work proposes a Deep Learning-based Code Authorship Identification System (DL-CAIS) for code authorship attribution that facilitates large-scale, language-oblivious, and obfuscation-resilient code authorship identification. The deep learning architecture adopted in this work includes TF-IDF-based deep representation using multiple Recurrent Neural Network (RNN) layers and fully-connected layers dedicated to authorship attribution learning. The deep representation then feeds into a random forest classifier for scalability to de-anonymize the author. Comprehensive experiments are conducted to evaluate DL-CAIS over the entire Google Code Jam (GCJ) dataset across all years (from 2008 to 2016) and over real-world code samples from 1987 public repositories on GitHub. The results of our work show the high accuracy despite requiring a smaller number of files per author. Namely, we achieve an accuracy of 96\\% when experimenting with 1,600 authors for GCJ, and 94.38\\% for the real-world dataset for 745 C programmers. Our system also allows us to identify 8,903 authors, the largest-scale dataset used by far, with an accuracy of 92.3\\%. Moreover, our technique is resilient to language-specifics, and thus it can identify authors of four programming languages (e.g. C, C++, Java, and Python), and authors writing in mixed languages (e.g. Java/C++, Python/C++). Finally, our system is resistant to sophisticated obfuscation (e.g. using C Tigress) with an accuracy of 93.42\\% for a set of 120 authors.\",\n    booktitle = \"Proceedings of the 2018 ACM SIGSAC Conference on Computer and Communications Security\",\n    pages = \"101\u2013114\",\n    numpages = \"14\",\n    keywords = \"deep learning identification, software forensics, program features, code authorship identification\",\n    location = \"Toronto, Canada\",\n    series = \"CCS '18\"\n}\n\n",
    "abstract": "Obfuscation is a mechanism used to hinder reverse engineering of programs. To cope with the large number of obfuscated programs, especially malware, reverse engineers automate the process of deobfuscation i.e. extracting information from obfuscated programs. Deobfuscation techniques target specific obfuscation transformations, which requires reverse engineers to manually identify the transformations used by a program, in what is known as metadata recovery attack. In this paper, we present Oedipus, a Python framework that uses machine learning classifiers viz., decision trees and naive Bayes, to automate metadata recovery attacks against obfuscated programs. We evaluated Oedipus' performance using two datasets totaling 1960 unobfuscated C programs, which were used to generate 11.075 programs obfuscated using 30 configurations of 6 different obfuscation transformations. Our results empirically show the feasibility of using machine learning to implement the metadata recovery attacks with classification accuracies of 100% in some cases."
}, {
    "py/object": "data.DataClassPaper",
    "Title": "Method name suggestion with hierarchical attention networks",
    "year": 2019,
    "ML_Techniques": "",
    "Category": "Program comprehension",
    "Sub_category": "Entity identification/recommendation",
    "Venue": "PEPM",
    "Link": "https://dl.acm.org/doi/10.1145/3294032.3294079",
    "bibtex": "inproceedings{Abuhamad2018_383,\n    author = \"Abuhamad, Mohammed and AbuHmed, Tamer and Mohaisen, Aziz and Nyang, DaeHun\",\n    title = \"Large-Scale and Language-Oblivious Code Authorship Identification\",\n    year = \"2018\",\n    isbn = \"9781450356930\",\n    publisher = \"Association for Computing Machinery\",\n    address = \"New York, NY, USA\",\n    url = \"https://doi.org/10.1145/3243734.3243738\",\n    doi = \"10.1145/3243734.3243738\",\n    abstract = \"Efficient extraction of code authorship attributes is key for successful identification. However, the extraction of such attributes is very challenging, due to various programming language specifics, the limited number of available code samples per author, and the average code lines per file, among others. To this end, this work proposes a Deep Learning-based Code Authorship Identification System (DL-CAIS) for code authorship attribution that facilitates large-scale, language-oblivious, and obfuscation-resilient code authorship identification. The deep learning architecture adopted in this work includes TF-IDF-based deep representation using multiple Recurrent Neural Network (RNN) layers and fully-connected layers dedicated to authorship attribution learning. The deep representation then feeds into a random forest classifier for scalability to de-anonymize the author. Comprehensive experiments are conducted to evaluate DL-CAIS over the entire Google Code Jam (GCJ) dataset across all years (from 2008 to 2016) and over real-world code samples from 1987 public repositories on GitHub. The results of our work show the high accuracy despite requiring a smaller number of files per author. Namely, we achieve an accuracy of 96\\% when experimenting with 1,600 authors for GCJ, and 94.38\\% for the real-world dataset for 745 C programmers. Our system also allows us to identify 8,903 authors, the largest-scale dataset used by far, with an accuracy of 92.3\\%. Moreover, our technique is resilient to language-specifics, and thus it can identify authors of four programming languages (e.g. C, C++, Java, and Python), and authors writing in mixed languages (e.g. Java/C++, Python/C++). Finally, our system is resistant to sophisticated obfuscation (e.g. using C Tigress) with an accuracy of 93.42\\% for a set of 120 authors.\",\n    booktitle = \"Proceedings of the 2018 ACM SIGSAC Conference on Computer and Communications Security\",\n    pages = \"101\u2013114\",\n    numpages = \"14\",\n    keywords = \"deep learning identification, software forensics, program features, code authorship identification\",\n    location = \"Toronto, Canada\",\n    series = \"CCS '18\"\n}\n\n",
    "abstract": "Method Rename has been a widely used refactoring operation that improves program comprehension and maintenance. Descriptive method names that summarize functionalities of source code can facilitate program comprehension. Much research has been done to suggest method names through source code summarization. However, unlike natural language, a code snippet consists of basic blocks organized by complicated structures. In this work, we observe a hierarchical structure --- tokens form basic blocks and basic blocks form a code snippet. Based on this observation, we exploit a hierarchical attention network to learn the representation of methods. Specifically, we apply two-level attention mechanism to learn the importance of each token in a basic block and that of a basic block in a method respectively. We evaluated our approach on 10 open source repositories and compared it against three state-of-the-art approaches. The results on these open-source data show the superiority of our hierarchical attention networks in terms of effectiveness."
}, {
    "py/object": "data.DataClassPaper",
    "Title": "Mining software repositories for adaptive change commits using machine learning techniques",
    "year": 2019,
    "ML_Techniques": "",
    "Category": "Program comprehension",
    "Sub_category": "Program classification",
    "Venue": "IST",
    "Link": "https://www.sciencedirect.com/science/article/abs/pii/S0950584919300084",
    "bibtex": "article{Meqdadi2019_387,\n    author = \"Meqdadi, Omar and Alhindawi, Nouh and Alsakran, Jamal and Saifan, Ahmad and Migdadi, Hatim\",\n    title = \"Mining software repositories for adaptive change commits using machine learning techniques\",\n    journal = \"Information and Software Technology\",\n    volume = \"109\",\n    pages = \"80 - 91\",\n    year = \"2019\",\n    issn = \"0950-5849\",\n    doi = \"https://doi.org/10.1016/j.infsof.2019.01.008\",\n    url = \"http://www.sciencedirect.com/science/article/pii/S0950584919300084\",\n    keywords = \"Code change metrics, Adaptive maintenance, Commit types, Maintenance classification, Machine learning\",\n    abstract = \"Context Version Control Systems, such as Subversion, are standard repositories that preserve all of the maintenance changes undertaken to source code artifacts during the evolution of a software system. The documented data of the version history are organized as commits; however, these commits do not keep a tag that would identify the purpose of the relevant undertaken change of a commit, thus, there is rarely enough detail to clearly direct developers to the changes associated with a specific type of maintenance. Objective This work examines the version histories of an open source system to automatically classify version commits into one of two categories, namely adaptive commits and non-adaptive commits. Method We collected the commits from the version history of three open source systems, then we obtained eight different code change metrics related to, for example, the number of changed statements, methods, hunks, and files. Based on these change metrics, we built a machine learning approach to classify whether a commit was adaptive or not. Results It is observed that code change metrics can be indicative of adaptive maintenance activities. Also, the classification findings show that the machine learning classifier developed has approximately 75\\% prediction accuracy within labeled change histories. Conclusion The proposed method automates the process of examining the version history of a software system and identifies which commits to the system are related to an adaptive maintenance task. The evaluation of the method supports its applicability and efficiency. Although the evaluation of the proposed classifier on unlabeled change histories shows that it is not much better than the random guessing in terms of F-measure, we feel that our classifier would serve as a better basis for developing advanced classifiers that have predictive power of adaptive commits without the need of manual efforts.\"\n}\n\n",
    "abstract": "Context\nVersion Control Systems, such as Subversion, are standard repositories that preserve all of the maintenance changes undertaken to source code artifacts during the evolution of a software system. The documented data of the version history are organized as commits; however, these commits do not keep a tag that would identify the purpose of the relevant undertaken change of a commit, thus, there is rarely enough detail to clearly direct developers to the changes associated with a specific type of maintenance.\n\nObjective\nThis work examines the version histories of an open source system to automatically classify version commits into one of two categories, namely adaptive commits and non-adaptive commits.\n\nMethod\nWe collected the commits from the version history of three open source systems, then we obtained eight different code change metrics related to, for example, the number of changed statements, methods, hunks, and files. Based on these change metrics, we built a machine learning approach to classify whether a commit was adaptive or not.\n\nResults\nIt is observed that code change metrics can be indicative of adaptive maintenance activities. Also, the classification findings show that the machine learning classifier developed has approximately 75% prediction accuracy within labeled change histories.\n\nConclusion\nThe proposed method automates the process of examining the version history of a software system and identifies which commits to the system are related to an adaptive maintenance task. The evaluation of the method supports its applicability and efficiency. Although the evaluation of the proposed classifier on unlabeled change histories shows that it is not much better than the random guessing in terms of F-measure, we feel that our classifier would serve as a better basis for developing advanced classifiers that have predictive power of adaptive commits without the need of manual efforts."
}, {
    "py/object": "data.DataClassPaper",
    "Title": "Neural Code Comprehension: A Learnable Representation of Code Semantics",
    "year": 2018,
    "ML_Techniques": " inst2vec",
    "Category": "Program comprehension",
    "Sub_category": "",
    "Venue": "NIPS",
    "Link": "https://arxiv.org/abs/1806.07336",
    "bibtex": "inproceedings{Ben-Nun2018_388,\n    author = \"Ben-Nun, Tal and Jakobovits, Alice Shoshana and Hoefler, Torsten\",\n    title = \"Neural Code Comprehension: A Learnable Representation of Code Semantics\",\n    year = \"2018\",\n    publisher = \"Curran Associates Inc.\",\n    address = \"Red Hook, NY, USA\",\n    abstract = \"With the recent success of embeddings in natural language processing, research has been conducted into applying similar methods to code analysis. Most works attempt to process the code directly or use a syntactic tree representation, treating it like sentences written in a natural language. However, none of the existing methods are sufficient to comprehend program semantics robustly, due to structural features such as function calls, branching, and interchangeable order of statements. In this paper, we propose a novel processing technique to learn code semantics, and apply it to a variety of program analysis tasks. In particular, we stipulate that a robust distributional hypothesis of code applies to both human- and machine-generated programs. Following this hypothesis, we define an embedding space, inst2vec, based on an Intermediate Representation (IR) of the code that is independent of the source programming language. We provide a novel definition of contextual flow for this IR, leveraging both the underlying data- and control-flow of the program. We then analyze the embeddings qualitatively using analogies and clustering, and evaluate the learned representation on three different high-level tasks. We show that even without fine-tuning, a single RNN architecture and fixed inst2vec embeddings outperform specialized approaches for performance prediction (compute device mapping, optimal thread coarsening); and algorithm classification from raw code (104 classes), where we set a new state-of-the-art.\",\n    booktitle = \"Proceedings of the 32nd International Conference on Neural Information Processing Systems\",\n    pages = \"3589\u20133601\",\n    numpages = \"13\",\n    location = \"Montr\\'{e}al, Canada\",\n    series = \"NIPS'18\"\n}\n\n",
    "abstract": "With the recent success of embeddings in natural language processing, research has been conducted into applying similar methods to code analysis. Most works attempt to process the code directly or use a syntactic tree representation, treating it like sentences written in a natural language. However, none of the existing methods are sufficient to comprehend program semantics robustly, due to structural features such as function calls, branching, and interchangeable order of statements. In this paper, we propose a novel processing technique to learn code semantics, and apply it to a variety of program analysis tasks. In particular, we stipulate that a robust distributional hypothesis of code applies to both human- and machine-generated programs. Following this hypothesis, we define an embedding space, inst2vec, based on an Intermediate Representation (IR) of the code that is independent of the source programming language. We provide a novel definition of contextual flow for this IR, leveraging both the underlying data- and control-flow of the program. We then analyze the embeddings qualitatively using analogies and clustering, and evaluate the learned representation on three different high-level tasks. We show that even without fine-tuning, a single RNN architecture and fixed inst2vec embeddings outperform specialized approaches for performance prediction (compute device mapping, optimal thread coarsening); and algorithm classification from raw code (104 classes), where we set a new state-of-the-art."
}, {
    "py/object": "data.DataClassPaper",
    "Title": "NL2Type: Inferring JavaScript Function Types fromNatural Language Information",
    "year": 2019,
    "ML_Techniques": "RNN",
    "Category": "Program comprehension",
    "Sub_category": "Entity identification/recommendation",
    "Venue": "ICSE",
    "Link": "https://ieeexplore.ieee.org/document/8811893",
    "bibtex": "inproceedings{Ben-Nun2018_388,\n    author = \"Ben-Nun, Tal and Jakobovits, Alice Shoshana and Hoefler, Torsten\",\n    title = \"Neural Code Comprehension: A Learnable Representation of Code Semantics\",\n    year = \"2018\",\n    publisher = \"Curran Associates Inc.\",\n    address = \"Red Hook, NY, USA\",\n    abstract = \"With the recent success of embeddings in natural language processing, research has been conducted into applying similar methods to code analysis. Most works attempt to process the code directly or use a syntactic tree representation, treating it like sentences written in a natural language. However, none of the existing methods are sufficient to comprehend program semantics robustly, due to structural features such as function calls, branching, and interchangeable order of statements. In this paper, we propose a novel processing technique to learn code semantics, and apply it to a variety of program analysis tasks. In particular, we stipulate that a robust distributional hypothesis of code applies to both human- and machine-generated programs. Following this hypothesis, we define an embedding space, inst2vec, based on an Intermediate Representation (IR) of the code that is independent of the source programming language. We provide a novel definition of contextual flow for this IR, leveraging both the underlying data- and control-flow of the program. We then analyze the embeddings qualitatively using analogies and clustering, and evaluate the learned representation on three different high-level tasks. We show that even without fine-tuning, a single RNN architecture and fixed inst2vec embeddings outperform specialized approaches for performance prediction (compute device mapping, optimal thread coarsening); and algorithm classification from raw code (104 classes), where we set a new state-of-the-art.\",\n    booktitle = \"Proceedings of the 32nd International Conference on Neural Information Processing Systems\",\n    pages = \"3589\u20133601\",\n    numpages = \"13\",\n    location = \"Montr\\'{e}al, Canada\",\n    series = \"NIPS'18\"\n}\n\n",
    "abstract": "JavaScript is dynamically typed and hence lacks the type safety of statically typed languages, leading to suboptimal IDE support, difficult to understand APIs, and unexpected runtime behavior. Several gradual type systems have been proposed, e.g., Flow and TypeScript, but they rely on developers to annotate code with types. This paper presents NL2Type, a learning-based approach for predicting likely type signatures of JavaScript functions. The key idea is to exploit natural language information in source code, such as comments, function names, and parameter names, a rich source of knowledge that is typically ignored by type inference algorithms. We formulate the problem of predicting types as a classification problem and train a recurrent, LSTM-based neural model that, after learning from an annotated code base, predicts function types for unannotated code. We evaluate the approach with a corpus of 162,673 JavaScript files from real-world projects. NL2Type predicts types with a precision of 84.1% and a recall of 78.9% when considering only the top-most suggestion, and with a precision of 95.5% and a recall of 89.6% when considering the top-5 suggestions. The approach outperforms both JSNice, a state-of-the-art approach that analyzes implementations of functions instead of natural language information, and DeepTyper, a recent type prediction approach that is also based on deep learning. Beyond predicting types, NL2Type serves as a consistency checker for existing type annotations. We show that it discovers 39 inconsistencies that deserve developer attention (from a manual analysis of 50 warnings), most of which are due to incorrect type annotations."
}, {
    "py/object": "data.DataClassPaper",
    "Title": "On Learning Meaningful Code Changes Via Neural Machine Translation",
    "year": 2019,
    "ML_Techniques": "EN-DE",
    "Category": "Program comprehension",
    "Sub_category": "Change analysis",
    "Venue": "ICSE",
    "Link": "https://ieeexplore.ieee.org/abstract/document/8811910",
    "bibtex": "INPROCEEDINGS{Tufano2019_390,\n    author = \"{Tufano}, M. and {Pantiuchina}, J. and {Watson}, C. and {Bavota}, G. and {Poshyvanyk}, D.\",\n    booktitle = \"2019 IEEE/ACM 41st International Conference on Software Engineering (ICSE)\",\n    title = \"On Learning Meaningful Code Changes Via Neural Machine Translation\",\n    year = \"2019\",\n    volume = \"\",\n    number = \"\",\n    pages = \"25-36\",\n    doi = \"10.1109/ICSE.2019.00021\"\n}\n\n",
    "abstract": "Recent years have seen the rise of Deep Learning (DL) techniques applied to source code. Researchers have exploited DL to automate several development and maintenance tasks, such as writing commit messages, generating comments and detecting vulnerabilities among others. One of the long lasting dreams of applying DL to source code is the possibility to automate non-trivial coding activities. While some steps in this direction have been taken (e.g., learning how to fix bugs), there is still a glaring lack of empirical evidence on the types of code changes that can be learned and automatically applied by DL.\n\nOur goal is to make this first important step by quantitatively and qualitatively investigating the ability of a Neural Machine Translation (NMT) model to learn how to automatically apply code changes implemented by developers during pull requests. We train and experiment with the NMT model on a set of 236k pairs of code components before and after the implementation of the changes provided in the pull requests. We show that, when applied in a narrow enough context (i.e., small/medium-sized pairs of methods before/after the pull request changes), NMT can automatically replicate the changes implemented by developers during pull requests in up to 36% of the cases. Moreover, our qualitative analysis shows that the model is capable of learning and replicating a wide variety of meaningful code changes, especially refactorings and bug-fixing activities. Our results pave the way for novel research in the area of DL on code, such as the automatic learning and applications of refactoring."
}, {
    "py/object": "data.DataClassPaper",
    "Title": "On using machine learning to automatically classify software applications into domain categories",
    "year": 2014,
    "ML_Techniques": "",
    "Category": "Program comprehension",
    "Sub_category": "Program classification",
    "Venue": "EMSE",
    "Link": "https://dl.acm.org/doi/10.1007/s10664-012-9230-z",
    "bibtex": "article{V\\'asquez2012_391,\n    author = \"V{\\'a}squez, M. and McMillan, Collin and Poshyvanyk, D. and Grechanik, M.\",\n    title = \"On using machine learning to automatically classify software applications into domain categories\",\n    journal = \"Empirical Software Engineering\",\n    year = \"2012\",\n    volume = \"19\",\n    pages = \"582-618\"\n}\n\n",
    "abstract": "Software repositories hold applications that are often categorized to improve the effectiveness of various maintenance tasks. Properly categorized applications allow stakeholders to identify requirements related to their applications and predict maintenance problems in software projects. Manual categorization is expensive, tedious, and laborious --- this is why automatic categorization approaches are gaining widespread importance. Unfortunately, for different legal and organizational reasons, the applications' source code is often not available, thus making it difficult to automatically categorize these applications. In this paper, we propose a novel approach in which we use Application Programming Interface (API) calls from third-party libraries for automatic categorization of software applications that use these API calls. Our approach is general since it enables different categorization algorithms to be applied to repositories that contain both source code and bytecode of applications, since API calls can be extracted from both the source code and byte-code. We compare our approach to a state-of-the-art approach that uses machine learning algorithms for software categorization, and conduct experiments on two large Java repositories: an open-source repository containing 3,286 projects and a closed-source repository with 745 applications, where the source code was not available. Our contribution is twofold: we propose a new approach that makes it possible to categorize software projects without any source code using a small number of API calls as attributes, and furthermore we carried out a comprehensive empirical evaluation of automatic categorization approaches."
}, {
    "py/object": "data.DataClassPaper",
    "Title": "Suggesting Accurate Method and Class Names",
    "year": 2015,
    "ML_Techniques": "neural context model",
    "Category": "Program comprehension",
    "Sub_category": "Entity identification/recommendation",
    "Venue": "FSE",
    "Link": "http://homepages.inf.ed.ac.uk/csutton/publications/accurate-method-and-class.pdf",
    "bibtex": "inproceedings{Allamanis2015_392,\n    author = \"Allamanis, Miltiadis and Barr, Earl T. and Bird, Christian and Sutton, Charles\",\n    title = \"Suggesting Accurate Method and Class Names\",\n    year = \"2015\",\n    isbn = \"9781450336758\",\n    publisher = \"Association for Computing Machinery\",\n    address = \"New York, NY, USA\",\n    url = \"https://doi.org/10.1145/2786805.2786849\",\n    doi = \"10.1145/2786805.2786849\",\n    abstract = \"Descriptive names are a vital part of readable, and hence maintainable, code. Recent progress on automatically suggesting names for local variables tantalizes with the prospect of replicating that success with method and class names. However, suggesting names for methods and classes is much more difficult. This is because good method and class names need to be functionally descriptive, but suggesting such names requires that the model goes beyond local context. We introduce a neural probabilistic language model for source code that is specifically designed for the method naming problem. Our model learns which names are semantically similar by assigning them to locations, called embeddings, in a high-dimensional continuous space, in such a way that names with similar embeddings tend to be used in similar contexts. These embeddings seem to contain semantic information about tokens, even though they are learned only from statistical co-occurrences of tokens. Furthermore, we introduce a variant of our model that is, to our knowledge, the first that can propose neologisms, names that have not appeared in the training corpus. We obtain state of the art results on the method, class, and even the simpler variable naming tasks. More broadly, the continuous embeddings that are learned by our model have the potential for wide application within software engineering.\",\n    booktitle = \"Proceedings of the 2015 10th Joint Meeting on Foundations of Software Engineering\",\n    pages = \"38\u201349\",\n    numpages = \"12\",\n    keywords = \"Coding conventions, naturalness of software\",\n    location = \"Bergamo, Italy\",\n    series = \"ESEC/FSE 2015\"\n}\n\n",
    "abstract": "Descriptive names are a vital part of readable, and hence maintainable, code. Recent progress on automatically suggesting names for local variables tantalizes with the prospect of replicating that success with method and class names. However, suggesting names for methods and classes is much more difficult. This is because good method and class names need to be functionally descriptive, but suggesting such names requires that the model goes beyond local context. We introduce a neural probabilistic language model for source code that is specifically designed for the method naming problem. Our model learns which names are semantically similar by assigning them to locations, called embeddings, in a high-dimensional continuous space, in such a way that names with similar embeddings tend to be used in similar contexts. These embeddings seem to contain semantic information about tokens, even though they are learned only from statistical co-occurrences of tokens. Furthermore, we introduce a variant of our model that is, to our knowledge, the first that can propose neologisms, names that have not appeared in the training corpus. We obtain state of the art results on the method, class, and even the simpler variable naming tasks. More broadly, the continuous embeddings that are learned by our model have the potential for wide application within software engineering."
}, {
    "py/object": "data.DataClassPaper",
    "Title": "Towards a universal code formatter through machine learning",
    "year": 2016,
    "ML_Techniques": "",
    "Category": "Program comprehension",
    "Sub_category": "",
    "Venue": "SLE",
    "Link": "https://dl.acm.org/doi/abs/10.1145/2997364.2997383",
    "bibtex": "inproceedings{Allamanis2015_392,\n    author = \"Allamanis, Miltiadis and Barr, Earl T. and Bird, Christian and Sutton, Charles\",\n    title = \"Suggesting Accurate Method and Class Names\",\n    year = \"2015\",\n    isbn = \"9781450336758\",\n    publisher = \"Association for Computing Machinery\",\n    address = \"New York, NY, USA\",\n    url = \"https://doi.org/10.1145/2786805.2786849\",\n    doi = \"10.1145/2786805.2786849\",\n    abstract = \"Descriptive names are a vital part of readable, and hence maintainable, code. Recent progress on automatically suggesting names for local variables tantalizes with the prospect of replicating that success with method and class names. However, suggesting names for methods and classes is much more difficult. This is because good method and class names need to be functionally descriptive, but suggesting such names requires that the model goes beyond local context. We introduce a neural probabilistic language model for source code that is specifically designed for the method naming problem. Our model learns which names are semantically similar by assigning them to locations, called embeddings, in a high-dimensional continuous space, in such a way that names with similar embeddings tend to be used in similar contexts. These embeddings seem to contain semantic information about tokens, even though they are learned only from statistical co-occurrences of tokens. Furthermore, we introduce a variant of our model that is, to our knowledge, the first that can propose neologisms, names that have not appeared in the training corpus. We obtain state of the art results on the method, class, and even the simpler variable naming tasks. More broadly, the continuous embeddings that are learned by our model have the potential for wide application within software engineering.\",\n    booktitle = \"Proceedings of the 2015 10th Joint Meeting on Foundations of Software Engineering\",\n    pages = \"38\u201349\",\n    numpages = \"12\",\n    keywords = \"Coding conventions, naturalness of software\",\n    location = \"Bergamo, Italy\",\n    series = \"ESEC/FSE 2015\"\n}\n\n",
    "abstract": "There are many declarative frameworks that allow us to implement code formatters relatively easily for any specific language, but constructing them is cumbersome. The first problem is that \u201ceverybody\u201d wants to format their code differently, leading to either many formatter variants or a ridiculous number of configuration options. Second, the size of each implementation scales with a language\u2019s grammar size, leading to hundreds of rules.\n\nIn this paper, we solve the formatter construction problem using a novel approach, one that automatically derives formatters for any given language without intervention from a language expert. We introduce a code formatter called CodeBuff that uses machine learning to abstract formatting rules from a representative corpus, using a carefully designed feature set. Our experiments on Java, SQL, and ANTLR grammars show that CodeBuff is efficient, has excellent accuracy, and is grammar invariant for a given language. It also generalizes to a 4th language tested during manuscript preparation."
}, {
    "py/object": "data.DataClassPaper",
    "Title": "What's the code?: automatic classification of source code archives",
    "year": 2002,
    "ML_Techniques": "",
    "Category": "Program comprehension",
    "Sub_category": "Program classification",
    "Venue": "KDD",
    "Link": "https://dl.acm.org/doi/10.1145/775047.775141",
    "bibtex": "inproceedings{Allamanis2015_392,\n    author = \"Allamanis, Miltiadis and Barr, Earl T. and Bird, Christian and Sutton, Charles\",\n    title = \"Suggesting Accurate Method and Class Names\",\n    year = \"2015\",\n    isbn = \"9781450336758\",\n    publisher = \"Association for Computing Machinery\",\n    address = \"New York, NY, USA\",\n    url = \"https://doi.org/10.1145/2786805.2786849\",\n    doi = \"10.1145/2786805.2786849\",\n    abstract = \"Descriptive names are a vital part of readable, and hence maintainable, code. Recent progress on automatically suggesting names for local variables tantalizes with the prospect of replicating that success with method and class names. However, suggesting names for methods and classes is much more difficult. This is because good method and class names need to be functionally descriptive, but suggesting such names requires that the model goes beyond local context. We introduce a neural probabilistic language model for source code that is specifically designed for the method naming problem. Our model learns which names are semantically similar by assigning them to locations, called embeddings, in a high-dimensional continuous space, in such a way that names with similar embeddings tend to be used in similar contexts. These embeddings seem to contain semantic information about tokens, even though they are learned only from statistical co-occurrences of tokens. Furthermore, we introduce a variant of our model that is, to our knowledge, the first that can propose neologisms, names that have not appeared in the training corpus. We obtain state of the art results on the method, class, and even the simpler variable naming tasks. More broadly, the continuous embeddings that are learned by our model have the potential for wide application within software engineering.\",\n    booktitle = \"Proceedings of the 2015 10th Joint Meeting on Foundations of Software Engineering\",\n    pages = \"38\u201349\",\n    numpages = \"12\",\n    keywords = \"Coding conventions, naturalness of software\",\n    location = \"Bergamo, Italy\",\n    series = \"ESEC/FSE 2015\"\n}\n\n",
    "abstract": "There are various source code archives on the World Wide Web. These archives are usually organized by application categories and programming languages. However, manually organizing source code repositories is not a trivial task since they grow rapidly and are very large (on the order of terabytes). We demonstrate machine learning methods for automatic classification of archived source code into eleven application topics and ten programming languages. For topical classification, we concentrate on C and C++ programs from the Ibiblio and the Sourceforge archives. Support vector machine (SVM) classifiers are trained on examples of a given programming language or programs in a specified category. We show that source code can be accurately and automatically classified into topical categories and can be identified to be in a specific programming language class."
}, {
    "py/object": "data.DataClassPaper",
    "Title": "Can AI Close the Design-Code Abstraction Gap?",
    "year": 2019,
    "ML_Techniques": "",
    "Category": "General",
    "Sub_category": "",
    "Venue": "ASEW",
    "Link": "https://ieeexplore.ieee.org/document/8967435",
    "bibtex": "INPROCEEDINGS{Ivers2019_395,\n    author = \"{Ivers}, J. and {Ozkaya}, I. and {Nord}, R. L.\",\n    booktitle = \"2019 34th IEEE/ACM International Conference on Automated Software Engineering Workshop (ASEW)\",\n    title = \"Can AI Close the Design-Code Abstraction Gap?\",\n    year = \"2019\",\n    volume = \"\",\n    number = \"\",\n    pages = \"122-125\",\n    doi = \"10.1109/ASEW.2019.00041\"\n}\n\n",
    "abstract": "Aligning the design of a system with its\nimplementation improves product quality and simplifies product\nevolution. While developers are empowered with AI/ML\naugmented tools and techniques that increasingly assist them in\nimplementation tasks, the abstraction gap between code and\ndesign limits automation for design tasks. In this position paper,\nwe argue that the software engineering community can take\nadvantage of the experiences built with AI/ML techniques to\nadvance automation in design analysis. We summarize research\nchallenges and describe two efforts that apply machine learning to\ncodebases to extract design constructs and detect deviation from\nintended designs and to use search-based refactoring to make\ndesign improvements for extracting functionality."
}, {
    "py/object": "data.DataClassPaper",
    "Title": "How does Machine Learning Change Software Development Practices?",
    "year": 2019,
    "ML_Techniques": "",
    "Category": "General",
    "Sub_category": "",
    "Venue": "TSE",
    "Link": "https://ieeexplore.ieee.org/abstract/document/8812912",
    "bibtex": "ARTICLE{Wan2019_396,\n    author = \"{Wan}, Z. and {Xia}, X. and {Lo}, D. and {Murphy}, G. C.\",\n    journal = \"IEEE Transactions on Software Engineering\",\n    title = \"How does Machine Learning Change Software Development Practices?\",\n    year = \"2019\",\n    volume = \"\",\n    number = \"\",\n    pages = \"1-1\",\n    doi = \"10.1109/TSE.2019.2937083\"\n}\n\n",
    "abstract": "Adding an ability for a system to learn inherently adds\nuncertainty into the system. Given the rising popularity of incorporating\nmachine learning into systems, we wondered how the addition alters\nsoftware development practices. We performed a mixture of qualitative\nand quantitative studies with 14 interviewees and 342 survey\nrespondents from 26 countries across four continents to elicit significant\ndifferences between the development of machine learning systems and\nthe development of non-machine-learning systems. Our study uncovers\nsignificant differences in various aspects of software engineering (e.g.,\nrequirements, design, testing, and process) and work characteristics\n(e.g., skill variety, problem solving and task identity). Based on our\nfindings, we highlight future research directions and provide recommendations\nfor practitioners."
}, {
    "py/object": "data.DataClassPaper",
    "Title": "Machine Learning and Software Engineering",
    "year": 2003,
    "ML_Techniques": "",
    "Category": "General",
    "Sub_category": "",
    "Venue": "SQJ",
    "Link": "https://link.springer.com/article/10.1023/A:1023760326768",
    "bibtex": "INPROCEEDINGS{Abubakar2020_230,\n    author = \"{Abubakar}, H. and {Obaidat}, M. S. and {Gupta}, A. and {Bhattacharya}, P. and {Tanwar}, S.\",\n    booktitle = \"2020 International Conference on Communications, Computing, Cybersecurity, and Informatics (CCCI)\",\n    title = \"Interplay of Machine Learning and Software Engineering for Quality Estimations\",\n    year = \"2020\",\n    volume = \"\",\n    number = \"\",\n    pages = \"1-6\",\n    doi = \"10.1109/CCCI49893.2020.9256507\"\n}\n\n",
    "abstract": "Machine learning deals with the issue of how to build programs that improve their performance\nat some task through experience. Machine learning algorithms have proven to be of great practical value in\na variety of application domains. They are particularly useful for (a) poorly understood problem domains\nwhere little knowledge exists for the humans to develop effective algorithms; (b) domains where there are\nlarge databases containing valuable implicit regularities to be discovered; or (c) domains where programs\nmust adapt to changing conditions. Not surprisingly, the field of software engineering turns out to be a fertile\nground where many software development and maintenance tasks could be formulated as learning problems\nand approached in terms of learning algorithms. This paper deals with the subject of applying machine\nlearning in software engineering. In the paper, we first provide the characteristics and applicability of some\nfrequently utilized machine learning algorithms. We then summarize and analyze the existing work and discuss\nsome general issues in this niche area. Finally we offer some guidelines on applying machine learning\nmethods to software engineering tasks and use some software development and maintenance tasks as examples\nto show how they can be formulated as learning problems and approached in terms of learning algorithms."
}, {
    "py/object": "data.DataClassPaper",
    "Title": "A manually-curated dataset of fixes to vulnerabilities of open-source software",
    "year": 2019,
    "ML_Techniques": "",
    "Category": "Dataset mining",
    "Sub_category": "",
    "Venue": "MSR",
    "Link": "https://dl.acm.org/doi/10.1109/MSR.2019.00064",
    "bibtex": "INPROCEEDINGS{Abubakar2020_230,\n    author = \"{Abubakar}, H. and {Obaidat}, M. S. and {Gupta}, A. and {Bhattacharya}, P. and {Tanwar}, S.\",\n    booktitle = \"2020 International Conference on Communications, Computing, Cybersecurity, and Informatics (CCCI)\",\n    title = \"Interplay of Machine Learning and Software Engineering for Quality Estimations\",\n    year = \"2020\",\n    volume = \"\",\n    number = \"\",\n    pages = \"1-6\",\n    doi = \"10.1109/CCCI49893.2020.9256507\"\n}\n\n",
    "abstract": "Advancing our understanding of software vulnerabilities, automating their identification, the analysis of their impact, and\nultimately their mitigation is necessary to enable the development of software that is more secure.\nWhile operating a vulnerability assessment tool that we developed and that is currently used by hundreds of development units\nat SAP, we manually collected and curated a dataset of vulnerabilities of open-source software and the commits fixing them.\nThe data was obtained both from the National Vulnerability Database (NVD) and from project-specific Web resources that we\nmonitor on a continuous basis.\nFrom that data, we extracted a dataset that maps 624 publicly disclosed vulnerabilities affecting 205 distinct open-source Java\nprojects, used in SAP products or internal tools, onto the 1282 commits that fix them. Out of 624 vulnerabilities, 29 do not\nhave a CVE identifier at all and 46, which do have a CVE identifier assigned by a numbering authority, are not available in\nthe NVD yet.\nThe dataset is released under an open-source license, together with supporting scripts that allow researchers to automatically\nretrieve the actual content of the commits from the corresponding repositories and to augment the attributes available for each\ninstance. Also, these scripts allow to complement the dataset with additional instances that are not security fixes (which is\nuseful, for example, in machine learning applications).\nOur dataset has been successfully used to train classifiers that could automatically identify security-relevant commits in code\nrepositories. The release of this dataset and the supporting code as open-source will allow future research to be based on\ndata of industrial relevance; also, it represents a concrete step towards making the maintenance of this dataset a shared effort\ninvolving open-source communities, academia, and the industry."
}, {
    "py/object": "data.DataClassPaper",
    "Title": "Learning to mine aligned code and natural language pairs from stack overflow",
    "year": 2018,
    "ML_Techniques": "LOG",
    "Category": "Dataset mining",
    "Sub_category": "",
    "Venue": "MSR",
    "Link": "https://dl.acm.org/doi/10.1145/3196398.3196408",
    "bibtex": "INPROCEEDINGS{Abubakar2020_230,\n    author = \"{Abubakar}, H. and {Obaidat}, M. S. and {Gupta}, A. and {Bhattacharya}, P. and {Tanwar}, S.\",\n    booktitle = \"2020 International Conference on Communications, Computing, Cybersecurity, and Informatics (CCCI)\",\n    title = \"Interplay of Machine Learning and Software Engineering for Quality Estimations\",\n    year = \"2020\",\n    volume = \"\",\n    number = \"\",\n    pages = \"1-6\",\n    doi = \"10.1109/CCCI49893.2020.9256507\"\n}\n\n",
    "abstract": "For tasks like code synthesis from natural language, code retrieval,\nand code summarization, data-driven models have shown great\npromise. However, creating these models require parallel data between\nnatural language (NL) and code with fine-grained alignments.\nStack Overflow (SO) is a promising source to create such a data\nset: the questions are diverse and most of them have corresponding\nanswers with high quality code snippets. However, existing\nheuristic methods (e.g., pairing the title of a post with the code in\nthe accepted answer) are limited both in their coverage and the\ncorrectness of the NL-code pairs obtained. In this paper, we propose\na novel method to mine high-quality aligned data from SO\nusing two sets of features: hand-crafted features considering the\nstructure of the extracted snippets, and correspondence features\nobtained by training a probabilistic model to capture the correlation\nbetween NL and code using neural networks. These features are\nfed into a classifier that determines the quality of mined NL-code\npairs. Experiments using Python and Java as test beds show that\nthe proposed method greatly expands coverage and accuracy over\nexisting mining methods, even when using only a small number\nof labeled examples. Further, we find that reasonable results are\nachieved even when training the classifier on one language and\ntesting on another, showing promise for scaling NL-code mining to\na wide variety of programming languages beyond those for which\nwe are able to annotate data."
}, {
    "py/object": "data.DataClassPaper",
    "Title": "A Convolutional Attention Network for Extreme Summarization of Source Code",
    "year": 2016,
    "ML_Techniques": "GRU, CNN",
    "Category": "Code summarization",
    "Sub_category": "",
    "Venue": "ICML",
    "Link": "https://arxiv.org/abs/1602.03001",
    "bibtex": "misc{Allamanis2016_403,\n    author = \"Allamanis, Miltiadis and Peng, Hao and Sutton, Charles\",\n    title = \"A Convolutional Attention Network for Extreme Summarization of Source Code\",\n    year = \"2016\",\n    eprint = \"1602.03001\",\n    archivePrefix = \"arXiv\",\n    primaryClass = \"cs.LG\"\n}\n\n",
    "abstract": "Attention mechanisms in neural networks have\nproved useful for problems in which the input\nand output do not have fixed dimension. Often\nthere exist features that are locally translation invariant\nand would be valuable for directing the\nmodel\u2019s attention, but previous attentional architectures\nare not constructed to learn such features\nspecifically. We introduce an attentional neural\nnetwork that employs convolution on the input tokens\nto detect local time-invariant and long-range\ntopical attention features in a context-dependent\nway. We apply this architecture to the problem\nof extreme summarization of source code snippets\ninto short, descriptive function name-like\nsummaries. Using those features, the model sequentially\ngenerates a summary bymarginalizing\nover two attention mechanisms: one that predicts\nthe next summary token based on the attention\nweights of the input tokens and another that is\nable to copy a code token as-is directly into the\nsummary. We demonstrate our convolutional attention\nneural network\u2019s performance on 10 popular\nJava projects showing that it achieves better\nperformance compared to previous attentional\nmechanisms."
}, {
    "py/object": "data.DataClassPaper",
    "Title": "A Human Study of Comprehension and Code Summarization",
    "year": 2020,
    "ML_Techniques": "GRU",
    "Category": "Code summarization",
    "Sub_category": ",code comprehension ",
    "Venue": "ICPC",
    "Link": "https://dl.acm.org/doi/abs/10.1145/3387904.3389258",
    "bibtex": "inproceedings{Stapleton2020_404,\n    author = \"Stapleton, Sean and Gambhir, Yashmeet and LeClair, Alexander and Eberhart, Zachary and Weimer, Westley and Leach, Kevin and Huang, Yu\",\n    title = \"A Human Study of Comprehension and Code Summarization\",\n    year = \"2020\",\n    isbn = \"9781450379588\",\n    publisher = \"Association for Computing Machinery\",\n    address = \"New York, NY, USA\",\n    url = \"https://doi.org/10.1145/3387904.3389258\",\n    doi = \"10.1145/3387904.3389258\",\n    abstract = \"Software developers spend a great deal of time reading and understanding code that is poorly-documented, written by other developers, or developed using differing styles. During the past decade, researchers have investigated techniques for automatically documenting code to improve comprehensibility. In particular, recent advances in deep learning have led to sophisticated summary generation techniques that convert functions or methods to simple English strings that succinctly describe that code's behavior. However, automatic summarization techniques are assessed using internal metrics such as BLEU scores, which measure natural language properties in translational models, or ROUGE scores, which measure overlap with human-written text. Unfortunately, these metrics do not necessarily capture how machine-generated code summaries actually affect human comprehension or developer productivity.We conducted a human study involving both university students and professional developers (n = 45). Participants reviewed Java methods and summaries and answered established program comprehension questions. In addition, participants completed coding tasks given summaries as specifications. Critically, the experiment controlled the source of the summaries: for a given method, some participants were shown human-written text and some were shown machine-generated text.We found that participants performed significantly better (p = 0.029) using human-written summaries versus machine-generated summaries. However, we found no evidence to support that participants perceive human- and machine-generated summaries to have different qualities. In addition, participants' performance showed no correlation with the BLEU and ROUGE scores often used to assess the quality of machine-generated summaries. These results suggest a need for revised metrics to assess and guide automatic summarization techniques.\",\n    booktitle = \"Proceedings of the 28th International Conference on Program Comprehension\",\n    pages = \"2\u201313\",\n    numpages = \"12\",\n    location = \"Seoul, Republic of Korea\",\n    series = \"ICPC '20\"\n}\n\n",
    "abstract": "Software developers spend a great deal of time reading and understanding\ncode that is poorly-documented, written by other developers,\nor developed using differing styles. During the past decade,\nresearchers have investigated techniques for automatically documenting\ncode to improve comprehensibility. In particular, recent\nadvances in deep learning have led to sophisticated summary generation\ntechniques that convert functions or methods to simple English\nstrings that succinctly describe that code\u2019s behavior. However,\nautomatic summarization techniques are assessed using internal\nmetrics such as BLEU scores, which measure natural language properties\nin translational models, or ROUGE scores, which measure\noverlap with human-written text. Unfortunately, these metrics do\nnot necessarily capture how machine-generated code summaries\nactually affect human comprehension or developer productivity.\nWe conducted a human study involving both university students\nand professional developers (n = 45). Participants reviewed Java\nmethods and summaries and answered established program comprehension\nquestions. In addition, participants completed coding\ntasks given summaries as specifications. Critically, the experiment\ncontrolled the source of the summaries: for a given method, some\nparticipants were shown human-written text and some were shown\nmachine-generated text.\nWe found that participants performed significantly better (p =\n0.029) using human-written summaries versus machine-generated\nsummaries. However, we found no evidence to support that participants\nperceive human- and machine-generated summaries to have\ndifferent qualities. In addition, participants\u2019 performance showed\nno correlation with the BLEU and ROUGE scores often used to\nassess the quality of machine-generated summaries. These results\nsuggest a need for revised metrics to assess and guide automatic\nsummarization techniques."
}, {
    "py/object": "data.DataClassPaper",
    "Title": "A machine learning based automatic folding of dynamically typed languages",
    "year": 2019,
    "ML_Techniques": "GB, RF",
    "Category": "Code summarization",
    "Sub_category": "",
    "Venue": "MaLTeSQuE",
    "Link": "https://dl.acm.org/doi/10.1145/3340482.3342746",
    "bibtex": "inproceedings{Stapleton2020_404,\n    author = \"Stapleton, Sean and Gambhir, Yashmeet and LeClair, Alexander and Eberhart, Zachary and Weimer, Westley and Leach, Kevin and Huang, Yu\",\n    title = \"A Human Study of Comprehension and Code Summarization\",\n    year = \"2020\",\n    isbn = \"9781450379588\",\n    publisher = \"Association for Computing Machinery\",\n    address = \"New York, NY, USA\",\n    url = \"https://doi.org/10.1145/3387904.3389258\",\n    doi = \"10.1145/3387904.3389258\",\n    abstract = \"Software developers spend a great deal of time reading and understanding code that is poorly-documented, written by other developers, or developed using differing styles. During the past decade, researchers have investigated techniques for automatically documenting code to improve comprehensibility. In particular, recent advances in deep learning have led to sophisticated summary generation techniques that convert functions or methods to simple English strings that succinctly describe that code's behavior. However, automatic summarization techniques are assessed using internal metrics such as BLEU scores, which measure natural language properties in translational models, or ROUGE scores, which measure overlap with human-written text. Unfortunately, these metrics do not necessarily capture how machine-generated code summaries actually affect human comprehension or developer productivity.We conducted a human study involving both university students and professional developers (n = 45). Participants reviewed Java methods and summaries and answered established program comprehension questions. In addition, participants completed coding tasks given summaries as specifications. Critically, the experiment controlled the source of the summaries: for a given method, some participants were shown human-written text and some were shown machine-generated text.We found that participants performed significantly better (p = 0.029) using human-written summaries versus machine-generated summaries. However, we found no evidence to support that participants perceive human- and machine-generated summaries to have different qualities. In addition, participants' performance showed no correlation with the BLEU and ROUGE scores often used to assess the quality of machine-generated summaries. These results suggest a need for revised metrics to assess and guide automatic summarization techniques.\",\n    booktitle = \"Proceedings of the 28th International Conference on Program Comprehension\",\n    pages = \"2\u201313\",\n    numpages = \"12\",\n    location = \"Seoul, Republic of Korea\",\n    series = \"ICPC '20\"\n}\n\n",
    "abstract": "The popularity of dynamically typed languages has been growing\nstrongly lately. Elegant syntax of such languages like javascript,\npython, PHP and ruby pays back when it comes to finding bugs\nin large codebases. The analysis is hindered by specific capabilities\nof dynamically typed languages, such as defining methods\ndynamically and evaluating string expressions. For finding bugs\nor investigating unfamiliar classes and libraries in modern IDEs\nand text editors features for folding unimportant code blocks are\nimplemented. In this work, data on user foldings from real projects\nwere collected and two classifiers were trained on their basis. The\ninput to the classifier is a set of parameters describing the structure\nand syntax of the code block. These classifiers were subsequently\nused to identify unimportant code fragments. The implemented\napproach was tested on JavaScript and Python programs and compared\nwith the best existing algorithm for automatic code folding."
}, {
    "py/object": "data.DataClassPaper",
    "Title": "A Neural Framework for Retrieval and Summarization of Source Code",
    "year": 2018,
    "ML_Techniques": "GRU",
    "Category": "Code summarization",
    "Sub_category": "",
    "Venue": "ASE",
    "Link": "https://ieeexplore.ieee.org/abstract/document/9000013",
    "bibtex": "INPROCEEDINGS{Chen2018_406,\n    author = \"{Chen}, Q. and {Zhou}, M.\",\n    booktitle = \"2018 33rd IEEE/ACM International Conference on Automated Software Engineering (ASE)\",\n    title = \"A Neural Framework for Retrieval and Summarization of Source Code\",\n    year = \"2018\",\n    volume = \"\",\n    number = \"\",\n    pages = \"826-831\",\n    doi = \"10.1145/3238147.3240471\"\n}\n\n",
    "abstract": "Code retrieval and summarization are two tasks often employed by\nsoftware developers to reuse code that spreads over online repositories.\nIn this paper, we present a neural framework that allows\nbidirectional mapping between source code and natural language\nto improve these two tasks. Our framework, BVAE, is designed\nto have two Variational AutoEncoders (VAEs) to model bimodal\ndata: C-VAE for source code and L-VAE for natural language. Both\nVAEs are trained jointly to reconstruct their input as much as possible\nwith regularization that captures the closeness between the\nlatent variables of code and description. BVAE could learn semantic\nvector representations for both code and description and generate\ncompletely new descriptions for arbitrary code snippets.We design\ntwo instance models of BVAE for retrieval and summarization tasks\nrespectively and evaluate their performance on a benchmark which\ninvolves two programming languages: C# and SQL. Experiments\ndemonstrate BVAE\u2019s potential on the two tasks."
}, {
    "py/object": "data.DataClassPaper",
    "Title": "A neural model for generating natural language summaries of program subroutines",
    "year": 2019,
    "ML_Techniques": "GRU",
    "Category": "Code summarization",
    "Sub_category": "",
    "Venue": "ICSE",
    "Link": "https://dl.acm.org/doi/10.1109/ICSE.2019.00087",
    "bibtex": "INPROCEEDINGS{Chen2018_406,\n    author = \"{Chen}, Q. and {Zhou}, M.\",\n    booktitle = \"2018 33rd IEEE/ACM International Conference on Automated Software Engineering (ASE)\",\n    title = \"A Neural Framework for Retrieval and Summarization of Source Code\",\n    year = \"2018\",\n    volume = \"\",\n    number = \"\",\n    pages = \"826-831\",\n    doi = \"10.1145/3238147.3240471\"\n}\n\n",
    "abstract": "Source code summarization \u2013 creating natural language\ndescriptions of source code behavior \u2013 is a rapidly-growing\nresearch topic with applications to automatic documentation\ngeneration, program comprehension, and software maintenance.\nTraditional techniques relied on heuristics and templates built\nmanually by human experts. Recently, data-driven approaches\nbased on neural machine translation have largely overtaken\ntemplate-based systems. But nearly all of these techniques rely\nalmost entirely on programs having good internal documentation;\nwithout clear identifier names, the models fail to create good\nsummaries. In this paper, we present a neural model that\ncombines words from code with code structure from an AST.\nUnlike previous approaches, our model processes each data\nsource as a separate input, which allows the model to learn code\nstructure independent of the text in code. This process helps\nour approach provide coherent summaries in many cases even\nwhen zero internal documentation is provided. We evaluate our\ntechnique with a dataset we created from 2.1m Java methods. We\nfind improvement over two baseline techniques from SE literature\nand one from NLP literature."
}, {
    "py/object": "data.DataClassPaper",
    "Title": "A Neural-Network based Code Summarization Approach by Using Source Code and its Call Dependencies",
    "year": 2019,
    "ML_Techniques": "EN-DE",
    "Category": "Code summarization",
    "Sub_category": "",
    "Venue": "Internetware",
    "Link": "https://dl.acm.org/doi/abs/10.1145/3361242.3362774",
    "bibtex": "INPROCEEDINGS{Chen2018_406,\n    author = \"{Chen}, Q. and {Zhou}, M.\",\n    booktitle = \"2018 33rd IEEE/ACM International Conference on Automated Software Engineering (ASE)\",\n    title = \"A Neural Framework for Retrieval and Summarization of Source Code\",\n    year = \"2018\",\n    volume = \"\",\n    number = \"\",\n    pages = \"826-831\",\n    doi = \"10.1145/3238147.3240471\"\n}\n\n",
    "abstract": "Code summarization aims at generating natural language\nabstraction for source code, and it can be of great help\nfor program comprehension and software maintenance. The\ncurrent code summarization approaches have made progress\nwith neural-network. However, most of these methods focus\non learning the semantic and syntax of source code snippets,\nignoring the dependency of codes. In this paper, we propose\na novel method based on neural-network model using the\nknowledge of the call dependency between source code and its\nrelated codes. We extract call dependencies from the source\ncode, transform it as a token sequence of method names, and\nleverage the Seq2Seq model for code summarization using the\ncombination of source code and call dependency information.\nAbout 100,000 code data is collected from 1,000 open source\nJava proejects on github for experiment. The large-scale code\nexperiment shows that by considering not only the code itself\nbut also the codes it called, the code summarization model\ncan be improved with the BLEU score to 33.08."
}, {
    "py/object": "data.DataClassPaper",
    "Title": "A Transformer-based Approach for Source Code Summarization",
    "year": 2020,
    "ML_Techniques": "TF",
    "Category": "Code summarization",
    "Sub_category": "",
    "Venue": "ACL",
    "Link": "https://arxiv.org/abs/2005.00653",
    "bibtex": "inproceedings{Ahmad2020_410,\n    author = \"Ahmad, Wasi and Chakraborty, Saikat and Ray, Baishakhi and Chang, Kai-Wei\",\n    title = \"A Transformer-based Approach for Source Code Summarization\",\n    booktitle = \"Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics\",\n    month = \"July\",\n    year = \"2020\",\n    address = \"Online\",\n    publisher = \"Association for Computational Linguistics\",\n    url = \"https://www.aclweb.org/anthology/2020.acl-main.449\",\n    doi = \"10.18653/v1/2020.acl-main.449\",\n    pages = \"4998--5007\",\n    abstract = \"Generating a readable summary that describes the functionality of a program is known as source code summarization. In this task, learning code representation by modeling the pairwise relationship between code tokens to capture their long-range dependencies is crucial. To learn code representation for summarization, we explore the Transformer model that uses a self-attention mechanism and has shown to be effective in capturing long-range dependencies. In this work, we show that despite the approach is simple, it outperforms the state-of-the-art techniques by a significant margin. We perform extensive analysis and ablation studies that reveal several important findings, e.g., the absolute encoding of source code tokens{'} position hinders, while relative encoding significantly improves the summarization performance. We have made our code publicly available to facilitate future research.\"\n}\n\n",
    "abstract": "Generating a readable summary that describes\nthe functionality of a program is known as\nsource code summarization. In this task,\nlearning code representation by modeling the\npairwise relationship between code tokens to\ncapture their long-range dependencies is crucial.\nTo learn code representation for summarization,\nwe explore the Transformer model\nthat uses a self-attention mechanism and has\nshown to be effective in capturing long-range\ndependencies. In this work, we show that despite\nthe approach is simple, it outperforms\nthe state-of-the-art techniques by a significant\nmargin. We perform extensive analysis and\nablation studies that reveal several important\nfindings, e.g., the absolute encoding of source\ncode tokens\u2019 position hinders, while relative\nencoding significantly improves the summarization\nperformance. We have made our code\npublicly available1 to facilitate future research."
}, {
    "py/object": "data.DataClassPaper",
    "Title": "AUSUM: approach for unsupervised bug report summarization",
    "year": 2012,
    "ML_Techniques": "MMR, GRASSHOPER, DR",
    "Category": "Code summarization",
    "Sub_category": "",
    "Venue": "FSE",
    "Link": "https://dl.acm.org/doi/abs/10.1145/2393596.2393607",
    "bibtex": "inproceedings{Ahmad2020_410,\n    author = \"Ahmad, Wasi and Chakraborty, Saikat and Ray, Baishakhi and Chang, Kai-Wei\",\n    title = \"A Transformer-based Approach for Source Code Summarization\",\n    booktitle = \"Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics\",\n    month = \"July\",\n    year = \"2020\",\n    address = \"Online\",\n    publisher = \"Association for Computational Linguistics\",\n    url = \"https://www.aclweb.org/anthology/2020.acl-main.449\",\n    doi = \"10.18653/v1/2020.acl-main.449\",\n    pages = \"4998--5007\",\n    abstract = \"Generating a readable summary that describes the functionality of a program is known as source code summarization. In this task, learning code representation by modeling the pairwise relationship between code tokens to capture their long-range dependencies is crucial. To learn code representation for summarization, we explore the Transformer model that uses a self-attention mechanism and has shown to be effective in capturing long-range dependencies. In this work, we show that despite the approach is simple, it outperforms the state-of-the-art techniques by a significant margin. We perform extensive analysis and ablation studies that reveal several important findings, e.g., the absolute encoding of source code tokens{'} position hinders, while relative encoding significantly improves the summarization performance. We have made our code publicly available to facilitate future research.\"\n}\n\n",
    "abstract": "In most software projects, resolved bugs are archived for future\nreference. These bug reports contain valuable information on the\nreported problem, investigation and resolution. When bug triaging,\ndevelopers look for how similar problems were resolved in the\npast. Search over bug repository gives the developer a set of recommended\nbugs to look into. However, the developer still needs\nto manually peruse the contents of the recommended bugs which\nmight vary in size from a couple of lines to thousands. Automatic\nsummarization of bug reports is one way to reduce the amount of\ndata a developer might need to go through. Prior work has presented\nlearning based approaches for bug summarization. These\napproaches have the disadvantage of requiring large training set and\nbeing biased towards the data on which the model was learnt. In\nfact, maximum efficacy was reported when the model was trained\nand tested on bug reports from the same project. In this paper, we\npresent the results of applying four unsupervised summarization\ntechniques for bug summarization. Industrial bug reports typically\ncontain a large amount of noise\u2014email dump, chat transcripts,\ncore-dump\u2014useless sentences from the perspective of summarization.\nThese derail the unsupervised approaches, which are optimized\nto work on more well-formed documents. We present an\napproach for noise reduction, which helps to improve the precision\nof summarization over the base technique (4% to 24% across\nsubjects and base techniques). Importantly, by applying noise reduction,\ntwo of the unsupervised techniques became scalable for\nlarge sized bug reports."
}, {
    "py/object": "data.DataClassPaper",
    "Title": "Automatic Source Code Summarization with Extended Tree-LSTM",
    "year": 2019,
    "ML_Techniques": "LSTM",
    "Category": "Code summarization",
    "Sub_category": "",
    "Venue": "IJCNN",
    "Link": "https://ieeexplore.ieee.org/abstract/document/8851751",
    "bibtex": "INPROCEEDINGS{Shido2019_415,\n    author = \"{Shido}, Y. and {Kobayashi}, Y. and {Yamamoto}, A. and {Miyamoto}, A. and {Matsumura}, T.\",\n    booktitle = \"2019 International Joint Conference on Neural Networks (IJCNN)\",\n    title = \"Automatic Source Code Summarization with Extended Tree-LSTM\",\n    year = \"2019\",\n    volume = \"\",\n    number = \"\",\n    pages = \"1-8\",\n    doi = \"10.1109/IJCNN.2019.8851751\"\n}\n\n",
    "abstract": "Neural machine translation models are used to automatically generate a document from given source code\nsince this can be regarded as a machine translation task. Source code summarization is one of the components for\nautomatic document generation, which generates a summary in natural language from given source code. This\nsuggests that techniques used in neural machine translation, such as Long Short-Term Memory (LSTM), can be\nused for source code summarization. However, there is a considerable di erence between source code and natural\nlanguage: Source code is essentially structured, having loops and conditional branching, etc. Therefore, there is\nsome obstacle to apply known machine translation models to source code.\nAbstract syntax trees (ASTs) capture these structural properties and play an important role in recent machine\nlearning studies on source code. Tree-LSTM is proposed as a generalization of LSTMs for tree-structured data.\nHowever, there is a critical issue when applying it to ASTs: It cannot handle a tree that contains nodes having\nan arbitrary number of children and their order simultaneously, which ASTs generally have such nodes. To\naddress this issue, we propose an extension of Tree-LSTM, which we call Multi-way Tree-LSTM and apply it for\nsource code summarization. As a result of computational experiments, our proposal achieved better results when\ncompared with several state-of-the-art techniques."
}, {
    "py/object": "data.DataClassPaper",
    "Title": "Automatically generating commit messages from diffs using neural machine translation",
    "year": 2017,
    "ML_Techniques": "EN-DE, LSTM, GRU",
    "Category": "Code summarization",
    "Sub_category": "",
    "Venue": "ASE",
    "Link": "https://ieeexplore.ieee.org/document/8115626",
    "bibtex": "INPROCEEDINGS{Jiang2017_416,\n    author = \"{Jiang}, S. and {Armaly}, A. and {McMillan}, C.\",\n    booktitle = \"2017 32nd IEEE/ACM International Conference on Automated Software Engineering (ASE)\",\n    title = \"Automatically generating commit messages from diffs using neural machine translation\",\n    year = \"2017\",\n    volume = \"\",\n    number = \"\",\n    pages = \"135-146\",\n    doi = \"10.1109/ASE.2017.8115626\"\n}\n\n",
    "abstract": "Commit messages are a valuable resource in comprehension\nof software evolution, since they provide a record of\nchanges such as feature additions and bug repairs. Unfortunately,\nprogrammers often neglect to write good commit messages.\nDifferent techniques have been proposed to help programmers\nby automatically writing these messages. These techniques are\neffective at describing what changed, but are often verbose and\nlack context for understanding the rationale behind a change. In\ncontrast, humans write messages that are short and summarize\nthe high level rationale. In this paper, we adapt Neural Machine\nTranslation (NMT) to automatically \u201ctranslate\u201d diffs into commit\nmessages. We trained an NMT algorithm using a corpus of diffs\nand human-written commit messages from the top 1k Github\nprojects. We designed a filter to help ensure that we only trained\nthe algorithm on higher-quality commit messages. Our evaluation\nuncovered a pattern in which the messages we generate tend to\nbe either very high or very low quality. Therefore, we created a\nquality-assurance filter to detect cases in which we are unable to\nproduce good messages, and return a warning instead."
}, {
    "py/object": "data.DataClassPaper",
    "Title": "CoaCor: Code Annotation for Code Retrieval with Reinforcement Learning",
    "year": 2019,
    "ML_Techniques": "LSTM",
    "Category": "Code summarization",
    "Sub_category": "",
    "Venue": "WWW ",
    "Link": "https://dl.acm.org/doi/abs/10.1145/3308558.3313632",
    "bibtex": "inproceedings{Yao2019_418,\n    author = \"Yao, Ziyu and Peddamail, Jayavardhan Reddy and Sun, Huan\",\n    title = \"CoaCor: Code Annotation for Code Retrieval with Reinforcement Learning\",\n    year = \"2019\",\n    isbn = \"9781450366748\",\n    publisher = \"Association for Computing Machinery\",\n    address = \"New York, NY, USA\",\n    url = \"https://doi.org/10.1145/3308558.3313632\",\n    doi = \"10.1145/3308558.3313632\",\n    abstract = \"To accelerate software development, much research has been performed to help people understand and reuse the huge amount of available code resources. Two important tasks have been widely studied: code retrieval, which aims to retrieve code snippets relevant to a given natural language query from a code base, and code annotation, where the goal is to annotate a code snippet with a natural language description. Despite their advancement in recent years, the two tasks are mostly explored separately. In this work, we investigate a novel perspective of Code annotation for Code retrieval (hence called \u201cCoaCor\u201d), where a code annotation model is trained to generate a natural language annotation that can represent the semantic meaning of a given code snippet and can be leveraged by a code retrieval model to better distinguish relevant code snippets from others. To this end, we propose an effective framework based on reinforcement learning, which explicitly encourages the code annotation model to generate annotations that can be used for the retrieval task. Through extensive experiments, we show that code annotations generated by our framework are much more detailed and more useful for code retrieval, and they can further improve the performance of existing code retrieval models significantly.1\",\n    booktitle = \"The World Wide Web Conference\",\n    pages = \"2203\u20132214\",\n    numpages = \"12\",\n    keywords = \"Code Retrieval, Reinforcement Learning, Code Annotation\",\n    location = \"San Francisco, CA, USA\",\n    series = \"WWW '19\"\n}\n\n",
    "abstract": "To accelerate software development, much research has been performed\nto help people understand and reuse the huge amount of\navailable code resources. Two important tasks have been widely\nstudied: code retrieval, which aims to retrieve code snippets relevant\nto a given natural language query from a code base, and code\nannotation, where the goal is to annotate a code snippet with a\nnatural language description. Despite their advancement in recent\nyears, the two tasks are mostly explored separately. In this work, we\ninvestigate a novel perspective of Code annotation for Code retrieval\n(hence called \u201cCoaCor\u201d), where a code annotation model is trained\nto generate a natural language annotation that can represent the\nsemantic meaning of a given code snippet and can be leveraged by\na code retrieval model to better distinguish relevant code snippets\nfrom others. To this end, we propose an effective framework based\non reinforcement learning, which explicitly encourages the code\nannotation model to generate annotations that can be used for the\nretrieval task. Through extensive experiments, we show that code\nannotations generated by our framework are much more detailed\nand more useful for code retrieval, and they can further improve\nthe performance of existing code retrieval models significantly."
}, {
    "py/object": "data.DataClassPaper",
    "Title": "Code fragment summarization",
    "year": 2013,
    "ML_Techniques": "NB, SVM",
    "Category": "Code summarization",
    "Sub_category": "",
    "Venue": "FSE",
    "Link": "https://dl.acm.org/doi/abs/10.1145/2491411.2494587",
    "bibtex": "inproceedings{Yao2019_418,\n    author = \"Yao, Ziyu and Peddamail, Jayavardhan Reddy and Sun, Huan\",\n    title = \"CoaCor: Code Annotation for Code Retrieval with Reinforcement Learning\",\n    year = \"2019\",\n    isbn = \"9781450366748\",\n    publisher = \"Association for Computing Machinery\",\n    address = \"New York, NY, USA\",\n    url = \"https://doi.org/10.1145/3308558.3313632\",\n    doi = \"10.1145/3308558.3313632\",\n    abstract = \"To accelerate software development, much research has been performed to help people understand and reuse the huge amount of available code resources. Two important tasks have been widely studied: code retrieval, which aims to retrieve code snippets relevant to a given natural language query from a code base, and code annotation, where the goal is to annotate a code snippet with a natural language description. Despite their advancement in recent years, the two tasks are mostly explored separately. In this work, we investigate a novel perspective of Code annotation for Code retrieval (hence called \u201cCoaCor\u201d), where a code annotation model is trained to generate a natural language annotation that can represent the semantic meaning of a given code snippet and can be leveraged by a code retrieval model to better distinguish relevant code snippets from others. To this end, we propose an effective framework based on reinforcement learning, which explicitly encourages the code annotation model to generate annotations that can be used for the retrieval task. Through extensive experiments, we show that code annotations generated by our framework are much more detailed and more useful for code retrieval, and they can further improve the performance of existing code retrieval models significantly.1\",\n    booktitle = \"The World Wide Web Conference\",\n    pages = \"2203\u20132214\",\n    numpages = \"12\",\n    keywords = \"Code Retrieval, Reinforcement Learning, Code Annotation\",\n    location = \"San Francisco, CA, USA\",\n    series = \"WWW '19\"\n}\n\n",
    "abstract": "Current research in software engineering has mostly focused\non the retrieval accuracy aspect but little on the presentation\naspect of code examples, e.g., how code examples are\npresented in a result page. We investigate the feasibility\nof summarizing code examples for better presenting a code\nexample. Our algorithm based on machine learning could\napproximate summaries in an oracle manually generated by\nhumans with a precision of 0.71. This result is promising\nas summaries with this level of precision achieved the same\nlevel of agreement as human annotators with each other."
}, {
    "py/object": "data.DataClassPaper",
    "Title": "Code Summarization with Abstract Syntax Tree",
    "year": 2019,
    "ML_Techniques": "EN-DE, LSTM, GRU",
    "Category": "Code summarization",
    "Sub_category": "",
    "Venue": "NIPS",
    "Link": "https://link.springer.com/chapter/10.1007/978-3-030-36802-9_69",
    "bibtex": "InProceedings{Chen2019_420,\n    author = \"Chen, Qiuyuan and Hu, Han and Liu, Zhaoyi\",\n    editor = \"Gedeon, Tom and Wong, Kok Wai and Lee, Minho\",\n    title = \"Code Summarization with Abstract Syntax Tree\",\n    booktitle = \"Neural Information Processing\",\n    year = \"2019\",\n    publisher = \"Springer International Publishing\",\n    address = \"Cham\",\n    pages = \"652--660\",\n    abstract = \"Code summarization, which provides a high-level description of the function implemented by code, plays a vital role in software maintenance and code retrieval. Traditional approaches focus on retrieving similar code snippets to generate summaries, and recently researchers pay increasing attention to leverage deep learning approaches, especially the encoder-decoder framework. Approaches based on encoder-decoder suffer from two drawbacks: (a) Lack of summarization in functionality level; (b) Code snippets are always too long (more than ten words), regular encoders perform poorly. In this paper, we propose a novel code representation with the help of Abstract Syntax Trees, which could describe the functionality of code snippets and shortens the length of inputs. Based on our proposed code representation, we develop Generative Task, which aims to generate summary sentences of code snippets. Experiments on large-scale real-world industrial Java projects indicate that our approaches are effective and outperform the state-of-the-art approaches in code summarization.\",\n    isbn = \"978-3-030-36802-9\"\n}\n\n",
    "abstract": "Code summarization, which provides a high-level description\nof the function implemented by code, plays a vital role in software maintenance\nand code retrieval. Traditional approaches focus on retrieving\nsimilar code snippets to generate summaries, and recently researchers\npay increasing attention to leverage deep learning approaches, especially\nthe encoder-decoder framework. Approaches based on encoder-decoder\nsuffer from two drawbacks: (a) Lack of summarization in functionality\nlevel; (b) Code snippets are always too long (more than ten words), regular\nencoders perform poorly. In this paper, we propose a novel code representation\nwith the help of Abstract Syntax Trees, which could describe\nthe functionality of code snippets and shortens the length of inputs.\nBased on our proposed code representation, we develop Generative Task,\nwhich aims to generate summary sentences of code snippets. Experiments\non large-scale real-world industrial Java projects indicate that our\napproaches are effective and outperform the state-of-the-art approaches\nin code summarization."
}, {
    "py/object": "data.DataClassPaper",
    "Title": "Deep Code Comment Generation",
    "year": 2018,
    "ML_Techniques": "EN-DE, LSTM, GRU",
    "Category": "Code summarization",
    "Sub_category": "",
    "Venue": "ICPC",
    "Link": "https://ieeexplore.ieee.org/abstract/document/8973050",
    "bibtex": "INPROCEEDINGS{Hu2018_421,\n    author = \"{Hu}, X. and {Li}, G. and {Xia}, X. and {Lo}, D. and {Jin}, Z.\",\n    booktitle = \"2018 IEEE/ACM 26th International Conference on Program Comprehension (ICPC)\",\n    title = \"Deep Code Comment Generation\",\n    year = \"2018\",\n    volume = \"\",\n    number = \"\",\n    pages = \"200-20010\",\n    doi = \"\"\n}\n\n",
    "abstract": "During software maintenance, code comments help developers\ncomprehend programs and reduce additional time spent on reading\nand navigating source code. Unfortunately, these comments are\noften mismatched, missing or outdated in the software projects.\nDevelopers have to infer the functionality from the source code.\nThis paper proposes a new approach named DeepCom to automatically\ngenerate code comments for Java methods. The generated\ncomments aim to help developers understand the functionality\nof Java methods. DeepCom applies Natural Language Processing\n(NLP) techniques to learn from a large code corpus and generates\ncomments from learned features. We use a deep neural network\nthat analyzes structural information of Java methods for better\ncomments generation. We conduct experiments on a large-scale\nJava corpus built from 9,714 open source projects from GitHub. We\nevaluate the experimental results on a machine translation metric.\nExperimental results demonstrate that our method DeepCom\noutperforms the state-of-the-art by a substantial margin."
}, {
    "py/object": "data.DataClassPaper",
    "Title": "Deep code comment generation with hybrid lexical and syntactical information",
    "year": 2020,
    "ML_Techniques": "EN-DE, LSTM, GRU",
    "Category": "Code summarization",
    "Sub_category": "",
    "Venue": "EMSE",
    "Link": "https://link.springer.com/article/10.1007/s10664-019-09730-9",
    "bibtex": "INPROCEEDINGS{Hu2018_421,\n    author = \"{Hu}, X. and {Li}, G. and {Xia}, X. and {Lo}, D. and {Jin}, Z.\",\n    booktitle = \"2018 IEEE/ACM 26th International Conference on Program Comprehension (ICPC)\",\n    title = \"Deep Code Comment Generation\",\n    year = \"2018\",\n    volume = \"\",\n    number = \"\",\n    pages = \"200-20010\",\n    doi = \"\"\n}\n\n",
    "abstract": "During software maintenance, developers spend a lot of time understanding the source\ncode. Existing studies show that code comments help developers comprehend programs\nand reduce additional time spent on reading and navigating source code. Unfortunately,\nthese comments are often mismatched, missing or outdated in software projects. Developers\nhave to infer the functionality from the source code. This paper proposes a new approach\nnamed Hybrid-DeepCom to automatically generate code comments for the functional units\nof Java language, namely, Java methods. The generated comments aim to help developers\nunderstand the functionality of Java methods. Hybrid-DeepCom applies Natural Language\nProcessing (NLP) techniques to learn from a large code corpus and generates comments\nfrom learned features. It formulates the comment generation task as the machine translation\nproblem. Hybrid-DeepCom exploits a deep neural network that combines the lexical\nand structure information of Java methods for better comments generation. We conduct\nexperiments on a large-scale Java corpus built from 9,714 open source projects on GitHub.\nWe evaluate the experimental results on both machine translation metrics and information\nretrieval metrics. Experimental results demonstrate that our method Hybrid-DeepCom outperforms\nthe state-of-the-art by a substantial margin. In addition, we evaluate the influence\nof out-of-vocabulary tokens on comment generation. The results show that reducing the\nout-of-vocabulary tokens improves the accuracy effectively."
}, {
    "py/object": "data.DataClassPaper",
    "Title": "Fret: Functional Reinforced Transformer With BERT for Code Summarization",
    "year": 2020,
    "ML_Techniques": "LSTM, EN-DE",
    "Category": "Code summarization",
    "Sub_category": "",
    "Venue": "IEEE Access",
    "Link": "https://ieeexplore.ieee.org/abstract/document/9146834/keywords#keywords",
    "bibtex": "ARTICLE{Wang2020_424,\n    author = \"{Wang}, R. and {Zhang}, H. and {Lu}, G. and {Lyu}, L. and {Lyu}, C.\",\n    journal = \"IEEE Access\",\n    title = \"Fret: Functional Reinforced Transformer With BERT for Code Summarization\",\n    year = \"2020\",\n    volume = \"8\",\n    number = \"\",\n    pages = \"135591-135604\",\n    doi = \"10.1109/ACCESS.2020.3011744\"\n}\n\n",
    "abstract": "Code summarization has long been viewed as a challenge in software engineering because of\nthe difficulties of understanding source code and generating natural language. Some mainstream methods\ncombine abstract syntax trees with language models to capture the structural information of the source\ncode and generate relatively satisfactory comments. However, these methods are still deficient in code\nunderstanding and limited by the long dependency problem. In this paper, we propose a novel model\ncalled Fret, which stands for Functional REinforced Transformer with BERT. The model provides a\nnew way to generate code comments by learning code functionalities and deepening code understanding\nwhile alleviating the problem of long dependency. For this purpose, a novel reinforcer is proposed for\nlearning the functional contents of code so that more accurate summaries to describe the code functionalities\ncan be generated. In addition, a more efficient algorithm is newly designed to capture the source code\nstructure. The experimental results show that the effectiveness of our model is remarkable. Fret significantly\noutperforms all the state-of-the-art methods we examine. It pushes the BLEU-4 score to 24.32 for Java code\nsummarization (14.23% absolute improvement) and the ROUGE-L score to 40.12 for Python. An ablation\ntest is also conducted to further explore the impact of each component of our method."
}, {
    "py/object": "data.DataClassPaper",
    "Title": "Improved Code Summarization via a Graph Neural Network",
    "year": 2020,
    "ML_Techniques": "LSTM, GRU, EN-DE, GNN",
    "Category": "Code summarization",
    "Sub_category": "",
    "Venue": "ICPC",
    "Link": "https://arxiv.org/abs/2004.02843",
    "bibtex": "inproceedings{LeClair2020_426,\n    author = \"LeClair, Alexander and Haque, Sakib and Wu, Lingfei and McMillan, Collin\",\n    title = \"Improved Code Summarization via a Graph Neural Network\",\n    year = \"2020\",\n    isbn = \"9781450379588\",\n    publisher = \"Association for Computing Machinery\",\n    address = \"New York, NY, USA\",\n    url = \"https://doi.org/10.1145/3387904.3389268\",\n    doi = \"10.1145/3387904.3389268\",\n    abstract = \"Automatic source code summarization is the task of generating natural language descriptions for source code. Automatic code summarization is a rapidly expanding research area, especially as the community has taken greater advantage of advances in neural network and AI technologies. In general, source code summarization techniques use the source code as input and outputs a natural language description. Yet a strong consensus is developing that using structural information as input leads to improved performance. The first approaches to use structural information flattened the AST into a sequence. Recently, more complex approaches based on random AST paths or graph neural networks have improved on the models using flattened ASTs. However, the literature still does not describe the using a graph neural network together with source code sequence as separate inputs to a model. Therefore, in this paper, we present an approach that uses a graph-based neural architecture that better matches the default structure of the AST to generate these summaries. We evaluate our technique using a data set of 2.1 million Java method-comment pairs and show improvement over four baseline techniques, two from the software engineering literature, and two from machine learning literature.\",\n    booktitle = \"Proceedings of the 28th International Conference on Program Comprehension\",\n    pages = \"184\u2013195\",\n    numpages = \"12\",\n    keywords = \"artificial intelligence, neural networks, deep learning, Automatic documentation\",\n    location = \"Seoul, Republic of Korea\",\n    series = \"ICPC '20\"\n}\n\n",
    "abstract": "Automatic source code summarization is the task of generating\nnatural language descriptions for source code. Automatic code\nsummarization is a rapidly expanding research area, especially as\nthe community has taken greater advantage of advances in neural\nnetwork and AI technologies. In general, source code summarization\ntechniques use the source code as input and outputs a natural\nlanguage description. Yet a strong consensus is developing that using\nstructural information as input leads to improved performance.\n\u008ce \u0080rst approaches to use structural information \u0083a\u008aened the\nAST into a sequence. Recently, more complex approaches based\non random AST paths or graph neural networks have improved\non the models using \u0083a\u008aened ASTs. However, the literature still\ndoes not describe the using a graph neural network together with\nsource code sequence as separate inputs to a model. \u008cerefore, in\nthis paper, we present an approach that uses a graph-based neural\narchitecture that be\u008aer matches the default structure of the AST\nto generate these summaries. We evaluate our technique using a\ndata set of 2.1 million Java method-comment pairs and show improvement\nover four baseline techniques, two from the so\u0089ware\nengineering literature, and two from machine learning literature."
}, {
    "py/object": "data.DataClassPaper",
    "Title": "Improving automatic source code summarization via deep reinforcement learning",
    "year": 2018,
    "ML_Techniques": "LSTM,  GNN",
    "Category": "Code summarization",
    "Sub_category": "",
    "Venue": "ASE",
    "Link": "https://dl.acm.org/doi/abs/10.1145/3238147.3238206",
    "bibtex": "inproceedings{LeClair2020_426,\n    author = \"LeClair, Alexander and Haque, Sakib and Wu, Lingfei and McMillan, Collin\",\n    title = \"Improved Code Summarization via a Graph Neural Network\",\n    year = \"2020\",\n    isbn = \"9781450379588\",\n    publisher = \"Association for Computing Machinery\",\n    address = \"New York, NY, USA\",\n    url = \"https://doi.org/10.1145/3387904.3389268\",\n    doi = \"10.1145/3387904.3389268\",\n    abstract = \"Automatic source code summarization is the task of generating natural language descriptions for source code. Automatic code summarization is a rapidly expanding research area, especially as the community has taken greater advantage of advances in neural network and AI technologies. In general, source code summarization techniques use the source code as input and outputs a natural language description. Yet a strong consensus is developing that using structural information as input leads to improved performance. The first approaches to use structural information flattened the AST into a sequence. Recently, more complex approaches based on random AST paths or graph neural networks have improved on the models using flattened ASTs. However, the literature still does not describe the using a graph neural network together with source code sequence as separate inputs to a model. Therefore, in this paper, we present an approach that uses a graph-based neural architecture that better matches the default structure of the AST to generate these summaries. We evaluate our technique using a data set of 2.1 million Java method-comment pairs and show improvement over four baseline techniques, two from the software engineering literature, and two from machine learning literature.\",\n    booktitle = \"Proceedings of the 28th International Conference on Program Comprehension\",\n    pages = \"184\u2013195\",\n    numpages = \"12\",\n    keywords = \"artificial intelligence, neural networks, deep learning, Automatic documentation\",\n    location = \"Seoul, Republic of Korea\",\n    series = \"ICPC '20\"\n}\n\n",
    "abstract": "Code summarization provides a high level natural\nlanguage description of the function performed by code, as it\ncan benefit the software maintenance, code categorization and\nretrieval. To the best of our knowledge, most state-of-the-art\napproaches follow an encoder-decoder framework which encodes\nthe code into a hidden space and then decode it into natural\nlanguage space, suffering from two major drawbacks: a) Their\nencoders only consider the sequential content of code, ignoring\nthe tree structure which is also critical for the task of code\nsummarization; b) Their decoders are typically trained to predict\nthe next word by maximizing the likelihood of next groundtruth\nword with previous ground-truth word given. However, it\nis expected to generate the entire sequence from scratch at test\ntime. This discrepancy can cause an exposure bias issue, making\nthe learnt decoder suboptimal. In this paper, we incorporate an\nabstract syntax tree structure as well as sequential content of\ncode snippets into a deep reinforcement learning framework (i.e.,\nactor-critic network). The actor network provides the confidence\nof predicting the next word according to current state. On the\nother hand, the critic network evaluates the reward value of all\npossible extensions of the current state and can provide global\nguidance for explorations. We employ an advantage reward composed\nof BLEU metric to train both networks. Comprehensive\nexperiments on a real-world dataset show the effectiveness of\nour proposed model when compared with some state-of-the-art\nmethods."
}, {
    "py/object": "data.DataClassPaper",
    "Title": "Leveraging Code Generation to Improve Code Retrieval and Summarization via Dual Learning",
    "year": 2020,
    "ML_Techniques": "Bi-LSTM",
    "Category": "Code summarization",
    "Sub_category": "",
    "Venue": "WWW ",
    "Link": "https://dl.acm.org/doi/abs/10.1145/3366423.3380295",
    "bibtex": "inproceedings{Ye2020_428,\n    author = \"Ye, Wei and Xie, Rui and Zhang, Jinglei and Hu, Tianxiang and Wang, Xiaoyin and Zhang, Shikun\",\n    title = \"Leveraging Code Generation to Improve Code Retrieval and Summarization via Dual Learning\",\n    year = \"2020\",\n    isbn = \"9781450370233\",\n    publisher = \"Association for Computing Machinery\",\n    address = \"New York, NY, USA\",\n    url = \"https://doi.org/10.1145/3366423.3380295\",\n    doi = \"10.1145/3366423.3380295\",\n    abstract = \"Code summarization generates brief natural language description given a source code snippet, while code retrieval fetches relevant source code given a natural language query. Since both tasks aim to model the association between natural language and programming language, recent studies have combined these two tasks to improve their performance. However, researchers have yet been able to effectively leverage the intrinsic connection between the two tasks as they train these tasks in a separate or pipeline manner, which means their performance can not be well balanced. In this paper, we propose a novel end-to-end model for the two tasks by introducing an additional code generation task. More specifically, we explicitly exploit the probabilistic correlation between code summarization and code generation with dual learning, and utilize the two encoders for code summarization and code generation to train the code retrieval task via multi-task learning. We have carried out extensive experiments on an existing dataset of SQL and Python, and results show that our model can significantly improve the results of the code retrieval task over the-state-of-art models, as well as achieve competitive performance in terms of BLEU score for the code summarization task.\",\n    booktitle = \"Proceedings of The Web Conference 2020\",\n    pages = \"2309\u20132319\",\n    numpages = \"11\",\n    keywords = \"code retrieval, code summarization, code generation, dual learning\",\n    location = \"Taipei, Taiwan\",\n    series = \"WWW '20\"\n}\n\n",
    "abstract": "Code summarization generates brief natural language description\ngiven a source code snippet, while code retrieval fetches relevant\nsource code given a natural language query. Since both tasks aim\nto model the association between natural language and programming\nlanguage, recent studies have combined these two tasks to\nimprove their performance. However, researchers have yet been\nable to effectively leverage the intrinsic connection between the\ntwo tasks as they train these tasks in a separate or pipeline manner,\nwhich means their performance can not be well balanced. In this\npaper, we propose a novel end-to-end model for the two tasks by\nintroducing an additional code generation task. More specifically,\nwe explicitly exploit the probabilistic correlation between code\nsummarization and code generation with dual learning, and utilize\nthe two encoders for code summarization and code generation to\ntrain the code retrieval task via multi-task learning. We have carried\nout extensive experiments on an existing dataset of SQL and\nPython, and results show that our model can significantly improve\nthe results of the code retrieval task over the-state-of-art models,\nas well as achieve competitive performance in terms of BLEU score\nfor the code summarization task."
}, {
    "py/object": "data.DataClassPaper",
    "Title": "Neural-machine-translation-based commit message generation: how far are we?",
    "year": 2018,
    "ML_Techniques": "KNN",
    "Category": "Code summarization",
    "Sub_category": "",
    "Venue": "ASE",
    "Link": "https://dl.acm.org/doi/10.1145/3238147.3238190",
    "bibtex": "inproceedings{Ye2020_428,\n    author = \"Ye, Wei and Xie, Rui and Zhang, Jinglei and Hu, Tianxiang and Wang, Xiaoyin and Zhang, Shikun\",\n    title = \"Leveraging Code Generation to Improve Code Retrieval and Summarization via Dual Learning\",\n    year = \"2020\",\n    isbn = \"9781450370233\",\n    publisher = \"Association for Computing Machinery\",\n    address = \"New York, NY, USA\",\n    url = \"https://doi.org/10.1145/3366423.3380295\",\n    doi = \"10.1145/3366423.3380295\",\n    abstract = \"Code summarization generates brief natural language description given a source code snippet, while code retrieval fetches relevant source code given a natural language query. Since both tasks aim to model the association between natural language and programming language, recent studies have combined these two tasks to improve their performance. However, researchers have yet been able to effectively leverage the intrinsic connection between the two tasks as they train these tasks in a separate or pipeline manner, which means their performance can not be well balanced. In this paper, we propose a novel end-to-end model for the two tasks by introducing an additional code generation task. More specifically, we explicitly exploit the probabilistic correlation between code summarization and code generation with dual learning, and utilize the two encoders for code summarization and code generation to train the code retrieval task via multi-task learning. We have carried out extensive experiments on an existing dataset of SQL and Python, and results show that our model can significantly improve the results of the code retrieval task over the-state-of-art models, as well as achieve competitive performance in terms of BLEU score for the code summarization task.\",\n    booktitle = \"Proceedings of The Web Conference 2020\",\n    pages = \"2309\u20132319\",\n    numpages = \"11\",\n    keywords = \"code retrieval, code summarization, code generation, dual learning\",\n    location = \"Taipei, Taiwan\",\n    series = \"WWW '20\"\n}\n\n",
    "abstract": "Commit messages can be regarded as the documentation of software\nchanges. These messages describe the content and purposes\nof changes, hence are useful for program comprehension and software\nmaintenance. However, due to the lack of time and direct\nmotivation, commit messages sometimes are neglected by developers.\nTo address this problem, Jiang et al. proposed an approach (we\nrefer to it as NMT), which leverages a neural machine translation\nalgorithm to automatically generate short commit messages from\ncode. The reported performance of their approach is promising,\nhowever, they did not explore why their approach performs well.\nThus, in this paper, we first perform an in-depth analysis of their\nexperimental results. We find that (1) Most of the test diffs from\nwhich NMT can generate high-quality messages are similar to one\nor more training diffs at the token level. (2) About 16% of the\ncommit messages in Jiang et al.\u2019s dataset are noisy due to being\nautomatically generated or due to them describing repetitive trivial\nchanges. (3) The performance of NMT declines by a large amount\nafter removing such noisy commit messages. In addition, NMT is\ncomplicated and time-consuming. Inspired by our first finding, we\nproposed a simpler and faster approach, named NNGen (Nearest\nNeighbor Generator), to generate concise commit messages using\nthe nearest neighbor algorithm. Our experimental results show\nthat NNGen is over 2,600 times faster than NMT, and outperforms\nNMT in terms of BLEU (an accuracy measure that is widely used\nto evaluate machine translation systems) by 21%. Finally, we also\ndiscuss some observations for the road ahead for automated commit\nmessage generation to inspire other researchers."
}, {
    "py/object": "data.DataClassPaper",
    "Title": "Reinforcement-Learning-Guided Source Code Summarization via Hierarchical Attention",
    "year": 2020,
    "ML_Techniques": "HAN, EN-DE",
    "Category": "Code summarization",
    "Sub_category": "",
    "Venue": "TSE",
    "Link": "https://ieeexplore.ieee.org/abstract/document/9031440",
    "bibtex": "ARTICLE{Wang2020_434,\n    author = \"{Wang}, W. and {Zhang}, Y. and {Sui}, Y. and {Wan}, Y. and {Zhao}, Z. and {Wu}, J. and {Yu}, P. and {Xu}, G.\",\n    journal = \"IEEE Transactions on Software Engineering\",\n    title = \"Reinforcement-Learning-Guided Source Code Summarization via Hierarchical Attention\",\n    year = \"2020\",\n    volume = \"\",\n    number = \"\",\n    pages = \"1-1\",\n    doi = \"10.1109/TSE.2020.2979701\"\n}\n\n",
    "abstract": "Code summarization (aka comment generation) provides a high-level natural language description of the function performed by code, which can benefit the software maintenance, code categorization and retrieval. To the best of our knowledge, the state-of-the-art approaches follow an encoder-decoder framework which encodes source code into a hidden space and later decodes it into a natural language space. Such approaches suffer from the following drawbacks: (a) they are mainly input by representing code as a sequence of tokens while ignoring code hierarchy; (b) most of the encoders only input simple features (e.g., tokens) while ignoring the features that can help capture the correlations between comments and code; (c) the decoders are typically trained to predict subsequent words by maximizing the likelihood of subsequent ground truth words, while in real world, they are excepted to generate the entire word sequence from scratch. As a result, such drawbacks lead to inferior and inconsistent comment generation accuracy. To address the above limitations, this paper presents a new code summarization approach using hierarchical attention network by incorporating multiple code features, including type-augmented abstract syntax trees and program control flows. Such features, along with plain code sequences, are injected into a deep reinforcement learning (DRL) framework (e.g., actor-critic network) for comment generation. Our approach assigns weights (pays \u201cattention\u201d) to tokens and statements when constructing the code representation to reflect the hierarchical code structure under different contexts regarding code features (e.g., control flows and abstract syntax trees). Our reinforcement learning mechanism further strengthens the prediction results through the actor network and the critic network, where the actor network provides the confidence of predicting subsequent words based on the current state, and the critic network computes the reward values of all the possible extensions of the current state to provide global guidance for explorations. Eventually, we employ an advantage reward to train both networks and conduct a set of experiments on a real-world dataset. The experimental results demonstrate that our approach outperforms the baselines by around 22% to 45% in BLEU-1 and outperforms the state-of-the-art approaches by around 5% to 60% in terms of S-BLEU and C-BLEU."
}, {
    "py/object": "data.DataClassPaper",
    "Title": "Retrieval-based neural source code summarization",
    "year": 2020,
    "ML_Techniques": "LSTM, EN-DE",
    "Category": "Code summarization",
    "Sub_category": "",
    "Venue": "ICSE",
    "Link": "https://dl.acm.org/doi/10.1145/3377811.3380383",
    "bibtex": "ARTICLE{Wang2020_434,\n    author = \"{Wang}, W. and {Zhang}, Y. and {Sui}, Y. and {Wan}, Y. and {Zhao}, Z. and {Wu}, J. and {Yu}, P. and {Xu}, G.\",\n    journal = \"IEEE Transactions on Software Engineering\",\n    title = \"Reinforcement-Learning-Guided Source Code Summarization via Hierarchical Attention\",\n    year = \"2020\",\n    volume = \"\",\n    number = \"\",\n    pages = \"1-1\",\n    doi = \"10.1109/TSE.2020.2979701\"\n}\n\n",
    "abstract": "Source code summarization aims to automatically generate concise\nsummaries of source code in natural language texts, in order to help\ndevelopers better understand and maintain source code. Traditional\nwork generates a source code summary by utilizing information\nretrieval techniques, which select terms from original source code\nor adapt summaries of similar code snippets. Recent studies adopt\nNeural Machine Translation techniques and generate summaries\nfrom code snippets using encoder-decoder neural networks. The\nneural-based approaches prefer the high-frequency words in the\ncorpus and have trouble with the low-frequency ones. In this paper,\nwe propose a retrieval-based neural source code summarization\napproach where we enhance the neural model with the most similar\ncode snippets retrieved from the training set. Our approach\ncan take advantages of both neural and retrieval-based techniques.\nSpecifically, we first train an attentional encoder-decoder model\nbased on the code snippets and the summaries in the training set;\nSecond, given one input code snippet for testing, we retrieve its\ntwo most similar code snippets in the training set from the aspects\nof syntax and semantics, respectively; Third, we encode the input\nand two retrieved code snippets, and predict the summary by fusing\nthem during decoding. We conduct extensive experiments to\nevaluate our approach and the experimental results show that our\nproposed approach can improve the state-of-the-art methods."
}, {
    "py/object": "data.DataClassPaper",
    "Title": "Source code fragment summarization with small-scale crowdsourcing based features",
    "year": 2016,
    "ML_Techniques": "SVM, NB",
    "Category": "Code summarization",
    "Sub_category": "",
    "Venue": "FCS",
    "Link": "https://link.springer.com/article/10.1007/s11704-015-4409-2",
    "bibtex": "article{Nazar2015_437,\n    author = \"Nazar, N. and Jiang, He and Gao, Guojun and Zhang, Tao and Li, Xiaochen and Ren, Zhilei\",\n    title = \"Source code fragment summarization with small-scale crowdsourcing based features\",\n    journal = \"Frontiers of Computer Science\",\n    year = \"2015\",\n    volume = \"10\",\n    pages = \"504-517\"\n}\n\n",
    "abstract": "Recent studies have applied different approaches\nfor summarizing software artifacts, and yet very few efforts\nhave been made in summarizing the source code fragments\navailable on web. This paper investigates the feasibility of\ngenerating code fragment summaries by using supervised\nlearning algorithms.We hire a crowd of ten individuals from\nthe same work place to extract source code features on a corpus\nof 127 code fragments retrieved from Eclipse and Net-\nBeans Official frequently asked questions (FAQs). Human annotators\nsuggest summary lines. Our machine learning algorithms\nproduce better results with the precision of 82% and\nperformstatistically better than existing code fragment classifiers.\nEvaluation of algorithms on several statistical measures\nendorses our result. This result is promising when employing\nmechanisms such as data-driven crowd enlistment improve\nthe efficacy of existing code fragment classifiers."
}, {
    "py/object": "data.DataClassPaper",
    "Title": "Source Code Summarization Using Attention-Based Keyword Memory Networks",
    "year": 2020,
    "ML_Techniques": "LSTM, CNN",
    "Category": "Code summarization",
    "Sub_category": "",
    "Venue": "BigComp",
    "Link": "https://ieeexplore.ieee.org/abstract/document/9070483",
    "bibtex": "INPROCEEDINGS{Choi2020_438,\n    author = \"{Choi}, Y. and {Kim}, S. and {Lee}, J.\",\n    booktitle = \"2020 IEEE International Conference on Big Data and Smart Computing (BigComp)\",\n    title = \"Source Code Summarization Using Attention-Based Keyword Memory Networks\",\n    year = \"2020\",\n    volume = \"\",\n    number = \"\",\n    pages = \"564-570\",\n    doi = \"10.1109/BigComp48618.2020.00011\"\n}\n\n",
    "abstract": "Recently, deep learning techniques have been developed\nfor source code summarization. Most existing studies have simply\nadopted natural language processing techniques, because source\ncode summarization can be considered as machine translation\ntasks from source code into descriptions. However, source code\nand its description are very different, not only in the languages of\nwriting, but also in the purpose of writing. There is a large\nsemantic gap between source codes in programming languages\nand their descriptions in natural languages. To respond to the\nsemantic gap, we propose a two-phase model that consists of a\nkeyword predictor and a description generator. The keyword\npredictor captures the natural language keywords semantically\nassociated with the source code, and the generator generates a\ndescription by referring to the natural language keywords\nprovided by the predictor. Using such keywords as scaffolding, we\ncan effectively reduce the semantic gap and generate more\naccurate descriptions of source codes. To evaluate the proposed\nmethod, we use datasets collected from GitHub and\nStackOverflow. We perform various experiments with these\ndatasets. Our methods show outstanding performance compared\nwith baselines that include state-of-the-art methods, which\nconcludes that keyword prediction is very helpful to the\ngeneration of accurate descriptions."
}, {
    "py/object": "data.DataClassPaper",
    "Title": "Summarizing Software Artifacts: A Literature Review",
    "year": 2016,
    "ML_Techniques": "",
    "Category": "Code summarization",
    "Sub_category": "",
    "Venue": "JCST",
    "Link": "https://link.springer.com/article/10.1007/s11390-016-1671-1",
    "bibtex": "article{Nazar2016_439,\n    author = \"Nazar, N. and Hu, Y. and Jiang, He\",\n    title = \"Summarizing Software Artifacts: A Literature Review\",\n    journal = \"Journal of Computer Science and Technology\",\n    year = \"2016\",\n    volume = \"31\",\n    pages = \"883-909\"\n}\n\n",
    "abstract": "This paper presents a literature review in the field of summarizing software artifacts, focusing on bug reports,\nsource code, mailing lists and developer discussions artifacts. From Jan. 2010 to Apr. 2016, numerous summarization\ntechniques, approaches, and tools have been proposed to satisfy the ongoing demand of improving software performance\nand quality and facilitating developers in understanding the problems at hand. Since aforementioned artifacts contain both\nstructured and unstructured data at the same time, researchers have applied different machine learning and data mining\ntechniques to generate summaries. Therefore, this paper first intends to provide a general perspective on the state of the art,\ndescribing the type of artifacts, approaches for summarization, as well as the common portions of experimental procedures\nshared among these artifacts. Moreover, we discuss the applications of summarization, i.e., what tasks at hand have been\nachieved through summarization. Next, this paper presents tools that are generated for summarization tasks or employed\nduring summarization tasks. In addition, we present different summarization evaluation methods employed in selected\nstudies as well as other important factors that are used for the evaluation of generated summaries such as adequacy and\nquality. Moreover, we briefly present modern communication channels and complementarities with commonalities among\ndifferent software artifacts. Finally, some thoughts about the challenges applicable to the existing studies in general as well\nas future research directions are also discussed. The survey of existing studies will allow future researchers to have a wide\nand useful background knowledge on the main and important aspects of this research field."
}, {
    "py/object": "data.DataClassPaper",
    "Title": "Summarizing Source Code using a Neural Attention Model",
    "year": 2016,
    "ML_Techniques": "LSTM",
    "Category": "Code summarization",
    "Sub_category": "",
    "Venue": "ACL",
    "Link": "https://www.aclweb.org/anthology/P16-1195/",
    "bibtex": "inproceedings{Iyer2016_440,\n    author = \"Iyer, Srinivasan and Konstas, Ioannis and Cheung, Alvin and Zettlemoyer, Luke\",\n    title = \"Summarizing Source Code using a Neural Attention Model\",\n    booktitle = \"Proceedings of the 54th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)\",\n    month = \"August\",\n    year = \"2016\",\n    address = \"Berlin, Germany\",\n    publisher = \"Association for Computational Linguistics\",\n    url = \"https://www.aclweb.org/anthology/P16-1195\",\n    doi = \"10.18653/v1/P16-1195\",\n    pages = \"2073--2083\"\n}\n\n",
    "abstract": "High quality source code is often paired\nwith high level summaries of the computation\nit performs, for example in code\ndocumentation or in descriptions posted\nin online forums. Such summaries are\nextremely useful for applications such as\ncode search but are expensive to manually\nauthor, hence only done for a small fraction\nof all code that is produced. In this\npaper, we present the first completely datadriven\napproach for generating high level\nsummaries of source code. Our model,\nCODE-NN , uses Long Short Term Memory\n(LSTM) networks with attention to\nproduce sentences that describe C# code\nsnippets and SQL queries. CODE-NN\nis trained on a new corpus that is automatically\ncollected from StackOverflow,\nwhich we release. Experiments demonstrate\nstrong performance on two tasks:\n(1) code summarization, where we establish\nthe first end-to-end learning results\nand outperform strong baselines, and (2)\ncode retrieval, where our learned model\nimproves the state of the art on a recently\nintroduced C# benchmark by a large margin."
}, {
    "py/object": "data.DataClassPaper",
    "Title": "Generating Question Titles for Stack Overflow from Mined Code Snippets",
    "year": 2020,
    "ML_Techniques": "Bi-LSTM, EN-DE",
    "Category": "Code summarization",
    "Sub_category": "",
    "Venue": "TOSEM",
    "Link": "https://dl.acm.org/doi/10.1145/3401026",
    "bibtex": "article{Gao2020_441,\n    author = \"Gao, Zhipeng and Xia, Xin and Grundy, John and Lo, David and Li, Yuan-Fang\",\n    title = \"Generating Question Titles for Stack Overflow from Mined Code Snippets\",\n    year = \"2020\",\n    issue_date = \"October 2020\",\n    publisher = \"Association for Computing Machinery\",\n    address = \"New York, NY, USA\",\n    volume = \"29\",\n    number = \"4\",\n    issn = \"1049-331X\",\n    url = \"https://doi.org/10.1145/3401026\",\n    doi = \"10.1145/3401026\",\n    abstract = \"Stack Overflow has been heavily used by software developers as a popular way to seek programming-related information from peers via the internet. The Stack Overflow community recommends users to provide the related code snippet when they are creating a question to help others better understand it and offer their help. Previous studies have shown that a significant number of these questions are of low-quality and not attractive to other potential experts in Stack Overflow. These poorly asked questions are less likely to receive useful answers and hinder the overall knowledge generation and sharing process. Considering one of the reasons for introducing low-quality questions in SO is that many developers may not be able to clarify and summarize the key problems behind their presented code snippets due to their lack of knowledge and terminology related to the problem, and/or their poor writing skills, in this study we propose an approach to assist developers in writing high-quality questions by automatically generating question titles for a code snippet using a deep sequence-to-sequence learning approach. Our approach is fully data-driven and uses an attention mechanism to perform better content selection, a copy mechanism to handle the rare-words problem and a coverage mechanism to eliminate word repetition problem. We evaluate our approach on Stack Overflow datasets over a variety of programming languages (e.g., Python, Java, Javascript, C\\# and SQL) and our experimental results show that our approach significantly outperforms several state-of-the-art baselines in both automatic and human evaluation. We have released our code and datasets to facilitate other researchers to verify their ideas and inspire the follow up work.\",\n    journal = \"ACM Trans. Softw. Eng. Methodol.\",\n    month = \"September\",\n    articleno = \"26\",\n    numpages = \"37\",\n    keywords = \"question quality, question generation, sequence-to-sequence, Stack overflow\"\n}\n\n",
    "abstract": "Stack Overflow has been heavily used by software developers as a popular way to seek programming-related\ninformation from peers via the internet. The Stack Overflow community recommends users to provide the\nrelated code snippet when they are creating a question to help others better understand it and offer their help.\nPrevious studies have shown that a significant number of these questions are of low-quality and not attractive\nto other potential experts in Stack Overflow. These poorly asked questions are less likely to receive useful\nanswers and hinder the overall knowledge generation and sharing process. Considering one of the reasons for\nintroducing low-quality questions in SO is that many developers may not be able to clarify and summarize the\nkey problems behind their presented code snippets due to their lack of knowledge and terminology related to\nthe problem, and/or their poor writing skills, in this study we propose an approach to assist developers in\nwriting high-quality questions by automatically generating question titles for a code snippet using a deep\nsequence-to-sequence learning approach. Our approach is fully data-driven and uses an attention mechanism\nto perform better content selection, a copy mechanism to handle the rare-words problem and a coverage\nmechanism to eliminate word repetition problem. We evaluate our approach on Stack Overflow datasets over\na variety of programming languages (e.g., Python, Java, Javascript, C# and SQL) and our experimental results\nshow that our approach significantly outperforms several state-of-the-art baselines in both automatic and\nhuman evaluation. We have released our code and datasets to facilitate other researchers to verify their ideas\nand inspire the follow up work."
}, {
    "py/object": "data.DataClassPaper",
    "Title": "Improving Code Search with Co-Attentive Representation Learning",
    "year": 2020,
    "ML_Techniques": "CNN",
    "Category": "Code Search",
    "Sub_category": "",
    "Venue": "ICPC",
    "Link": "https://dl.acm.org/doi/10.1145/3387904.3389269",
    "bibtex": "inproceedings{Shuai2020_442,\n    author = \"Shuai, Jianhang and Xu, Ling and Liu, Chao and Yan, Meng and Xia, Xin and Lei, Yan\",\n    title = \"Improving Code Search with Co-Attentive Representation Learning\",\n    year = \"2020\",\n    isbn = \"9781450379588\",\n    publisher = \"Association for Computing Machinery\",\n    address = \"New York, NY, USA\",\n    url = \"https://doi.org/10.1145/3387904.3389269\",\n    doi = \"10.1145/3387904.3389269\",\n    abstract = \"Searching and reusing existing code from a large-scale codebase, e.g, GitHub, can help developers complete a programming task efficiently. Recently, Gu et al. proposed a deep learning-based model (i.e., DeepCS), which significantly outperformed prior models. The DeepCS embedded codebase and natural language queries into vectors by two LSTM (long and short-term memory) models separately, and returned developers the code with higher similarity to a code search query. However, such embedding method learned two isolated representations for code and query but ignored their internal semantic correlations. As a result, the learned isolated representations of code and query may limit the effectiveness of code search.To address the aforementioned issue, we propose a co-attentive representation learning model, i.e., Co-Attentive Representation Learning Code Search-CNN (CARLCS-CNN). CARLCS-CNN learns interdependent representations for the embedded code and query with a co-attention mechanism. Generally, such mechanism learns a correlation matrix between embedded code and query, and co-attends their semantic relationship via row/column-wise max-pooling. In this way, the semantic correlation between code and query can directly affect their individual representations. We evaluate the effectiveness of CARLCS-CNN on Gu et al.'s dataset with 10k queries. Experimental results show that the proposed CARLCS-CNN model significantly outperforms DeepCS by 26.72\\% in terms of MRR (mean reciprocal rank). Additionally, CARLCS-CNN is five times faster than DeepCS in model training and four times in testing.\",\n    booktitle = \"Proceedings of the 28th International Conference on Program Comprehension\",\n    pages = \"196\u2013207\",\n    numpages = \"12\",\n    keywords = \"co-attention mechanism, representation learning, code search\",\n    location = \"Seoul, Republic of Korea\",\n    series = \"ICPC '20\"\n}\n\n",
    "abstract": "Searching and reusing existing code from a large-scale codebase,\ne.g, GitHub, can help developers complete a programming task efficiently.\nRecently, Gu et al. proposed a deep learning-based model\n(i.e., DeepCS), which significantly outperformed prior models. The\nDeepCS embedded codebase and natural language queries into\nvectors by two LSTM (long and short-term memory) models separately,\nand returned developers the code with higher similarity\nto a code search query. However, such embedding method learned\ntwo isolated representations for code and query but ignored their\ninternal semantic correlations. As a result, the learned isolated representations\nof code and query may limit the effectiveness of code\nsearch.\nTo address the aforementioned issue, we propose a co-attentive\nrepresentation learning model, i.e., Co-Attentive Representation\nLearning Code Search-CNN (CARLCS-CNN). CARLCS-CNN learns\ninterdependent representations for the embedded code and query\nwith a co-attention mechanism. Generally, such mechanism learns\na correlation matrix between embedded code and query, and coattends\ntheir semantic relationship via row/column-wise max-pooling.\nIn this way, the semantic correlation between code and query can\ndirectly affect their individual representations. We evaluate the effectiveness\nof CARLCS-CNN on Gu et al.\u2019s dataset with 10k queries.\nExperimental results show that the proposed CARLCS-CNN model\nsignificantly outperforms DeepCS by 26.72% in terms of MRR (mean\nreciprocal rank). Additionally, CARLCS-CNN is five times faster\nthan DeepCS in model training and four times in testing."
}, {
    "py/object": "data.DataClassPaper",
    "Title": "Multi-modal attention network learning for semantic source code retrieval",
    "year": 2019,
    "ML_Techniques": "LSTM, GGNN",
    "Category": "Code Search",
    "Sub_category": "",
    "Venue": "ASE",
    "Link": "https://dl.acm.org/doi/10.1109/ASE.2019.00012",
    "bibtex": "inproceedings{Shuai2020_442,\n    author = \"Shuai, Jianhang and Xu, Ling and Liu, Chao and Yan, Meng and Xia, Xin and Lei, Yan\",\n    title = \"Improving Code Search with Co-Attentive Representation Learning\",\n    year = \"2020\",\n    isbn = \"9781450379588\",\n    publisher = \"Association for Computing Machinery\",\n    address = \"New York, NY, USA\",\n    url = \"https://doi.org/10.1145/3387904.3389269\",\n    doi = \"10.1145/3387904.3389269\",\n    abstract = \"Searching and reusing existing code from a large-scale codebase, e.g, GitHub, can help developers complete a programming task efficiently. Recently, Gu et al. proposed a deep learning-based model (i.e., DeepCS), which significantly outperformed prior models. The DeepCS embedded codebase and natural language queries into vectors by two LSTM (long and short-term memory) models separately, and returned developers the code with higher similarity to a code search query. However, such embedding method learned two isolated representations for code and query but ignored their internal semantic correlations. As a result, the learned isolated representations of code and query may limit the effectiveness of code search.To address the aforementioned issue, we propose a co-attentive representation learning model, i.e., Co-Attentive Representation Learning Code Search-CNN (CARLCS-CNN). CARLCS-CNN learns interdependent representations for the embedded code and query with a co-attention mechanism. Generally, such mechanism learns a correlation matrix between embedded code and query, and co-attends their semantic relationship via row/column-wise max-pooling. In this way, the semantic correlation between code and query can directly affect their individual representations. We evaluate the effectiveness of CARLCS-CNN on Gu et al.'s dataset with 10k queries. Experimental results show that the proposed CARLCS-CNN model significantly outperforms DeepCS by 26.72\\% in terms of MRR (mean reciprocal rank). Additionally, CARLCS-CNN is five times faster than DeepCS in model training and four times in testing.\",\n    booktitle = \"Proceedings of the 28th International Conference on Program Comprehension\",\n    pages = \"196\u2013207\",\n    numpages = \"12\",\n    keywords = \"co-attention mechanism, representation learning, code search\",\n    location = \"Seoul, Republic of Korea\",\n    series = \"ICPC '20\"\n}\n\n",
    "abstract": "Code retrieval techniques and tools have been playing\na key role in facilitating software developers to retrieve\nexisting code fragments from available open-source repositories\ngiven a user query (e.g., a short natural language text describing\nthe functionality for retrieving a particular code snippet). Despite\nthe existing efforts in improving the effectiveness of code retrieval,\nthere are still two main issues hindering them from being used\nto accurately retrieve satisfiable code fragments from largescale\nrepositories when answering complicated queries. First, the\nexisting approaches only consider shallow features of source code\nsuch as method names and code tokens, but ignoring structured\nfeatures such as abstract syntax trees (ASTs) and control-flow\ngraphs (CFGs) of source code, which contains rich and welldefined\nsemantics of source code. Second, although the deep\nlearning-based approach performs well on the representation of\nsource code, it lacks the explainability, making it hard to interpret\nthe retrieval results and almost impossible to understand which\nfeatures of source code contribute more to the final results.\nTo tackle the two aforementioned issues, this paper proposes\nMMAN, a novel Multi-Modal Attention Network for semantic\nsource code retrieval. A comprehensive multi-modal representation\nis developed for representing unstructured and structured\nfeatures of source code, with one LSTM for the sequential tokens\nof code, a Tree-LSTM for the AST of code and a GGNN (Gated\nGraph Neural Network) for the CFG of code. Furthermore, a\nmulti-modal attention fusion layer is applied to assign weights to\ndifferent parts of each modality of source code and then integrate\nthem into a single hybrid representation. Comprehensive experiments\nand analysis on a large-scale real-world dataset show that\nour proposed model can accurately retrieve code snippets and\noutperforms the state-of-the-art methods."
}, {
    "py/object": "data.DataClassPaper",
    "Title": "Retrieval on source code: a neural code search",
    "year": 2018,
    "ML_Techniques": "DNN",
    "Category": "Code Search",
    "Sub_category": "",
    "Venue": "MAPL",
    "Link": "https://dl.acm.org/doi/10.1145/3211346.3211353",
    "bibtex": "inproceedings{Shuai2020_442,\n    author = \"Shuai, Jianhang and Xu, Ling and Liu, Chao and Yan, Meng and Xia, Xin and Lei, Yan\",\n    title = \"Improving Code Search with Co-Attentive Representation Learning\",\n    year = \"2020\",\n    isbn = \"9781450379588\",\n    publisher = \"Association for Computing Machinery\",\n    address = \"New York, NY, USA\",\n    url = \"https://doi.org/10.1145/3387904.3389269\",\n    doi = \"10.1145/3387904.3389269\",\n    abstract = \"Searching and reusing existing code from a large-scale codebase, e.g, GitHub, can help developers complete a programming task efficiently. Recently, Gu et al. proposed a deep learning-based model (i.e., DeepCS), which significantly outperformed prior models. The DeepCS embedded codebase and natural language queries into vectors by two LSTM (long and short-term memory) models separately, and returned developers the code with higher similarity to a code search query. However, such embedding method learned two isolated representations for code and query but ignored their internal semantic correlations. As a result, the learned isolated representations of code and query may limit the effectiveness of code search.To address the aforementioned issue, we propose a co-attentive representation learning model, i.e., Co-Attentive Representation Learning Code Search-CNN (CARLCS-CNN). CARLCS-CNN learns interdependent representations for the embedded code and query with a co-attention mechanism. Generally, such mechanism learns a correlation matrix between embedded code and query, and co-attends their semantic relationship via row/column-wise max-pooling. In this way, the semantic correlation between code and query can directly affect their individual representations. We evaluate the effectiveness of CARLCS-CNN on Gu et al.'s dataset with 10k queries. Experimental results show that the proposed CARLCS-CNN model significantly outperforms DeepCS by 26.72\\% in terms of MRR (mean reciprocal rank). Additionally, CARLCS-CNN is five times faster than DeepCS in model training and four times in testing.\",\n    booktitle = \"Proceedings of the 28th International Conference on Program Comprehension\",\n    pages = \"196\u2013207\",\n    numpages = \"12\",\n    keywords = \"co-attention mechanism, representation learning, code search\",\n    location = \"Seoul, Republic of Korea\",\n    series = \"ICPC '20\"\n}\n\n",
    "abstract": "Searching over large code corpora can be a powerful productivity\ntool for both beginner and experienced developers\nbecause it helps them quickly find examples of code related\nto their intent. Code search becomes even more attractive\nif developers could express their intent in natural language,\nsimilar to the interaction that Stack Overflow supports.\nIn this paper, we investigate the use of natural language\nprocessing and information retrieval techniques to carry\nout natural language search directly over source code, i.e.\nwithout having a curated Q&A forum such as Stack Overflow\nat hand.\nOur experiments using a benchmark suite derived from\nStack Overflow and GitHub repositories show promising\nresults. We find that while a basic word\u2013embedding based\nsearch procedure works acceptably, better results can be\nobtained by adding a layer of supervision, as well as by a\ncustomized ranking strategy."
}, {
    "py/object": "data.DataClassPaper",
    "Title": "A Survey on Source Code Review Using Machine Learning",
    "year": 2018,
    "ML_Techniques": "CNN",
    "Category": "Code review",
    "Sub_category": "",
    "Venue": "ICISE",
    "Link": "https://ieeexplore.ieee.org/abstract/document/8614720",
    "bibtex": "INPROCEEDINGS{Xiaomeng2018_445,\n    author = \"{Xiaomeng}, W. and {Tao}, Z. and {Wei}, X. and {Changyu}, H.\",\n    booktitle = \"2018 3rd International Conference on Information Systems Engineering (ICISE)\",\n    title = \"A Survey on Source Code Review Using Machine Learning\",\n    year = \"2018\",\n    volume = \"\",\n    number = \"\",\n    pages = \"56-60\",\n    doi = \"10.1109/ICISE.2018.00018\"\n}\n\n",
    "abstract": "Source code review constrains software system security\nsufficiently. Scalability and precision are of importance for\nthe deployment of code review tools. However, traditional tools\ncan only detect some security flaws automatically with high\nfalse positive and false negative by tedious reviewing largescale\nsource code. Various flaws and vulnerabilities show specific\ncharacteristic in source code. Machine learning systems\nfounded feature matrixes of source code as input, including\nvariables, functions and files, generating ad-hoc label by distinguish\nor generation methodologies to review source code\nautomatically and intelligently. Source code, whatever the programming\nlanguage, is text information in nature. Both secure\nand vulnerable feature can be curved from source code. Fortunately,\na variety of machine learning approaches have been\ndeveloped to learn and detect flaws and vulnerabilities in intelligent\nsource code security review. Combination of code semantic\nand syntactic feature contribute to the optimation of\nfalse positive and false negative during source code review. In\nthis paper, we give the review of literature related to intelligent\nsource code security review using machine learning methods. It\nillustrate the primary evidence of approaching ML in source\ncode security review. We believe machine learning and its\nbranches will become out-standing in source code review."
}, {
    "py/object": "data.DataClassPaper",
    "Title": "Code review analysis of software system using machine learning techniques",
    "year": 2017,
    "ML_Techniques": "",
    "Category": "Code review",
    "Sub_category": "",
    "Venue": "ISCO",
    "Link": "https://ieeexplore.ieee.org/abstract/document/7855962",
    "bibtex": "INPROCEEDINGS{Lal2017_446,\n    author = \"{Lal}, H. and {Pahwa}, G.\",\n    booktitle = \"2017 11th International Conference on Intelligent Systems and Control (ISCO)\",\n    title = \"Code review analysis of software system using machine learning techniques\",\n    year = \"2017\",\n    volume = \"\",\n    number = \"\",\n    pages = \"8-13\",\n    doi = \"10.1109/ISCO.2017.7855962\"\n}\n\n",
    "abstract": "Code review is systematic examination of a software system's source code. It is intended to find mistakes overlooked in the initial development phase, improving the overall quality of software and reducing the risk of bugs among other benefits. Reviews are done in various forms such as pair programming, informal walk-through, and formal inspections. Code review has been found to accelerate and streamline the process of software development like very few other practices in software development can. In this paper we propose a machine learning approach for the code reviews in a software system. This would help in faster and a cleaner reviews of the checked in code. The proposed approach is evaluated for feasibility on an open source system eclipse. [1], [2], [3]."
}, {
    "py/object": "data.DataClassPaper",
    "Title": "Detecting Defects with an Interactive Code Review Tool Based on Visualisation and Machine Learning",
    "year": 2009,
    "ML_Techniques": "KNN",
    "Category": "Code review",
    "Sub_category": "",
    "Venue": "SEKE",
    "Link": "https://www.diva-portal.org/smash/record.jsf?pid=diva2%3A835773&dswid=-7493",
    "bibtex": "inproceedings{Axelsson2009_447,\n    author = \"Axelsson, S. and Baca, D. and Feldt, Robert and Sidlauskas, Darius and Kacan, Denis\",\n    title = \"Detecting Defects with an Interactive Code Review Tool Based on Visualisation and Machine Learning\",\n    booktitle = \"SEKE\",\n    year = \"2009\"\n}\n\n",
    "abstract": "Code review is often suggested as a means of improving\ncode quality. Since humans are poor at repetitive tasks,\nsome form of tool support is valuable. To that end we developed\na prototype tool to illustrate the novel idea of applying\nmachine learning (based on Normalised Compression\nDistance) to the problem of static analysis of source\ncode. Since this tool learns by example, it is trivially programmer\nadaptable. As machine learning algorithms are\nnotoriously difficult to understand operationally (they are\nopaque) we applied information visualisation to the results\nof the learner. In order to validate the approach we applied\nthe prototype to source code from the open-source project\nSamba and from an industrial, telecom software system.\nOur results showed that the tool did indeed correctly find\nand classify problematic sections of code based on training\nexamples."
}, {
    "py/object": "data.DataClassPaper",
    "Title": "A deep neural network language model with contexts for source code",
    "year": 2018,
    "ML_Techniques": "DNN",
    "Category": "Code representation",
    "Sub_category": "",
    "Venue": "SANER",
    "Link": "https://ieeexplore.ieee.org/document/8330220",
    "bibtex": "INPROCEEDINGS{Nguyen2018_448,\n    author = \"{Nguyen}, A. T. and {Nguyen}, T. D. and {Phan}, H. D. and {Nguyen}, T. N.\",\n    booktitle = \"2018 IEEE 25th International Conference on Software Analysis, Evolution and Reengineering (SANER)\",\n    title = \"A deep neural network language model with contexts for source code\",\n    year = \"2018\",\n    volume = \"\",\n    number = \"\",\n    pages = \"323-334\",\n    doi = \"10.1109/SANER.2018.8330220\"\n}\n\n",
    "abstract": "Statistical language models (LMs) have been applied\nin several software engineering applications. However, they have\nissues in dealing with ambiguities in the names of program and\nAPI elements (classes and method calls). In this paper, inspired by\nthe success of Deep Neural Network (DNN) in natural language\nprocessing, we present Dnn4C, a DNN language model that\ncomplements the local context of lexical code elements with both\nsyntactic and type contexts. We designed a context-incorporating\nmethod to use with syntactic and type annotations for source code\nin order to learn to distinguish the lexical tokens in different\nsyntactic and type contexts. Our empirical evaluation on code\ncompletion for real-world projects shows that Dnn4C relatively\nimproves 11.6%, 16.3%, 27.1%, and 44.7% top-1 accuracy over\nthe state-of-the-art language models for source code used with the\nsame features: RNN LM, DNN LM, SLAMC, and n-gram LM,\nrespectively. For another application, we showed that Dnn4C\nhelps improve accuracy over n-gram LM in migrating source\ncode from Java to C# with a machine translation model."
}, {
    "py/object": "data.DataClassPaper",
    "Title": "A General Path-Based Representation for Predicting Program Properties",
    "year": 2018,
    "ML_Techniques": "",
    "Category": "Code representation",
    "Sub_category": "",
    "Venue": "PLDI",
    "Link": "https://arxiv.org/abs/1803.09544",
    "bibtex": "article{Alon2018_449,\n    author = \"Alon, Uri and Zilberstein, Meital and Levy, Omer and Yahav, Eran\",\n    title = \"A General Path-Based Representation for Predicting Program Properties\",\n    year = \"2018\",\n    issue_date = \"April 2018\",\n    publisher = \"Association for Computing Machinery\",\n    address = \"New York, NY, USA\",\n    volume = \"53\",\n    number = \"4\",\n    issn = \"0362-1340\",\n    url = \"https://doi.org/10.1145/3296979.3192412\",\n    doi = \"10.1145/3296979.3192412\",\n    abstract = \"Predicting program properties such as names or expression types has a wide range of applications. It can ease the task of programming, and increase programmer productivity. A major challenge when learning from programs is how to represent programs in a way that facilitates effective learning. We present a general path-based representation for learning from programs. Our representation is purely syntactic and extracted automatically. The main idea is to represent a program using paths in its abstract syntax tree (AST). This allows a learning model to leverage the structured nature of code rather than treating it as a flat sequence of tokens. We show that this representation is general and can: (i) cover different prediction tasks, (ii) drive different learning algorithms (for both generative and discriminative models), and (iii) work across different programming languages. We evaluate our approach on the tasks of predicting variable names, method names, and full types. We use our representation to drive both CRF-based and word2vec-based learning, for programs of four languages: JavaScript, Java, Python and C\\#. Our evaluation shows that our approach obtains better results than task-specific handcrafted representations across different tasks and programming languages.\",\n    journal = \"SIGPLAN Not.\",\n    month = \"June\",\n    pages = \"404\u2013419\",\n    numpages = \"16\",\n    keywords = \"Machine Learning, Learning Representations, Big Code, Programming Languages\"\n}\n\n",
    "abstract": "Predicting program properties such as names or expression\ntypes has a wide range of applications. It can ease the task\nof programming, and increase programmer productivity. A\nmajor challenge when learning from programs is how to represent\nprograms in a way that facilitates effective learning.\nWe present a general path-based representation for learning\nfrom programs. Our representation is purely syntactic\nand extracted automatically. The main idea is to represent a\nprogram using paths in its abstract syntax tree (AST). This\nallows a learning model to leverage the structured nature of\ncode rather than treating it as a flat sequence of tokens.\nWe show that this representation is general and can: (i) cover\ndifferent prediction tasks, (ii) drive different learning algorithms\n(for both generative and discriminative models), and\n(iii) work across different programming languages.\nWe evaluate our approach on the tasks of predicting variable\nnames, method names, and full types. We use our representation\nto drive both CRF-based and word2vec-based learning,\nfor programs of four languages: JavaScript, Java, Python\nand C#. Our evaluation shows that our approach obtains better\nresults than task-specific handcrafted representations across\ndifferent tasks and programming languages."
}, {
    "py/object": "data.DataClassPaper",
    "Title": "A multi-task representation learning approach for source code",
    "year": 2020,
    "ML_Techniques": "BERT, EN-DE",
    "Category": "Code representation",
    "Sub_category": "",
    "Venue": "RL+SE&PL",
    "Link": "https://dl.acm.org/doi/10.1145/3416506.3423575",
    "bibtex": "article{Alon2018_449,\n    author = \"Alon, Uri and Zilberstein, Meital and Levy, Omer and Yahav, Eran\",\n    title = \"A General Path-Based Representation for Predicting Program Properties\",\n    year = \"2018\",\n    issue_date = \"April 2018\",\n    publisher = \"Association for Computing Machinery\",\n    address = \"New York, NY, USA\",\n    volume = \"53\",\n    number = \"4\",\n    issn = \"0362-1340\",\n    url = \"https://doi.org/10.1145/3296979.3192412\",\n    doi = \"10.1145/3296979.3192412\",\n    abstract = \"Predicting program properties such as names or expression types has a wide range of applications. It can ease the task of programming, and increase programmer productivity. A major challenge when learning from programs is how to represent programs in a way that facilitates effective learning. We present a general path-based representation for learning from programs. Our representation is purely syntactic and extracted automatically. The main idea is to represent a program using paths in its abstract syntax tree (AST). This allows a learning model to leverage the structured nature of code rather than treating it as a flat sequence of tokens. We show that this representation is general and can: (i) cover different prediction tasks, (ii) drive different learning algorithms (for both generative and discriminative models), and (iii) work across different programming languages. We evaluate our approach on the tasks of predicting variable names, method names, and full types. We use our representation to drive both CRF-based and word2vec-based learning, for programs of four languages: JavaScript, Java, Python and C\\#. Our evaluation shows that our approach obtains better results than task-specific handcrafted representations across different tasks and programming languages.\",\n    journal = \"SIGPLAN Not.\",\n    month = \"June\",\n    pages = \"404\u2013419\",\n    numpages = \"16\",\n    keywords = \"Machine Learning, Learning Representations, Big Code, Programming Languages\"\n}\n\n",
    "abstract": "Representation learning has shown impressive results for a multitude\nof tasks in software engineering. However, most researches\nstill focus on a single problem. As a result, the learned representations\ncannot be applied to other problems and lack generalizability\nand interpretability. In this paper, we propose a Multi-task learning\napproach for representation learning across multiple downstream\ntasks of software engineering. From the perspective of generalization,\nwe build a shared sequence encoder with a pretrained BERT\nfor the token sequence and a structure encoder with a Tree-LSTM\nfor the abstract syntax tree of code. From the perspective of interpretability,\nwe integrate attention mechanism to focus on different\nrepresentations and set learnable parameters to adjust the relationship\nbetween tasks. We also present the early results of our model.\nThe learning process analysis shows our model has a significant\nimprovement over strong baselines."
}, {
    "py/object": "data.DataClassPaper",
    "Title": "A Novel Neural Source Code Representation based on Abstract Syntax Tree",
    "year": 2019,
    "ML_Techniques": "Bi-GRU",
    "Category": "Code representation",
    "Sub_category": "",
    "Venue": "ICSE",
    "Link": "http://xuwang.tech/paper/astnn_icse2019.pdf",
    "bibtex": "article{Alon2018_449,\n    author = \"Alon, Uri and Zilberstein, Meital and Levy, Omer and Yahav, Eran\",\n    title = \"A General Path-Based Representation for Predicting Program Properties\",\n    year = \"2018\",\n    issue_date = \"April 2018\",\n    publisher = \"Association for Computing Machinery\",\n    address = \"New York, NY, USA\",\n    volume = \"53\",\n    number = \"4\",\n    issn = \"0362-1340\",\n    url = \"https://doi.org/10.1145/3296979.3192412\",\n    doi = \"10.1145/3296979.3192412\",\n    abstract = \"Predicting program properties such as names or expression types has a wide range of applications. It can ease the task of programming, and increase programmer productivity. A major challenge when learning from programs is how to represent programs in a way that facilitates effective learning. We present a general path-based representation for learning from programs. Our representation is purely syntactic and extracted automatically. The main idea is to represent a program using paths in its abstract syntax tree (AST). This allows a learning model to leverage the structured nature of code rather than treating it as a flat sequence of tokens. We show that this representation is general and can: (i) cover different prediction tasks, (ii) drive different learning algorithms (for both generative and discriminative models), and (iii) work across different programming languages. We evaluate our approach on the tasks of predicting variable names, method names, and full types. We use our representation to drive both CRF-based and word2vec-based learning, for programs of four languages: JavaScript, Java, Python and C\\#. Our evaluation shows that our approach obtains better results than task-specific handcrafted representations across different tasks and programming languages.\",\n    journal = \"SIGPLAN Not.\",\n    month = \"June\",\n    pages = \"404\u2013419\",\n    numpages = \"16\",\n    keywords = \"Machine Learning, Learning Representations, Big Code, Programming Languages\"\n}\n\n",
    "abstract": "Exploiting machine learning techniques for analyzing\nprograms has attracted much attention. One key problem\nis how to represent code fragments well for follow-up analysis.\nTraditional information retrieval based methods often treat\nprograms as natural language texts, which could miss important\nsemantic information of source code. Recently, state-of-the-art\nstudies demonstrate that abstract syntax tree (AST) based neural\nmodels can better represent source code. However, the sizes of\nASTs are usually large and the existing models are prone to\nthe long-term dependency problem. In this paper, we propose\na novel AST-based Neural Network (ASTNN) for source code\nrepresentation. Unlike existing models that work on entire ASTs,\nASTNN splits each large AST into a sequence of small statement\ntrees, and encodes the statement trees to vectors by capturing\nthe lexical and syntactical knowledge of statements. Based on the\nsequence of statement vectors, a bidirectional RNN model is used\nto leverage the naturalness of statements and finally produce the\nvector representation of a code fragment. We have applied our\nneural network based source code representation method to two\ncommon program comprehension tasks: source code classification\nand code clone detection. Experimental results on the two tasks\nindicate that our model is superior to state-of-the-art approaches"
}, {
    "py/object": "data.DataClassPaper",
    "Title": "A Survey of Machine Learning for Big Code and Naturalness",
    "year": 2018,
    "ML_Techniques": "",
    "Category": "Code representation",
    "Sub_category": "",
    "Venue": "CSUR",
    "Link": "https://arxiv.org/abs/1709.06182v1",
    "bibtex": "article{Allamanis2018_452,\n    author = \"Allamanis, Miltiadis and Barr, Earl T. and Devanbu, Premkumar and Sutton, Charles\",\n    title = \"A Survey of Machine Learning for Big Code and Naturalness\",\n    year = \"2018\",\n    issue_date = \"September 2018\",\n    publisher = \"Association for Computing Machinery\",\n    address = \"New York, NY, USA\",\n    volume = \"51\",\n    number = \"4\",\n    issn = \"0360-0300\",\n    url = \"https://doi.org/10.1145/3212695\",\n    doi = \"10.1145/3212695\",\n    abstract = \"Research at the intersection of machine learning, programming languages, and software engineering has recently taken important steps in proposing learnable probabilistic models of source code that exploit the abundance of patterns of code. In this article, we survey this work. We contrast programming languages against natural languages and discuss how these similarities and differences drive the design of probabilistic models. We present a taxonomy based on the underlying design principles of each model and use it to navigate the literature. Then, we review how researchers have adapted these models to application areas and discuss cross-cutting and application-specific challenges and opportunities.\",\n    journal = \"ACM Comput. Surv.\",\n    month = \"July\",\n    articleno = \"81\",\n    numpages = \"37\",\n    keywords = \"software engineering tools, Big code, code naturalness, machine learning\"\n}\n\n",
    "abstract": "Research at the intersection of machine learning, programming languages, and software engineering has\nrecently taken important steps in proposing learnable probabilistic models of source code that exploit the\nabundance of patterns of code. In this article, we survey this work. We contrast programming languages\nagainst natural languages and discuss how these similarities and differences drive the design of probabilistic\nmodels.We present a taxonomy based on the underlying design principles of eachmodel and use it to navigate\nthe literature. Then, we review how researchers have adapted these models to application areas and discuss\ncross-cutting and application-specific challenges and opportunities."
}, {
    "py/object": "data.DataClassPaper",
    "Title": "Applying Code Vectors for Presenting Software Features in Machine Learning",
    "year": 2018,
    "ML_Techniques": "SVM",
    "Category": "Code representation",
    "Sub_category": "",
    "Venue": "COMPSAC",
    "Link": "https://ieeexplore.ieee.org/document/8377753",
    "bibtex": "INPROCEEDINGS{Lim2018_453,\n    author = \"{Lim}, H.\",\n    booktitle = \"2018 IEEE 42nd Annual Computer Software and Applications Conference (COMPSAC)\",\n    title = \"Applying Code Vectors for Presenting Software Features in Machine Learning\",\n    year = \"2018\",\n    volume = \"01\",\n    number = \"\",\n    pages = \"803-804\",\n    doi = \"10.1109/COMPSAC.2018.00128\"\n}\n\n",
    "abstract": "Machine learning is a statistical approach to give\nmachines the ability to learn with data, without being explicitly\nprogrammed. This approach is widely used in various areas with\ncomplex problems, such as image recognition, speech recognition,\nregression, classification, and prediction. The most important\nfactor is how to express the characteristics of the data being\nanalyzed. In this paper, we present code vectors as training data\nfor presenting software features in software analysis, and give\navailability results for applying code vectors in machine learning\napproach for analyzing software through experiments with Java\napplications."
}, {
    "py/object": "data.DataClassPaper",
    "Title": "Applying probabilistic models to C++ code on an industrial scale",
    "year": 2020,
    "ML_Techniques": "",
    "Category": "Code representation",
    "Sub_category": "",
    "Venue": "ICSEW",
    "Link": "https://dl.acm.org/doi/10.1145/3387940.3391477",
    "bibtex": "INPROCEEDINGS{Lim2018_453,\n    author = \"{Lim}, H.\",\n    booktitle = \"2018 IEEE 42nd Annual Computer Software and Applications Conference (COMPSAC)\",\n    title = \"Applying Code Vectors for Presenting Software Features in Machine Learning\",\n    year = \"2018\",\n    volume = \"01\",\n    number = \"\",\n    pages = \"803-804\",\n    doi = \"10.1109/COMPSAC.2018.00128\"\n}\n\n",
    "abstract": "Machine learning approaches are widely applied to different re\nsearch\ntasks of software engineering, but C/C++ code presents a\nchallenge for these approaches because of its complex build system.\nHowever, C and C++ languages still remain two of the most popular\nprogramming languages, especially in industrial software, where\na big amount of legacy code is still used. This fact prevents the\napplication of recent advances in probabilistic modeling of source\ncode to the C/C++ domain.\nWe demonstrate that it is possible to at least partially overcome\nthese difficulties by the use of a simple token-based representation\nof C/C++ code that can be used as a possible replacement for more\nprecise representations. Enriched token representation is verifie\nat a large scale to ensure that its precision is good enough to learn\nrules from.\nWe consider two different tasks as an application of this represen\ntation:\ncoding style detection and API usage anomaly detection.We\napply simple probabilistic models to these tasks and demonstrate\nthat even complex coding style rules and API usage patterns can\nbe detected by the means of this representation.\nThis paper provides a vision of how different research ML-based\nmethods for software engineering could be applied to the domain of\nC/C++ languages and show how they can be applied to the source\ncode of a large software company like Samsung."
}, {
    "py/object": "data.DataClassPaper",
    "Title": "Are Deep Neural Networks the Best Choice for Modeling Source Code",
    "year": 2017,
    "ML_Techniques": "",
    "Category": "Code representation",
    "Sub_category": "",
    "Venue": "FSE",
    "Link": "https://web.cs.ucdavis.edu/~devanbu/isDLgood.pdf",
    "bibtex": "inproceedings{Hellendoorn2017_455,\n    author = \"Hellendoorn, Vincent J. and Devanbu, Premkumar\",\n    title = \"Are Deep Neural Networks the Best Choice for Modeling Source Code?\",\n    year = \"2017\",\n    isbn = \"9781450351058\",\n    publisher = \"Association for Computing Machinery\",\n    address = \"New York, NY, USA\",\n    url = \"https://doi.org/10.1145/3106237.3106290\",\n    doi = \"10.1145/3106237.3106290\",\n    booktitle = \"Proceedings of the 2017 11th Joint Meeting on Foundations of Software Engineering\",\n    pages = \"763\u2013773\",\n    numpages = \"11\",\n    keywords = \"software tools, naturalness, language models\",\n    location = \"Paderborn, Germany\",\n    series = \"ESEC/FSE 2017\"\n}\n\n",
    "abstract": "Current statistical language modeling techniques, including deeplearning\nbased models, have proven to be quite effective for source\ncode. We argue here that the special properties of source code can\nbe exploited for further improvements. In this work, we enhance\nestablished language modeling approaches to handle the special\nchallenges of modeling source code, such as: frequent changes,\nlarger, changing vocabularies, deeply nested scopes, etc.We present\na fast, nested language modeling toolkit specifically designed for\nsoftware, with the ability to add & remove text, and mix & swap out\nmany models. Specifically, we improve upon prior cache-modeling\nwork and present a model with a much more expansive, multi-level\nnotion of locality that we show to be well-suited for modeling\nsoftware. We present results on varying corpora in comparison\nwith traditional N-gram, as well as RNN, and LSTM deep-learning\nlanguage models, and release all our source code for public use.\nOur evaluations suggest that carefully adapting N-gram models for\nsource code can yield performance that"
}, {
    "py/object": "data.DataClassPaper",
    "Title": "Big code != big vocabulary: open-vocabulary models for source code",
    "year": 2020,
    "ML_Techniques": "RNN GRU",
    "Category": "Code representation",
    "Sub_category": "",
    "Venue": "ICSE",
    "Link": "https://dl.acm.org/doi/10.1145/3377811.3380342",
    "bibtex": "inproceedings{Hellendoorn2017_455,\n    author = \"Hellendoorn, Vincent J. and Devanbu, Premkumar\",\n    title = \"Are Deep Neural Networks the Best Choice for Modeling Source Code?\",\n    year = \"2017\",\n    isbn = \"9781450351058\",\n    publisher = \"Association for Computing Machinery\",\n    address = \"New York, NY, USA\",\n    url = \"https://doi.org/10.1145/3106237.3106290\",\n    doi = \"10.1145/3106237.3106290\",\n    booktitle = \"Proceedings of the 2017 11th Joint Meeting on Foundations of Software Engineering\",\n    pages = \"763\u2013773\",\n    numpages = \"11\",\n    keywords = \"software tools, naturalness, language models\",\n    location = \"Paderborn, Germany\",\n    series = \"ESEC/FSE 2017\"\n}\n\n",
    "abstract": "Statistical language modeling techniques have successfully been\napplied to large source code corpora, yielding a variety of new\nsoftware development tools, such as tools for code suggestion, improving\nreadability, and API migration. A major issue with these\ntechniques is that code introduces new vocabulary at a far higher\nrate than natural language, as new identifier names proliferate.\nBoth large vocabularies and out-of-vocabulary issues severely affect\nNeural Language Models (NLMs) of source code, degrading\ntheir performance and rendering them unable to scale.\nIn this paper, we address this issue by: 1) studying how various\nmodelling choices impact the resulting vocabulary on a large-scale\ncorpus of 13,362 projects; 2) presenting an open vocabulary source\ncode NLM that can scale to such a corpus, 100 times larger than in\nprevious work; and 3) showing that such models outperform the\nstate of the art on three distinct code corpora (Java, C, Python). To\nour knowledge, these are the largest NLMs for code that have been\nreported."
}, {
    "py/object": "data.DataClassPaper",
    "Title": "Bimodal modelling of source code and natural language",
    "year": 2015,
    "ML_Techniques": "",
    "Category": "Code representation",
    "Sub_category": "",
    "Venue": "ICML",
    "Link": "https://dl.acm.org/doi/10.5555/3045118.3045344",
    "bibtex": "inproceedings{Hellendoorn2017_455,\n    author = \"Hellendoorn, Vincent J. and Devanbu, Premkumar\",\n    title = \"Are Deep Neural Networks the Best Choice for Modeling Source Code?\",\n    year = \"2017\",\n    isbn = \"9781450351058\",\n    publisher = \"Association for Computing Machinery\",\n    address = \"New York, NY, USA\",\n    url = \"https://doi.org/10.1145/3106237.3106290\",\n    doi = \"10.1145/3106237.3106290\",\n    booktitle = \"Proceedings of the 2017 11th Joint Meeting on Foundations of Software Engineering\",\n    pages = \"763\u2013773\",\n    numpages = \"11\",\n    keywords = \"software tools, naturalness, language models\",\n    location = \"Paderborn, Germany\",\n    series = \"ESEC/FSE 2017\"\n}\n\n",
    "abstract": "We consider the problem of building probabilistic\nmodels that jointly model short natural language\nutterances and source code snippets. The aim is to\nbring together recent work on statistical modelling\nof source code and work on bimodal models of\nimages and natural language. The resulting models\nare useful for a variety of tasks that involve\nnatural language and source code. We demonstrate\ntheir performance on two retrieval tasks:\nretrieving source code snippets given a natural language\nquery, and retrieving natural language descriptions\ngiven a source code query (i.e., source\ncode captioning). Experiments show there to be\npromise in this direction, and that modelling the\nstructure of source code improves performance."
}, {
    "py/object": "data.DataClassPaper",
    "Title": "Building Implicit Vector Representations of Individual Coding Style",
    "year": 2020,
    "ML_Techniques": "",
    "Category": "Code representation",
    "Sub_category": "",
    "Venue": "ICSEW",
    "Link": "https://dl.acm.org/doi/10.1145/3387940.3391494",
    "bibtex": "inproceedings{Kovalenko2020_458,\n    author = \"Kovalenko, Vladimir and Bogomolov, Egor and Bryksin, Timofey and Bacchelli, Alberto\",\n    title = \"Building Implicit Vector Representations of Individual Coding Style\",\n    year = \"2020\",\n    isbn = \"9781450379632\",\n    publisher = \"Association for Computing Machinery\",\n    address = \"New York, NY, USA\",\n    url = \"https://doi.org/10.1145/3387940.3391494\",\n    doi = \"10.1145/3387940.3391494\",\n    abstract = \"We propose a new approach to building vector representations of individual developers by capturing their individual contribution style, or coding style. Such representations can find use in the next generation of software development team collaboration tools, for example by enabling the tools to track knowledge transfer in teams. The key idea of our approach is to avoid using explicitly defined metrics of coding style and instead build the representations through training a model for authorship recognition and extracting the representations of individual developers from the trained model. By empirically evaluating the output of our approach, we find that implicitly built individual representations reflect some properties of team structure: developers who report learning from each other are represented closer to each other.\",\n    booktitle = \"Proceedings of the IEEE/ACM 42nd International Conference on Software Engineering Workshops\",\n    pages = \"117\u2013124\",\n    numpages = \"8\",\n    location = \"Seoul, Republic of Korea\",\n    series = \"ICSEW'20\"\n}\n\n",
    "abstract": "With the goal of facilitating team collaboration, we propose a new approach to building vector representations of individual developers by capturing their individual contribution style, or coding style. Such representations can find use in the next generation of software development team collaboration tools, for example by enabling the tools to track knowledge transfer in teams. The key idea of our approach is to avoid using explicitly defined metrics of coding style and instead build the representations through training a model for authorship recognition and extracting the representations of individual developers from the trained model. By empirically evaluating the output of our approach, we find that implicitly built individual representations reflect some properties of team structure: developers who report learning from each other are represented closer to each other."
}, {
    "py/object": "data.DataClassPaper",
    "Title": "Can Latent Topics in Source Code Predict Missing Architectural Tactics?",
    "year": 2017,
    "ML_Techniques": "RF, LOG, NN, LDA",
    "Category": "Code completion",
    "Sub_category": "",
    "Venue": "ICSE",
    "Link": "https://ieeexplore.ieee.org/document/7985646",
    "bibtex": "INPROCEEDINGS{Gopalakrishnan2017_459,\n    author = \"{Gopalakrishnan}, R. and {Sharma}, P. and {Mirakhorli}, M. and {Galster}, M.\",\n    booktitle = \"2017 IEEE/ACM 39th International Conference on Software Engineering (ICSE)\",\n    title = \"Can Latent Topics in Source Code Predict Missing Architectural Tactics?\",\n    year = \"2017\",\n    volume = \"\",\n    number = \"\",\n    pages = \"15-26\",\n    doi = \"10.1109/ICSE.2017.10\"\n}\n\n",
    "abstract": "Architectural tactics such as heartbeat, resource pooling, and scheduling provide solutions to satisfy reliability, security, performance, and other critical characteristics of a software system. Current design practices advocate rigorous up-front analysis of the systems quality concerns to identify tactics and where in the code they should be used. In this paper, we explore a bottom-up approach to recommend architectural tactics based on latent topics discovered in the source code of projects. We present a recommender system developed by building predictor models which capture relationships between topical concepts in source code and the use of specific architectural tactics in that code. Based on an extensive analysis of over 116,000 open source systems, we identify significant correlations between latent topics in source code and the usage of architectural tactics. We use this information to construct a predictor for generating tactic recommendations. Our approach is validated through a series of experiments which demonstrate the ability to generate package-level tactic recommendations. We provide further validation via two large-scale studies of Apache Hive and Hadoop to illustrate that our recommender system predicts tactics that are actually implemented by developers in later releases."
}, {
    "py/object": "data.DataClassPaper",
    "Title": "Capturing source code semantics via tree-based convolution over API-enhanced AST",
    "year": 2019,
    "ML_Techniques": "CNN",
    "Category": "Code representation",
    "Sub_category": "",
    "Venue": "CF",
    "Link": "https://dl.acm.org/doi/10.1145/3310273.3321560",
    "bibtex": "INPROCEEDINGS{Gopalakrishnan2017_459,\n    author = \"{Gopalakrishnan}, R. and {Sharma}, P. and {Mirakhorli}, M. and {Galster}, M.\",\n    booktitle = \"2017 IEEE/ACM 39th International Conference on Software Engineering (ICSE)\",\n    title = \"Can Latent Topics in Source Code Predict Missing Architectural Tactics?\",\n    year = \"2017\",\n    volume = \"\",\n    number = \"\",\n    pages = \"15-26\",\n    doi = \"10.1109/ICSE.2017.10\"\n}\n\n",
    "abstract": "When deep learning meets big code, a key question is how to efficiently\nlearn a distributed representation for source code that\ncan capture its semantics effectively. We propose to use tree-based\nconvolution over API-enhanced AST. To demonstrate the effectiveness\nof our approach, we apply it to detect semantic clones\u2014\ncode fragments with similar semantics but dissimilar syntax. Experiment\nresults show that our approach outperforms an existing\nstate-of-the-art approach that uses tree-based LSTM, with an increase\nof 0.39 and 0.12 in F1-score on OJClone and BigCloneBench\nrespectively. We further propose architectures that incorporate our\napproach for code search and code summarization."
}, {
    "py/object": "data.DataClassPaper",
    "Title": "CC2Vec: distributed representations of code changes",
    "year": 2020,
    "ML_Techniques": "HAN, EN-DE",
    "Category": "Code representation",
    "Sub_category": "",
    "Venue": "ICSE",
    "Link": "https://dl.acm.org/doi/10.1145/3377811.3380361",
    "bibtex": "INPROCEEDINGS{Gopalakrishnan2017_459,\n    author = \"{Gopalakrishnan}, R. and {Sharma}, P. and {Mirakhorli}, M. and {Galster}, M.\",\n    booktitle = \"2017 IEEE/ACM 39th International Conference on Software Engineering (ICSE)\",\n    title = \"Can Latent Topics in Source Code Predict Missing Architectural Tactics?\",\n    year = \"2017\",\n    volume = \"\",\n    number = \"\",\n    pages = \"15-26\",\n    doi = \"10.1109/ICSE.2017.10\"\n}\n\n",
    "abstract": "Existing work on software patches often use features specific to a\nsingle task. These works often rely on manually identified features,\nand human effort is required to identify these features for each\ntask. In this work, we propose CC2Vec, a neural network model\nthat learns a representation of code changes guided by their accompanying\nlog messages, which represent the semantic intent of\nthe code changes. CC2Vec models the hierarchical structure of a\ncode change with the help of the attention mechanism and uses\nmultiple comparison functions to identify the differences between\nthe removed and added code.\nTo evaluate if CC2Vec can produce a distributed representation\nof code changes that is general and useful for multiple tasks on\nsoftware patches, we use the vectors produced by CC2Vec for three\ntasks: log message generation, bug fixing patch identification, and\njust-in-time defect prediction. In all tasks, the models using CC2Vec\noutperform the state-of-the-art techniques."
}, {
    "py/object": "data.DataClassPaper",
    "Title": "Code vectors: understanding programs through embedded abstracted symbolic traces",
    "year": 2018,
    "ML_Techniques": "Glove",
    "Category": "Code representation",
    "Sub_category": "",
    "Venue": "FSE",
    "Link": "https://dl.acm.org/doi/10.1145/3236024.3236085",
    "bibtex": "INPROCEEDINGS{Gopalakrishnan2017_459,\n    author = \"{Gopalakrishnan}, R. and {Sharma}, P. and {Mirakhorli}, M. and {Galster}, M.\",\n    booktitle = \"2017 IEEE/ACM 39th International Conference on Software Engineering (ICSE)\",\n    title = \"Can Latent Topics in Source Code Predict Missing Architectural Tactics?\",\n    year = \"2017\",\n    volume = \"\",\n    number = \"\",\n    pages = \"15-26\",\n    doi = \"10.1109/ICSE.2017.10\"\n}\n\n",
    "abstract": "With the rise of machine learning, there is a great deal of interest in\ntreating programs as data to be fed to learning algorithms. However,\nprograms do not start off in a form that is immediately amenable\nto most off-the-shelf learning techniques. Instead, it is necessary to\ntransform the program to a suitable representation before a learning\ntechnique can be applied.\nIn this paper, we use abstractions of traces obtained from symbolic\nexecution of a program as a representation for learning word\nembeddings. We trained a variety of word embeddings under hundreds\nof parameterizations, and evaluated each learned embedding\non a suite of different tasks. In our evaluation, we obtain 93% top-1\naccuracy on a benchmark consisting of over 19,000 API-usage analogies\nextracted from the Linux kernel. In addition, we show that\nembeddings learned from (mainly) semantic abstractions provide\nnearly triple the accuracy of those learned from (mainly) syntactic\nabstractions."
}, {
    "py/object": "data.DataClassPaper",
    "Title": "code2seq: Generating Sequences from Structured Representations of Code",
    "year": 2019,
    "ML_Techniques": "EN-DE, LSTM",
    "Category": "Code representation",
    "Sub_category": "",
    "Venue": "ICLR",
    "Link": "https://arxiv.org/abs/1808.01400",
    "bibtex": "misc{Alon2019_463,\n    author = \"Alon, Uri and Brody, Shaked and Levy, Omer and Yahav, Eran\",\n    title = \"code2seq: Generating Sequences from Structured Representations of Code\",\n    year = \"2019\",\n    eprint = \"1808.01400\",\n    archivePrefix = \"arXiv\",\n    primaryClass = \"cs.LG\"\n}\n\n",
    "abstract": "The ability to generate natural language sequences from source code snippets has\na variety of applications such as code summarization, documentation, and retrieval.\nSequence-to-sequence (seq2seq) models, adopted from neural machine\ntranslation (NMT), have achieved state-of-the-art performance on these tasks by\ntreating source code as a sequence of tokens. We present CODE2SEQ: an alternative\napproach that leverages the syntactic structure of programming languages\nto better encode source code. Our model represents a code snippet as\nthe set of compositional paths in its abstract syntax tree (AST) and uses attention\nto select the relevant paths while decoding. We demonstrate the effectiveness\nof our approach for two tasks, two programming languages, and four\ndatasets of up to 16M examples. Our model significantly outperforms previous\nmodels that were specifically designed for programming languages, as well\nas state-of-the-art NMT models. An online demo of our model is available at\nhttp://code2seq.org. Our code, data and trained models are available at\nhttp://github.com/tech-srl/code2seq."
}, {
    "py/object": "data.DataClassPaper",
    "Title": "code2vec: Learning Distributed Representations of Code",
    "year": 2019,
    "ML_Techniques": "Code2Vec",
    "Category": "Code representation",
    "Sub_category": "",
    "Venue": "POPL",
    "Link": "https://arxiv.org/abs/1803.09473v2",
    "bibtex": "misc{Alon2019_463,\n    author = \"Alon, Uri and Brody, Shaked and Levy, Omer and Yahav, Eran\",\n    title = \"code2seq: Generating Sequences from Structured Representations of Code\",\n    year = \"2019\",\n    eprint = \"1808.01400\",\n    archivePrefix = \"arXiv\",\n    primaryClass = \"cs.LG\"\n}\n\n",
    "abstract": "We present a neural model for representing snippets of code as continuous distributed vectors. The main idea\nis to represent code as a collection of paths in its abstract syntax tree, and aggregate these paths, in a smart and\nscalable way, into a single fixed-length code vector, which can be used to predict semantic properties of the\nsnippet.\nWe demonstrate the effectiveness of our approach by using it to predict a method\u2019s name from the vector\nrepresentation of its body. We evaluate our approach by training a model on a dataset of 14M methods. We show\nthat code vectors trained on this dataset can predict method names from files that were completely unobserved\nduring training. Furthermore, we show that our model learns useful method name vectors that capture semantic\nsimilarities, combinations, and analogies.\nComparing previous techniques over the same data set, our approach obtains a relative improvement of over\n75%, being the first to successfully predict method names based on a large, cross-project, corpus."
}, {
    "py/object": "data.DataClassPaper",
    "Title": "Compiler-based graph representations for deep learning models of code",
    "year": 2020,
    "ML_Techniques": "GNN",
    "Category": "Code representation",
    "Sub_category": "",
    "Venue": "CC",
    "Link": "https://dl.acm.org/doi/10.1145/3377555.3377894",
    "bibtex": "misc{Alon2019_463,\n    author = \"Alon, Uri and Brody, Shaked and Levy, Omer and Yahav, Eran\",\n    title = \"code2seq: Generating Sequences from Structured Representations of Code\",\n    year = \"2019\",\n    eprint = \"1808.01400\",\n    archivePrefix = \"arXiv\",\n    primaryClass = \"cs.LG\"\n}\n\n",
    "abstract": "In natural language processing, novel methods in deep learning,\nlike recurrent neural networks (RNNs) on sequences of\nwords, have been very successful. In contrast to natural languages,\nprogramming languages usually have a well-defined\nstructure. With this structure compilers can reason about\nprograms, using graphs such as abstract syntax trees (ASTs)\nor control-data flow graphs (CDFGs). In this paper, we argue\nthat we should use these graph structures instead of\nsequences for learning compiler optimization tasks. To this\nend, we use graph neural networks (GNNs) for learning predictive\ncompiler tasks on two representations based on ASTs\nand CDFGs. Experiments show that this improves upon the\nstate-of-the-art in the task of heterogeneous OpenCL mapping,\nwhile providing orders of magnitude faster inference\ntimes, crucial for compiler optimizations. When testing on\nbenchmark suites not included for training, our AST-based\nmodel significantly outperforms the state-of-the-art by over\n12 percentage points in terms of accuracy. It is the only one\nto perform clearly better than a random mapping. On the\ntask of predicting thread coarsening factors, we show that\nall of the methods fail to produce an overall speedup."
}, {
    "py/object": "data.DataClassPaper",
    "Title": "Convolutional Neural Networks over Tree Structures for Programming Language Processing",
    "year": 2016,
    "ML_Techniques": "CNN",
    "Category": "Code representation",
    "Sub_category": "",
    "Venue": "AAAI",
    "Link": "https://arxiv.org/abs/1409.5718",
    "bibtex": "inproceedings{Mou2016_466,\n    author = \"Mou, Lili and Li, Ge and Zhang, Lu and Wang, Tao and Jin, Zhi\",\n    title = \"Convolutional Neural Networks over Tree Structures for Programming Language Processing\",\n    year = \"2016\",\n    publisher = \"AAAI Press\",\n    abstract = \"Programming language processing (similar to natural language processing) is a hot research topic in the field of software engineering; it has also aroused growing interest in the artificial intelligence community. However, different from a natural language sentence, a program contains rich, explicit, and complicated structural information. Hence, traditional NLP models may be inappropriate for programs. In this paper, we propose a novel tree-based convolutional neural network (TBCNN) for programming language processing, in which a convolution kernel is designed over programs' abstract syntax trees to capture structural information. TBCNN is a generic architecture for programming language processing; our experiments show its effectiveness in two different program analysis tasks: classifying programs according to functionality, and detecting code snippets of certain patterns. TBCNN outperforms baseline methods, including several neural models for NLP.\",\n    booktitle = \"Proceedings of the Thirtieth AAAI Conference on Artificial Intelligence\",\n    pages = \"1287\u20131293\",\n    numpages = \"7\",\n    location = \"Phoenix, Arizona\",\n    series = \"AAAI'16\"\n}\n\n",
    "abstract": "Programming language processing (similar to natural\nlanguage processing) is a hot research topic in the field\nof software engineering; it has also aroused growing interest\nin the artificial intelligence community. However,\ndifferent from a natural language sentence, a program\ncontains rich, explicit, and complicated structural information.\nHence, traditional NLP models may be inappropriate\nfor programs. In this paper, we propose a novel\ntree-based convolutional neural network (TBCNN) for\nprogramming language processing, in which a convolution\nkernel is designed over programs\u2019 abstract syntax\ntrees to capture structural information. TBCNN is\na generic architecture for programming language processing;\nour experiments show its effectiveness in two\ndifferent program analysis tasks: classifying programs\naccording to functionality, and detecting code snippets\nof certain patterns. TBCNN outperforms baseline methods,\nincluding several neural models for NLP."
}, {
    "py/object": "data.DataClassPaper",
    "Title": "Deep learning similarities from different representations of source code",
    "year": 2018,
    "ML_Techniques": "RNN",
    "Category": "Code representation",
    "Sub_category": "",
    "Venue": "MSR",
    "Link": "https://dl.acm.org/doi/10.1145/3196398.3196431",
    "bibtex": "inproceedings{Mou2016_466,\n    author = \"Mou, Lili and Li, Ge and Zhang, Lu and Wang, Tao and Jin, Zhi\",\n    title = \"Convolutional Neural Networks over Tree Structures for Programming Language Processing\",\n    year = \"2016\",\n    publisher = \"AAAI Press\",\n    abstract = \"Programming language processing (similar to natural language processing) is a hot research topic in the field of software engineering; it has also aroused growing interest in the artificial intelligence community. However, different from a natural language sentence, a program contains rich, explicit, and complicated structural information. Hence, traditional NLP models may be inappropriate for programs. In this paper, we propose a novel tree-based convolutional neural network (TBCNN) for programming language processing, in which a convolution kernel is designed over programs' abstract syntax trees to capture structural information. TBCNN is a generic architecture for programming language processing; our experiments show its effectiveness in two different program analysis tasks: classifying programs according to functionality, and detecting code snippets of certain patterns. TBCNN outperforms baseline methods, including several neural models for NLP.\",\n    booktitle = \"Proceedings of the Thirtieth AAAI Conference on Artificial Intelligence\",\n    pages = \"1287\u20131293\",\n    numpages = \"7\",\n    location = \"Phoenix, Arizona\",\n    series = \"AAAI'16\"\n}\n\n",
    "abstract": "Assessing the similarity between code components plays a pivotal\nrole in a number of Software Engineering (SE) tasks, such as clone\ndetection, impact analysis, refactoring, etc. Code similarity is generally\nmeasured by relying on manually defined or hand-crafted\nfeatures, e.g., by analyzing the overlap among identifiers or comparing\nthe Abstract Syntax Trees of two code components. These\nfeatures represent a best guess at what SE researchers can utilize to\nexploit and reliably assess code similarity for a given task. Recent\nwork has shown, when using a stream of identifiers to represent\nthe code, that Deep Learning (DL) can effectively replace manual\nfeature engineering for the task of clone detection. However, source\ncode can be represented at different levels of abstraction: identifiers,\nAbstract Syntax Trees, Control Flow Graphs, and Bytecode.\nWe conjecture that each code representation can provide a different,\nyet orthogonal view of the same code fragment, thus, enabling a\nmore reliable detection of similarities in code. In this paper, we\ndemonstrate how SE tasks can benefit from a DL-based approach,\nwhich can aut"
}, {
    "py/object": "data.DataClassPaper",
    "Title": "Feature Maps: A Comprehensible Software Representation for Design Pattern Detection",
    "year": 2019,
    "ML_Techniques": "CNN, RF",
    "Category": "Code representation",
    "Sub_category": "",
    "Venue": "SANER",
    "Link": "https://ieeexplore.ieee.org/document/8667978",
    "bibtex": "INPROCEEDINGS{Thaller2019_468,\n    author = \"{Thaller}, H. and {Linsbauer}, L. and {Egyed}, A.\",\n    booktitle = \"2019 IEEE 26th International Conference on Software Analysis, Evolution and Reengineering (SANER)\",\n    title = \"Feature Maps: A Comprehensible Software Representation for Design Pattern Detection\",\n    year = \"2019\",\n    volume = \"\",\n    number = \"\",\n    pages = \"207-217\",\n    doi = \"10.1109/SANER.2019.8667978\"\n}\n\n",
    "abstract": "Design patterns are elegant and well-tested solutions\nto recurrent software development problems. They are the result\nof software developers dealing with problems that frequently\noccur, solving them in the same or a slightly adapted way. A pattern\u2019s\nsemantics provide the intent, motivation, and applicability,\ndescribing what it does, why it is needed, and where it is useful.\nConsequently, design patterns encode a well of information. Developers\nweave this information into their systems whenever they\nuse design patterns to solve problems. This work presents Feature\nMaps, a flexible human- and machine-comprehensible software\nrepresentation based on micro-structures. Our algorithm, the\nFeature-Role Normalization, presses the high-dimensional, inhomogeneous\nvector space of micro-structures into a feature map.\nWe apply these concepts to the problem of detecting instances of\ndesign patterns in source code. We evaluate our methodology on\nfour design patterns, a wide range of balanced and imbalanced\nlabeled training data, and compare classical machine learning\n(Random Forests) with modern deep learning approaches\n(Convolutional Neural Networks). Feature maps yield robust\nclassifiers even under challenging settings of strongly imbalanced\ndata distributions without sacrificing human comprehensibility.\nResults suggest that feature maps are an excellent addition in\nthe software analysis toolbox that can reveal useful information\nhidden in the source code."
}, {
    "py/object": "data.DataClassPaper",
    "Title": "Flow2Vec: value-flow-based precise code embedding",
    "year": 2020,
    "ML_Techniques": "Code2Vec, EN-DE",
    "Category": "Code representation",
    "Sub_category": "",
    "Venue": "OOPSLA",
    "Link": " https://dl.acm.org/doi/10.1145/3428301",
    "bibtex": "INPROCEEDINGS{Thaller2019_468,\n    author = \"{Thaller}, H. and {Linsbauer}, L. and {Egyed}, A.\",\n    booktitle = \"2019 IEEE 26th International Conference on Software Analysis, Evolution and Reengineering (SANER)\",\n    title = \"Feature Maps: A Comprehensible Software Representation for Design Pattern Detection\",\n    year = \"2019\",\n    volume = \"\",\n    number = \"\",\n    pages = \"207-217\",\n    doi = \"10.1109/SANER.2019.8667978\"\n}\n\n",
    "abstract": "Code embedding, as an emerging paradigm for source code analysis, has attracted much attention over the past\nfew years. It aims to represent code semantics through distributed vector representations, which can be used to\nsupport a variety of program analysis tasks (e.g., code summarization and semantic labeling). However, existing\ncode embedding approaches are intraprocedural, alias-unaware and ignoring the asymmetric transitivity\nof directed graphs abstracted from source code, thus they are still ineffective in preserving the structural\ninformation of code.\nThis paper presents Flow2Vec, a new code embedding approach that precisely preserves interprocedural\nprogram dependence (a.k.a value-flows). By approximating the high-order proximity, i.e., the asymmetric\ntransitivity of value-flows, Flow2Vec embeds control-flows and alias-aware data-flows of a program in a\nlow-dimensional vector space. Our value-flow embedding is formulated as matrix multiplication to preserve\ncontext-sensitive transitivity through CFL reachability by filtering out infeasible value-flow paths.\nWe have evaluated Flow2Vec using 32 popular open-source projects. Results from our experiments show\nthat Flow2Vec successfully boosts the performance of two recent code embedding approaches code2vec and\ncode2seq for two client applications, i.e., code classification and code summarization. For code classification,\nFlow2Vec improves code2vec with an average increase of 21.2%, 20.1% and 20.7% in precision, recall and F1,\nrespectively. For code summarization, Flow2Vec outperforms code2seq by an average of 13.2%, 18.8% and\n16.0% in precision, recall and F1, respectively."
}, {
    "py/object": "data.DataClassPaper",
    "Title": "From Programs to Interpretable Deep Models and Back",
    "year": 2018,
    "ML_Techniques": "",
    "Category": "Code representation",
    "Sub_category": "",
    "Venue": "CAV",
    "Link": "https://link.springer.com/content/pdf/10.1007%2F978-3-319-96145-3_2.pdf",
    "bibtex": "InProceedings{Yahav2018_470,\n    author = \"Yahav, Eran\",\n    editor = \"Chockler, Hana and Weissenbacher, Georg\",\n    title = \"From Programs to Interpretable Deep Models and Back\",\n    booktitle = \"Computer Aided Verification\",\n    year = \"2018\",\n    publisher = \"Springer International Publishing\",\n    address = \"Cham\",\n    pages = \"27--37\",\n    abstract = \"We demonstrate how deep learning over programs is used to provide (preliminary) augmented programmer intelligence. In the first part, we show how to tackle tasks like code completion, code summarization, and captioning. We describe a general path-based representation of source code that can be used across programming languages and learning tasks, and discuss how this representation enables different learning algorithms. In the second part, we describe techniques for extracting interpretable representations from deep models, shedding light on what has actually been learned in various tasks.\",\n    isbn = \"978-3-319-96145-3\"\n}\n\n",
    "abstract": "We demonstrate how deep learning over programs is used to\nprovide (preliminary) augmented programmer intelligence. In the first\npart, we show how to tackle tasks like code completion, code summarization,\nand captioning. We describe a general path-based representation of\nsource code that can be used across programming languages and learning\ntasks, and discuss how this representation enables different learning\nalgorithms. In the second part, we describe techniques for extracting\ninterpretable representations from deep models, shedding light on what\nhas actually been learned in various tasks."
}, {
    "py/object": "data.DataClassPaper",
    "Title": "GENERATIVE CODE MODELING WITH GRAPHS",
    "year": 2019,
    "ML_Techniques": "GNN",
    "Category": "Code representation",
    "Sub_category": "",
    "Venue": "ICLR",
    "Link": "https://openreview.net/forum?id=Bke4KsA5FX",
    "bibtex": "InProceedings{Yahav2018_470,\n    author = \"Yahav, Eran\",\n    editor = \"Chockler, Hana and Weissenbacher, Georg\",\n    title = \"From Programs to Interpretable Deep Models and Back\",\n    booktitle = \"Computer Aided Verification\",\n    year = \"2018\",\n    publisher = \"Springer International Publishing\",\n    address = \"Cham\",\n    pages = \"27--37\",\n    abstract = \"We demonstrate how deep learning over programs is used to provide (preliminary) augmented programmer intelligence. In the first part, we show how to tackle tasks like code completion, code summarization, and captioning. We describe a general path-based representation of source code that can be used across programming languages and learning tasks, and discuss how this representation enables different learning algorithms. In the second part, we describe techniques for extracting interpretable representations from deep models, shedding light on what has actually been learned in various tasks.\",\n    isbn = \"978-3-319-96145-3\"\n}\n\n",
    "abstract": "Generative models for source code are an interesting structured prediction problem,\nrequiring to reason about both hard syntactic and semantic constraints as well as\nabout natural, likely programs. We present a novel model for this problem that\nuses a graph to represent the intermediate state of the generated output. Our model\ngenerates code by interleaving grammar-driven expansion steps with graph augmentation\nand neural message passing steps. An experimental evaluation shows\nthat our new model can generate semantically meaningful expressions, outperforming\na range of strong baselines."
}, {
    "py/object": "data.DataClassPaper",
    "Title": "Learning Programs: A Hierarchical Bayesian Approach",
    "year": 2010,
    "ML_Techniques": "",
    "Category": "Code representation",
    "Sub_category": "",
    "Venue": "ICML",
    "Link": "https://www.semanticscholar.org/paper/Learning-Programs%3A-A-Hierarchical-Bayesian-Approach-Liang-Jordan/c26770f29afafe22f2a507506e3f43c413f6a619",
    "bibtex": "inproceedings{Liang2010_472,\n    author = \"Liang, Percy and Jordan, Michael I. and Klein, D.\",\n    title = \"Learning Programs: A Hierarchical Bayesian Approach\",\n    booktitle = \"ICML\",\n    year = \"2010\"\n}\n\n",
    "abstract": "We are interested in learning programs for\nmultiple related tasks given only a few training\nexamples per task. Since the program\nfor a single task is underdetermined by its\ndata, we introduce a nonparametric hierarchical\nBayesian prior over programs which\nshares statistical strength across multiple\ntasks. The key challenge is to parametrize\nthis multi-task sharing. For this, we introduce\na new representation of programs\nbased on combinatory logic and provide an\nMCMC algorithm that can perform safe program\ntransformations on this representation\nto reveal shared inter-program substructures."
}, {
    "py/object": "data.DataClassPaper",
    "Title": "Learning semantic program embeddings with graph interval neural network",
    "year": 2020,
    "ML_Techniques": "GINN",
    "Category": "Code representation",
    "Sub_category": "",
    "Venue": "OOPSLA",
    "Link": "https://dl.acm.org/doi/10.1145/3428205",
    "bibtex": "inproceedings{Liang2010_472,\n    author = \"Liang, Percy and Jordan, Michael I. and Klein, D.\",\n    title = \"Learning Programs: A Hierarchical Bayesian Approach\",\n    booktitle = \"ICML\",\n    year = \"2010\"\n}\n\n",
    "abstract": "Learning distributed representations of source code has been a challenging task for machine learning models.\nEarlier works treated programs as text so that natural language methods can be readily applied. Unfortunately,\nsuch approaches do not capitalize on the rich structural information possessed by source code. Of late, Graph\nNeural Network (GNN) was proposed to learn embeddings of programs from their graph representations.\nDue to the homogeneous (i.e. do not take advantage of the program-speci\u0080c graph characteristics) and\nexpensive (i.e. require heavy information exchange among nodes in the graph) message-passing procedure,\nGNN can su\u0082er from precision issues, especially when dealing with programs rendered into large graphs.\nIn this paper, we present a new graph neural architecture, called Graph Interval Neural Network (GINN),\nto tackle the weaknesses of the existing GNN. Unlike the standard GNN, GINN generalizes from a curated\ngraph representation obtained through an abstraction method designed to aid models to learn. In particular,\nGINN focuses exclusively on intervals (generally manifested in looping construct) for mining the feature\nrepresentation of a program, furthermore, GINN operates on a hierarchy of intervals for scaling the learning\nto large graphs.\nWe evaluate GINN for two popular downstream applications: variable misuse prediction and method name\nprediction. Results show in both cases GINN outperforms the state-of-the-art models by a comfortable margin.\nWe have also created a neural bug detector based on GINN to catch null pointer deference bugs in Java code.\nWhile learning from the same 9,000 methods extracted from 64 projects, GINN-based bug detector signi\u0080cantly\noutperforms GNN-based bug detector on 13 unseen test projects. Next, we deploy our trained GINN-based\nbug detector and Facebook Infer, arguably the state-of-the-art static analysis tool, to scan the codebase of 20\nhighly starred projects on GitHub. \u008crough our manual inspection, we con\u0080rm 38 bugs out of 102 warnings\nraised by GINN-based bug detector compared to 34 bugs out of 129 warnings for Facebook Infer. We have\nreported 38 bugs GINN caught to developers, among which 11 have been \u0080xed and 12 have been con\u0080rmed\n(\u0080x pending). GINN has shown to be a general, powerful deep neural network for learning precise, semantic\nprogram embeddings."
}, {
    "py/object": "data.DataClassPaper",
    "Title": "Mining Source Code Repositories at Massive Scale using Language Modeling",
    "year": 2013,
    "ML_Techniques": "",
    "Category": "Code representation",
    "Sub_category": "",
    "Venue": "MSR",
    "Link": "http://homepages.inf.ed.ac.uk/csutton/publications/msr2013.pdf",
    "bibtex": "inproceedings{Liang2010_472,\n    author = \"Liang, Percy and Jordan, Michael I. and Klein, D.\",\n    title = \"Learning Programs: A Hierarchical Bayesian Approach\",\n    booktitle = \"ICML\",\n    year = \"2010\"\n}\n\n",
    "abstract": "The tens of thousands of high-quality open source\nsoftware projects on the Internet raise the exciting possibility\nof studying software development by finding patterns across\ntruly large source code repositories. This could enable new tools\nfor developing code, encouraging reuse, and navigating large\nprojects. In this paper, we build the first giga-token probabilistic\nlanguage model of source code, based on 352 million lines of\nJava. This is 100 times the scale of the pioneering work by\nHindle et al. The giga-token model is significantly better at the\ncode suggestion task than previous models. More broadly, our\napproach provides a new \u201clens\u201d for analyzing software projects,\nenabling new complexity metrics based on statistical analysis\nof large corpora. We call these metrics data-driven complexity\nmetrics. We propose new metrics that measure the complexity of\na code module and the topical centrality of a module to a software\nproject. In particular, it is possible to distinguish reusable utility\nclasses from classes that are part of a program\u2019s core logic based\nsolely on general information theoretic criteria."
}, {
    "py/object": "data.DataClassPaper",
    "Title": "Modular Tree Network for Source Code Representation Learning",
    "year": 2020,
    "ML_Techniques": "MTN, RNN",
    "Category": "Code representation",
    "Sub_category": "",
    "Venue": "TOSEM",
    "Link": "https://dl.acm.org/doi/abs/10.1145/3409331",
    "bibtex": "article{Wang2020_475,\n    author = \"Wang, Wenhan and Li, Ge and Shen, Sijie and Xia, Xin and Jin, Zhi\",\n    title = \"Modular Tree Network for Source Code Representation Learning\",\n    year = \"2020\",\n    issue_date = \"October 2020\",\n    publisher = \"Association for Computing Machinery\",\n    address = \"New York, NY, USA\",\n    volume = \"29\",\n    number = \"4\",\n    issn = \"1049-331X\",\n    url = \"https://doi.org/10.1145/3409331\",\n    doi = \"10.1145/3409331\",\n    journal = \"ACM Trans. Softw. Eng. Methodol.\",\n    month = \"September\",\n    articleno = \"31\",\n    numpages = \"23\",\n    keywords = \"Deep learning, code clone detection, neural networks, program classification\"\n}\n\n",
    "abstract": "Learning representation for source code is a foundation of many program analysis tasks. In recent years,\nneural networks have already shown success in this area, but most existing models did not make full use of\nthe unique structural information of programs. Although abstract syntax tree (AST)-based neural models can\nhandle the tree structure in the source code, they cannot capture the richness of different types of substructure\nin programs. In this article, we propose a modular tree network that dynamically composes different\nneural network units into tree structures based on the input AST. Different from previous tree-structural\nneural network models, a modular tree network can capture the semantic differences between types of AST\nsubstructures. We evaluate our model on two tasks: program classification and code clone detection. Our\nmodel achieves the best performance compared with state-of-the-art approaches in both tasks, showing the\nadvantage of leveraging more elaborate structure information of the source code."
}, {
    "py/object": "data.DataClassPaper",
    "Title": "Open Vocabulary Learning on Source Code with a Graph-Structured Cache",
    "year": 2019,
    "ML_Techniques": "GNN",
    "Category": "Code representation",
    "Sub_category": "",
    "Venue": "ICML",
    "Link": "http://proceedings.mlr.press/v97/cvitkovic19b.html",
    "bibtex": "InProceedings{Cvitkovic2019_476,\n    author = \"Cvitkovic, Milan and Singh, Badal and Anandkumar, Animashree\",\n    editor = \"Chaudhuri, Kamalika and Salakhutdinov, Ruslan\",\n    title = \"Open Vocabulary Learning on Source Code with a Graph-Structured Cache\",\n    pages = \"1475--1485\",\n    year = \"2019\",\n    volume = \"97\",\n    series = \"Proceedings of Machine Learning Research\",\n    address = \"Long Beach, California, USA\",\n    month = \"09--15 Jun\",\n    publisher = \"PMLR\",\n    pdf = \"http://proceedings.mlr.press/v97/cvitkovic19b/cvitkovic19b.pdf\",\n    url = \"http://proceedings.mlr.press/v97/cvitkovic19b.html\"\n}\n\n",
    "abstract": "Machine learning models that take computer program\nsource code as input typically use Natural\nLanguage Processing (NLP) techniques. However,\na major challenge is that code is written\nusing an open, rapidly changing vocabulary due\nto, e.g., the coinage of new variable and method\nnames. Reasoning over such a vocabulary is not\nsomething for which most NLP methods are designed.\nWe introduce a Graph\u2013Structured Cache\nto address this problem; this cache contains a\nnode for each new word the model encounters\nwith edges connecting each word to its occurrences\nin the code. We find that combining\nthis graph\u2013structured cache strategy with recent\nGraph\u2013Neural\u2013Network\u2013based models for supervised\nlearning on code improves the models\u2019 performance\non a code completion task and a variable\nnaming task \u2014 with over 100% relative improvement\non the latter \u2014 at the cost of a moderate\nincrease in computation time."
}, {
    "py/object": "data.DataClassPaper",
    "Title": "RobustFill: Neural Program Learning under Noisy I/O",
    "year": 2017,
    "ML_Techniques": "RNN",
    "Category": "Program synthesis",
    "Sub_category": "",
    "Venue": "ICML",
    "Link": "https://arxiv.org/abs/1703.07469v1",
    "bibtex": "inproceedings{Devlin2017_480,\n    author = \"Devlin, Jacob and Uesato, Jonathan and Bhupatiraju, Surya and Singh, Rishabh and Mohamed, Abdel-rahman and Kohli, Pushmeet\",\n    title = \"RobustFill: Neural Program Learning under Noisy I/O\",\n    year = \"2017\",\n    publisher = \"JMLR.org\",\n    abstract = \"The problem of automatically generating a computer program from some specification has been studied since the early days of AI. Recently, two competing approaches for automatic program learning have received significant attention: (1) neural program synthesis, where a neural network is conditioned on input/output (I/O) examples and learns to generate a program, and (2) neural program induction, where a neural network generates new outputs directly using a latent program representation. Here, for the first time, we directly compare both approaches on a large-scale, real-world learning task and we additionally contrast to rule-based program synthesis, which uses hand-crafted semantics to guide the program generation. Our neural models use a modified attention RNN to allow encoding of variable-sized sets of I/O pairs, which achieve 92\\% accuracy on a real-world test set, compared to the 34\\% accuracy of the previous best neural synthesis approach. The synthesis model also outperforms a comparable induction model on this task, but we more importantly demonstrate that the strength of each approach is highly dependent on the evaluation metric and end-user application. Finally, we show that we can train our neural models to remain very robust to the type of noise expected in real-world data (e.g., typos), while a highly-engineered rule-based system fails entirely.\",\n    booktitle = \"Proceedings of the 34th International Conference on Machine Learning - Volume 70\",\n    pages = \"990\u2013998\",\n    numpages = \"9\",\n    location = \"Sydney, NSW, Australia\",\n    series = \"ICML'17\"\n}\n\n",
    "abstract": "The problem of automatically generating a computer program from some specification has been studied since the early days of AI. Recently, two competing approaches for automatic program learning have received significant attention: (1) neural program synthesis, where a neural network is conditioned on input/output (I/O) examples and learns to generate a program, and (2) neural program induction, where a neural network generates new outputs directly using a latent program representation.\nHere, for the first time, we directly compare both approaches on a large-scale, real-world learning task. We additionally contrast to rule-based program synthesis, which uses hand-crafted semantics to guide the program generation. Our neural models use a modified attention RNN to allow encoding of variable-sized sets of I/O pairs. Our best synthesis model achieves 92% accuracy on a real-world test set, compared to the 34% accuracy of the previous best neural synthesis approach. The synthesis model also outperforms a comparable induction model on this task, but we more importantly demonstrate that the strength of each approach is highly dependent on the evaluation metric and end-user application. Finally, we show that we can train our neural models to remain very robust to the type of noise expected in real-world data (e.g., typos), while a highly-engineered rule-based system fails entirely."
}, {
    "py/object": "data.DataClassPaper",
    "Title": "Towards demystifying dimensions of source code embeddings",
    "year": 2020,
    "ML_Techniques": "Code2Vec",
    "Category": "Code representation",
    "Sub_category": "",
    "Venue": "RL+SE&PL",
    "Link": "https://dl.acm.org/doi/10.1145/3416506.3423580",
    "bibtex": "inproceedings{Devlin2017_480,\n    author = \"Devlin, Jacob and Uesato, Jonathan and Bhupatiraju, Surya and Singh, Rishabh and Mohamed, Abdel-rahman and Kohli, Pushmeet\",\n    title = \"RobustFill: Neural Program Learning under Noisy I/O\",\n    year = \"2017\",\n    publisher = \"JMLR.org\",\n    abstract = \"The problem of automatically generating a computer program from some specification has been studied since the early days of AI. Recently, two competing approaches for automatic program learning have received significant attention: (1) neural program synthesis, where a neural network is conditioned on input/output (I/O) examples and learns to generate a program, and (2) neural program induction, where a neural network generates new outputs directly using a latent program representation. Here, for the first time, we directly compare both approaches on a large-scale, real-world learning task and we additionally contrast to rule-based program synthesis, which uses hand-crafted semantics to guide the program generation. Our neural models use a modified attention RNN to allow encoding of variable-sized sets of I/O pairs, which achieve 92\\% accuracy on a real-world test set, compared to the 34\\% accuracy of the previous best neural synthesis approach. The synthesis model also outperforms a comparable induction model on this task, but we more importantly demonstrate that the strength of each approach is highly dependent on the evaluation metric and end-user application. Finally, we show that we can train our neural models to remain very robust to the type of noise expected in real-world data (e.g., typos), while a highly-engineered rule-based system fails entirely.\",\n    booktitle = \"Proceedings of the 34th International Conference on Machine Learning - Volume 70\",\n    pages = \"990\u2013998\",\n    numpages = \"9\",\n    location = \"Sydney, NSW, Australia\",\n    series = \"ICML'17\"\n}\n\n",
    "abstract": "Source code representations are key in applying machine learning\ntechniques for processing and analyzing programs. A popular approach\nin representing source code is neural source code embedding\nthat represents programs with high-dimensional vectors computed\nby training deep neural networks on a large volume of programs.\nAlthough successful, there is li\u008ale known about the contents of\nthese vectors and their characteristics.\nIn this paper, we present our preliminary results towards be\u008aer\nunderstanding the contents of code2vec neural source code embeddings.\nIn particular, in a small case study, we use the embeddings\nto create binary SVM classi\u0080ers and we compare their performance\nwith handcra\u0089ed features. Our results suggest that the handcra\u0089ed\nfeatures can perform very close to highly-dimensional code2vec\nembeddings, and the information gains are more evenly distributed\nin the code2vec embeddings compared to handcra\u0089ed features. We\nalso \u0080nd that code2vec is more resilient to the removal of dimensions\nwith low information gains than handcra\u0089ed features. We\nhope our results serve a stepping stone toward principled analysis\nand evaluation of these code representations."
}, {
    "py/object": "data.DataClassPaper",
    "Title": "user2code2vec: Embeddings for Profiling Students Based on Distributional Representations of Source Code",
    "year": 2019,
    "ML_Techniques": "",
    "Category": "Code representation",
    "Sub_category": "",
    "Venue": "LAK",
    "Link": "https://dl.acm.org/doi/10.1145/3303772.3303813",
    "bibtex": "inproceedings{Devlin2017_480,\n    author = \"Devlin, Jacob and Uesato, Jonathan and Bhupatiraju, Surya and Singh, Rishabh and Mohamed, Abdel-rahman and Kohli, Pushmeet\",\n    title = \"RobustFill: Neural Program Learning under Noisy I/O\",\n    year = \"2017\",\n    publisher = \"JMLR.org\",\n    abstract = \"The problem of automatically generating a computer program from some specification has been studied since the early days of AI. Recently, two competing approaches for automatic program learning have received significant attention: (1) neural program synthesis, where a neural network is conditioned on input/output (I/O) examples and learns to generate a program, and (2) neural program induction, where a neural network generates new outputs directly using a latent program representation. Here, for the first time, we directly compare both approaches on a large-scale, real-world learning task and we additionally contrast to rule-based program synthesis, which uses hand-crafted semantics to guide the program generation. Our neural models use a modified attention RNN to allow encoding of variable-sized sets of I/O pairs, which achieve 92\\% accuracy on a real-world test set, compared to the 34\\% accuracy of the previous best neural synthesis approach. The synthesis model also outperforms a comparable induction model on this task, but we more importantly demonstrate that the strength of each approach is highly dependent on the evaluation metric and end-user application. Finally, we show that we can train our neural models to remain very robust to the type of noise expected in real-world data (e.g., typos), while a highly-engineered rule-based system fails entirely.\",\n    booktitle = \"Proceedings of the 34th International Conference on Machine Learning - Volume 70\",\n    pages = \"990\u2013998\",\n    numpages = \"9\",\n    location = \"Sydney, NSW, Australia\",\n    series = \"ICML'17\"\n}\n\n",
    "abstract": "In this work, we propose a new methodology to profile individual\nstudents of computer science based on their programming design\nusing a technique called embeddings. We investigate different approaches\nto analyze user source code submissions in the Python\nlanguage. We compare the performances of different source code\nvectorization techniques to predict the correctness of a code submission.\nIn addition, we propose a new mechanism to represent\nstudents based on their code submissions for a given set of laboratory\ntasks on a particular course. This way, we can make deeper\nrecommendations for programming solutions and pathways to support\nstudent learning and progression in computer programming\nmodules effectively at a Higher Education Institution. Recent work\nusing Deep Learning tends to work better when more and more\ndata is provided. However, in Learning Analytics, the number of\nstudents in a course is an unavoidable limit. Thus we cannot simply\ngenerate more data as is done in other domains such as FinTech\nor Social Network Analysis. Our findings indicate there is a need\nto learn and develop better mechanisms to extract and learn effective\ndata features from students so as to analyze the students\u2019\nprogression and performance effectively."
}, {
    "py/object": "data.DataClassPaper",
    "Title": "A Neural Network Based Intelligent Support Model for Program Code Completion",
    "year": 2020,
    "ML_Techniques": "LSTM",
    "Category": "Code completion",
    "Sub_category": "",
    "Venue": "SP",
    "Link": "https://www.hindawi.com/journals/sp/2020/7426461/",
    "bibtex": "article{Rahman2020_484,\n    author = \"Rahman, M. and Watanobe, Yutaka and Nakamura, K.\",\n    title = \"A Neural Network Based Intelligent Support Model for Program Code Completion\",\n    journal = \"Sci. Program.\",\n    year = \"2020\",\n    volume = \"2020\",\n    doi = \"10.1155/2020/7426461\",\n    pages = \"7426461:1-7426461:18\"\n}\n\n",
    "abstract": "In recent years, millions of source codes are generated in different languages on a daily basis all over the world. A deep neural network-based intelligent support model for source code completion would be a great advantage in software engineering and programming education fields. Vast numbers of syntax, logical, and other critical errors that cannot be detected by normal compilers continue to exist in source codes, and the development of an intelligent evaluation methodology that does not rely on manual compilation has become essential. Even experienced programmers often find it necessary to analyze an entire program in order to find a single error and are thus being forced to waste valuable time debugging their source codes. With this point in mind, we proposed an intelligent model that is based on long short-term memory (LSTM) and combined it with an attention mechanism for source code completion. Thus, the proposed model can detect source code errors with locations and then predict the correct words. In addition, the proposed model can classify the source codes as to whether they are erroneous or not. We trained our proposed model using the source code and then evaluated the performance. All of the data used in our experiments were extracted from Aizu Online Judge (AOJ) system. The experimental results obtained show that the accuracy in terms of error detection and prediction of our proposed model approximately is 62% and source code classification accuracy is approximately 96% which outperformed a standard LSTM and other state-of-the-art models. Moreover, in comparison to state-of-the-art models, our proposed model achieved an interesting level of success in terms of error detection, prediction, and classification when applied to long source code sequences. Overall, these experimental results indicate the usefulness of our proposed model in software engineering and programming education arena."
}, {
    "py/object": "data.DataClassPaper",
    "Title": "A Self-Attentional Neural Architecture for Code Completion with Multi-Task Learning",
    "year": 2020,
    "ML_Techniques": "MTN, RNN",
    "Category": "Code completion",
    "Sub_category": "",
    "Venue": "ICPC",
    "Link": "https://dl.acm.org/doi/abs/10.1145/3387904.3389261",
    "bibtex": "inproceedings{Liu2020_485,\n    author = \"Liu, Fang and Li, Ge and Wei, Bolin and Xia, Xin and Fu, Zhiyi and Jin, Zhi\",\n    title = \"A Self-Attentional Neural Architecture for Code Completion with Multi-Task Learning\",\n    year = \"2020\",\n    isbn = \"9781450379588\",\n    publisher = \"Association for Computing Machinery\",\n    address = \"New York, NY, USA\",\n    url = \"https://doi.org/10.1145/3387904.3389261\",\n    doi = \"10.1145/3387904.3389261\",\n    abstract = \"Code completion, one of the most useful features in the Integrated Development Environments (IDEs), can accelerate software development by suggesting the libraries, APIs, and method names in real-time. Recent studies have shown that statistical language models can improve the performance of code completion tools through learning from large-scale software repositories. However, these models suffer from three major drawbacks: a) The hierarchical structural information of the programs is not fully utilized in the program's representation; b) In programs, the semantic relationships can be very long. Existing recurrent neural networks based language models are not sufficient to model the long-term dependency. c) Existing approaches perform a specific task in one model, which leads to the underuse of the information from related tasks. To address these challenges, in this paper, we propose a self-attentional neural architecture for code completion with multi-task learning. To utilize the hierarchical structural information of the programs, we present a novel method that considers the path from the predicting node to the root node. To capture the long-term dependency in the input programs, we adopt a self-attentional architecture based network as the base language model. To enable the knowledge sharing between related tasks, we creatively propose a Multi-Task Learning (MTL) framework to learn two related tasks in code completion jointly. Experiments on three real-world datasets demonstrate the effectiveness of our model when compared with state-of-the-art methods.\",\n    booktitle = \"Proceedings of the 28th International Conference on Program Comprehension\",\n    pages = \"37\u201347\",\n    numpages = \"11\",\n    keywords = \"Self-attention, Multi-task learning, Hierarchical structure, Code completion\",\n    location = \"Seoul, Republic of Korea\",\n    series = \"ICPC '20\"\n}\n\n",
    "abstract": "Code completion, one of the most useful features in the Integrated Development Environments (IDEs), can accelerate software development by suggesting the libraries, APIs, and method names in real-time. Recent studies have shown that statistical language models can improve the performance of code completion tools through learning from large-scale software repositories. However, these models suffer from three major drawbacks: a) The hierarchical structural information of the programs is not fully utilized in the program's representation; b) In programs, the semantic relationships can be very long. Existing recurrent neural networks based language models are not sufficient to model the long-term dependency. c) Existing approaches perform a specific task in one model, which leads to the underuse of the information from related tasks. To address these challenges, in this paper, we propose a self-attentional neural architecture for code completion with multi-task learning. To utilize the hierarchical structural information of the programs, we present a novel method that considers the path from the predicting node to the root node. To capture the long-term dependency in the input programs, we adopt a self-attentional architecture based network as the base language model. To enable the knowledge sharing between related tasks, we creatively propose a Multi-Task Learning (MTL) framework to learn two related tasks in code completion jointly. Experiments on three real-world datasets demonstrate the effectiveness of our model when compared with state-of-the-art methods."
}, {
    "py/object": "data.DataClassPaper",
    "Title": "Code Completion for Programming Education based on Recurrent Neural Network",
    "year": 2019,
    "ML_Techniques": "LSTM",
    "Category": "Code completion",
    "Sub_category": "",
    "Venue": "IWCIA",
    "Link": "https://ieeexplore.ieee.org/document/8955090",
    "bibtex": "INPROCEEDINGS{Terada2019_487,\n    author = \"{Terada}, K. and {Watanobe}, Y.\",\n    booktitle = \"2019 IEEE 11th International Workshop on Computational Intelligence and Applications (IWCIA)\",\n    title = \"Code Completion for Programming Education based on Recurrent Neural Network\",\n    year = \"2019\",\n    volume = \"\",\n    number = \"\",\n    pages = \"109-114\",\n    doi = \"10.1109/IWCIA47330.2019.8955090\"\n}\n\n",
    "abstract": "In solving programming problems, it is difficult for beginners to create program code from scratch. One way to navigate this difficulty is to provide a function of automatic code completion. In this work, we propose a method to predict the next word following a given incomplete program that has two key constituents, prediction of within-vocabulary words and prediction of identifiers. In terms of predicting within-vocabulary words, a neural language model based on a Long Short-Term Memory (LSTM) network is proposed. Regarding the prediction of identifiers, a model based on a pointer network is proposed. Additionally, a model for switching between these two models is proposed. For evaluation of the proposed method, source code accumulated in an online judge system is used. The results of the experiment demonstrate that the proposed method can predict both the next within-vocabulary word and the next identifier to a high degree of accuracy."
}, {
    "py/object": "data.DataClassPaper",
    "Title": "Code Completion from Abbreviated Input",
    "year": 2009,
    "ML_Techniques": "HMM",
    "Category": "Code completion",
    "Sub_category": "",
    "Venue": "ASE",
    "Link": "https://ieeexplore.ieee.org/abstract/document/5431761",
    "bibtex": "INPROCEEDINGS{Han2009_488,\n    author = \"{Han}, S. and {Wallace}, D. R. and {Miller}, R. C.\",\n    booktitle = \"2009 IEEE/ACM International Conference on Automated Software Engineering\",\n    title = \"Code Completion from Abbreviated Input\",\n    year = \"2009\",\n    volume = \"\",\n    number = \"\",\n    pages = \"332-343\",\n    doi = \"10.1109/ASE.2009.64\"\n}\n\n",
    "abstract": "Abbreviation Completion is a novel technique to improve the efficiency of code-writing by supporting code completion of multiple keywords based on non-predefined abbreviated input - a different approach from conventional code completion that finds one keyword at a time based on an exact character match. Abbreviated input is expanded into keywords by a Hidden Markov Model learned from a corpus of existing code. The technique does not require the user to memorize abbreviations and provides incremental feedback of the most likely completions. This paper presents the algorithm for abbreviation completion, integrated with a new user interface for multiple-keyword completion. We tested the system by sampling 3000 code lines from open source projects and found that more than 98% of the code lines could be resolved from acronym-like abbreviations. A user study found 30% reduction in time usage and 41% reduction of keystrokes over conventional code completion."
}, {
    "py/object": "data.DataClassPaper",
    "Title": "Code completion of multiple keywords from abbreviated input",
    "year": 2011,
    "ML_Techniques": "HMM",
    "Category": "Code completion",
    "Sub_category": "",
    "Venue": "ASE",
    "Link": "https://link.springer.com/article/10.1007%2Fs10515-011-0083-2",
    "bibtex": "INPROCEEDINGS{Han2009_488,\n    author = \"{Han}, S. and {Wallace}, D. R. and {Miller}, R. C.\",\n    booktitle = \"2009 IEEE/ACM International Conference on Automated Software Engineering\",\n    title = \"Code Completion from Abbreviated Input\",\n    year = \"2009\",\n    volume = \"\",\n    number = \"\",\n    pages = \"332-343\",\n    doi = \"10.1109/ASE.2009.64\"\n}\n\n",
    "abstract": "Abbreviation Completion is a novel technique to improve the efficiency of code-writing by supporting code completion of multiple keywords based on non-predefined abbreviated input--a different approach from conventional code completion that finds one keyword at a time based on an exact character match. Abbreviated input consisting of abbreviated keywords and non-alphanumeric characters between each abbreviated keyword (e.g. pb st nm) is expanded into a full expression (e.g. public String name) by a Hidden Markov Model learned from a corpus of existing code and abbreviation examples. The technique does not require the user to memorize abbreviations and provides incremental feedback of the most likely completions.\n\nIn addition to code completion by disabbreviation of multiple keywords, abbreviation completion supports prediction of the next keywords and non-alphanumeric characters of a code completion candidate, a technique called code completion by extrapolation. The system finds the most likely next keywords and non-alphanumeric characters using an n-gram model of programming language. This enables a code completion scenario in which a user first types a short abbreviated expression to complete the beginning part of a desired full expression and then uses the extrapolation feature to complete the remaining part without further typing.\n\nThis paper presents the algorithm for abbreviation completion, integrated with a new user interface for multiple-keyword code completion. We tested the system by sampling 4919 code lines from open source projects and found that more than 99% of the code lines could be resolved from acronym-like abbreviations. The system could also extrapolate code completion candidates to complete the next one or two keywords with the accuracy of 96% and 82%, respectively. A user study of code completion by disabbreviation found 30% reduction in time usage and 41% reduction of keystrokes over conventional code completion."
}, {
    "py/object": "data.DataClassPaper",
    "Title": "Code Completion with Neural Attention and Pointer Networks",
    "year": 2018,
    "ML_Techniques": "RNN",
    "Category": "Code completion",
    "Sub_category": "",
    "Venue": "IJCAI",
    "Link": "https://dl.acm.org/doi/10.5555/3304222.3304348",
    "bibtex": "inproceedings{Li2018_491,\n    author = \"Li, Jian and Wang, Yue and Lyu, Michael R. and King, Irwin\",\n    title = \"Code Completion with Neural Attention and Pointer Networks\",\n    year = \"2018\",\n    isbn = \"9780999241127\",\n    publisher = \"AAAI Press\",\n    abstract = \"Intelligent code completion has become an essential research task to accelerate modern software development. To facilitate effective code completion for dynamically-typed programming languages, we apply neural language models by learning from large codebases, and develop a tailored attention mechanism for code completion. However, standard neural language models even with attention mechanism cannot correctly predict the out-of-vocabulary (OoV) words that restrict the code completion performance. In this paper, inspired by the prevalence of locally repeated terms in program source code, and the recently proposed pointer copy mechanism, we propose a pointer mixture network for better predicting OoV words in code completion. Based on the context, the pointer mixture network learns to either generate a within-vocabulary word through an RNN component, or regenerate an OoV word from local context through a pointer component. Experiments on two benchmarked datasets demonstrate the effectiveness of our attention mechanism and pointer mixture network on the code completion task.\",\n    booktitle = \"Proceedings of the 27th International Joint Conference on Artificial Intelligence\",\n    pages = \"4159\u201325\",\n    numpages = \"7\",\n    location = \"Stockholm, Sweden\",\n    series = \"IJCAI'18\"\n}\n\n",
    "abstract": "Intelligent code completion has become an essential research task to accelerate modern software development. To facilitate effective code completion for dynamically-typed programming languages, we apply neural language models by learning from large codebases, and develop a tailored attention mechanism for code completion. However, standard neural language models even with attention mechanism cannot correctly predict the out-of-vocabulary (OoV) words that restrict the code completion performance. In this paper, inspired by the prevalence of locally repeated terms in program source code, and the recently proposed pointer copy mechanism, we propose a pointer mixture network for better predicting OoV words in code completion. Based on the context, the pointer mixture network learns to either generate a within-vocabulary word through an RNN component, or regenerate an OoV word from local context through a pointer component. Experiments on two benchmarked datasets demonstrate the effectiveness of our attention mechanism and pointer mixture network on the code completion task."
}, {
    "py/object": "data.DataClassPaper",
    "Title": "CodeGRU: Context-aware deep learning with gated recurrent unit for source code modeling",
    "year": 2020,
    "ML_Techniques": "GRU",
    "Category": "Code completion",
    "Sub_category": "",
    "Venue": "IST",
    "Link": "https://www.sciencedirect.com/science/article/abs/pii/S0950584920300616",
    "bibtex": "article{Hussain2020_492,\n    author = \"Hussain, Yasir and Huang, Zhiqiu and Zhou, Yu and Wang, Senzhang\",\n    title = \"CodeGRU: Context-aware deep learning with gated recurrent unit for source code modeling\",\n    journal = \"Information and Software Technology\",\n    volume = \"125\",\n    pages = \"106309\",\n    year = \"2020\",\n    issn = \"0950-5849\",\n    doi = \"https://doi.org/10.1016/j.infsof.2020.106309\",\n    url = \"http://www.sciencedirect.com/science/article/pii/S0950584920300616\",\n    keywords = \"Machine learning, Deep learning, Software language models, Source code suggestion, Source code completion\",\n    abstract = \"Context: Recently deep learning based Natural Language Processing (NLP) models have shown great potential in the modeling of source code. However, a major limitation of these approaches is that they take source code as simple tokens of text and ignore its contextual, syntactical and structural dependencies. Objective: In this work, we present CodeGRU, a gated recurrent unit based source code language model that is capable of capturing source code\u2019s contextual, syntactical and structural dependencies. Method: We introduce a novel approach which can capture the source code context by leveraging the source code token types. Further, we adopt a novel approach which can learn variable size context by taking into account source code\u2019s syntax, and structural information. Results: We evaluate CodeGRU with real-world data set and it shows that CodeGRU outperforms the state-of-the-art language models and help reduce the vocabulary size up to 24.93\\%. Unlike previous works, we tested CodeGRU with an independent test set which suggests that our methodology does not requisite the source code comes from the same domain as training data while providing suggestions. We further evaluate CodeGRU with two software engineering applications: source code suggestion, and source code completion. Conclusion: Our experiment confirms that the source code\u2019s contextual information can be vital and can help improve the software language models. The extensive evaluation of CodeGRU shows that it outperforms the state-of-the-art models. The results further suggest that the proposed approach can help reduce the vocabulary size and is of practical use for software developers.\"\n}\n\n",
    "abstract": "Recently deep learning based Natural Language Processing (NLP) models have shown great potential in the modeling of source code. However, a major limitation of these approaches is that they take source code as simple tokens of text and ignore its contextual, syntactical and structural dependencies. In this work, we present CodeGRU, a gated recurrent unit based source code language model that is capable of capturing source code's contextual, syntactical and structural dependencies. We introduce a novel approach which can capture the source code context by leveraging the source code token types. Further, we adopt a novel approach which can learn variable size context by taking into account source code's syntax, and structural information. We evaluate CodeGRU with real-world data set and it shows that CodeGRU outperforms the state-of-the-art language models and help reduce the vocabulary size up to 24.93\\%. Unlike previous works, we tested CodeGRU with an independent test set which suggests that our methodology does not requisite the source code comes from the same domain as training data while providing suggestions. We further evaluate CodeGRU with two software engineering applications: source code suggestion, and source code completion. Our experiment confirms that the source code's contextual information can be vital and can help improve the software language models. The extensive evaluation of CodeGRU shows that it outperforms the state-of-the-art models. The results further suggest that the proposed approach can help reduce the vocabulary size and is of practical use for software developers."
}, {
    "py/object": "data.DataClassPaper",
    "Title": "Deep Learning Based Code Completion Models for Programming Codes",
    "year": 2019,
    "ML_Techniques": "LSTM",
    "Category": "Code completion",
    "Sub_category": "",
    "Venue": "ISCSIC",
    "Link": "https://dl.acm.org/doi/10.1145/3386164.3389083",
    "bibtex": "inproceedings{Wang2019_494,\n    author = \"Wang, Shuai and Liu, Jinyang and Qiu, Ye and Ma, Zhiyi and Liu, Junfei and Wu, Zhonghai\",\n    title = \"Deep Learning Based Code Completion Models for Programming Codes\",\n    year = \"2019\",\n    isbn = \"9781450376617\",\n    publisher = \"Association for Computing Machinery\",\n    address = \"New York, NY, USA\",\n    url = \"https://doi.org/10.1145/3386164.3389083\",\n    doi = \"10.1145/3386164.3389083\",\n    booktitle = \"Proceedings of the 2019 3rd International Symposium on Computer Science and Intelligent Control\",\n    articleno = \"16\",\n    numpages = \"9\",\n    keywords = \"Deep Learning, Software Engineering, Artificial Intelligence, Programming Language\",\n    location = \"Amsterdam, Netherlands\",\n    series = \"ISCSIC 2019\"\n}\n\n",
    "abstract": "With the fast development of Information Technology, program software and mobile applications have been widely used in the world, and are playing important roles in human's daily life. Thus, writing programming codes has been important work in many fields. however, it is a hard and time-cost task which presents a great amount of workload to programmers. To make programmers' work easier, intelligent code completion models have been a popular research topic in recent years. This paper designs Deep Learning based models to automatically complete programming codes, which are LSTM-based neural networks, and are combined with several techniques such as Word Embedding models in NLP (Natural Language Processing), and Multihead Attention Mechanism. Moreover, in the models, this paper raises a new algorithm of generating input sequences from partial AST (Abstract Syntax Tree) that have most relevance with nodes to be predicted which is named as RZT (Reverse Zig-zag Traverse) Algorithm, and is the first work of applying Multihead Attention Block into this task. This paper makes insight into codes of several different programming languages, and the models this paper presents show good performances in accuracy comparing with the state-of-art models."
}, {
    "py/object": "data.DataClassPaper",
    "Title": "Deep Learning-Based Logging Recommendation Using Merged Code Representation",
    "year": 2021,
    "ML_Techniques": "LSTM",
    "Category": "Code completion",
    "Sub_category": "",
    "Venue": "ITCS",
    "Link": "https://link.springer.com/chapter/10.1007/978-981-15-9354-3_5",
    "bibtex": "InProceedings{Lee2021_495,\n    author = \"Lee, Suin and Lee, Youngseok and Lee, Chan-Gun and Woo, Honguk\",\n    editor = \"Kim, Hyuncheol and Kim, Kuinam J.\",\n    title = \"Deep Learning-Based Logging Recommendation Using Merged Code Representation\",\n    booktitle = \"IT Convergence and Security\",\n    year = \"2021\",\n    publisher = \"Springer Singapore\",\n    address = \"Singapore\",\n    pages = \"49--53\",\n    abstract = \"When developing a large scale software product, it is essential to share a common set of structural coding guidelines and standards among the project team members. In this paper, we propose MergeLogging, a deep learning-based merged network using various code representations for automated logging decisions or other tasks. MergeLogging archives the enhanced recommendation ability that utilizes orthogonal code features from code representations. Our case study with three open-source project datasets demonstrates that logging accuracy can reach as high as 93{\\\\%}.\",\n    isbn = \"978-981-15-9354-3\"\n}\n\n",
    "abstract": "When developing a large scale software product, it is essential to share a common set of structural coding guidelines and standards among the project team members. In this paper, we propose MergeLogging, a deep learning-based merged network using various code representations for automated logging decisions or other tasks. MergeLogging archives the enhanced recommendation ability that utilizes orthogonal code features from code representations. Our case study with three open-source project datasets demonstrates that logging accuracy can reach as high as 93%."
}, {
    "py/object": "data.DataClassPaper",
    "Title": "Improve Language Modeling for Code Completion Through Learning General Token Repetition of Source Code with Optimized Memory",
    "year": 2019,
    "ML_Techniques": "MNN",
    "Category": "Code completion",
    "Sub_category": "",
    "Venue": "IJSEKE",
    "Link": "https://www.worldscientific.com/doi/abs/10.1142/S0218194019400229",
    "bibtex": "article{Yang2019_496,\n    author = \"Yang, Yixiao and Chen, Xiang and Sun, Jiaguang\",\n    title = \"Improve Language Modeling for Code Completion Through Learning General Token Repetition of Source Code with Optimized Memory\",\n    journal = \"International Journal of Software Engineering and Knowledge Engineering\",\n    volume = \"29\",\n    number = \"11n12\",\n    pages = \"1801-1818\",\n    year = \"2019\",\n    doi = \"10.1142/S0218194019400229\",\n    URL = \"https://doi.org/10.1142/S0218194019400229\",\n    eprint = \"https://doi.org/10.1142/S0218194019400229\",\n    abstract = \"In last few years, applying language model to source code is the state-of-the-art method for solving the problem of code completion. However, compared with natural language, code has more obvious repetition characteristics. For example, a variable can be used many times in the following code. Variables in source code have a high chance to be repetitive. Cloned code and templates, also have the property of token repetition. Capturing the token repetition of source code is important. In different projects, variables or types are usually named differently. This means that a model trained in a finite data set will encounter a lot of unseen variables or types in another data set. How to model the semantics of the unseen data and how to predict the unseen data based on the patterns of token repetition are two challenges in code completion. Hence, in this paper, token repetition is modelled as a graph, we propose a novel REP model which is based on deep neural graph network to learn the code toke repetition. The REP model is to identify the edge connections of a graph to recognize the token repetition. For predicting the token repetition of token n, the information of all the previous tokens needs to be considered. We use memory neural network (MNN) to model the semantics of each distinct token to make the framework of REP model more targeted. The experiments indicate that the REP model performs better than LSTM model. Compared with Attention-Pointer network, we also discover that the attention mechanism does not work in all situations. The proposed REP model could achieve similar or slightly better prediction accuracy compared to Attention-Pointer network and consume less training time. We also find other attention mechanism which could further improve the prediction accuracy.\"\n}\n\n",
    "abstract": "In last few years, applying language model to source code is the state-of-the-art method for solving the problem of code completion. However, compared with natural language, code has more obvious repetition characteristics. For example, a variable can be used many times in the following code. Variables in source code have a high chance to be repetitive. Cloned code and templates, also have the property of token repetition. Capturing the token repetition of source code is important. In different projects, variables or types are usually named differently. This means that a model trained in a finite data set will encounter a lot of unseen variables or types in another data set. How to model the semantics of the unseen data and how to predict the unseen data based on the patterns of token repetition are two challenges in code completion. Hence, in this paper, token repetition is modelled as a graph, we propose a novel REP model which is based on deep neural graph network to learn the code toke repetition. The REP model is to identify the edge connections of a graph to recognize the token repetition. For predicting the token repetition of token n, the information of all the previous tokens needs to be considered. We use memory neural network (MNN) to model the semantics of each distinct token to make the framework of REP model more targeted. The experiments indicate that the REP model performs better than LSTM model. Compared with Attention-Pointer network, we also discover that the attention mechanism does not work in all situations. The proposed REP model could achieve similar or slightly better prediction accuracy compared to Attention-Pointer network and consume less training time. We also find other attention mechanism which could further improve the prediction accuracy.\n\n"
}, {
    "py/object": "data.DataClassPaper",
    "Title": "Improving Code Recommendations by Combining Neural and Classical Machine Learning Approaches",
    "year": 2020,
    "ML_Techniques": "RNN, PN",
    "Category": "Code completion",
    "Sub_category": "",
    "Venue": "ICSEW",
    "Link": "https://dl.acm.org/doi/10.1145/3387940.3391489",
    "bibtex": "inproceedings{Schumacher2020_497,\n    author = \"Schumacher, Max Eric Henry and Le, Kim Tuyen and Andrzejak, Artur\",\n    title = \"Improving Code Recommendations by Combining Neural and Classical Machine Learning Approaches\",\n    year = \"2020\",\n    isbn = \"9781450379632\",\n    publisher = \"Association for Computing Machinery\",\n    address = \"New York, NY, USA\",\n    url = \"https://doi.org/10.1145/3387940.3391489\",\n    doi = \"10.1145/3387940.3391489\",\n    booktitle = \"Proceedings of the IEEE/ACM 42nd International Conference on Software Engineering Workshops\",\n    pages = \"476\u2013482\",\n    numpages = \"7\",\n    keywords = \"neural networks, code recommendations, machine learning\",\n    location = \"Seoul, Republic of Korea\",\n    series = \"ICSEW'20\"\n}\n\n",
    "abstract": "Code recommendation systems for software engineering are designed to accelerate the development of large software projects. A classical example is code completion or next token prediction offered by modern integrated development environments. A particular challenging case for such systems are dynamic languages like Python due to limited type information at editing time. Recently, researchers proposed machine learning approaches to address this challenge. In particular, the Probabilistic Higher Order Grammar technique (Bielik et al., ICML 2016) uses a grammar-based approach with a classical machine learning schema to exploit local context. A method by Li et al., (IJCAI 2018) uses deep learning methods, in detail a Recurrent Neural Network coupled with a Pointer Network. We compare these two approaches quantitatively on a large corpus of Python files from GitHub. We also propose a combination of both approaches, where a neural network decides which schema to use for each prediction. The proposed method achieves a slightly better accuracy than either of the systems alone. This demonstrates the potential of ensemble-like methods for code completion and recommendation tasks in dynamically typed languages."
}, {
    "py/object": "data.DataClassPaper",
    "Title": "Intelligent Code Completion with Bayesian Networks",
    "year": 2015,
    "ML_Techniques": "BN",
    "Category": "Code completion",
    "Sub_category": "",
    "Venue": "TOSEM",
    "Link": "https://dl.acm.org/doi/abs/10.1145/2744200",
    "bibtex": "article{Proksch2015_498,\n    author = \"Proksch, Sebastian and Lerch, Johannes and Mezini, Mira\",\n    title = \"Intelligent Code Completion with Bayesian Networks\",\n    year = \"2015\",\n    issue_date = \"December 2015\",\n    publisher = \"Association for Computing Machinery\",\n    address = \"New York, NY, USA\",\n    volume = \"25\",\n    number = \"1\",\n    issn = \"1049-331X\",\n    url = \"https://doi.org/10.1145/2744200\",\n    doi = \"10.1145/2744200\",\n    abstract = \"Code completion is an integral part of modern Integrated Development Environments (IDEs). Developers often use it to explore Application Programming Interfaces (APIs). It is also useful to reduce the required amount of typing and to help avoid typos. Traditional code completion systems propose all type-correct methods to the developer. Such a list is often very long with many irrelevant items. More intelligent code completion systems have been proposed in prior work to reduce the list of proposed methods to relevant items.This work extends one of these existing approaches, the Best Matching Neighbor (BMN) algorithm. We introduce Bayesian networks as an alternative underlying model, use additional context information for more precise recommendations, and apply clustering techniques to improve model sizes. We compare our new approach, Pattern-based Bayesian Networks (PBN), to the existing BMN algorithm. We extend previously used evaluation methodologies and, in addition to prediction quality, we also evaluate model size and inference speed.Our results show that the additional context information we collect improves prediction quality, especially for queries that do not contain method calls. We also show that PBN can obtain comparable prediction quality to BMN, while model size and inference speed scale better with large input sizes.\",\n    journal = \"ACM Trans. Softw. Eng. Methodol.\",\n    month = \"December\",\n    articleno = \"3\",\n    numpages = \"31\",\n    keywords = \"productivity, machine learning, integrated development environments, Content assist, code completion, evaluation, code recommender\"\n}\n\n",
    "abstract": "Code completion is an integral part of modern Integrated Development Environments (IDEs). Developers often use it to explore Application Programming Interfaces (APIs). It is also useful to reduce the required amount of typing and to help avoid typos. Traditional code completion systems propose all type-correct methods to the developer. Such a list is often very long with many irrelevant items. More intelligent code completion systems have been proposed in prior work to reduce the list of proposed methods to relevant items.\n\nThis work extends one of these existing approaches, the Best Matching Neighbor (BMN) algorithm. We introduce Bayesian networks as an alternative underlying model, use additional context information for more precise recommendations, and apply clustering techniques to improve model sizes. We compare our new approach, Pattern-based Bayesian Networks (PBN), to the existing BMN algorithm. We extend previously used evaluation methodologies and, in addition to prediction quality, we also evaluate model size and inference speed.\n\nOur results show that the additional context information we collect improves prediction quality, especially for queries that do not contain method calls. We also show that PBN can obtain comparable prediction quality to BMN, while model size and inference speed scale better with large input sizes."
}, {
    "py/object": "data.DataClassPaper",
    "Title": "JavaScript Code Suggestion Based on Deep Learning",
    "year": 2019,
    "ML_Techniques": "LSTM",
    "Category": "Code completion",
    "Sub_category": "",
    "Venue": "ICIAI",
    "Link": "https://dl.acm.org/doi/10.1145/3319921.3319922",
    "bibtex": "inproceedings{Zhong2019_499,\n    author = \"Zhong, Chaoliang and Yang, Ming and Sun, Jun\",\n    title = \"JavaScript Code Suggestion Based on Deep Learning\",\n    year = \"2019\",\n    isbn = \"9781450361286\",\n    publisher = \"Association for Computing Machinery\",\n    address = \"New York, NY, USA\",\n    url = \"https://doi.org/10.1145/3319921.3319922\",\n    doi = \"10.1145/3319921.3319922\",\n    abstract = \"Code suggestion system is widely used in integrated development environments (IDEs) for generating code recommendations while editing to improve program efficiency. Current most common systems focus on the settings that complete a single code unit or predict likely next single unit. In this paper, we describe a code suggestion prototype system for JavaScript based on Jupyter Notebook [1] (an IDE) to provide multiple successive code units completion. Our main work is as follows: 1. Provide a JavaScript pre-processing solution for feature extraction; 2. Apply several deep learning technologies, including LSTM [2], attention mechanism (AM) [3] and sparse point network (SPN) [4] to support system performance; 3. Design a solution for model deployment and provide post-processing methods to improve user experience. Offline model performance shows that the LSTM + SPN has achieved a 79.73\\% all-token accuracy rate and 44.34\\% identifier accuracy rate among top 5 predictions respectively. Online evaluation shows that the demo system fits practical application experience.\",\n    booktitle = \"Proceedings of the 2019 3rd International Conference on Innovation in Artificial Intelligence\",\n    pages = \"145\u2013149\",\n    numpages = \"5\",\n    keywords = \"Code suggestion, Code completion, Deep learning\",\n    location = \"Suzhou, China\",\n    series = \"ICIAI 2019\"\n}\n\n",
    "abstract": "Code suggestion system is widely used in integrated development environments (IDEs) for generating code recommendations while editing to improve program efficiency. Current most common systems focus on the settings that complete a single code unit or predict likely next single unit. In this paper, we describe a code suggestion prototype system for JavaScript based on Jupyter Notebook [1] (an IDE) to provide multiple successive code units completion. Our main work is as follows: 1. Provide a JavaScript pre-processing solution for feature extraction; 2. Apply several deep learning technologies, including LSTM [2], attention mechanism (AM) [3] and sparse point network (SPN) [4] to support system performance; 3. Design a solution for model deployment and provide post-processing methods to improve user experience. Offline model performance shows that the LSTM + SPN has achieved a 79.73% all-token accuracy rate and 44.34% identifier accuracy rate among top 5 predictions respectively. Online evaluation shows that the demo system fits practical application experience."
}, {
    "py/object": "data.DataClassPaper",
    "Title": "Learning from examples to improve code completion systems",
    "year": 2009,
    "ML_Techniques": "BMN, ARM",
    "Category": "Code completion",
    "Sub_category": "",
    "Venue": "FSE",
    "Link": "https://dl.acm.org/doi/10.1145/1595696.1595728",
    "bibtex": "inproceedings{Zhong2019_499,\n    author = \"Zhong, Chaoliang and Yang, Ming and Sun, Jun\",\n    title = \"JavaScript Code Suggestion Based on Deep Learning\",\n    year = \"2019\",\n    isbn = \"9781450361286\",\n    publisher = \"Association for Computing Machinery\",\n    address = \"New York, NY, USA\",\n    url = \"https://doi.org/10.1145/3319921.3319922\",\n    doi = \"10.1145/3319921.3319922\",\n    abstract = \"Code suggestion system is widely used in integrated development environments (IDEs) for generating code recommendations while editing to improve program efficiency. Current most common systems focus on the settings that complete a single code unit or predict likely next single unit. In this paper, we describe a code suggestion prototype system for JavaScript based on Jupyter Notebook [1] (an IDE) to provide multiple successive code units completion. Our main work is as follows: 1. Provide a JavaScript pre-processing solution for feature extraction; 2. Apply several deep learning technologies, including LSTM [2], attention mechanism (AM) [3] and sparse point network (SPN) [4] to support system performance; 3. Design a solution for model deployment and provide post-processing methods to improve user experience. Offline model performance shows that the LSTM + SPN has achieved a 79.73\\% all-token accuracy rate and 44.34\\% identifier accuracy rate among top 5 predictions respectively. Online evaluation shows that the demo system fits practical application experience.\",\n    booktitle = \"Proceedings of the 2019 3rd International Conference on Innovation in Artificial Intelligence\",\n    pages = \"145\u2013149\",\n    numpages = \"5\",\n    keywords = \"Code suggestion, Code completion, Deep learning\",\n    location = \"Suzhou, China\",\n    series = \"ICIAI 2019\"\n}\n\n",
    "abstract": "The suggestions made by current IDE's code completion features are based exclusively on static type system of the programming language. As a result, often proposals are made which are irrelevant for a particular working context. Also, these suggestions are ordered alphabetically rather than by their relevance in a particular context. In this paper, we present intelligent code completion systems that learn from existing code repositories. We have implemented three such systems, each using the information contained in repositories in a different way. We perform a large-scale quantitative evaluation of these systems, integrate the best performing one into Eclipse, and evaluate the latter also by a user study. Our experiments give evidence that intelligent code completion systems which learn from examples significantly outperform mainstream code completion systems in terms of the relevance of their suggestions and thus have the potential to enhance developers' productivity."
}, {
    "py/object": "data.DataClassPaper",
    "Title": "Multi-task Learning based Pre-trained Language Model for Code Completion",
    "year": 2020,
    "ML_Techniques": "TF",
    "Category": "Code completion",
    "Sub_category": "",
    "Venue": "ASE",
    "Link": "https://ieeexplore.ieee.org/abstract/document/9285991",
    "bibtex": "INPROCEEDINGS{Liu2020_501,\n    author = \"{Liu}, F. and {Li}, G. and {Zhao}, Y. and {Jin}, Z.\",\n    booktitle = \"2020 35th IEEE/ACM International Conference on Automated Software Engineering (ASE)\",\n    title = \"Multi-task Learning based Pre-trained Language Model for Code Completion\",\n    year = \"2020\",\n    volume = \"\",\n    number = \"\",\n    pages = \"473-485\",\n    doi = \"\"\n}\n\n",
    "abstract": "Code completion is one of the most useful features in the Integrated Development Environments (IDEs), which can accelerate software development by suggesting the next probable token based on the contextual code in real-time. Recent studies have shown that statistical language modeling techniques can improve the performance of code completion tools through learning from large-scale software repositories. However, these models suffer from two major drawbacks: a) Existing research uses static embeddings, which map a word to the same vector regardless of its context. The differences in the meaning of a token in varying contexts are lost when each token is associated with a single representation; b) Existing language model based code completion models perform poor on completing identifiers, and the type information of the identifiers is ignored in most of these models. To address these challenges, in this paper, we develop a multi-task learning based pre-trained language model for code understanding and code generation with a Transformer-based neural architecture. We pre-train it with hybrid objective functions that incorporate both code understanding and code generation tasks. Then we fine-tune the pre-trained model on code completion. During the completion, our model does not directly predict the next token. Instead, we adopt multi-task learning to predict the token and its type jointly and utilize the predicted type to assist the token prediction. Experiments results on two real-world datasets demonstrate the effectiveness of our model when compared with state-of-the-art methods."
}, {
    "py/object": "data.DataClassPaper",
    "Title": "Neural Comment Generation for Source Code with Auxiliary Code Classification Task",
    "year": 2019,
    "ML_Techniques": "EN-DE",
    "Category": "Code completion",
    "Sub_category": "",
    "Venue": "APSEC",
    "Link": "https://ieeexplore.ieee.org/document/8945708",
    "bibtex": "INPROCEEDINGS{Chen2019_503,\n    author = \"{Chen}, M. and {Wan}, X.\",\n    booktitle = \"2019 26th Asia-Pacific Software Engineering Conference (APSEC)\",\n    title = \"Neural Comment Generation for Source Code with Auxiliary Code Classification Task\",\n    year = \"2019\",\n    volume = \"\",\n    number = \"\",\n    pages = \"522-529\",\n    doi = \"10.1109/APSEC48747.2019.00076\"\n}\n\n",
    "abstract": "Code comments help program developers understand programs, read and navigate source code, thus resulting in more efficient software maintenance. Unfortunately, many codes are not commented adequately, or the code comments are missing. So developers have to spend additional time in reading source code. In this paper, we propose a new approach to automatically generating comments for source codes. Following the intuition behind the traditional sequence-to-sequence (Seq2Seq) model for machine translation, we propose a tree-to-sequence (Tree2Seq) model for code comment generation, which leverages an encoder to capture the structure information of source code. More importantly, code classification is involved as an auxiliary task for aiding the Tree2Seq model. We build a multi-task learning model to achieve this goal. We evaluate our models on a benchmark dataset with automatic metrics like BLEU, ROUGE, and METEOR. Experimental results show that our proposed Tree2Seq model outperforms traditional Seq2Seq model with attention, and our proposed multi-task learning model outperforms the state-of-the-art approaches by a substantial margin."
}, {
    "py/object": "data.DataClassPaper",
    "Title": "Probabilistic model for code with decision trees",
    "year": 2016,
    "ML_Techniques": "DT",
    "Category": "Code completion",
    "Sub_category": ",Code induction",
    "Venue": "OOPSLA",
    "Link": "https://dl.acm.org/doi/10.1145/2983990.2984041",
    "bibtex": "INPROCEEDINGS{Chen2019_503,\n    author = \"{Chen}, M. and {Wan}, X.\",\n    booktitle = \"2019 26th Asia-Pacific Software Engineering Conference (APSEC)\",\n    title = \"Neural Comment Generation for Source Code with Auxiliary Code Classification Task\",\n    year = \"2019\",\n    volume = \"\",\n    number = \"\",\n    pages = \"522-529\",\n    doi = \"10.1109/APSEC48747.2019.00076\"\n}\n\n",
    "abstract": "In this paper we introduce a new approach for learning precise and general probabilistic models of code based on decision tree learning. Our approach directly benefits an emerging class of statistical programming tools which leverage probabilistic models of code learned over large codebases (e.g., GitHub) to make predictions about new programs (e.g., code completion, repair, etc).\n\nThe key idea is to phrase the problem of learning a probabilistic model of code as learning a decision tree in a domain specific language over abstract syntax trees (called TGen). This allows us to condition the prediction of a program element on a dynamically computed context. Further, our problem formulation enables us to easily instantiate known decision tree learning algorithms such as ID3, but also to obtain new variants we refer to as ID3+ and E13, not previously explored and ones that outperform ID3 in prediction accuracy.\n\nOur approach is general and can be used to learn a probabilistic model of any programming language. We implemented our approach in a system called Deep3 and evaluated it for the challenging task of learning probabilistic models of JavaScript and Python. Our experimental results indicate that Deep3 predicts elements of JavaScript and Python code with precision above 82% and 69%, respectively. Further, Deep3 often significantly outperforms state-of-the-art approaches in overall prediction accuracy"
}, {
    "py/object": "data.DataClassPaper",
    "Title": "Pythia: AI-assisted Code Completion System",
    "year": 2019,
    "ML_Techniques": "LSTM",
    "Category": "Code completion",
    "Sub_category": "",
    "Venue": "KDD",
    "Link": "https://dl.acm.org/doi/abs/10.1145/3292500.3330699",
    "bibtex": "INPROCEEDINGS{Chen2019_503,\n    author = \"{Chen}, M. and {Wan}, X.\",\n    booktitle = \"2019 26th Asia-Pacific Software Engineering Conference (APSEC)\",\n    title = \"Neural Comment Generation for Source Code with Auxiliary Code Classification Task\",\n    year = \"2019\",\n    volume = \"\",\n    number = \"\",\n    pages = \"522-529\",\n    doi = \"10.1109/APSEC48747.2019.00076\"\n}\n\n",
    "abstract": "In this paper, we propose a novel end-to-end approach for AI-assisted code completion called Pythia. It generates ranked lists of method and API recommendations which can be used by software developers at edit time. The system is currently deployed as part of Intellicode extension in Visual Studio Code IDE. Pythia exploits state-of-the-art large-scale deep learning models trained on code contexts extracted from abstract syntax trees. It is designed to work at a high throughput predicting the best matching code completions on the order of 100 ms.\n\nWe describe the architecture of the system, perform comparisons to frequency-based approach and invocation-based Markov Chain language model, and discuss challenges serving Pythia models on lightweight client devices.\n\nThe offline evaluation results obtained on 2700 Python open source software GitHub repositories show a top-5 accuracy of 92%, surpassing the baseline models by 20% averaged over classes, for both intra and cross-project settings."
}, {
    "py/object": "data.DataClassPaper",
    "Title": "Statistical machine translation outperforms neural machine translation in software engineering: why and how",
    "year": 2020,
    "ML_Techniques": "NMT",
    "Category": "Code completion",
    "Sub_category": ",Code induction",
    "Venue": "RL+SE&PL",
    "Link": "https://dl.acm.org/doi/10.1145/3416506.3423576",
    "bibtex": "INPROCEEDINGS{Chen2019_503,\n    author = \"{Chen}, M. and {Wan}, X.\",\n    booktitle = \"2019 26th Asia-Pacific Software Engineering Conference (APSEC)\",\n    title = \"Neural Comment Generation for Source Code with Auxiliary Code Classification Task\",\n    year = \"2019\",\n    volume = \"\",\n    number = \"\",\n    pages = \"522-529\",\n    doi = \"10.1109/APSEC48747.2019.00076\"\n}\n\n",
    "abstract": "Neural Machine Translation (NMT) is the current trend approach\nin Natural Language Processing (NLP) to solve the problem of automatically inferring the content of target language given the source\nlanguage. The ability of NMT is to learn deep knowledge inside languages by deep learning approaches. However, prior works show\nthat NMT has its own drawbacks in NLP and in some research\nproblems of Software Engineering (SE). In this work, we provide a\nhypothesis that SE corpus has inherent characteristics that NMT\nwill confront challenges compared to the state-of-the-art translation engine based on Statistical Machine Translation. We introduce\na problem which is significant in SE and has characteristics that\nchallenges the ability of NMT to learn correct sequences, called\nPrefix Mapping. We implement and optimize the original SMT and\nNMT to mitigate those challenges. By the evaluation, we show that\nSMT outperforms NMT for this research problem, which provides\npotential directions to optimize the current NMT engines for specific classes of parallel corpus. By achieving the accuracy from 65%\nto 90% for code tokens generation of 1000 Github code corpus, we\nshow the potential of using MT for code completion at token level."
}, {
    "py/object": "data.DataClassPaper",
    "Title": "You Autocomplete Me: Poisoning Vulnerabilities in Neural Code Completion",
    "year": 2021,
    "ML_Techniques": "TF",
    "Category": "Code completion",
    "Sub_category": "",
    "Venue": "USENIX Security",
    "Link": "https://www.usenix.org/conference/usenixsecurity21/presentation/schuster",
    "bibtex": "inproceedings{Schuster2021_508,\n    author = \"Schuster, R. and Song, Congzheng and Tromer, Eran and Shmatikov, Vitaly\",\n    title = \"You Autocomplete Me: Poisoning Vulnerabilities in Neural Code Completion\",\n    booktitle = \"30th {USENIX} Security Symposium ({USENIX} Security 21)\",\n    year = \"2021\",\n    address = \"Vancouver, B.C.\",\n    url = \"https://www.usenix.org/conference/usenixsecurity21/presentation/schuster\",\n    publisher = \"{USENIX} Association\",\n    month = \"August\"\n}\n\n",
    "abstract": "Code autocompletion is an integral feature of modern code editors and IDEs. The latest generation of autocompleters uses neural language models, trained on public open-source code repositories, to suggest likely (not just statically feasible) completions given the current context.\nWe demonstrate that neural code autocompleters are vulnerable to poisoning attacks. By adding a few specially-crafted files to the autocompleter's training corpus (data poisoning), or else by directly fine-tuning the autocompleter on these files (model poisoning), the attacker can influence its suggestions for attacker-chosen contexts. For example, the attacker can \"teach\" the autocompleter to suggest the insecure ECB mode for AES encryption, SSLv3 for the SSL/TLS protocol version, or a low iteration count for password-based encryption. Moreover, we show that these attacks can be targeted: an autocompleter poisoned by a targeted attack is much more likely to suggest the insecure completion for files from a specific repo or specific developer.\nWe quantify the efficacy of targeted and untargeted data- and model-poisoning attacks against state-of-the-art autocompleters based on Pythia and GPT-2. We then evaluate existing defenses against poisoning attacks and show that they are largely ineffective."
}, {
    "py/object": "data.DataClassPaper",
    "Title": "Code smell detection by deep direct-learning and transfer-learning",
    "year": 2021,
    "ML_Techniques": "CNN, RNN, AE",
    "Category": "Quality assessment",
    "Sub_category": "Code smell detection",
    "Venue": "JSS",
    "Link": "https://tusharma.in/preprints/JSS21_Code-Smell-Detection-Using-Deep-Learning_Preprint.pdf",
    "bibtex": "article{Sharma2021_510,\n    author = \"Sharma, Tushar and Efstathiou, Vasiliki and Louridas, Panos and Spinellis, Diomidis\",\n    title = \"Code smell detection by deep direct-learning and transfer-learning\",\n    journal = \"Journal of Systems and Software\",\n    volume = \"176\",\n    pages = \"110936\",\n    year = \"2021\",\n    issn = \"0164-1212\",\n    doi = \"https://doi.org/10.1016/j.jss.2021.110936\",\n    url = \"https://www.sciencedirect.com/science/article/pii/S0164121221000339\",\n    keywords = \"Code smells, Smell detection tools, Deep learning, Transfer-learning\"\n}\n\n",
    "abstract": "Context:\nAn excessive number of code smells make a software system hard to evolve and maintain. Machine learning methods, in addition to metric-based and heuristic-based methods, have been recently applied to detect code smells; however, current methods are considered far from mature.\n\nObjective:\nFirst, explore the feasibility of applying deep learning models to detect smells without extensive feature engineering. Second, investigate the possibility of applying transfer-learning in the context of detecting code smells.\n\nMethods:\nWe train smell detection models based on Convolution Neural Networks and Recurrent Neural Networks as their principal hidden layers along with autoencoder models. For the first objective, we perform training and evaluation on C# samples, whereas for the second objective, we train the models from C# code and evaluate the models over Java code samples and vice-versa.\n\nResults:\nWe find it feasible to detect smells using deep learning methods though the models\u2019 performance is smell-specific. Our experiments show that transfer-learning is definitely feasible for implementation smells with performance comparable to that of direct-learning. This work opens up a new paradigm to detect code smells by transfer-learning especially for the programming languages where the comprehensive code smell detection tools are not available."
}, {
    "py/object": "data.DataClassPaper",
    "Title": "A Hybrid Approach To Detect Code Smells using Deep Learning",
    "year": 2018,
    "ML_Techniques": "AE, ANN",
    "Category": "Quality assessment",
    "Sub_category": "Code smell detection",
    "Venue": "ENASE",
    "Link": "https://dl.acm.org/doi/10.5220/0006709801370146",
    "bibtex": "inproceedings{Hadj-Kacem2018_511,\n    author = \"Hadj-Kacem, Mouna and Bouassida, Nadia\",\n    title = \"A Hybrid Approach To Detect Code Smells using Deep Learning.\",\n    booktitle = \"ENASE\",\n    pages = \"137--146\",\n    year = \"2018\"\n}\n\n",
    "abstract": "The detection of code smells is a fundamental prerequisite for guiding the subsequent steps in the refactoring\nprocess. The more the detection results are accurate, the more the performance of the refactoring on the\nsoftware is improved. Given its influential role in the software maintenance, this challenging research topic\nhas so far attracted an increasing interest. However, the lack of consensus about the definition of code smells in\nthe literature has led to a considerable diversity of the existing results. To reduce the confusion associated with\nthis lack of consensus, there is a real need to achieve a deep and consistent representation of the code smells.\nRecently, the advance of deep learning has demonstrated an undeniable contribution in many research fields\nincluding the pattern recognition issues. In this paper, we propose a hybrid detection approach based on deep\nAuto-encoder and Artificial Neural Network algorithms. Four code smells (God Class, Data Class, Feature\nEnvy and Long Method) are the focus of our experiment on four adopted datasets that are extracted from\n74 open source systems. The values of recall and precision measurements have demonstrated high accuracy\nresults."
}, {
    "py/object": "data.DataClassPaper",
    "Title": "Deep learning based code smell detection",
    "year": 2019,
    "ML_Techniques": "CNN, RNN",
    "Category": "Quality assessment",
    "Sub_category": "Code smell detection",
    "Venue": "TSE",
    "Link": "https://ieeexplore.ieee.org/document/8807230",
    "bibtex": "article{Liu2019_512,\n    author = \"Liu, Hui and Jin, Jiahao and Xu, Zhifeng and Bu, Yifan and Zou, Yanzhen and Zhang, Lu\",\n    title = \"Deep learning based code smell detection\",\n    journal = \"IEEE Transactions on Software Engineering\",\n    year = \"2019\",\n    publisher = \"IEEE\"\n}\n\n",
    "abstract": "Code smells are structures in the source code that suggest the possibility of refactorings. Consequently, developers may\nidentify refactoring opportunities by detecting code smells. However, manual identification of code smells is challenging and tedious. To\nthis end, a number of approaches have been proposed to identify code smells automatically or semi-automatically. Most of such\napproaches rely on manually designed heuristics to map manually selected source code metrics into predictions. However, it is\nchallenging to manually select the best features. It is also difficult to manually construct the optimal heuristics. To this end, in this paper\nwe propose a deep learning based novel approach to detecting code smells. The key insight is that deep neural networks and\nadvanced deep learning techniques could automatically select features of source code for code smell detection, and could\nautomatically build the complex mapping between such features and predictions. A big challenge for deep learning based smell\ndetection is that deep learning often requires a large number of labeled training data (to tune a large number of parameters within the\nemployed deep neural network) whereas existing datasets for code smell detection are rather small. To this end, we propose an\nautomatic approach to generating labeled training data for the neural network based classifier, which does not require any human\nintervention. As an initial try, we apply the proposed approach to four common and well-known code smells, i.e., feature envy, long\nmethod, large class, and misplaced class. Evaluation results on open-source applications suggest that the proposed approach\nsignificantly improves the state-of-the-art."
}, {
    "py/object": "data.DataClassPaper",
    "Title": "Adaptive Deep Code Search",
    "year": 2020,
    "ML_Techniques": "RNN",
    "Category": "Code search",
    "Sub_category": "",
    "Venue": "ICPC",
    "Link": "https://conf.researchr.org/details/icpc-2020/icpc-2020-research/22/Adaptive-Deep-Code-Search",
    "bibtex": "article{Liu2019_512,\n    author = \"Liu, Hui and Jin, Jiahao and Xu, Zhifeng and Bu, Yifan and Zou, Yanzhen and Zhang, Lu\",\n    title = \"Deep learning based code smell detection\",\n    journal = \"IEEE Transactions on Software Engineering\",\n    year = \"2019\",\n    publisher = \"IEEE\"\n}\n\n",
    "abstract": "\nSearching code in a large-scale codebase using natural language queries is a common practice during software development. Deep learning-based code search methods demonstrate superior performance if models are trained with large amount of text-code pairs. However, few deep code search models can be easily transferred from one codebase to another. It can be very costly to prepare training data for a new codebase and re-train an appropriate deep learning model. In this paper, we propose AdaCS, an adaptive deep code search method that can be trained once and transferred to new codebases. AdaCS decomposes the learning process into embedding domain-specific words and matching general syntactic patterns. Firstly, an unsupervised word embedding technique is used to construct a matching matrix to represent the lexical similarities. Then, a recurrent neural network is used to capture latent syntactic patterns from these matching matrices in a supervised way. As the supervised task learns general syntactic patterns that exist across domains, AdaCS is transferable to new codebases. Experimental results show that: when extended to new software projects never seen in the training data, AdaCS is more robust and significantly outperforms state-of-the-art deep code search methods."
}, {
    "py/object": "data.DataClassPaper",
    "Title": "Exploiting Code Knowledge Graph for Bug Localization via Bi-directional Attention",
    "year": 2020,
    "ML_Techniques": "Bi-LSTM",
    "Category": "Program comprehension",
    "Sub_category": "",
    "Venue": "ICPC",
    "Link": "https://dl.acm.org/doi/10.1145/3387904.3389281",
    "bibtex": "article{Liu2019_512,\n    author = \"Liu, Hui and Jin, Jiahao and Xu, Zhifeng and Bu, Yifan and Zou, Yanzhen and Zhang, Lu\",\n    title = \"Deep learning based code smell detection\",\n    journal = \"IEEE Transactions on Software Engineering\",\n    year = \"2019\",\n    publisher = \"IEEE\"\n}\n\n",
    "abstract": "Bug localization automatic localize relevant source files given a natural language description of bug within a software project. For a large project containing hundreds and thousands of source files, developers need cost lots of time to understand bug reports generated by quality assurance and localize these buggy source files. Traditional methods are heavily depending on the information retrieval technologies which rank the similarity between source files and bug reports in lexical level. Recently, deep learning based models are used to extract semantic information of code with significant improvements for bug localization. However, programming language is a highly structural and logical language, which contains various relations within and cross source files. Thus, we propose KGBugLocator to utilize knowledge graph embeddings to extract these interrelations of code, and a keywords supervised bi-directional attention mechanism regularize model with interactive information between source files and bug reports. With extensive experiments on four different projects, we prove our model can reach the new the-state-of-art(SOTA) for bug localization."
}, {
    "py/object": "data.DataClassPaper",
    "Title": "GGF: A Graph-based Method for Programming Language Syntax Error Correction",
    "year": 2020,
    "ML_Techniques": "GGNN",
    "Category": "Program comprehension",
    "Sub_category": "",
    "Venue": "ICPC",
    "Link": "https://dl.acm.org/doi/abs/10.1145/3387904.3389252",
    "bibtex": "article{Liu2019_512,\n    author = \"Liu, Hui and Jin, Jiahao and Xu, Zhifeng and Bu, Yifan and Zou, Yanzhen and Zhang, Lu\",\n    title = \"Deep learning based code smell detection\",\n    journal = \"IEEE Transactions on Software Engineering\",\n    year = \"2019\",\n    publisher = \"IEEE\"\n}\n\n",
    "abstract": "Syntax errors combined with obscure error messages generated by compilers usually annoy programmers and cause them to waste a lot of time on locating errors. The existing models do not utilize the structure in the code and just treat the code as token sequences. It causes low accuracy and poor performance on this task. In this paper, we propose a novel deep supervised learning model, called Graph-based Grammar Fix(GGF), to help programmers locate and fix the syntax errors. GGF treats the code as a mixture of the token sequences and graphs. The graphs build upon the Abstract Syntax Tree (AST) structure information. GGF encodes an erroneous code with its sub-AST structure, predicts the error position using pointer network and generates the right token. We utilized the DeepFix dataset which contains 46500 correct C programs and 6975 programs with errors written by students taking an introductory programming course. GGF is trained with the correct programs from the DeepFix dataset with intentionally injected syntax errors. After training, GGF could fix 4054 (58.12%) of the erroneous code, while the existing state of the art tool DeepFix fixes 1365 (19.57%) of the erroneous code."
}, {
    "py/object": "data.DataClassPaper",
    "Title": "A Multi-Modal Transformer-based Code Summarization Approach for Smart Contracts",
    "year": 2021,
    "ML_Techniques": "TF",
    "Category": "Code summarization",
    "Sub_category": "",
    "Venue": "ICPC",
    "Link": "https://transfer-learning.ai/paper/a-multi-modal-transformer-based-code-summarization-approach-for-smart-contracts/",
    "bibtex": "article{Liu2019_512,\n    author = \"Liu, Hui and Jin, Jiahao and Xu, Zhifeng and Bu, Yifan and Zou, Yanzhen and Zhang, Lu\",\n    title = \"Deep learning based code smell detection\",\n    journal = \"IEEE Transactions on Software Engineering\",\n    year = \"2019\",\n    publisher = \"IEEE\"\n}\n\n",
    "abstract": "Code comment has been an important part of computer programs, greatly facilitating the understanding and maintenance of source code. However, high-quality code comments are often unavailable in smart contracts, the increasingly popular programs that run on the blockchain. In this paper, we propose a Multi-Modal Transformer-based (MMTrans) code summarization approach for smart contracts. Specifically, the MMTrans learns the representation of source code from the two heterogeneous modalities of the Abstract Syntax Tree (AST), i.e., Structure-based Traversal (SBT) sequences and graphs. The SBT sequence provides the global semantic information of AST, while the graph convolution focuses on the local details. The MMTrans uses two encoders to extract both global and local semantic information from the two modalities respectively, and then uses a joint decoder to generate code comments. Both the encoders and the decoder employ the multi-head attention structure of the Transformer to enhance the ability to capture the long-range dependencies between code tokens. We build a dataset with over 300K <method, comment> pairs of smart contracts, and evaluate the MMTrans on it. The experimental results demonstrate that the MMTrans outperforms the state-of-the-art baselines in terms of four evaluation metrics by a substantial margin, and can generate higher quality comments."
}, {
    "py/object": "data.DataClassPaper",
    "Title": "Exploiting Method Names to Improve Code Summarization: A Deliberation Multi-Task Learning Approach",
    "year": 2021,
    "ML_Techniques": "EN-DE",
    "Category": "Code summarization",
    "Sub_category": "",
    "Venue": "ICPC",
    "Link": "https://www.computer.org/csdl/proceedings-article/icpc/2021/140300a138/1tB7w3sIsxi",
    "bibtex": "article{Liu2019_512,\n    author = \"Liu, Hui and Jin, Jiahao and Xu, Zhifeng and Bu, Yifan and Zou, Yanzhen and Zhang, Lu\",\n    title = \"Deep learning based code smell detection\",\n    journal = \"IEEE Transactions on Software Engineering\",\n    year = \"2019\",\n    publisher = \"IEEE\"\n}\n\n",
    "abstract": "Code summaries are brief natural language descriptions of source code pieces. The main purpose of code summarization is to assist developers in understanding code and to reduce documentation workload. In this paper, we design a novel multi-task learning (MTL) approach for code summarization through mining the relationship between method code summaries and method names. More specifically, since a method's name can be considered as a shorter version of its code summary, we first introduce the tasks of generation and informativeness prediction of method names as two auxiliary training objectives for code summarization. A novel two-pass deliberation mechanism is then incorporated into our MTL architecture to generate more consistent intermediate states fed into a summary decoder, especially when informative method names do not exist. To evaluate our deliberation MTL approach, we carried out a large-scale experiment on two existing datasets for Java and Python. The experiment results show that our technique can be easily applied to many state-of-the-art neural models for code summarization and improve their performance. Meanwhile, our approach shows significant superiority when generating summaries for methods with non-informative names."
}, {
    "py/object": "data.DataClassPaper",
    "Title": "Locating Faulty Methods with a Mixed RNN and Attention Model",
    "year": 2021,
    "ML_Techniques": "RNN",
    "Category": "Testing",
    "Sub_category": "",
    "Venue": "ICPC",
    "Link": "https://conf.researchr.org/details/icpc-2021/icpc-2021-research/12/Locating-Faulty-Methods-with-a-Mixed-RNN-and-Attention-Model",
    "bibtex": "article{Liu2019_512,\n    author = \"Liu, Hui and Jin, Jiahao and Xu, Zhifeng and Bu, Yifan and Zou, Yanzhen and Zhang, Lu\",\n    title = \"Deep learning based code smell detection\",\n    journal = \"IEEE Transactions on Software Engineering\",\n    year = \"2019\",\n    publisher = \"IEEE\"\n}\n\n",
    "abstract": "IR-based fault localization approaches achieves promising results when locating faulty files by comparing a bug report with source code. Unfortunately, they become less effective to locate faulty methods. We conduct a preliminary study to explore its challenges, and identify three problems: the semantic gap problem, the representation sparseness problem, and the single revision problem. To tackle these problems, we propose MRAM, a mixed RNN and attention model, which combines bug-fixing features and method structured features to explore both implicit and explicit relevance between methods and bug reports for method level fault localization task. The core ideas of our model are: (1) constructing code revision graphs from code, commits and past bug reports, which reveal the latent relations among methods to augment short methods and as well provide all revisions of code and past fixes to train more accurate models; (2) embedding three method structured features (token sequences, API invocation sequences, and comments) jointly with RNN and soft attention to represent source methods and obtain their implicit relevance with bug reports; and (3) integrating multirevision bug-fixing features, which provide the explicit relevance between bug reports and methods, to improve the performance. We have implemented MRAM and conducted a controlled experiment on five open-source projects. Comparing with stateof-the-art approaches, our MRAM improves MRR values by 3.8- 5.1% (3.7-5.4%) when the dataset contains (does not contain) localized bug reports. Our statistics test shows that our improvements are significant"
}, {
    "py/object": "data.DataClassPaper",
    "Title": "Project-Level Encoding for Neural Source Code Summarization of Subroutines",
    "year": 2021,
    "ML_Techniques": "AE",
    "Category": "Code summarization",
    "Sub_category": "",
    "Venue": "ICPC",
    "Link": "https://par.nsf.gov/biblio/10293954",
    "bibtex": "article{Liu2019_512,\n    author = \"Liu, Hui and Jin, Jiahao and Xu, Zhifeng and Bu, Yifan and Zou, Yanzhen and Zhang, Lu\",\n    title = \"Deep learning based code smell detection\",\n    journal = \"IEEE Transactions on Software Engineering\",\n    year = \"2019\",\n    publisher = \"IEEE\"\n}\n\n",
    "abstract": "Source code summarization of a subroutine is the task of writing a short, natural language description of that subroutine. The description usually serves in documentation aimed at programmers, where even brief phrase (e.g. \"compresses data to a zip file\") can help readers rapidly comprehend what a subroutine does without resorting to reading the code itself. Techniques based on neural networks (and encoder-decoder model designs in particular) have established themselves as the state-of-the-art. Yet a problem widely recognized with these models is that they assume the information needed to create a summary is present within the code being summarized itself - an assumption which is at odds with program comprehension literature. Thus a current research frontier lies in the question of encoding source code context into neural models of summarization. In this paper, we present a project-level encoder to improve models of code summarization. By project-level, we mean that we create a vectorized representation of selected code files in a software project, and use that representation to augment the encoder of state-of-the-art neural code summarization techniques. We demonstrate how our encoder improves several existing models, and provide guidelines for maximizing improvement while controlling time and resource costs in model size."
},
{
    "py/object": "data.DataClassPaper",
    "Title": "Deep Semantic Feature Learning for Software Defect Prediction",
    "year": 2020,
    "ML_Techniques": "DBN",
    "Category": "Testing",
    "Sub_category": "Defect prediction",
    "Venue": "TSE",
    "Link": "https://ieeexplore.ieee.org/abstract/document/8502853",
    "bibtex": "article{\ufeff526_Wang2018,\n    author = \"Wang, Song and Liu, Taiyue and Nam, Jaechang and Tan, Lin\",\n    title = \"Deep semantic feature learning for software defect prediction\",\n    journal = \"IEEE Transactions on Software Engineering\",\n    volume = \"46\",\n    number = \"12\",\n    pages = \"1267--1293\",\n    year = \"2018\",\n    publisher = \"IEEE\"\n}\n\n",
    "abstract": "Software defect prediction, which predicts defective code regions, can assist developers in finding bugs and prioritizing their testing efforts. Traditional defect prediction features often fail to capture the semantic differences between different programs. This degrades the performance of the prediction models built on these traditional features. Thus, the capability to capture the semantics in programs is required to build accurate prediction models. To bridge the gap between semantics and defect prediction features, we propose leveraging a powerful representation-learning algorithm, deep learning, to learn the semantic representations of programs automatically from source code files and code changes. Specifically, we leverage a deep belief network (DBN) to automatically learn semantic features using token vectors extracted from the programs' abstract syntax trees (AST) (for file-level defect prediction models) and source code changes (for change-level defect prediction models). We examine the effectiveness of our approach on two file-level defect prediction tasks (i.e., file-level within-project defect prediction and file-level cross-project defect prediction) and two change-level defect prediction tasks (i.e., change-level within-project defect prediction and change-level cross-project defect prediction). Our experimental results indicate that the DBN-based semantic features can significantly improve the examined defect prediction tasks. Specifically, the improvements of semantic features against existing traditional features (in F1) range from 2.1 to 41.9 percentage points for file-level within-project defect prediction, from 1.5 to 13.4 percentage points for file-level cross-project defect prediction, from 1.0 to 8.6 percentage points for change-level within-project defect prediction, and from 0.6 to 9.9 percentage points for change-level cross-project defect prediction."
},
{
    "py/object": "data.DataClassPaper",
    "Title": "Semantic Feature Learning via Dual Sequences for Defect Prediction",
    "year": 2021,
    "ML_Techniques": "Bi-LSTM, LOG",
    "Category": "Testing",
    "Sub_category": "Defect prediction",
    "Venue": "IEEE Access",
    "Link": "https://ieeexplore.ieee.org/abstract/document/9326378",
    "bibtex": "article{527_Lin2021,\n    author = \"Lin, Junhao and Lu, Lu\",\n    title = \"Semantic feature learning via dual sequences for defect prediction\",\n    journal = \"IEEE Access\",\n    volume = \"9\",\n    pages = \"13112--13124\",\n    year = \"2021\",\n    publisher = \"IEEE\"\n}\n\n",
    "abstract": "Software defect prediction (SDP) can help developers reasonably allocate limited resources for locating bugs and prioritizing their testing efforts. Existing methods often serialize an Abstract Syntax Tree (AST) obtained from the program source code into a token sequence, which is then inputted into the deep learning model to learn the semantic features. However, there are different ASTs with the same token sequence, and it is impossible to distinguish the tree structure of the ASTs only by a token sequence. To solve this problem, this paper proposes a framework called Semantic Feature Learning via Dual Sequences (SFLDS), which can capture the semantic and structural information in the AST for feature generation. Specifically, based on the AST, we select the representative nodes in the AST and convert the program source code into a simplified AST (S-AST). Our method introduces two sequences to represent the semantic and structural information of the S-AST, one is the result of traversing the S-AST node in pre-order, and another is composed of parent nodes. Then each token in the dual sequences is encoded as a numerical vector via mapping and word embedding. Finally, we use a bi-directional long short-term memory (BiLSTM) based neural network to automatically generate semantic features from the dual sequences for SDP. In addition, to leverage the statistical characteristics contained in the handcrafted metrics, we also propose a framework called Defect Prediction via SFLDS (DP-SFLDS) which combines the semantic features generated from SFLDS with handcrafted metrics to perform SDP. In our empirical studies, eight open-source Java projects from the PROMISE repository are chosen as our empirical subjects. Experimental results show that our proposed approach can perform better than several state-of-the-art baseline SDP methods."
},
{
    "py/object": "data.DataClassPaper",
    "Title": "Large-scale and Robust Code Authorship Identification with Deep Feature Learning",
    "year": 2021,
    "ML_Techniques": "RNN, LSTM",
    "Category": "Program comprehension",
    "Sub_category": "",
    "Venue": "TOPS",
    "Link": "https://dl.acm.org/doi/abs/10.1145/3461666",
    "bibtex": "article{528_Abuhamad2021,\n    author = \"Abuhamad, Mohammed and Abuhmed, Tamer and Mohaisen, David and Nyang, Daehun\",\n    title = \"Large-scale and Robust Code Authorship Identification with Deep Feature Learning\",\n    journal = \"ACM Transactions on Privacy and Security (TOPS)\",\n    volume = \"24\",\n    number = \"4\",\n    pages = \"1--35\",\n    year = \"2021\",\n    publisher = \"ACM New York, NY, USA\"\n}\n\n",
    "abstract": "Successful software authorship de-anonymization has both software forensics applications and privacy implications. However, the process requires an efficient extraction of authorship attributes. The extraction of such attributes is very challenging, due to various software code formats from executable binaries with different toolchain provenance to source code with different programming languages. Moreover, the quality of attributes is bounded by the availability of software samples to a certain number of samples per author and a specific size for software samples. To this end, this work proposes a deep Learning-based approach for software authorship attribution, that facilitates large-scale, format-independent, language-oblivious, and obfuscation-resilient software authorship identification. This proposed approach incorporates the process of learning deep authorship attribution using a recurrent neural network, and ensemble random forest classifier for scalability to de-anonymize programmers. Comprehensive experiments are conducted to evaluate the proposed approach over the entire Google Code Jam (GCJ) dataset across all years (from 2008 to 2016) and over real-world code samples from 1,987 public repositories on GitHub. The results of our work show high accuracy despite requiring a smaller number of samples per author. Experimenting with source-code, our approach allows us to identify 8,903 GCJ authors, the largest-scale dataset used by far, with an accuracy of 92.3%. Using the real-world dataset, we achieved an identification accuracy of 94.38% for 745 C programmers on GitHub. Moreover, the proposed approach is resilient to language-specifics, and thus it can identify authors of four programming languages (e.g., C, C++, Java, and Python), and authors writing in mixed languages (e.g., Java/C++, Python/C++). Finally, our system is resistant to sophisticated obfuscation (e.g., using C Tigress) with an accuracy of 93.42% for a set of 120 authors. Experimenting with executable binaries, our approach achieves 95.74% for identifying 1,500 programmers of software binaries. Similar results were obtained when software binaries are generated with different compilation options, optimization levels, and removing of symbol information. Moreover, our approach achieves 93.86% for identifying 1,500 programmers of obfuscated binaries using all features adopted in Obfuscator-LLVM tool."
},
{
    "py/object": "data.DataClassPaper",
    "Title": "Deep Semantic Feature Learning with Embedded Static Metrics for Software Defect Prediction",
    "year": 2019,
    "ML_Techniques": "RNN, LOG",
    "Category": "Testing",
    "Sub_category": "Defect prediction",
    "Venue": "APSEC",
    "Link": "https://ieeexplore.ieee.org/abstract/document/8946058",
    "bibtex": "inproceedings{529_Fan2019,\n    author = \"Fan, Guisheng and Diao, Xuyang and Yu, Huiqun and Yang, Kang and Chen, Liqiong\",\n    title = \"Deep semantic feature learning with embedded static metrics for software defect prediction\",\n    booktitle = \"2019 26th Asia-Pacific Software Engineering Conference (APSEC)\",\n    pages = \"244--251\",\n    year = \"2019\",\n    organization = \"IEEE\"\n}\n\n",
    "abstract": "Software defect prediction, which locates defective code snippets, can assist developers in finding potential bugs and assigning their testing efforts. Traditional defect prediction features are static code metrics, which only contain statistic information of programs and fail to capture semantics in programs, leading to the degradation of defect prediction performance. To take full advantage of the semantics and static metrics of programs, we propose a framework called Defect Prediction via Attention Mechanism (DP-AM) in this paper. Specifically, DPAM first extracts vectors which are then encoded as digital vectors by mapping and word embedding from abstract syntax trees (ASTs) of programs. Then it feeds these numerical vectors into Recurrent Neural Network to automatically learn semantic features of programs. After that, it applies self-attention mechanism to further build relationship among these features. Furthermore, it employs global attention mechanism to generate significant features among them. Finally, we combine these semantic features with traditional static metrics for accurate software defect prediction. We evaluate our method in terms of F1-measure on seven open-source Java projects in Apache. Our experimental results show that DP-AM improves F1-measure by 11% in average, compared with the state-of-the-art methods."
},
{
    "py/object": "data.DataClassPaper",
    "Title": "The flowing nature matters: feature learning from the control flow graph of source code for bug localization",
    "year": 2022,
    "ML_Techniques": "",
    "Category": "Testing",
    "Sub_category": "Defect prediction",
    "Venue": "Machine Learning",
    "Link": "https://link.springer.com/article/10.1007/s10994-021-06078-4",
    "bibtex": "article{530_Ma2022,\n    author = \"Ma, Yi-Fan and Li, Ming\",\n    title = \"The flowing nature matters: feature learning from the control flow graph of source code for bug localization\",\n    journal = \"Machine Learning\",\n    volume = \"111\",\n    number = \"3\",\n    pages = \"853--870\",\n    year = \"2022\",\n    publisher = \"Springer\"\n}\n\n",
    "abstract": "Bug localization plays an important role in software maintenance. Traditional works treat the source code from the lexical perspective, while some recent researches indicate that exploiting the program structure is beneficial for improving bug localization. Control flow graph (CFG) is a widely used graph representation, which essentially represents the program structure. Although using graph neural network for feature learning is a straightforward way and has been proven effective in various software mining problems, this approach is inappropriate since adjacent nodes in the CFG could be totally unrelated in semantics. On the other hand, previous statements may affect the semantics of subsequent statements along the execution path, which we call the\u00a0flowing nature\u00a0of control flow graph. In this paper, we claim that the\u00a0flowing nature\u00a0should be explicitly considered and propose a novel model named cFlow for bug localization, which employs a particular designed flow-based GRU for feature learning from the CFG. The flow-based GRU exploits the program structure represented by the CFG to transmit the semantics of statements along the execution path, which reflects the\u00a0flowing nature. Experimental results on widely-used real-world software projects show that cFlow significantly outperforms the state-of-the-art bug localization methods, indicating that exploiting the program structure from the CFG with respect to the\u00a0flowing nature\u00a0is beneficial for improving bug localization."
},
{
    "py/object": "data.DataClassPaper",
    "Title": "Buffer Overflow Vulnerability Prediction from x86 Executables Using Static Analysis and Machine Learning",
    "year": 2015,
    "ML_Techniques": "NB, MLP, SL, SMO",
    "Category": "Vulnerability analysis",
    "Sub_category": "",
    "Venue": "COMPSAC",
    "Link": "https://ieeexplore.ieee.org/abstract/document/7273653",
    "bibtex": "INPROCEEDINGS{534_Padmanabhuni2015,\n    author = \"Padmanabhuni, Bindu Madhavi and Tan, Hee Beng Kuan\",\n    booktitle = \"2015 IEEE 39th Annual Computer Software and Applications Conference\",\n    title = \"Buffer Overflow Vulnerability Prediction from x86 Executables Using Static Analysis and Machine Learning\",\n    year = \"2015\",\n    volume = \"2\",\n    number = \"\",\n    pages = \"450-459\",\n    doi = \"10.1109/COMPSAC.2015.78\"\n}\n\n",
    "abstract": "Mining static code attributes for predicting software vulnerabilities has received some attention recently. There are a number of approaches for detecting vulnerabilities from source code, but commercial off the shelf components are, in general, distributed in binary form. Before using such third-party components it is imperative to check for presence of vulnerabilities. We investigate the use of static analysis and machine learning for predicting buffer overflow vulnerabilities from binaries in this study. To mitigate buffer overflows, developers typically perform size checks and input validation. We propose static code attributes characterizing buffer usage and defense mechanisms implemented in the code for preventing buffer overflows. The proposed approach starts by identifying potential vulnerable statement constructs during binary program analysis and extracts static code attributes for each of them as per proposed characterization scheme to capture buffer usage patterns and defensive mechanisms employed in the code. Data mining methods are then used on these collected code attributes for predicting buffer overflows. Our experimental evaluation on standard buffer overflow benchmark binaries shows that the proposed static code attributes are effective in predicting buffer overflow vulnerabilities."
},
{
    "py/object": "data.DataClassPaper",
    "Title": "Predicting Web Vulnerabilities in Web Applications Based on Machine Learning",
    "year": 2019,
    "ML_Techniques": "DT, RF, NB",
    "Category": "Vulnerability analysis",
    "Sub_category": "",
    "Venue": "INTAP",
    "Link": "https://link.springer.com/chapter/10.1007/978-981-13-6052-7_41",
    "bibtex": "inproceedings{535_Khalid2019,\n    author = \"Khalid, Muhammad Noman and Farooq, Humera and Iqbal, Muhammad and Alam, Muhammad Talha and Rasheed, Kamran\",\n    editor = \"Bajwa, Imran Sarwar and Kamareddine, Fairouz and Costa, Anna\",\n    address = \"Singapore\",\n    series = \"Communications in {Computer} and {Information} {Science}\",\n    title = \"Predicting {Web} {Vulnerabilities} in {Web} {Applications} {Based} on {Machine} {Learning}\",\n    isbn = \"9789811360527\",\n    doi = \"10.1007/978-981-13-6052-7\\_41\",\n    abstract = \"Building a secure website is time-consuming, expensive and challenging task for web developers. Researchers to identify webpage sinks to address security efforts, as it helps to reduce time and money to secure web application, are introducing different web vulnerabilities prediction models. Some of the well-known web vulnerabilities are SQL Injection, Cross Site Scripting (XSS) and Cross Site Request Forgery (CSRF). Different machine learning methods are being employed by the existing vulnerability prediction models to prevent vulnerable components in web applications. However, majority of these methods cannot challenge all web vulnerabilities. Therefore, this paper proposed a method namely NMPREDICTOR to predict vulnerable files in website for vulnerability prediction as a classification problem by predicting legitimate or vulnerable code. In addition, it is an effort to employ the classification on different classifier of machine learning algorithms to judge elimination of vulnerable components. Numerous experiments have been conducted in our study to evaluate the performance of our proposed model. Through our proposed method, we have builds 6 classifiers on a training set of labeled files represented by their software metrics and text features. Additionally, we builds a Meta classifier, which combines the six underlying classifiers i.e. J48, Naive Bayes and Random forest. NMPREDICTOR is evaluated on datasets of three web applications, which offers 223 superior quality vulnerabilities found in PHPMyAdmin, Moodle and Drupal. Our proposed method shows a clearly has an advantage over results of existing studies in case of Drupal, PhpMyAdmin and Moodle.\",\n    language = \"en\",\n    booktitle = \"Intelligent {Technologies} and {Applications}\",\n    publisher = \"Springer\",\n    year = \"2019\",\n    keywords = \"Machine learning, Text mining, Vulnerable file, Web vulnerabilities\",\n    pages = \"473--484\"\n}\n\n",
    "abstract": "Building a secure website is time-consuming, expensive and challenging task for web developers. Researchers to identify webpage sinks to address security efforts, as it helps to reduce time and money to secure web application, are introducing different web vulnerabilities prediction models. Some of the well-known web vulnerabilities are SQL Injection, Cross Site Scripting (XSS) and Cross Site Request Forgery (CSRF). Different machine learning methods are being employed by the existing vulnerability prediction models to prevent vulnerable components in web applications. However, majority of these methods cannot challenge all web vulnerabilities. Therefore, this paper proposed a method namely NMPREDICTOR to predict vulnerable files in website for vulnerability prediction as a classification problem by predicting legitimate or vulnerable code. In addition, it is an effort to employ the classification on different classifier of machine learning algorithms to judge elimination of vulnerable components. Numerous experiments have been conducted in our study to evaluate the performance of our proposed model. Through our proposed method, we have builds 6 classifiers on a training set of labeled files represented by their software metrics and text features. Additionally, we builds a Meta classifier, which combines the six underlying classifiers i.e. J48, Naive Bayes and Random forest. NMPREDICTOR is evaluated on datasets of three web applications, which offers 223 superior quality vulnerabilities found in PHPMyAdmin, Moodle and Drupal. Our proposed method shows a clearly has an advantage over results of existing studies in case of Drupal, PhpMyAdmin and Moodle."
},
{
    "py/object": "data.DataClassPaper",
    "Title": "Survey on Software Vulnerability Analysis Method Based on Machine Learning",
    "year": 2016,
    "ML_Techniques": "",
    "Category": "Vulnerability analysis",
    "Sub_category": "",
    "Venue": "DSC",
    "Link": "https://ieeexplore.ieee.org/abstract/document/7866201",
    "bibtex": "INPROCEEDINGS{537_Jie2016,\n    author = \"Jie, Gong and Xiao-Hui, Kuang and Qiang, Liu\",\n    booktitle = \"2016 IEEE First International Conference on Data Science in Cyberspace (DSC)\",\n    title = \"Survey on Software Vulnerability Analysis Method Based on Machine Learning\",\n    year = \"2016\",\n    volume = \"\",\n    number = \"\",\n    pages = \"642-647\",\n    doi = \"10.1109/DSC.2016.33\"\n}\n\n",
    "abstract": "With the increasingly rich of vulnerability related data and the extensive application of machine learning methods, software vulnerability analysis methods based on machine learning is becoming an important research area of information security. In this paper, the up-to-date and well-known works in this research area were analyzed deeply. A framework for software vulnerability analysis based on machine learning was proposed. And the existing works were described and compared, the limitations of these works were discussed. The future research directions on software vulnerability analysis based on machine learning were put forward in the end."
},
{
    "py/object": "data.DataClassPaper",
    "Title": "Using software metrics for predicting vulnerable classes and methods in Java projects: A machine learning approach",
    "year": 2020,
    "ML_Techniques": "SVM, LOG",
    "Category": "Vulnerability analysis",
    "Sub_category": "",
    "Venue": "Journal of Software: Evolution and Process",
    "Link": "https://onlinelibrary.wiley.com/doi/abs/10.1002/smr.2303",
    "bibtex": "article{538_Sultana2021,\n    author = \"Sultana, Kazi Zakia and Anu, Vaibhav and Chong, Tai-Yin\",\n    title = \"Using software metrics for predicting vulnerable classes and methods in {Java} projects: {A} machine learning approach\",\n    volume = \"33\",\n    issn = \"2047-7481\",\n    shorttitle = \"Using software metrics for predicting vulnerable classes and methods in {Java} projects\",\n    url = \"https://onlinelibrary.wiley.com/doi/abs/10.1002/smr.2303\",\n    doi = \"10.1002/smr.2303\",\n    abstract = \"[Context]A software vulnerability becomes harmful for software when an attacker successfully exploits the insecure code and reveals the vulnerability. A single vulnerability in code can put the entire software at risk. Therefore, maintaining software security throughout the software life cycle is an important and at the same time challenging task for development teams. This can also leave the door open for vulnerable code being evolved during successive releases. In recent years, researchers have used software metrics-based vulnerability prediction approaches to detect vulnerable code early and ensure secure code releases. Software metrics have been employed to predict vulnerability specifically in C/C++ and Java-based systems. However, the prediction performance of metrics at different granularity levels (class level or method level) has not been analyzed. In this paper, we focused on metrics that are specific to lower granularity levels (Java classes and methods). Based on statistical analysis, we first identified a set of class-level metrics and a set of method-level metrics and then employed them as features in machine learning techniques to predict vulnerable classes and methods, respectively. This paper describes a comparative study on how our selected metrics perform at different granularity levels. Such a comparative study can help the developers in choosing the appropriate metrics (at the desired level of granularity). [Objective] The goal of this research is to propose a set of metrics at two lower granularity levels and provide evidence for their usefulness during vulnerability prediction (which will help in maintaining secure code and ensure secure software evolution). [Method] For four Java-based open source systems (including two releases of Apache Tomcat), we designed and conducted experiments based on statistical tests to propose a set of software metrics that can be used for predicting vulnerable code components (i.e., vulnerable classes and methods). Next, we used our identified metrics as features to train supervised machine learning algorithms to classify Java code as vulnerable or non-vulnerable. [Result] Our study has successfully identified a set of class-level metrics and a second set of method-level metrics that can be useful from a vulnerability prediction standpoint. We achieved recall higher than 70\\\\% and precision higher than 75\\\\% in vulnerability prediction using our identified class-level metrics as features of machine learning. Furthermore, method-level metrics showed recall higher than 65\\\\% and precision higher than 80\\\\%.\",\n    language = \"en\",\n    number = \"3\",\n    urldate = \"2022-05-27\",\n    journal = \"Journal of Software: Evolution and Process\",\n    year = \"2021\",\n    note = \"\\\\_eprint: https://onlinelibrary.wiley.com/doi/pdf/10.1002/smr.2303\",\n    keywords = \"software evolution, software maintenance, software metrics, software security, vulnerability prediction\",\n    pages = \"e2303\",\n    annote = \"e2303 smr.2303\",\n    file = \"Snapshot:/home/sgeorgiou/Zotero/storage/ZW5CVN3L/smr.html:text/html\"\n}\n\n",
    "abstract": "[Context]A software vulnerability becomes harmful for software when an attacker successfully exploits the insecure code and reveals the vulnerability. A single vulnerability in code can put the entire software at risk. Therefore, maintaining software security throughout the software life cycle is an important and at the same time challenging task for development teams. This can also leave the door open for vulnerable code being evolved during successive releases. In recent years, researchers have used software metrics-based vulnerability prediction approaches to detect vulnerable code early and ensure secure code releases. Software metrics have been employed to predict vulnerability specifically in C/C++ and Java-based systems. However, the prediction performance of metrics at different granularity levels (class level or method level) has not been analyzed. In this paper, we focused on metrics that are specific to lower granularity levels (Java classes and methods). Based on statistical analysis, we first identified a set of class-level metrics and a set of method-level metrics and then employed them as features in machine learning techniques to predict vulnerable classes and methods, respectively. This paper describes a comparative study on how our selected metrics perform at different granularity levels. Such a comparative study can help the developers in choosing the appropriate metrics (at the desired level of granularity). [Objective] The goal of this research is to propose a set of metrics at two lower granularity levels and provide evidence for their usefulness during vulnerability prediction (which will help in maintaining secure code and ensure secure software evolution). [Method] For four Java-based open source systems (including two releases of Apache Tomcat), we designed and conducted experiments based on statistical tests to propose a set of software metrics that can be used for predicting vulnerable code components (i.e., vulnerable classes and methods). Next, we used our identified metrics as features to train supervised machine learning algorithms to classify Java code as vulnerable or non-vulnerable. [Result] Our study has successfully identified a set of class-level metrics and a second set of method-level metrics that can be useful from a vulnerability prediction standpoint. We achieved recall higher than 70% and precision higher than 75% in vulnerability prediction using our identified class-level metrics as features of machine learning. Furthermore, method-level metrics showed recall higher than 65% and precision higher than 80%."
},
{
    "py/object": "data.DataClassPaper",
    "Title": "Deep Learning for Software Vulnerabilities Detection Using Code Metrics",
    "year": 2020,
    "ML_Techniques": "CNN",
    "Category": "Vulnerability analysis",
    "Sub_category": "",
    "Venue": "IEEE Access",
    "Link": "https://ieeexplore.ieee.org/abstract/document/9069943",
    "bibtex": "ARTICLE{542_Zagane2020,\n    author = \"Zagane, Mohammed and Abdi, Mustapha Kamel and Alenezi, Mamdouh\",\n    journal = \"IEEE Access\",\n    title = \"Deep Learning for Software Vulnerabilities Detection Using Code Metrics\",\n    year = \"2020\",\n    volume = \"8\",\n    number = \"\",\n    pages = \"74562-74570\",\n    doi = \"10.1109/ACCESS.2020.2988557\"\n}\n\n",
    "abstract": "Software vulnerability can cause disastrous consequences for information security. Earlier detection of vulnerabilities minimizes these consequences. Manual detection of vulnerable code is very difficult and very costly in terms of time and budget. Therefore, developers must use automatic vulnerabilities prediction (AVP) tools to minimize costs. Recent works on AVP begin to use techniques of deep learning (DL). All the proposed approaches are based on techniques of feature extraction inspired by previous applications of DL such as automatic language processing. Code metrics were widely used as features to build AVP models based on classic machine learning. This study bridges the gap between deep learning and machine learning features and discusses a deep-learning-based approach to finding vulnerabilities in code using code metrics. Obtained results show that code metrics are very good but not the better to use as features in DL-based AVP."
},
{
    "py/object": "data.DataClassPaper",
    "Title": "The rise of software vulnerability: Taxonomy of software vulnerabilities detection and machine learning approaches",
    "year": 2021,
    "ML_Techniques": "",
    "Category": "Vulnerability analysis",
    "Sub_category": "",
    "Venue": "JNCA",
    "Link": "https://www.sciencedirect.com/science/article/abs/pii/S1084804521000369",
    "bibtex": "article{545_Hanif2021,\n    author = \"Hanif, Hazim and Md Nasir, Mohd Hairul Nizam and Ab Razak, Mohd Faizal and Firdaus, Ahmad and Anuar, Nor Badrul\",\n    title = \"The rise of software vulnerability: {Taxonomy} of software vulnerabilities detection and machine learning approaches\",\n    volume = \"179\",\n    issn = \"1084-8045\",\n    shorttitle = \"The rise of software vulnerability\",\n    url = \"https://www.sciencedirect.com/science/article/pii/S1084804521000369\",\n    doi = \"10.1016/j.jnca.2021.103009\",\n    abstract = \"The detection of software vulnerability requires critical attention during the development phase to make it secure and less vulnerable. Vulnerable software always invites hackers to perform malicious activities and disrupt the operation of the software, which leads to millions in financial losses to software companies. In order to reduce the losses, there are many reliable and effective vulnerability detection systems introduced by security communities aiming to detect the software vulnerabilities as early as in the development or testing phases. To summarise the software vulnerability detection system, existing surveys discussed the conventional and data mining approaches. These approaches are widely used and mostly consist of traditional detection techniques. However, they lack discussion on the newly trending machine learning approaches, such as supervised learning and deep learning techniques. Furthermore, existing studies fail to discuss the growing research interest in the software vulnerability detection community throughout the years. With more discussion on this, we can predict and focus on what are the research problems in software vulnerability detection that need to be urgently addressed. Aiming to reduce these gaps, this paper presents the research interests\u2019 taxonomy in software vulnerability detection, such as methods, detection, features, code and dataset. The research interest categories exhibit current trends in software vulnerability detection. The analysis shows that there is considerable interest in addressing methods and detection problems, while only a few are interested in code and dataset problems. This indicates that there is still much work to be done in terms of code and dataset problems in the future. Furthermore, this paper extends the machine learning approaches taxonomy, which is used to detect the software vulnerabilities, like supervised learning, semi-supervised learning, ensemble learning and deep learning. Based on the analysis, supervised learning and deep learning approaches are trending in the software vulnerability detection community as these techniques are able to detect vulnerabilities such as buffer overflow, SQL injection and cross-site scripting effectively with a significant detection performance, up to 95\\\\% of F1 score. Finally, this paper concludes with several discussions on potential future work in software vulnerability detection in terms of datasets, multi-vulnerabilities detection, transfer learning and real-world applications.\",\n    language = \"en\",\n    urldate = \"2022-05-25\",\n    journal = \"Journal of Network and Computer Applications\",\n    month = \"April\",\n    year = \"2021\",\n    keywords = \"Computer security, Deep learning, Machine learning, Software security, Software vulnerability detection\",\n    pages = \"103009\",\n    file = \"ScienceDirect Snapshot:/home/sgeorgiou/Zotero/storage/68J5YQUL/S1084804521000369.html:text/html\"\n}\n\n",
    "abstract": "The detection of software vulnerability requires critical attention during the development phase to make it secure and less vulnerable. Vulnerable software always invites hackers to perform\u00a0malicious activities\u00a0and disrupt the operation of the software, which leads to millions in financial losses to software companies. In order to reduce the losses, there are many reliable and effective\u00a0vulnerability detection\u00a0systems introduced by security communities aiming to detect the software vulnerabilities as early as in the development or testing phases. To summarise the software vulnerability detection system, existing surveys discussed the conventional and\u00a0data mining\u00a0approaches. These approaches are widely used and mostly consist of traditional detection techniques. However, they lack discussion on the newly trending\u00a0machine learning approaches, such as supervised learning and\u00a0deep learning techniques. Furthermore, existing studies fail to discuss the growing research interest in the software vulnerability detection community throughout the years. With more discussion on this, we can predict and focus on what are the research problems in software vulnerability detection that need to be urgently addressed. Aiming to reduce these gaps, this paper presents the research interests\u2019 taxonomy in software vulnerability detection, such as methods, detection, features, code and dataset. The research interest categories exhibit current trends in software vulnerability detection. The analysis shows that there is considerable interest in addressing methods and detection problems, while only a few are interested in code and dataset problems. This indicates that there is still much work to be done in terms of code and dataset problems in the future. Furthermore, this paper extends the machine learning approaches taxonomy, which is used to detect the software vulnerabilities, like supervised learning, semi-supervised learning,\u00a0ensemble learning\u00a0and deep learning. Based on the analysis, supervised learning and deep learning approaches are trending in the software vulnerability detection community as these techniques are able to detect vulnerabilities such as\u00a0buffer overflow,\u00a0SQL\u00a0injection and cross-site scripting effectively with a significant detection performance, up to 95% of F1 score. Finally, this paper concludes with several discussions on potential future work in software vulnerability detection in terms of datasets, multi-vulnerabilities detection, transfer learning and real-world applications."
},
{
    "py/object": "data.DataClassPaper",
    "Title": "Towards Cross Project Vulnerability Prediction in Open Source Web Applications",
    "year": 2015,
    "ML_Techniques": " NB, LOG, SVM, DT, RF",
    "Category": "Vulnerability analysis",
    "Sub_category": "",
    "Venue": "ICEMIS",
    "Link": "https://dl.acm.org/doi/abs/10.1145/2832987.2833051",
    "bibtex": "inproceedings{547_Abunadi2015,\n    author = \"Abunadi, Ibrahim and Alenezi, Mamdouh\",\n    title = \"Towards Cross Project Vulnerability Prediction in Open Source Web Applications\",\n    year = \"2015\",\n    isbn = \"9781450334181\",\n    publisher = \"Association for Computing Machinery\",\n    address = \"New York, NY, USA\",\n    url = \"https://doi.org/547_Abunadi2015\",\n    doi = \"547_Abunadi2015\",\n    abstract = \"Building secure software is challenging, time-consuming, and expensive. Software vulnerability prediction models that identify vulnerable software components are usually used to focus security efforts, with the aim of helping to reduce the time and effort needed to secure software. Existing vulnerability prediction models use process or product metrics and machine learning techniques to identify vulnerable software components. Cross project vulnerability prediction plays a significant role in appraising the most likely vulnerable software components, specifically for new or inactive projects. Little effort has been spent to deliver clear guidelines on how to choose the training data for project vulnerability prediction. In this work, we present an empirical study aiming at clarifying how useful cross project prediction techniques in predicting software vulnerabilities. Our study employs the classification provided by different machine learning techniques to improve the detection of vulnerable components. We have elaborately compared the prediction performance of five well-known classifiers. The study is conducted on a publicly available dataset of several PHP open source web applications and in the context of cross project vulnerability prediction, which represents one of the main challenges in the vulnerability prediction field.\",\n    booktitle = \"Proceedings of the The International Conference on Engineering \\&amp; MIS 2015\",\n    articleno = \"42\",\n    numpages = \"5\",\n    keywords = \"Data mining, Software quality, Software security, Cross-project vulnerability prediction\",\n    location = \"Istanbul, Turkey\",\n    series = \"ICEMIS '15\"\n}\n\n",
    "abstract": "Building secure software is challenging, time-consuming, and expensive. Software vulnerability prediction models that identify vulnerable software components are usually used to focus security efforts, with the aim of helping to reduce the time and effort needed to secure software. Existing vulnerability prediction models use process or product metrics and machine learning techniques to identify vulnerable software components. Cross project vulnerability prediction plays a significant role in appraising the most likely vulnerable software components, specifically for new or inactive projects. Little effort has been spent to deliver clear guidelines on how to choose the training data for project vulnerability prediction. In this work, we present an empirical study aiming at clarifying how useful cross project prediction techniques in predicting software vulnerabilities. Our study employs the classification provided by different machine learning techniques to improve the detection of vulnerable components. We have elaborately compared the prediction performance of five well-known classifiers. The study is conducted on a publicly available dataset of several PHP open source web applications and in the context of cross project vulnerability prediction, which represents one of the main challenges in the vulnerability prediction field."
},
{
    "py/object": "data.DataClassPaper",
    "Title": "A Buffer Overflow Prediction Approach Based on Software Metrics and Machine Learning",
    "year": 2019,
    "ML_Techniques": "SVM, NB, AB, RF, DT",
    "Category": "Vulnerability analysis",
    "Sub_category": "",
    "Venue": "Security and Communication Networks",
    "Link": "https://www.hindawi.com/journals/scn/2019/8391425/",
    "bibtex": "article{550_Ren2019,\n    author = \"Ren, Jiadong and Zheng, Zhangqi and Liu, Qian and Wei, Zhiyao and Yan, Huaizhi\",\n    title = \"A {Buffer} {Overflow} {Prediction} {Approach} {Based} on {Software} {Metrics} and {Machine} {Learning}\",\n    volume = \"2019\",\n    issn = \"1939-0114\",\n    url = \"https://www.hindawi.com/journals/scn/2019/8391425/\",\n    doi = \"10.1155/2019/8391425\",\n    abstract = \"Buffer overflow vulnerability is the most common and serious type of vulnerability in software today, as network security issues have become increasingly critical. To alleviate the security threat, many vulnerability mining methods based on static and dynamic analysis have been developed. However, the current analysis methods have problems regarding high computational time, low test efficiency, low accuracy, and low versatility. This paper proposed a software buffer overflow vulnerability prediction method by using software metrics and a decision tree algorithm. First, the software metrics were extracted from the software source code, and data from the dynamic data stream at the functional level was extracted by a data mining method. Second, a model based on a decision tree algorithm was constructed to measure multiple types of buffer overflow vulnerabilities at the functional level. Finally, the experimental results showed that our method ran in less time than SVM, Bayes, adaboost, and random forest algorithms and achieved 82.53\\\\% and 87.51\\\\% accuracy in two different data sets. The method presented in this paper achieved the effect of accurately predicting software buffer overflow vulnerabilities in C/C++ and Java programs.\",\n    language = \"en\",\n    urldate = \"2022-05-19\",\n    journal = \"Security and Communication Networks\",\n    month = \"March\",\n    year = \"2019\",\n    note = \"Publisher: Hindawi\",\n    pages = \"e8391425\",\n    file = \"Full Text PDF:C\\:\\\\Users\\\\stefa\\\\Zotero\\\\storage\\\\C6UG65HX\\\\Ren et al. - 2019 - A Buffer Overflow Prediction Approach Based on Sof.pdf:application/pdf;Snapshot:C\\:\\\\Users\\\\stefa\\\\Zotero\\\\storage\\\\PGNUYNZN\\\\8391425.html:text/html\"\n}\n\n",
    "abstract": "Buffer overflow vulnerability is the most common and serious type of vulnerability in software today, as network security issues have become increasingly critical. To alleviate the security threat, many vulnerability mining methods based on static and dynamic analysis have been developed. However, the current analysis methods have problems regarding high computational time, low test efficiency, low accuracy, and low versatility. This paper proposed a software buffer overflow vulnerability prediction method by using software metrics and a\u00a0decision tree\u00a0algorithm. First, the software metrics were extracted from the software source code, and data from the dynamic data stream at the functional level was extracted by a data mining method. Second, a model based on a\u00a0decision tree\u00a0algorithm was constructed to measure multiple types of buffer overflow vulnerabilities at the functional level. Finally, the experimental results showed that our method ran in less time than\u00a0SVM, Bayes, adaboost, and random forest\u00a0algorithms and achieved 82.53% and 87.51% accuracy in two different data sets. The method presented in this paper achieved the effect of accurately predicting software buffer overflow vulnerabilities in C/C++ and Java programs."
},
{
    "py/object": "data.DataClassPaper",
    "Title": "Prediction of Cross-Site Scripting Attack Using Machine Learning Algorithms",
    "year": 2014,
    "ML_Techniques": "SVM, DT, NB",
    "Category": "Vulnerability analysis",
    "Sub_category": "",
    "Venue": "ICONIAA",
    "Link": "https://dl.acm.org/doi/abs/10.1145/2660859.2660969",
    "bibtex": "inproceedings{552_Vishnu2014,\n    author = \"Vishnu, B. A. and Jevitha, K. P.\",\n    title = \"Prediction of Cross-Site Scripting Attack Using Machine Learning Algorithms\",\n    year = \"2014\",\n    isbn = \"9781450329088\",\n    publisher = \"Association for Computing Machinery\",\n    address = \"New York, NY, USA\",\n    url = \"https://doi.org/552_Vishnu2014\",\n    doi = \"552_Vishnu2014\",\n    abstract = {Dynamic web pages are widely used by web applications to provide better user experience and to attract more web users. The web applications use the client side and server side scripts to provide dynamic behavior to the web pages. Cross-Site Scripting (XSS) attack uses malicious scripts and links injected into the trusted web pages to steal sensitive data from the victims. In this paper, we present the experimental results obtained using three machine learning algorithms (Na\\\"\"{\\i}ve Bayes, Support Vector Machine and J48 Decision Tree) for the prediction of Cross-site scripting attack. This is done using the features based on normal and malicious URLs and JavaScript. J48 gave better results than Na\\\"\"{\\i}ve Bayes and Support Vector Machine based on the features extracted from URL and Java Script code. All the algorithms gave comparatively better results with discretized attributes but noticeable difference in performance was seen only in the case of SVM.},\n    booktitle = \"Proceedings of the 2014 International Conference on Interdisciplinary Advances in Applied Computing\",\n    articleno = \"55\",\n    numpages = \"5\",\n    keywords = \"Cross Site Scripting (XSS), Web application security, Machine learning\",\n    location = \"Amritapuri, India\",\n    series = \"ICONIAAC '14\"\n}\n\n",
    "abstract": "Dynamic web pages are widely used by web applications to provide better user experience and to attract more web users. The web applications use the client side and server side scripts to provide dynamic behavior to the web pages. Cross-Site Scripting (XSS) attack uses malicious scripts and links injected into the trusted web pages to steal sensitive data from the victims. In this paper, we present the experimental results obtained using three machine learning algorithms (Na\u00efve Bayes, Support Vector Machine and J48 Decision Tree) for the prediction of Cross-site scripting attack. This is done using the features based on normal and malicious URLs and JavaScript. J48 gave better results than Na\u00efve Bayes and Support Vector Machine based on the features extracted from URL and Java Script code. All the algorithms gave comparatively better results with discretized attributes but noticeable difference in performance was seen only in the case of SVM."
},
{
    "py/object": "data.DataClassPaper",
    "Title": "FastEmbed: Predicting vulnerability exploitation possibility based on ensemble machine learning algorithm",
    "year": 2020,
    "ML_Techniques": "FT, LGBM",
    "Category": "Vulnerability analysis",
    "Sub_category": "",
    "Venue": "PLoS ONE",
    "Link": "https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0228439",
    "bibtex": "article{553_Fang2020,\n    author = \"Fang, Yong and Liu, Yongcheng and Huang, Cheng and Liu, Liang\",\n    title = \"{FastEmbed}: {Predicting} vulnerability exploitation possibility based on ensemble machine learning algorithm\",\n    volume = \"15\",\n    shorttitle = \"{FastEmbed}\",\n    url = \"https://ui.adsabs.harvard.edu/abs/2020PLoSO..1528439F\",\n    doi = \"10.1371/journal.pone.0228439\",\n    urldate = \"2022-05-25\",\n    journal = \"PLoS ONE\",\n    month = \"February\",\n    year = \"2020\",\n    note = \"ADS Bibcode: 2020PLoSO..1528439F\",\n    pages = \"e0228439\",\n    file = \"Full Text:/home/sgeorgiou/Zotero/storage/EI2YDX7D/Fang et al. - 2020 - FastEmbed Predicting vulnerability exploitation p.pdf:application/pdf\"\n}\n\n",
    "abstract": "In recent years, the number of vulnerabilities discovered and publicly disclosed has shown a sharp upward trend. However, the value of exploitation of vulnerabilities varies for attackers, considering that only a small fraction of vulnerabilities are exploited. Therefore, the realization of quick exclusion of the non-exploitable vulnerabilities and optimal patch prioritization on limited resources has become imperative for organizations. Recent works using machine learning techniques predict exploited vulnerabilities by extracting features from open-source intelligence (OSINT). However, in the face of explosive growth of vulnerability information, there is room for improvement in the application of past methods to multiple threat intelligence. A more general method is needed to deal with various threat intelligence sources. Moreover, in previous methods, traditional text processing methods were used to deal with vulnerability related descriptions, which only grasped the static statistical characteristics but ignored the context and the meaning of the words of the text. To address these challenges, we propose an exploit prediction model, which is based on a combination of fastText and LightGBM algorithm and called fastEmbed. We replicate key portions of the state-of-the-art work of exploit prediction and use them as benchmark models. Our model outperforms the baseline model whether in terms of the generalization ability or the prediction ability without temporal intermixing with an average overall improvement of 6.283% by learning the embedding of vulnerability-related text on extremely imbalanced data sets. Besides, in terms of predicting the exploits in the wild, our model also outperforms the baseline model with an F1 measure of 0.586 on the minority class (33.577% improvement over the work using features from darkweb/deepweb). The results demonstrate that the model can improve the ability to describe the exploitability of vulnerabilities and predict exploits in the wild effectively."
},
{
    "py/object": "data.DataClassPaper",
    "Title": "Towards a software vulnerability prediction model using traceable code patterns and software metrics",
    "year": 2017,
    "ML_Techniques": "SVM, LOG",
    "Category": "Vulnerability analysis",
    "Sub_category": "",
    "Venue": "ASE",
    "Link": "https://ieeexplore.ieee.org/abstract/document/8115724",
    "bibtex": "INPROCEEDINGS{554_Sultana2017,\n    author = \"Sultana, Kazi Zakia\",\n    booktitle = \"2017 32nd IEEE/ACM International Conference on Automated Software Engineering (ASE)\",\n    title = \"Towards a software vulnerability prediction model using traceable code patterns and software metrics\",\n    year = \"2017\",\n    volume = \"\",\n    number = \"\",\n    pages = \"1022-1025\",\n    doi = \"10.1109/ASE.2017.554_Sultana2017\"\n}\n\n",
    "abstract": "Software security is an important aspect of ensuring software quality. The goal of this study is to help developers evaluate software security using traceable patterns and software metrics during development. The concept of traceable patterns is similar to design patterns but they can be automatically recognized and extracted from source code. If these patterns can better predict vulnerable code compared to traditional software metrics, they can be used in developing a vulnerability prediction model to classify code as vulnerable or not. By analyzing and comparing the performance of traceable patterns with metrics, we propose a vulnerability prediction model. This study explores the performance of some code patterns in vulnerability prediction and compares them with traditional software metrics. We use the findings to build an effective vulnerability prediction model. We evaluate security vulnerabilities reported for Apache Tomcat, Apache CXF and three stand-alone Java web applications. We use machine learning and statistical techniques for predicting vulnerabilities using traceable patterns and metrics as features. We found that patterns have a lower false negative rate and higher recall in detecting vulnerable code than the traditional software metrics."
},
{
    "py/object": "data.DataClassPaper",
    "Title": "Development of a Software Vulnerability Prediction Web Service Based on Artificial Neural Networks",
    "year": 2017,
    "ML_Techniques": "MLP, BPM, BDT, DF, DJ, LDSVM, LOG, SVM, ANN ",
    "Category": "Vulnerability analysis",
    "Sub_category": "",
    "Venue": "PAKDD",
    "Link": "https://link.springer.com/chapter/10.1007/978-3-319-67274-8_6",
    "bibtex": "inproceedings{560_Catal2017,\n    author = \"Catal, Cagatay and Akbulut, Akhan and Ekenoglu, Ecem and Alemdaroglu, Meltem\",\n    title = \"Development of a software vulnerability prediction web service based on artificial neural networks\",\n    booktitle = \"Pacific-Asia Conference on Knowledge Discovery and Data Mining\",\n    pages = \"59--67\",\n    year = \"2017\",\n    organization = \"Springer\"\n}\n\n",
    "abstract": "Detecting vulnerable components of a web application is an important activity to allocate verification resources effectively. Most of the studies proposed several vulnerability prediction models based on private and public datasets so far. In this study, we aimed to design and implement a software vulnerability prediction web service which will be hosted on Azure cloud computing platform. We investigated several machine learning techniques which exist in Azure Machine Learning Studio environment and observed that the best overall performance on three datasets is achieved when Multi-Layer Perceptron method is applied. Software metrics values are received from a web form and sent to the vulnerability prediction web service. Later, prediction result is computed and shown on the web form to notify the testing expert. Training models were built on datasets which include vulnerability data from Drupal, Moodle, and PHPMyAdmin projects. Experimental results showed that Artificial Neural Networks is a good alternative to build a vulnerability prediction model and building a web service for vulnerability prediction purpose is a good approach for complex systems."
},
{
    "py/object": "data.DataClassPaper",
    "Title": "Deep Learning based Vulnerability Detection: Are We There Yet",
    "year": 2021,
    "ML_Techniques": "",
    "Category": "Vulnerability analysis",
    "Sub_category": "",
    "Venue": "TSE",
    "Link": "https://ieeexplore.ieee.org/abstract/document/9448435",
    "bibtex": "article{562_Chakraborty2021,\n    author = \"Chakraborty, Saikat and Krishna, Rahul and Ding, Yangruibo and Ray, Baishakhi\",\n    title = \"Deep learning based vulnerability detection: Are we there yet\",\n    journal = \"IEEE Transactions on Software Engineering\",\n    year = \"2021\",\n    publisher = \"IEEE\"\n}\n\n",
    "abstract": "Automated detection of software vulnerabilities is a fundamental problem in software security. Existing program analysis techniques either suffer from high false positives or false negatives. Recent progress in Deep Learning (DL) has resulted in a surge of interest in applying DL for automated vulnerability detection. Several recent studies have demonstrated promising results achieving an accuracy of up to 95% at detecting vulnerabilities. In this paper, we ask, \"how well do the state-of-the-art DL-based techniques perform in a real-world vulnerability prediction scenario\". To our surprise, we find that their performance drops by more than 50%. A systematic investigation of what causes such precipitous performance drop reveals that existing DL-based vulnerability prediction approaches suffer from challenges with the training data (e.g., data duplication, unrealistic distribution of vulnerable classes, etc.) and with the model choices (e.g., simple token-based models). As a result, these approaches often do not learn features related to the actual cause of the vulnerabilities. Instead, they learn unrelated artifacts from the dataset (e.g., specific variable/function names, etc.). Leveraging these empirical findings, we demonstrate how a more principled approach to data collection and model design, based on realistic settings of vulnerability prediction, can lead to better solutions. The resulting tools perform significantly better than the studied baseline up to 33.57% boost in precision and 128.38% boost in recall compared to the best performing model in the literature. Overall, this paper elucidates existing DL-based vulnerability prediction systems' potential issues and draws a roadmap for future DL-based vulnerability prediction research. In that spirit, we make available all the artifacts supporting our results: https://git.io/Jf6IA."
},
{
    "py/object": "data.DataClassPaper",
    "Title": "A Machine Learning Approach for Vulnerability Curation",
    "year": 2020,
    "ML_Techniques": "RF, GNB, KNN, SVM, GB, AB, LOG",
    "Category": "Vulnerability analysis",
    "Sub_category": "",
    "Venue": "MSR",
    "Link": "https://dl.acm.org/doi/abs/10.1145/3379597.3387461",
    "bibtex": "inbook{563_Chen2020,\n    author = \"Chen, Yang and Santosa, Andrew E. and Yi, Ang Ming and Sharma, Abhishek and Sharma, Asankhaya and Lo, David\",\n    title = \"A Machine Learning Approach for Vulnerability Curation\",\n    year = \"2020\",\n    isbn = \"9781450375177\",\n    publisher = \"Association for Computing Machinery\",\n    address = \"New York, NY, USA\",\n    url = \"https://doi.org/563_Chen2020\",\n    abstract = \"Software composition analysis depends on database of open-source library vulerabilities, curated by security researchers using various sources, such as bug tracking systems, commits, and mailing lists. We report the design and implementation of a machine learning system to help the curation by by automatically predicting the vulnerability-relatedness of each data item. It supports a complete pipeline from data collection, model training and prediction, to the validation of new models before deployment. It is executed iteratively to generate better models as new input data become available. We use self-training to significantly and automatically increase the size of the training dataset, opportunistically maximizing the improvement in the models' quality at each iteration. We devised new deployment stability metric to evaluate the quality of the new models before deployment into production, which helped to discover an error. We experimentally evaluate the improvement in the performance of the models in one iteration, with 27.59\\% maximum PR AUC improvements. Ours is the first of such study across a variety of data sources. We discover that the addition of the features of the corresponding commits to the features of issues/pull requests improve the precision for the recall values that matter. We demonstrate the effectiveness of self-training alone, with 10.50\\% PR AUC improvement, and we discover that there is no uniform ordering of word2vec parameters sensitivity across data sources.\",\n    booktitle = \"Proceedings of the 17th International Conference on Mining Software Repositories\",\n    pages = \"32\u201342\",\n    numpages = \"11\"\n}\n\n",
    "abstract": "Software composition analysis depends on database of open-source library vulerabilities, curated by security researchers using various sources, such as bug tracking systems, commits, and mailing lists. We report the design and implementation of a machine learning system to help the curation by by automatically predicting the vulnerability-relatedness of each data item. It supports a complete pipeline from data collection, model training and prediction, to the validation of new models before deployment. It is executed iteratively to generate better models as new input data become available. We use self-training to significantly and automatically increase the size of the training dataset, opportunistically maximizing the improvement in the models' quality at each iteration. We devised new deployment stability metric to evaluate the quality of the new models before deployment into production, which helped to discover an error. We experimentally evaluate the improvement in the performance of the models in one iteration, with 27.59% maximum PR AUC improvements. Ours is the first of such study across a variety of data sources. We discover that the addition of the features of the corresponding commits to the features of issues/pull requests improve the precision for the recall values that matter. We demonstrate the effectiveness of self-training alone, with 10.50% PR AUC improvement, and we discover that there is no uniform ordering of word2vec parameters sensitivity across data sources."
},
{
    "py/object": "data.DataClassPaper",
    "Title": "Predicting Vulnerable Software Components through N-Gram Analysis and Statistical Feature Selection",
    "year": 2015,
    "ML_Techniques": "SVM",
    "Category": "Vulnerability analysis",
    "Sub_category": "",
    "Venue": "ICMLA",
    "Link": "https://ieeexplore.ieee.org/abstract/document/7424372",
    "bibtex": "INPROCEEDINGS{565_Pang2015,\n    author = \"Pang, Yulei and Xue, Xiaozhen and Namin, Akbar Siami\",\n    booktitle = \"2015 IEEE 14th International Conference on Machine Learning and Applications (ICMLA)\",\n    title = \"Predicting Vulnerable Software Components through N-Gram Analysis and Statistical Feature Selection\",\n    year = \"2015\",\n    volume = \"\",\n    number = \"\",\n    pages = \"543-548\",\n    doi = \"10.1109/ICMLA.2015.99\"\n}\n\n",
    "abstract": "Vulnerabilities need to be detected and removed from software. Although previous studies demonstrated the usefulness of employing prediction techniques in deciding about vulnerabilities of software components, the accuracy and improvement of effectiveness of these prediction techniques is still a grand challenging research question. This paper proposes a hybrid technique based on combining N-gram analysis and feature selection algorithms for predicting vulnerable software components where features are defined as continuous sequences of token in source code files, i.e., Java class file. Machine learning-based feature selection algorithms are then employed to reduce the feature and search space. We evaluated the proposed technique based on some Java Android applications, and the results demonstrated that the proposed technique could predict vulnerable classes, i.e., software components, with high precision, accuracy and recall."
},
{
    "py/object": "data.DataClassPaper",
    "Title": "A performance evaluation of deep-learnt features for software vulnerability detection",
    "year": 2018,
    "ML_Techniques": "DT, KNN, LDA, NN, RF, SVM",
    "Category": "Vulnerability analysis",
    "Sub_category": "",
    "Venue": "Concurrency and Computation: Practice and Experience",
    "Link": "https://onlinelibrary.wiley.com/doi/abs/10.1002/cpe.5103",
    "bibtex": "article{567_Ban2019,\n    author = \"Ban, Xinbo and Liu, Shigang and Chen, Chao and Chua, Caslon\",\n    title = \"A performance evaluation of deep-learnt features for software vulnerability detection\",\n    volume = \"31\",\n    issn = \"1532-0634\",\n    url = \"https://onlinelibrary.wiley.com/doi/abs/10.1002/cpe.5103\",\n    doi = \"10.1002/cpe.5103\",\n    abstract = \"Software vulnerability is a critical issue in the realm of cyber security. In terms of techniques, machine learning (ML) has been successfully used in many real-world problems such as software vulnerability detection, malware detection and function recognition, for high-quality feature representation learning. In this paper, we propose a performance evaluation study on ML based solutions for software vulnerability detection, conducting three experiments: machine learning-based techniques for software vulnerability detection based on the scenario of single type of vulnerability and multiple types of vulnerabilities per dataset; machine learning-based techniques for cross-project software vulnerability detection; and software vulnerability detection when facing the class imbalance problem with varying imbalance ratios. Experimental results show that it is possible to employ software vulnerability detection based on ML techniques. However, ML-based techniques suffer poor performance on both cross-project and class imbalance problem in software vulnerability detection.\",\n    language = \"en\",\n    number = \"19\",\n    urldate = \"2022-05-28\",\n    journal = \"Concurrency and Computation: Practice and Experience\",\n    year = \"2019\",\n    note = \"\\\\_eprint: https://onlinelibrary.wiley.com/doi/pdf/10.1002/cpe.5103\",\n    keywords = \"deep learning, security, software vulnerability\",\n    pages = \"e5103\",\n    annote = \"e5103 cpe.5103\",\n    file = \"Snapshot:/home/sgeorgiou/Zotero/storage/FR76M223/cpe.html:text/html\"\n}\n\n",
    "abstract": "Software vulnerability is a critical issue in the realm of cyber security. In terms of techniques, machine learning (ML) has been successfully used in many real-world problems such as software vulnerability detection, malware detection and function recognition, for high-quality feature representation learning. In this paper, we propose a performance evaluation study on ML based solutions for software vulnerability detection, conducting three experiments: machine learning-based techniques for software vulnerability detection based on the scenario of single type of vulnerability and multiple types of vulnerabilities per dataset; machine learning-based techniques for cross-project software vulnerability detection; and software vulnerability detection when facing the class imbalance problem with varying imbalance ratios. Experimental results show that it is possible to employ software vulnerability detection based on ML techniques. However, ML-based techniques suffer poor performance on both cross-project and class imbalance problem in software vulnerability detection."
},
{
    "py/object": "data.DataClassPaper",
    "Title": "Predicting Vulnerability Type in Common Vulnerabilities and Exposures (CVE) Database with Machine Learning Classifiers",
    "year": 2021,
    "ML_Techniques": "RF, SVM, NB",
    "Category": "Vulnerability analysis",
    "Sub_category": "",
    "Venue": "ELECTRONICA",
    "Link": "https://ieeexplore.ieee.org/abstract/document/9513723",
    "bibtex": "INPROCEEDINGS{569_Yosifova2021,\n    author = \"Yosifova, Veneta and Tasheva, Antoniya and Trifonov, Roumen\",\n    booktitle = \"2021 12th National Conference with International Participation (ELECTRONICA)\",\n    title = \"Predicting Vulnerability Type in Common Vulnerabilities and Exposures (CVE) Database with Machine Learning Classifiers\",\n    year = \"2021\",\n    volume = \"\",\n    number = \"\",\n    pages = \"1-6\",\n    doi = \"10.1109/ELECTRONICA52725.2021.569_Yosifova2021\"\n}\n\n",
    "abstract": "Vulnerability type is not part of the standard CVE scheme so the ability to determine it only on the basis of text description would be a very useful for automated vulnerability handling. The growing number of hardware and software vulnerabilities discovered every year makes it more difficult for manual classification of the vulnerabilities types. This justifies the need for automatic machine learning classification. In this study we research the performance of base ML classifier algorithms, such as Linear Support Vector Classification, Naive Bayes, and Random Forest Classifier. To measure the performance of our classifiers, we use precision, recall, and f1-score evaluation metrics. Previous studies have focused on machine learning methods predicting platform vendor and products, vulnerability scoring, software vulnerabilities exploitation. Our study aims to show that machine learning is suitable for automated vulnerability type classification."
},
{
    "py/object": "data.DataClassPaper",
    "Title": "Deep-water framework: The Swiss army knife of humans working with machine learning models",
    "year": 2020,
    "ML_Techniques": "",
    "Category": "Code representation",
    "Sub_category": "",
    "Venue": "SoftwareX",
    "Link": "https://www.sciencedirect.com/science/article/pii/S2352711019303772 ",
    "bibtex": "article{578_Ferenc2020,\n    author = \"Ferenc, Rudolf and Viszkok, Tam\u00e1s and Aladics, Tam\u00e1s and J\u00e1sz, Judit and Heged\u0171s, P\u00e9ter\",\n    title = \"Deep-water framework: The Swiss army knife of humans working with machine learning models\",\n    journal = \"SoftwareX\",\n    volume = \"12\",\n    pages = \"100551\",\n    year = \"2020\",\n    issn = \"2352-7110\",\n    doi = \"https://doi.org/10.1016/j.softx.2020.100551\",\n    url = \"https://www.sciencedirect.com/science/article/pii/S2352711019303772\",\n    keywords = \"Deep-learning, Machine learning, Software analysis, Model management, Data visualization\",\n    abstract = \"Working with machine learning models has become an everyday task not only for software engineers, but for a much wider spectrum of researchers and professionals. Training such models involves finding the best learning methods and their best hyper-parameters for a specific task, keeping track of the achieved performance measures, comparing the results visually, etc. If we add feature extraction methods \u2013 that precede the learning phase and depend on many hyper-parameters themselves \u2013 into the mixture, like source code embedding that is quite common in the field of software analysis, the task cries out for supporting tools. We propose a framework called Deep-Water that works similarly to a configuration management tool in the area of software engineering. It supports defining arbitrary feature extraction and learning methods for an input dataset and helps in executing all the training tasks with different hyper-parameters in a distributed manner. The framework stores all circumstances, parameters and results of training, which can be filtered and visualized later. We successfully used the tool in several software analysis based prediction tasks, like vulnerability or bug prediction, but it is general enough to be applicable in other areas as well, e.g. NLP, image processing, or even other non-IT fields.\"\n}\n\n",
    "abstract": "Working with machine learning models has become an everyday task not only for software engineers, but for a much wider spectrum of researchers and professionals. Training such models involves finding the best learning methods and their best hyper-parameters for a specific task, keeping track of the achieved performance measures, comparing the results visually, etc. If we add feature extraction methods \u2013 that precede the learning phase and depend on many hyper-parameters themselves \u2013 into the mixture, like source code embedding that is quite common in the field of software analysis, the task cries out for supporting tools. We propose a framework called Deep-Water that works similarly to a configuration management tool in the area of software engineering. It supports defining arbitrary feature extraction and learning methods for an input dataset and helps in executing all the training tasks with different hyper-parameters in a distributed manner. The framework stores all circumstances, parameters and results of training, which can be filtered and visualized later. We successfully used the tool in several software analysis based prediction tasks, like vulnerability or bug prediction, but it is general enough to be applicable in other areas as well, e.g. NLP, image processing, or even other non-IT fields."
},
{
    "py/object": "data.DataClassPaper",
    "Title": "Predicting Vulnerable Software Components through Deep Neural Network",
    "year": 2017,
    "ML_Techniques": "DNN",
    "Category": "Vulnerability analysis",
    "Sub_category": "",
    "Venue": "ICDLT",
    "Link": "https://dl.acm.org/doi/abs/10.1145/3094243.3094245 ",
    "bibtex": "inproceedings{583_Pang2017,\n    author = \"Pang, Yulei and Xue, Xiaozhen and Wang, Huaying\",\n    title = \"Predicting Vulnerable Software Components through Deep Neural Network\",\n    year = \"2017\",\n    isbn = \"9781450352321\",\n    publisher = \"Association for Computing Machinery\",\n    address = \"New York, NY, USA\",\n    url = \"https://doi.org/583_Pang2017\",\n    doi = \"583_Pang2017\",\n    abstract = \"Vulnerabilities need to be detected and removed from software. Although previous studies demonstrated the usefulness of employing prediction techniques in deciding about vulnerabilities of software components, the improvement of effectiveness of these prediction techniques is still a grand challenging research question. This paper employed a technique based on a deep neural network with rectifier linear units trained with stochastic gradient descent method and batch normalization, for predicting vulnerable software components. The features are defined as continuous sequences of tokens in source code files. Besides, a statistical feature selection algorithm is then employed to reduce the feature and search space. We evaluated the proposed technique based on some Java Android applications, and the results demonstrated that the proposed technique could predict vulnerable classes, i.e., software components, with high precision, accuracy and recall.\",\n    booktitle = \"Proceedings of the 2017 International Conference on Deep Learning Technologies\",\n    pages = \"6\u201310\",\n    numpages = \"5\",\n    keywords = \"vulnerability prediction, Android, deep learning, neural network\",\n    location = \"Chengdu, China\",\n    series = \"ICDLT '17\"\n}\n\n",
    "abstract": "Vulnerabilities need to be detected and removed from software. Although previous studies demonstrated the usefulness of employing prediction techniques in deciding about vulnerabilities of software components, the improvement of effectiveness of these prediction techniques is still a grand challenging research question. This paper employed a technique based on a deep neural network with rectifier linear units trained with stochastic gradient descent method and batch normalization, for predicting vulnerable software components. The features are defined as continuous sequences of tokens in source code files. Besides, a statistical feature selection algorithm is then employed to reduce the feature and search space. We evaluated the proposed technique based on some Java Android applications, and the results demonstrated that the proposed technique could predict vulnerable classes, i.e., software components, with high precision, accuracy and recall."
},
{
    "py/object": "data.DataClassPaper",
    "Title": "Cross-Project Transfer Representation Learning for Vulnerable Function Discovery",
    "year": 2018,
    "ML_Techniques": "BOW, Bi-LSTM",
    "Category": "Vulnerability analysis",
    "Sub_category": "",
    "Venue": "TII",
    "Link": "https://ieeexplore.ieee.org/abstract/document/8329207",
    "bibtex": "ARTICLE{584_Lin2018,\n    author = \"Lin, Guanjun and Zhang, Jun and Luo, Wei and Pan, Lei and Xiang, Yang and De Vel, Olivier and Montague, Paul\",\n    journal = \"IEEE Transactions on Industrial Informatics\",\n    title = \"Cross-Project Transfer Representation Learning for Vulnerable Function Discovery\",\n    year = \"2018\",\n    volume = \"14\",\n    number = \"7\",\n    pages = \"3289-3297\",\n    doi = \"10.1109/TII.2018.2821768\"\n}\n\n",
    "abstract": "Machine learning is now widely used to detect security vulnerabilities in the software, even before the software is released. But its potential is often severely compromised at the early stage of a software project when we face a shortage of high-quality training data and have to rely on overly generic hand-crafted features. This paper addresses this cold-start problem of machine learning, by learning rich features that generalize across similar projects. To reach an optimal balance between feature-richness and generalizability, we devise a data-driven method including the following innovative ideas. First, the code semantics are revealed through serialized abstract syntax trees (ASTs), with tokens encoded by Continuous Bag-of-Words neural embeddings. Next, the serialized ASTs are fed to a sequential deep learning classifier (Bi-LSTM) to obtain a representation indicative of software vulnerability. Finally, the neural representation obtained from existing software projects is then transferred to the new project to enable early vulnerability detection even with a small set of training labels. To validate this vulnerability detection approach, we manually labeled 457 vulnerable functions and collected 30\u00a0000+ nonvulnerable functions from six open-source projects. The empirical results confirmed that the trained model is capable of generating representations that are indicative of program vulnerability and is adaptable across multiple projects. Compared with the traditional code metrics, our transfer-learned representations are more effective for predicting vulnerable functions, both within a project and across multiple projects."
},
{
    "py/object": "data.DataClassPaper",
    "Title": "LEOPARD: Identifying Vulnerable Code for Vulnerability Assessment Through Program Metrics",
    "year": 2019,
    "ML_Techniques": "RF, SVM, NB, GB",
    "Category": "Vulnerability analysis",
    "Sub_category": "",
    "Venue": "ICSE",
    "Link": "https://ieeexplore.ieee.org/abstract/document/8812029",
    "bibtex": "INPROCEEDINGS{587_Du2019,\n    author = \"Du, Xiaoning and Chen, Bihuan and Li, Yuekang and Guo, Jianmin and Zhou, Yaqin and Liu, Yang and Jiang, Yu\",\n    booktitle = \"2019 IEEE/ACM 41st International Conference on Software Engineering (ICSE)\",\n    title = \"LEOPARD: Identifying Vulnerable Code for Vulnerability Assessment Through Program Metrics\",\n    year = \"2019\",\n    volume = \"\",\n    number = \"\",\n    pages = \"60-71\",\n    doi = \"10.1109/ICSE.2019.00024\"\n}\n\n",
    "abstract": "Identifying potentially vulnerable locations in a code base is critical as a pre-step for effective vulnerability assessment; i.e., it can greatly help security experts put their time and effort to where it is needed most. Metric-based and pattern-based methods have been presented for identifying vulnerable code. The former relies on machine learning and cannot work well due to the severe imbalance between non-vulnerable and vulnerable code or lack of features to characterize vulnerabilities. The latter needs the prior knowledge of known vulnerabilities and can only identify similar but not new types of vulnerabilities. In this paper, we propose and implement a generic, lightweight and extensible framework, LEOPARD, to identify potentially vulnerable functions through program metrics. LEOPARD requires no prior knowledge about known vulnerabilities. It has two steps by combining two sets of systematically derived metrics. First, it uses complexity metrics to group the functions in a target application into a set of bins. Then, it uses vulnerability metrics to rank the functions in each bin and identifies the top ones as potentially vulnerable. Our experimental results on 11 real-world projects have demonstrated that, LEOPARD can cover 74.0% of vulnerable functions by identifying 20% of functions as vulnerable and outperform machine learning-based and static analysis-based techniques. We further propose three applications of LEOPARD for manual code review and fuzzing, through which we discovered 22 new bugs in real applications like PHP, radare2 and FFmpeg, and eight of them are new vulnerabilities."
},
{
    "py/object": "data.DataClassPaper",
    "Title": "A novel deep learning-based feature selection model for improving the static analysis of vulnerability detection",
    "year": 2021,
    "ML_Techniques": "CNN, DNN, RNN, LSTM, GRU",
    "Category": "Vulnerability analysis",
    "Sub_category": "",
    "Venue": "NCA",
    "Link": "https://link.springer.com/article/10.1007/s00521-021-06047-x",
    "bibtex": "article{589_Batur2021,\n    author = \"Batur \\c{S}ahin, Canan and Abualigah, Laith\",\n    title = \"A Novel Deep Learning-Based Feature Selection Model for Improving the Static Analysis of Vulnerability Detection\",\n    year = \"2021\",\n    issue_date = \"Oct 2021\",\n    publisher = \"Springer-Verlag\",\n    address = \"Berlin, Heidelberg\",\n    volume = \"33\",\n    number = \"20\",\n    issn = \"0941-0643\",\n    url = \"https://doi.org/589_Batur2021\",\n    doi = \"589_Batur2021\",\n    abstract = \"The automatic detection of software vulnerabilities is considered a complex and common research problem. It is possible to detect several security vulnerabilities using static analysis (SA) tools, but comparatively high false-positive rates are observed in this case. Existing solutions to this problem depend on human experts to identify functionality, and as a result, several vulnerabilities are often overlooked. This paper introduces a novel approach for effectively and reliably finding vulnerabilities in open-source software programs. In this paper, we are motivated to examine the potential of the clonal selection theory. A novel deep learning-based vulnerability detection model is proposed to define features using the clustering theory of the clonal selection algorithm. To our knowledge, this is the first time we have used deep-learned long-lived team-hacker features to process memories of sequential features and mapping from the entire history of previous inputs to target vectors in theory. With an immune-based feature selection model, the proposed approach aimed to improve static analyses' detection abilities. A real-world SA dataset is used based on three open-source PHP applications. Comparisons are conducted based on using a classification model for all features to measure the proposed feature selection methods' classification improvement. The results demonstrated that the proposed method got significant enhancements, which occurred in the classification accuracy also in the true positive rate.\",\n    journal = \"Neural Comput. Appl.\",\n    month = \"oct\",\n    pages = \"14049\u201314067\",\n    numpages = \"19\",\n    keywords = \"Feature selection, Immune systems, Software vulnerability prediction, Deep learning\"\n}\n\n",
    "abstract": "The automatic detection of software vulnerabilities is considered a complex and common research problem. It is possible to detect several security vulnerabilities using static analysis (SA) tools, but comparatively high false-positive rates are observed in this case. Existing solutions to this problem depend on human experts to identify functionality, and as a result, several vulnerabilities are often overlooked. This paper introduces a novel approach for effectively and reliably finding vulnerabilities in open-source software programs. In this paper, we are motivated to examine the potential of the clonal selection theory. A novel deep learning-based vulnerability detection model is proposed to define features using the clustering theory of the clonal selection algorithm. To our knowledge, this is the first time we have used deep-learned long-lived team-hacker features to process memories of sequential features and mapping from the entire history of previous inputs to target vectors in theory. With an immune-based feature selection model, the proposed approach aimed to improve static analyses' detection abilities. A real-world SA dataset is used based on three open-source PHP applications. Comparisons are conducted based on using a classification model for all features to measure the proposed feature selection methods' classification improvement. The results demonstrated that the proposed method got significant enhancements, which occurred in the classification accuracy also in the true positive rate."
},
{
    "py/object": "data.DataClassPaper",
    "Title": "Deep Learning-Based Vulnerable Function Detection: A Benchmark",
    "year": 2019,
    "ML_Techniques": "DNN, LSTM, GRU, Bi-LSTM, Bi-GRU, Text-CNN",
    "Category": "Vulnerability analysis",
    "Sub_category": "",
    "Venue": "ICICS",
    "Link": "https://link.springer.com/chapter/10.1007/978-3-030-41579-2_13",
    "bibtex": "inproceedings{591_Lin2020,\n    author = \"Lin, Guanjun and Xiao, Wei and Zhang, Jun and Xiang, Yang\",\n    editor = \"Zhou, Jianying and Luo, Xiapu and Shen, Qingni and Xu, Zhen\",\n    address = \"Cham\",\n    series = \"Lecture {Notes} in {Computer} {Science}\",\n    title = \"Deep {Learning}-{Based} {Vulnerable} {Function} {Detection}: {A} {Benchmark}\",\n    isbn = \"978-3-030-41579-2\",\n    shorttitle = \"Deep {Learning}-{Based} {Vulnerable} {Function} {Detection}\",\n    doi = \"10.1007/978-3-030-41579-2\\_13\",\n    abstract = \"The application of Deep Learning (DL) technique for code analysis enables the rich and latent patterns within software code to be revealed, facilitating various downstream tasks such as the software defect and vulnerability detection. Many DL architectures have been applied for identifying vulnerable code segments in recent literature. However, the proposed studies were evaluated on self-constructed/-collected datasets. There is a lack of unified performance criteria, acting as a baseline for measuring the effectiveness of the proposed DL-based approaches. This paper proposes a benchmarking framework for building and testing DL-based vulnerability detectors, providing six built-in mainstream neural network models with three embedding solutions available for selection. The framework also offers easy-to-use APIs for integration of new network models and embedding methods. In addition, we constructed a real-world vulnerability ground truth dataset containing manually labelled 1,471 vulnerable functions and 1,320 vulnerable files from nine open-source software projects. With the proposed framework and the ground truth dataset, researchers can conveniently establish a vulnerability detection baseline system for comparison and evaluation. This paper also includes usage examples of the proposed framework, aiming to investigate the performance behaviours of mainstream neural network models and providing a reference for DL-based vulnerability detection at function-level.\",\n    language = \"en\",\n    booktitle = \"Information and {Communications} {Security}\",\n    publisher = \"Springer International Publishing\",\n    year = \"2020\",\n    keywords = \"Function-level detection, Neural network, Vulnerability detection\",\n    pages = \"219--232\"\n}\n\n",
    "abstract": "The application of Deep Learning (DL) technique for code analysis enables the rich and latent patterns within software code to be revealed, facilitating various downstream tasks such as the software defect and vulnerability detection. Many DL architectures have been applied for identifying vulnerable code segments in recent literature. However, the proposed studies were evaluated on self-constructed/-collected datasets. There is a lack of unified performance criteria, acting as a baseline for measuring the effectiveness of the proposed DL-based approaches. This paper proposes a benchmarking framework for building and testing DL-based vulnerability detectors, providing six built-in mainstream neural network models with three embedding solutions available for selection. The framework also offers easy-to-use APIs for integration of new network models and embedding methods. In addition, we constructed a real-world vulnerability ground truth dataset containing manually labelled 1,471 vulnerable functions and 1,320 vulnerable files from nine open-source software projects. With the proposed framework and the ground truth dataset, researchers can conveniently establish a vulnerability detection baseline system for comparison and evaluation. This paper also includes usage examples of the proposed framework, aiming to investigate the performance behaviours of mainstream neural network models and providing a reference for DL-based vulnerability detection at function-level."
},
{
    "py/object": "data.DataClassPaper",
    "Title": "A Novel Solutions for Malicious Code Detection and Family Clustering Based on Machine Learning",
    "year": 2019,
    "ML_Techniques": "MNB, BNB, KNN, GBDT, SVM, XG",
    "Category": "Vulnerability analysis",
    "Sub_category": "",
    "Venue": "IEEE Access",
    "Link": "https://ieeexplore.ieee.org/abstract/document/8863895",
    "bibtex": "ARTICLE{595_Yang2019,\n    author = \"Yang, Hangfeng and Li, Shudong and Wu, Xiaobo and Lu, Hui and Han, Weihong\",\n    journal = \"IEEE Access\",\n    title = \"A Novel Solutions for Malicious Code Detection and Family Clustering Based on Machine Learning\",\n    year = \"2019\",\n    volume = \"7\",\n    number = \"\",\n    pages = \"148853-148860\",\n    doi = \"10.1109/ACCESS.2019.2946482\"\n}\n\n",
    "abstract": "Malware has become a major threat to cyberspace security, not only because of the increasing complexity of malware itself, but also because of the continuously created and produced malicious code. In this paper, we propose two novel methods to solve the malware identification problem. One is to solve to malware classification. Different from traditional machine learning, our method introduces the ensemble models to solve the malware classification problem. The other is to solve malware family clustering. Different from the classic malware family clustering algorithm, our method introduces the t-SNE algorithm to visualize the feature data and then determines the number of malware families. The two proposed novel methods have been extensively tested on a large number of real-world malware samples. The results show that the first one is far superior to the existed individual models and the second one has a good adaptation ability. Our methods can be used for malicious code classification and family clustering, also with higher accuracy."
},
{
    "py/object": "data.DataClassPaper",
    "Title": "A Hybrid Malicious Code Detection Method based on Deep Learning",
    "year": 2015,
    "ML_Techniques": "AE, DBN",
    "Category": "Vulnerability analysis",
    "Sub_category": "",
    "Venue": "IJSIA",
    "Link": "http://www.covert.io/research-papers/deep-learning-security/A%20Hybrid%20Malicious%20Code%20Detection%20Method%20based%20on%20Deep%20Learning.pdf",
    "bibtex": "article{598_Li2015,\n    author = \"Li, Yuancheng and Ma, Rong and Jiao, Runhai\",\n    title = \"A Hybrid Malicious Code Detection Method based on Deep Learning\",\n    journal = \"International journal of security and its applications\",\n    year = \"2015\",\n    volume = \"9\",\n    pages = \"205-216\"\n}\n\n",
    "abstract": "In this paper, we propose a hybrid malicious code detection scheme based on AutoEncoder and DBN (Deep Belief Networks). Firstly, we use the AutoEncoder deep learning method to reduce the dimensionality of data. This could convert complicated high-dimensional data into low dimensional codes with the nonlinear mapping, thereby reducing the dimensionality of data, extracting the main features of the data; then using DBN learning method to detect malicious code. DBN is composed of multilayer Restricted Boltzmann Machines (RBM, Restricted Boltzmann Machine) and a layer of BP neural network. Based on unsupervised training of every layer of RBM, we make the output vector of the last layer of RBM as the input vectors of BP neural network, then conduct supervised training to the BP neural network, finally achieve the optimal hybrid model by fine-tuning the entire network. After inputting testing samples into the hybrid model, the experimental results show that the detection accuracy getting by the hybrid detection method proposed in this paper is higher than that of single DBN. The proposed method reduces the time complexity and has better detection performance."
},
{
    "py/object": "data.DataClassPaper",
    "Title": "Obfuscated VBA Macro Detection Using Machine Learning",
    "year": 2018,
    "ML_Techniques": "SVM, RF, MLP, LDA, BNB",
    "Category": "Vulnerability analysis",
    "Sub_category": "",
    "Venue": "DSN",
    "Link": "https://ieeexplore.ieee.org/abstract/document/8416509",
    "bibtex": "",
    "abstract": "Malware using document files as an attack vector has continued to increase and now constitutes a large portion of phishing attacks. To avoid anti-virus detection, malware writers usually implement obfuscation techniques in their source code. Although obfuscation is related to malicious code detection, little research has been conducted on obfuscation with regards to Visual Basic for Applications (VBA) macros. In this paper, we summarize the obfuscation techniques and propose an obfuscated macro code detection method using five machine learning classifiers. To train these classifiers, our proposed method uses 15 discriminant static features, taking into account the characteristics of the VBA macros. We evaluated our approach using a real-world dataset of obfuscated and non-obfuscated VBA macros extracted from Microsoft Office document files. The experimental results demonstrate that our detection approach achieved a F2 score improvement of greater than 23% compared to those of related studies."
},
{
    "py/object": "data.DataClassPaper",
    "Title": "Decompiled APK based malicious code classification",
    "year": 2020,
    "ML_Techniques": "BOW, LSTM",
    "Category": "Vulnerability analysis",
    "Sub_category": "",
    "Venue": "FGCS",
    "Link": "https://www.sciencedirect.com/science/article/abs/pii/S0167739X19325129",
    "bibtex": "article{609_Mateless2020,\n    author = \"Mateless, Roni and Rejabek, Daniel and Margalit, Oded and Moskovitch, Robert\",\n    title = \"Decompiled {APK} based malicious code classification\",\n    volume = \"110\",\n    issn = \"0167-739X\",\n    url = \"https://www.sciencedirect.com/science/article/pii/S0167739X19325129\",\n    doi = \"https://doi.org/10.1016/j.future.2020.03.052\",\n    abstract = \"Due to the increasing growth in the variety of Android malware, it is important to distinguish between the unique types of each. In this paper, we introduce the use of a decompiled source code for malicious code classification. This decompiled source code provides deeper analysis opportunities and understanding of the nature of malware. Malicious code differs from text due to syntax rules of compilers and the effort of attackers to evade potential detection. Hence, we adapt Natural Language Processing-based techniques under some constraints for malicious code classification. First, the proposed methodology decompiles the Android Package Kit files, then API calls, keywords, and non-obfuscated tokens are extracted from the source code and categorized to stop-tokens, feature-tokens, and long-tail-tokens. We also introduce the use of generalized N-tokens to represent tokens that are typically less frequent. Our approach was evaluated, in comparison to the use of API calls and permissions for features, as a baseline, and their combination, as well as in comparison to the use of neural network architectures based on decompiled Android Package Kits. A rigorous evaluation of comprehensive public real-world Android malware datasets, including 24,553 apps that were categorized to 71 families for the malicious families classification, and 60,000 apps for malicious code detection was performed. Our approach outperformed the baselines in both tasks.\",\n    journal = \"Future Generation Computer Systems\",\n    year = \"2020\",\n    keywords = \"Android malware, Malicious code, Source code analysis\",\n    pages = \"135--147\"\n}\n\n",
    "abstract": "Due to the increasing growth in the variety of\u00a0Android\u00a0malware, it is important to distinguish between the unique types of each. In this paper, we introduce the use of a decompiled source code for\u00a0malicious code\u00a0classification. This decompiled source code provides deeper analysis opportunities and understanding of the nature of malware. Malicious code differs from text due to syntax rules of compilers and the effort of attackers to evade potential detection. Hence, we adapt Natural Language Processing-based techniques under some constraints for malicious code classification. First, the proposed methodology decompiles the Android Package Kit files, then API calls, keywords, and non-obfuscated tokens are extracted from the source code and categorized to stop-tokens, feature-tokens, and long-tail-tokens. We also introduce the use of generalized N-tokens to represent tokens that are typically less frequent. Our approach was evaluated, in comparison to the use of API calls and permissions for features, as a baseline, and their combination, as well as in comparison to the use of\u00a0neural network architectures\u00a0based on decompiled Android Package Kits. A rigorous evaluation of comprehensive public real-world\u00a0Android malware\u00a0datasets, including 24,553 apps that were categorized to 71 families for the malicious families classification, and 60,000 apps for malicious code detection was performed. Our approach outperformed the baselines in both tasks."
},
{
    "py/object": "data.DataClassPaper",
    "Title": "A static Android malicious code detection method based on multi-source fusion",
    "year": 2015,
    "ML_Techniques": "SVM, DT, BN",
    "Category": "Vulnerability analysis",
    "Sub_category": "",
    "Venue": "Security and Communication Networks",
    "Link": "https://onlinelibrary.wiley.com/doi/abs/10.1002/sec.1248",
    "bibtex": "article{615_Du2015,\n    author = \"Du, Yao and Wang, Xiaoqing and Wang, Junfeng\",\n    title = \"A Static Android Malicious Code Detection Method Based on Multi-Source Fusion\",\n    year = \"2015\",\n    issue_date = \"November 2015\",\n    publisher = \"John Wiley \\&amp; Sons, Inc.\",\n    address = \"USA\",\n    volume = \"8\",\n    number = \"17\",\n    issn = \"1939-0114\",\n    url = \"https://doi.org/615_Du2015\",\n    doi = \"615_Du2015\",\n    abstract = \"The rapid development of mobile malwares makes the traditional signature-based and single-feature based malware detection methods a challenging task. The surge of new malwares with more complex structures and dynamic characteristics leads to efficient fusion of multi-source malicious information more difficult in detection. In this paper, we propose a new multi-source based method to detect Android malwares by emphasizing on the traditional static features, control flow graph, and repacking characteristics. Each category of features is treated as an independent information source in feature extracting rules building and classification. Then, the Dempster-Shafer algorithm is used to fuse these information sources. This method can improve accuracy of malware detection without adding too many instability characteristics that are extracted from disassembled codes, and have better performance in the resistance to code obfuscation technologies. To verify our method, different categories of apps are collected to build the dataset in our experiment. Based on the dataset, our method can achieve 97\\% detection accuracy and 1.9\\% false positive rate. Copyright \u00a9 2015John Wiley \\&amp; Sons, Ltd.\",\n    journal = \"Sec. and Commun. Netw.\",\n    month = \"nov\",\n    pages = \"3238\u20133246\",\n    numpages = \"9\",\n    keywords = \"multi-source fusion, Dempster-Shafer theory, Android malware\"\n}\n\n",
    "abstract": "The rapid development of mobile malwares makes the traditional signature-based and single-feature based malware detection methods a challenging task. The surge of new malwares with more complex structures and dynamic characteristics leads to efficient fusion of multi-source malicious information more difficult in detection. In this paper, we propose a new multi-source based method to detect Android malwares by emphasizing on the traditional static features, control flow graph, and repacking characteristics. Each category of features is treated as an independent information source in feature extracting rules building and classification. Then, the Dempster\u2013Shafer algorithm is used to fuse these information sources. This method can improve accuracy of malware detection without adding too many instability characteristics that are extracted from disassembled codes, and have better performance in the resistance to code obfuscation technologies. To verify our method, different categories of apps are collected to build the dataset in our experiment. Based on the dataset, our method can achieve 97% detection accuracy and 1.9% false positive rate."
},
{
    "py/object": "data.DataClassPaper",
    "Title": "Malicious Code Detection Based on Code Semantic Features",
    "year": 2020,
    "ML_Techniques": "GCN",
    "Category": "Vulnerability analysis",
    "Sub_category": "",
    "Venue": "IEEE Access",
    "Link": "https://ieeexplore.ieee.org/abstract/document/9204732",
    "bibtex": "ARTICLE{617_Zhang2020,\n    author = \"Zhang, Yu and Li, Binglong\",\n    journal = \"IEEE Access\",\n    title = \"Malicious Code Detection Based on Code Semantic Features\",\n    year = \"2020\",\n    volume = \"8\",\n    number = \"\",\n    pages = \"176728-176737\",\n    doi = \"10.1109/ACCESS.2020.3026052\"\n}\n\n",
    "abstract": "With the development of smart phones, malicious applications for the Android platform have increased dramatically. The existing Android malicious code analysis methods majorly focus on detection based on signatures, inter-component communication, and other configuration information features. Such methods ignore the effect of the semantic features of the malicious code. Even a few such studies that exist are based on the statistical features of the code for malicious code detection. To address these shortcomings, we (1) use the code semantic structure features to reflect deep semantic information, (2) propose a preprocessing method of APK files to generate graphics that reflect the code semantic features, and (3) introduce the advanced graphical semantics for a graph convolutional network (GCN) model to automatically identify and learn semantics and extract features for malicious code detection. Experiments on a dataset confirm that the proposed method can achieve 95.8% detection accuracy. Compared with the existing methods that adopt configuration information features or statistical features of codes, our method shows higher accuracy."
},
{
    "py/object": "data.DataClassPaper",
    "Title": "Android malicious code Classification using Deep Belief Network",
    "year": 2017,
    "ML_Techniques": "DBN",
    "Category": "Vulnerability analysis",
    "Sub_category": "",
    "Venue": "KSII Transactions on Internet and Information Systems",
    "Link": "https://www.koreascience.or.kr/article/JAKO201810237888304.page",
    "bibtex": "article{618_Shiqi2018,\n    author = \"Shiqi, L. and Shengwei, T. and Long, Y. and Jiong, Y. and Hua, S.\",\n    title = \"Android malicious code {Classification} using {Deep} {Belief} {Network}\",\n    volume = \"12\",\n    doi = \"10.3837/tiis.2018.01.022\",\n    abstract = {This paper presents a novel Android malware classification model planned to classify and categorize Android malicious code at Drebin dataset. The amount of malicious mobile application targeting Android based smartphones has increased rapidly. In this paper, Restricted Boltzmann Machine and Deep Belief Network are used to classify malware into families of Android application. A texture-fingerprint based approach is proposed to extract or detect the feature of malware content. A malware has a unique \"\"image texture\"\" in feature spatial relations. The method uses information on texture image extracted from malicious or benign code, which are mapped to uncompressed gray-scale according to the texture image-based approach. By studying and extracting the implicit features of the API call from a large number of training samples, we get the original dynamic activity features sets. In order to improve the accuracy of classification algorithm on the features selection, on the basis of which, it combines the implicit features of the texture image and API call in malicious code, to train Restricted Boltzmann Machine and Back Propagation. In an evaluation with different malware and benign samples, the experimental results suggest that the usability of this method---using Deep Belief Network to classify Android malware by their texture images and API calls, it detects more than 94\\\\% of the malware with few false alarms. Which is higher than shallow machine learning algorithm clearly.},\n    journal = \"KSII Transactions on Internet and Information Systems\",\n    month = \"January\",\n    year = \"2018\",\n    pages = \"454--475\",\n    file = \"Full Text:C\\:\\\\Users\\\\stefa\\\\Zotero\\\\storage\\\\IT2G9AHK\\\\Shiqi et al. - 2018 - Android malicious code Classification using Deep B.pdf:application/pdf\"\n}\n\n",
    "abstract": "This paper presents a novel Android malware classification model planned to classify and categorize Android malicious code at Drebin dataset. The amount of malicious mobile application targeting Android based smartphones has increased rapidly. In this paper, Restricted Boltzmann Machine and Deep Belief Network are used to classify malware into families of Android application. A texture-fingerprint based approach is proposed to extract or detect the feature of malware content. A malware has a unique \"image texture\" in feature spatial relations. The method uses information on texture image extracted from malicious or benign code, which are mapped to uncompressed gray-scale according to the texture image-based approach. By studying and extracting the implicit features of the API call from a large number of training samples, we get the original dynamic activity features sets. In order to improve the accuracy of classification algorithm on the features selection, on the basis of which, it combines the implicit features of the texture image and API call in malicious code, to train Restricted Boltzmann Machine and Back Propagation. In an evaluation with different malware and benign samples, the experimental results suggest that the usability of this method---using Deep Belief Network to classify Android malware by their texture images and API calls, it detects more than 94% of the malware with few false alarms. Which is higher than shallow machine learning algorithm clearly."
},
{
    "py/object": "data.DataClassPaper",
    "Title": "A multi-view context-aware approach to Android malware detection and malicious code localization",
    "year": 2018,
    "ML_Techniques": "SVM",
    "Category": "Vulnerability analysis",
    "Sub_category": "",
    "Venue": "EMSE",
    "Link": "https://link.springer.com/article/10.1007/s10664-017-9539-8",
    "bibtex": "article{625_Narayanan2018,\n    author = \"Narayanan, Annamalai and Chandramohan, Mahinthan and Chen, Lihui and Liu, Yang\",\n    title = \"A Multi-View Context-Aware Approach to Android Malware Detection and Malicious Code Localization\",\n    year = \"2018\",\n    issue_date = \"Jun 2018\",\n    publisher = \"Kluwer Academic Publishers\",\n    address = \"USA\",\n    volume = \"23\",\n    number = \"3\",\n    issn = \"1382-3256\",\n    url = \"https://doi.org/625_Narayanan2018\",\n    doi = \"625_Narayanan2018\",\n    abstract = \"Many existing Machine Learning (ML) based Android malware detection approaches use a variety of features such as security-sensitive APIs, system calls, control-flow structures and information flows in conjunction with ML classifiers to achieve accurate detection. Each of these feature sets provides a unique semantic perspective (or view) of apps\u2019 behaviors with inherent strengths and limitations. Meaning, some views are more amenable to detect certain attacks but may not be suitable to characterize several other attacks. Most of the existing malware detection approaches use only one (or a selected few) of the aforementioned feature sets which prevents them from detecting a vast majority of attacks. Addressing this limitation, we propose MKLDroid, a unified framework that systematically integrates multiple views of apps for performing comprehensive malware detection and malicious code localization. The rationale is that, while a malware app can disguise itself in some views, disguising in every view while maintaining malicious intent will be much harder. MKLDroid uses a graph kernel to capture structural and contextual information from apps\u2019 dependency graphs and identify malice code patterns in each view. Subsequently, it employs Multiple Kernel Learning (MKL) to find a weighted combination of the views which yields the best detection accuracy. Besides multi-view learning, MKLDroid\u2019s unique and salient trait is its ability to locate fine-grained malice code portions in dependency graphs (e.g., methods/classes). Malicious code localization caters several important applications such as supporting human analysts studying malware behaviors, engineering malware signatures, and other counter-measures. Through our large-scale experiments on several datasets (incl. wild apps), we demonstrate that MKLDroid outperforms three state-of-the-art techniques consistently, in terms of accuracy while maintaining comparable efficiency. In our malicious code localization experiments on a dataset of repackaged malware, MKLDroid was able to identify all the malice classes with 94\\% average recall. Our work opens up two new avenues in malware research: (i) enables the research community to elegantly look at Android malware behaviors in multiple perspectives simultaneously, and (ii) performing precise and scalable malicious code localization.\",\n    journal = \"Empirical Softw. Engg.\",\n    month = \"jun\",\n    pages = \"1222\u20131274\",\n    numpages = \"53\",\n    keywords = \"Graph kernels, Android malware detection, Multiple kernel learning, Malicious code localization\"\n}\n\n",
    "abstract": "Many existing Machine Learning (ML) based Android malware detection approaches use a variety of features such as security-sensitive APIs, system calls, control-flow structures and information flows in conjunction with ML classifiers to achieve accurate detection. Each of these feature sets provides a unique semantic\u00a0perspective\u00a0(or\u00a0view) of apps\u2019 behaviors with inherent strengths and limitations. Meaning, some views are more amenable to detect certain attacks but may not be suitable to characterize several other attacks. Most of the existing malware detection approaches use only one (or a selected few) of the aforementioned feature sets which prevents them from detecting a vast majority of attacks. Addressing this limitation, we propose MKLDROID, a unified framework that systematically integrates multiple views of apps for performing comprehensive malware detection and malicious code localization. The rationale is that, while a malware app can disguise itself in some views, disguising in every view while maintaining malicious intent will be much harder. MKLDROID\u00a0uses a graph kernel to capture structural and contextual information from apps\u2019 dependency graphs and identify malice code patterns in each view. Subsequently, it employs Multiple Kernel Learning (MKL) to find a weighted combination of the views which yields the best detection accuracy. Besides multi-view learning, MKLDROID\u2019s unique and salient trait is its ability to locate fine-grained malice code portions in dependency graphs (e.g., methods/classes). Malicious code localization caters several important applications such as supporting human analysts studying malware behaviors, engineering malware signatures, and other counter-measures. Through our large-scale experiments on several datasets (incl. wild apps), we demonstrate that MKLDROID\u00a0outperforms three state-of-the-art techniques consistently, in terms of accuracy while maintaining comparable efficiency. In our malicious code localization experiments on a dataset of repackaged malware, MKLDROID\u00a0was able to identify all the malice classes with 94% average recall. Our work opens up two new avenues in malware research: (i) enables the research community to elegantly look at Android malware behaviors in multiple perspectives simultaneously, and (ii) performing precise and scalable malicious code localization."
},
{
    "py/object": "data.DataClassPaper",
    "Title": "Machine Learning-Based Malicious Application Detection of Android",
    "year": 2017,
    "ML_Techniques": "NB, DT",
    "Category": "Vulnerability analysis",
    "Sub_category": "",
    "Venue": "IEEE Access",
    "Link": "https://ieeexplore.ieee.org/abstract/document/8101455",
    "bibtex": "ARTICLE{632_Wei2017,\n    author = \"Wei, Linfeng and Luo, Weiqi and Weng, Jian and Zhong, Yanjun and Zhang, Xiaoqian and Yan, Zheng\",\n    journal = \"IEEE Access\",\n    title = \"Machine Learning-Based Malicious Application Detection of Android\",\n    year = \"2017\",\n    volume = \"5\",\n    number = \"\",\n    pages = \"25591-25601\",\n    doi = \"10.1109/ACCESS.2017.2771470\"\n}\n\n",
    "abstract": "In this paper, we propose a machine learning-based approach to detect malicious mobile malware in Android applications. This paper is able to capture instantaneous attacks that cannot be effectively detected in the past work. Based on the proposed approach, we implemented a malicious app detection tool, named Androidetect. First, we analyze the relationship between system functions, sensitive permissions, and sensitive application programming interfaces. The combination of system functions has been used to describe the application behaviors and construct eigenvectors. Subsequently, based on the eigenvectors, we compare the methodologies of naive Bayesian, J48 decision tree, and application functions decision algorithm regarding effective detection of malicious Android applications. Androidetect is then applied to test sample programs and real-world applications. The experimental results prove that Androidetect can better detect malicious applications of Android by using a combination of system functions compared with the previous work."
},
{
    "py/object": "data.DataClassPaper",
    "Title": "On Software Defect Prediction Using Machine Learning",
    "year": 2013,
    "ML_Techniques": "KBL",
    "Category": "Testing",
    "Sub_category": "Defect prediction",
    "Venue": "JAM",
    "Link": "https://www.hindawi.com/journals/jam/2014/785435/",
    "bibtex": "article{637_Ren2014,\n    author = \"Ren, Jinsheng and Qin, Ke and Ma, Ying and Luo, Guangchun\",\n    title = \"On software defect prediction using machine learning\",\n    journal = \"Journal of Applied Mathematics\",\n    volume = \"2014\",\n    year = \"2014\",\n    publisher = \"Hindawi\"\n}\n\n",
    "abstract": "This paper mainly deals with how kernel method can be used for software defect prediction, since the class imbalance can greatly reduce the performance of defect prediction. In this paper, two classifiers, namely, the asymmetric kernel partial least squares classifier (AKPLSC) and asymmetric kernel principal component analysis classifier (AKPCAC), are proposed for solving the class imbalance problem. This is achieved by applying kernel function to the asymmetric partial least squares classifier and asymmetric principal component analysis classifier, respectively. The kernel function used for the two classifiers is Gaussian function. Experiments conducted on NASA and SOFTLAB data sets using\u00a0F-measure, Friedman\u2019s test, and Tukey\u2019s test confirm the validity of our methods."
},
{
    "py/object": "data.DataClassPaper",
    "Title": "Software Defect Prediction Using Ensemble Learning: A Systematic Literature Review",
    "year": 2021,
    "ML_Techniques": "",
    "Category": "Testing",
    "Sub_category": "Defect prediction",
    "Venue": "IEEE Access",
    "Link": "https://ieeexplore.ieee.org/abstract/document/9477596",
    "bibtex": "article{644_Matloob2021,\n    author = \"Matloob, Faseeha and Ghazal, Taher M and Taleb, Nasser and Aftab, Shabib and Ahmad, Munir and Khan, Muhammad Adnan and Abbas, Sagheer and Soomro, Tariq Rahim\",\n    title = \"Software defect prediction using ensemble learning: A systematic literature review\",\n    journal = \"IEEE Access\",\n    year = \"2021\",\n    publisher = \"IEEE\"\n}\n\n",
    "abstract": "Recent advances in the domain of software defect prediction (SDP) include the integration of multiple classification techniques to create an ensemble or hybrid approach. This technique was introduced to improve the prediction performance by overcoming the limitations of any single classification technique. This research provides a systematic literature review on the use of the ensemble learning approach for software defect prediction. The review is conducted after critically analyzing research papers published since 2012 in four well-known online libraries: ACM, IEEE, Springer Link, and Science Direct. In this study, five research questions covering the different aspects of research progress on the use of ensemble learning for software defect prediction are addressed. To extract the answers to identified questions, 46 most relevant papers are shortlisted after a thorough systematic research process. This study will provide compact information regarding the latest trends and advances in ensemble learning for software defect prediction and provide a baseline for future innovations and further reviews. Through our study, we discovered that frequently employed ensemble methods by researchers are the random forest, boosting, and bagging. Less frequently employed methods include stacking, voting and Extra Trees. Researchers proposed many promising frameworks, such as EMKCA, SMOTE-Ensemble, MKEL, SDAEsTSE, TLEL, and LRCR, using ensemble learning methods. The AUC, accuracy, F-measure, Recall, Precision, and MCC were mostly utilized to measure the prediction performance of models. WEKA was widely adopted as a platform for machine learning. Many researchers showed through empirical analysis that features selection, and data sampling was necessary pre-processing steps that improve the performance of ensemble classifiers."
},
{
    "py/object": "data.DataClassPaper",
    "Title": "Software Defect Prediction via Convolutional Neural Network",
    "year": 2017,
    "ML_Techniques": "CNN, LOG",
    "Category": "Testing",
    "Sub_category": "Defect prediction",
    "Venue": "QRS",
    "Link": "https://ieeexplore.ieee.org/abstract/document/8009936",
    "bibtex": "inproceedings{652_Li2017,\n    author = \"Li, Jian and He, Pinjia and Zhu, Jieming and Lyu, Michael R\",\n    title = \"Software defect prediction via convolutional neural network\",\n    booktitle = \"2017 IEEE International Conference on Software Quality, Reliability and Security (QRS)\",\n    pages = \"318--328\",\n    year = \"2017\",\n    organization = \"IEEE\"\n}\n\n",
    "abstract": "To improve software reliability, software defect prediction is utilized to assist developers in finding potential bugs and allocating their testing efforts. Traditional defect prediction studies mainly focus on designing hand-crafted features, which are input into machine learning classifiers to identify defective code. However, these hand-crafted features often fail to capture the semantic and structural information of programs. Such information is important in modeling program functionality and can lead to more accurate defect prediction. In this paper, we propose a framework called Defect Prediction via Convolutional Neural Network (DP-CNN), which leverages deep learning for effective feature generation. Specifically, based on the programs' Abstract Syntax Trees (ASTs), we first extract token vectors, which are then encoded as numerical vectors via mapping and word embedding. We feed the numerical vectors into Convolutional Neural Network to automatically learn semantic and structural features of programs. After that, we combine the learned features with traditional hand-crafted features, for accurate software defect prediction. We evaluate our method on seven open source projects in terms of F-measure in defect prediction. The experimental results show that in average, DP-CNN improves the state-of-the-art method by 12%."
},
{
    "py/object": "data.DataClassPaper",
    "Title": "An Empirical Study of Robustness and Stability of Machine Learning Classifiers in Software Defect Prediction",
    "year": 2015,
    "ML_Techniques": "",
    "Category": "Testing",
    "Sub_category": "Defect prediction",
    "Venue": "AISC",
    "Link": "https://link.springer.com/chapter/10.1007/978-3-319-11218-3_35",
    "bibtex": "incollection{653_Kaur2015,\n    author = \"Kaur, Arvinder and Kaur, Kamaldeep\",\n    title = \"An empirical study of robustness and stability of machine learning classifiers in software defect prediction\",\n    booktitle = \"Advances in intelligent informatics\",\n    pages = \"383--397\",\n    year = \"2015\",\n    publisher = \"Springer\"\n}\n\n",
    "abstract": "Software is one of the key drivers of twenty first century business and society. Delivering high quality software systems is a challenging task for software developers. Early software defect prediction, based on software code metrics, has been intensely researched by the software engineering research community. Recent knowledge advancements in machine learning have been intensely explored for development of highly accurate automatic software defect prediction models. This study contributes to the application of machine learning in software defect prediction by investigating the robustness and stability of 17 classifiers on 44 open source software defect prediction data sets obtained from PROMISE repository. The Area under curve (AUC) of Receiver Operating Characteristic Curve (ROC) for each of the 17 classifiers is obtained for 44 defect prediction data sets. Our experiments show that Random Forests, Logistic Regression and Kstar are robust as well as stable classifiers for software defect prediction applications. Further, we demonstrate that Na\u00efve Bayes and Bayes Networks, which have been shown to be robust and comprehensible classifiers in previous on software defect prediction, have poor stability in open source software defect prediction."
},
{
    "py/object": "data.DataClassPaper",
    "Title": "Dictionary learning based software defect prediction",
    "year": 2014,
    "ML_Techniques": "",
    "Category": "Testing",
    "Sub_category": "Defect prediction",
    "Venue": "ICSE",
    "Link": "https://dl.acm.org/doi/abs/10.1145/2568225.2568320",
    "bibtex": "inproceedings{656_Jing2014,\n    author = \"Jing, Xiao-Yuan and Ying, Shi and Zhang, Zhi-Wu and Wu, Shan-Shan and Liu, Jin\",\n    title = \"Dictionary learning based software defect prediction\",\n    booktitle = \"Proceedings of the 36th international conference on software engineering\",\n    pages = \"414--423\",\n    year = \"2014\"\n}\n\n",
    "abstract": "In order to improve the quality of a software system, software defect prediction aims to automatically identify defective software modules for efficient software test. To predict software defect, those classification methods with static code attributes have attracted a great deal of attention. In recent years, machine learning techniques have been applied to defect prediction. Due to the fact that there exists the similarity among different software modules, one software module can be approximately represented by a small proportion of other modules. And the representation coefficients over the pre-defined dictionary, which consists of historical software module data, are generally sparse. In this paper, we propose to use the dictionary learning technique to predict software defect. By using the characteristics of the metrics mined from the open source software, we learn multiple dictionaries (including defective module and defective-free module sub-dictionaries and the total dictionary) and sparse representation coefficients. Moreover, we take the misclassification cost issue into account because the misclassification of defective modules generally incurs much higher risk cost than that of defective-free ones. We thus propose a cost-sensitive discriminative dictionary learning (CDDL) approach for software defect classification and prediction. The widely used datasets from NASA projects are employed as test data to evaluate the performance of all compared methods. Experimental results show that CDDL outperforms several representative state-of-the-art defect prediction methods."
},
{
    "py/object": "data.DataClassPaper",
    "Title": "Software defect prediction using relational association rule mining",
    "year": 2014,
    "ML_Techniques": "",
    "Category": "Testing",
    "Sub_category": "Defect prediction",
    "Venue": "Information Sciences",
    "Link": "https://www.sciencedirect.com/science/article/abs/pii/S0020025513008876",
    "bibtex": "article{658_Czibula2014,\n    author = \"Czibula, Gabriela and Marian, Zsuzsanna and Czibula, Istvan Gergely\",\n    title = \"Software defect prediction using relational association rule mining\",\n    journal = \"Information Sciences\",\n    volume = \"264\",\n    pages = \"260--278\",\n    year = \"2014\",\n    publisher = \"Elsevier\"\n}\n\n",
    "abstract": "This paper focuses on the problem of\u00a0defect prediction, a problem of major importance during software maintenance and evolution. It is essential for software developers to identify defective software modules in order to continuously improve the quality of a software system. As the conditions for a software module to have defects are hard to identify,\u00a0machine learning\u00a0based\u00a0classification models\u00a0are still developed to approach the problem of\u00a0defect prediction. We propose a novel classification model based on relational\u00a0association rules mining. Relational association rules are an extension of ordinal association rules, which are a particular type of association rules that describe numerical orderings between attributes that commonly occur over a dataset. Our\u00a0classifier\u00a0is based on the discovery of relational association rules for predicting whether a software module is or it is not defective. An experimental evaluation of the proposed model on the open source NASA datasets, as well as a comparison to similar existing approaches is provided. The obtained results show that our\u00a0classifier\u00a0overperforms, for most of the considered evaluation measures, the existing\u00a0machine learning\u00a0based techniques for defect prediction. This confirms the potential of our proposal."
},
{
    "py/object": "data.DataClassPaper",
    "Title": "Software defect prediction using Bayesian networks",
    "year": 2012,
    "ML_Techniques": "",
    "Category": "Testing",
    "Sub_category": "Defect prediction",
    "Venue": "ESE",
    "Link": "https://link.springer.com/article/10.1007/s10664-012-9218-8",
    "bibtex": "article{661_Okutan2014,\n    author = \"Okutan, Ahmet and Y{\\i}ld{\\i}z, Olcay Taner\",\n    title = \"Software defect prediction using Bayesian networks\",\n    journal = \"Empirical Software Engineering\",\n    volume = \"19\",\n    number = \"1\",\n    pages = \"154--181\",\n    year = \"2014\",\n    publisher = \"Springer\"\n}\n\n",
    "abstract": "There are lots of different software metrics discovered and used for defect prediction in the literature. Instead of dealing with so many metrics, it would be practical and easy if we could determine the set of metrics that are most important and focus on them more to predict defectiveness. We use Bayesian networks to determine the probabilistic influential relationships among software metrics and defect proneness. In addition to the metrics used in Promise data repository, we define two more metrics, i.e. NOD for the number of developers and LOCQ for the source code quality. We extract these metrics by inspecting the source code repositories of the selected Promise data repository data sets. At the end of our modeling, we learn the marginal defect proneness probability of the whole software system, the set of most effective metrics, and the influential relationships among metrics and defectiveness. Our experiments on nine open source Promise data repository data sets show that response for class (RFC), lines of code (LOC), and lack of coding quality (LOCQ) are the most effective metrics whereas coupling between objects (CBO), weighted method per class (WMC), and lack of cohesion of methods (LCOM) are less effective metrics on defect proneness. Furthermore, number of children (NOC) and depth of inheritance tree (DIT) have very limited effect and are untrustworthy. On the other hand, based on the experiments on Poi, Tomcat, and Xalan data sets, we observe that there is a positive correlation between the number of developers (NOD) and the level of defectiveness. However, further investigation involving a greater number of projects is needed to confirm our findings."
},
{
    "py/object": "data.DataClassPaper",
    "Title": "Software defect prediction using ensemble learning on selected features",
    "year": 2015,
    "ML_Techniques": "RF, GB, SGD, SVM, LOG, MNB, BNB ",
    "Category": "Testing",
    "Sub_category": "Defect prediction",
    "Venue": "IST",
    "Link": "https://www.sciencedirect.com/science/article/abs/pii/S0950584914001591",
    "bibtex": "article{663_Laradji2015,\n    author = \"Laradji, Issam H and Alshayeb, Mohammad and Ghouti, Lahouari\",\n    title = \"Software defect prediction using ensemble learning on selected features\",\n    journal = \"Information and Software Technology\",\n    volume = \"58\",\n    pages = \"388--402\",\n    year = \"2015\",\n    publisher = \"Elsevier\"\n}\n\n",
    "abstract": "Context\nSeveral issues hinder software defect data including redundancy, correlation, feature irrelevance and missing samples. It is also hard to ensure balanced distribution between data pertaining to defective and non-defective software. In most experimental cases, data related to the latter software class is dominantly present in the dataset.\n\nObjective\nThe objectives of this paper are to demonstrate the positive effects of combining feature selection and ensemble learning on the performance of defect classification. Along with efficient feature selection, a new two-variant (with and without feature selection) ensemble learning algorithm is proposed to provide robustness to both data imbalance and feature redundancy.\n\nMethod\nWe carefully combine selected ensemble learning models with efficient feature selection to address these issues and mitigate their effects on the defect classification performance.\n\nResults\nForward selection showed that only few features contribute to high area under the receiver-operating curve (AUC). On the tested datasets, greedy forward selection (GFS) method outperformed other feature selection techniques such as Pearson\u2019s correlation. This suggests that features are highly unstable. However, ensemble learners like random forests and the proposed algorithm, average probability ensemble (APE), are not as affected by poor features as in the case of weighted support vector machines (W-SVMs). Moreover, the APE model combined with greedy forward selection (enhanced APE) achieved AUC values of approximately 1.0 for the NASA datasets: PC2, PC4, and MC1.\n\nConclusion\nThis paper shows that features of a software dataset must be carefully selected for accurate classification of defective components. Furthermore, tackling the software data issues, mentioned above, with the proposed combined learning model resulted in remarkable classification performance paving the way for successful quality control.\n\n"
},
{
    "py/object": "data.DataClassPaper",
    "Title": "Integrated Approach to Software Defect Prediction",
    "year": 2017,
    "ML_Techniques": "LR",
    "Category": "Testing",
    "Sub_category": "Defect prediction",
    "Venue": "IEEE Access",
    "Link": "https://ieeexplore.ieee.org/abstract/document/8058420",
    "bibtex": "article{666_Felix2017,\n    author = \"Felix, Ebubeogu Amarachukwu and Lee, Sai Peck\",\n    title = \"Integrated approach to software defect prediction\",\n    journal = \"IEEE Access\",\n    volume = \"5\",\n    pages = \"21524--21547\",\n    year = \"2017\",\n    publisher = \"IEEE\"\n}\n\n",
    "abstract": "Software defect prediction provides actionable outputs to software teams while contributing to industrial success. Empirical studies have been conducted on software defect prediction for both cross-project and within-project defect prediction. However, existing studies have yet to demonstrate a method of predicting the number of defects in an upcoming product release. This paper presents such a method using predictor variables derived from the defect acceleration, namely, the defect density, defect velocity, and defect introduction time, and determines the correlation of each predictor variable with the number of defects. We report the application of an integrated machine learning approach based on regression models constructed from these predictor variables. An experiment was conducted on ten different data sets collected from the PROMISE repository, containing 22838 instances. The regression model constructed as a function of the average defect velocity achieved an adjusted R-square of 98.6%, with a p-value of <; 0.001. The average defect velocity is strongly positively correlated with the number of defects, with a correlation coefficient of 0.98. Thus, it is demonstrated that this technique can provide a blueprint for program testing to enhance the effectiveness of software development activities."
},
{
    "py/object": "data.DataClassPaper",
    "Title": "A Review on Machine Learning Techniques for Software Defect Prediction",
    "year": 2018,
    "ML_Techniques": "",
    "Category": "Testing",
    "Sub_category": "Defect prediction",
    "Venue": "Technical Journal",
    "Link": "https://tj.uettaxila.edu.pk/index.php/technical-journal/article/view/405",
    "bibtex": "article{667_Hassan2018,\n    author = \"Hassan, Fareeha and Farhan, Saima and Fahiem, Muhammad Abuzar and Tauseef, Huma\",\n    title = \"A review on machine learning techniques for software defect prediction\",\n    journal = \"Technical Journal\",\n    volume = \"23\",\n    number = \"02\",\n    pages = \"63--71\",\n    year = \"2018\"\n}\n\n",
    "abstract": "Software defect prediction has been an interest of research era because predicting defects on early stages improves software quality with reduced cost and effective software management. Researchers from different domains are contributing their efforts to propose an approach that effectively and efficiently helps in this regard. Different machine learning techniques have been applied to remove unnecessary and fault data from defect prone modules and many approaches, frameworks, methods and models have been proposed using different datasets, metrics, and evaluation strategies. In this paper, 30 Clarivate Analytics indexed journal papers from 2009-2017 are reviewed for the upcoming practitioners of software defect prediction. Review in this paper reflects some of the work that has been done in software defect prediction so far. Detailed classification taxonomy of the machine learning techniques used for software defect prediction has been presented. Defective, non-defective datasets along with the classification of the metrics used are part of the review. Despite of all works and efforts done in this research domain, there still exist many ambiguities because no single technique and method dominates due to the imbalance nature of different datasets and methods. A lot of research work is needed to overcome the existing issues."
},
{
    "py/object": "data.DataClassPaper",
    "Title": "Software defect prediction using cost-sensitive neural network",
    "year": 2015,
    "ML_Techniques": "ANN",
    "Category": "Testing",
    "Sub_category": "Defect prediction",
    "Venue": "ASC",
    "Link": "https://www.sciencedirect.com/science/article/abs/pii/S1568494615002720",
    "bibtex": "article{674_Arar2015,\n    author = {Arar, {\\\"\"O}mer Faruk and Ayan, K{\\\"\"u}r{\\c{s}}at},\n    title = \"Software defect prediction using cost-sensitive neural network\",\n    journal = \"Applied Soft Computing\",\n    volume = \"33\",\n    pages = \"263--277\",\n    year = \"2015\",\n    publisher = \"Elsevier\"\n}\n\n",
    "abstract": "The software development life cycle generally includes analysis, design, implementation, test and release phases. The testing phase should be operated effectively in order to release bug-free software to end users. In the last two decades, academicians have taken an increasing interest in the software defect prediction problem, several machine learning techniques have been applied for more robust prediction. A different classification approach for this problem is proposed in this paper. A combination of traditional Artificial Neural Network (ANN) and the novel Artificial Bee Colony (ABC) algorithm are used in this study. Training the neural network is performed by ABC algorithm in order to find optimal weights. The False Positive Rate (FPR) and False Negative Rate (FNR) multiplied by parametric cost coefficients are the optimization task of the ABC algorithm. Software defect data in nature have a class imbalance because of the skewed distribution of defective and non-defective modules, so that conventional error functions of the neural network produce unbalanced FPR and FNR results. The proposed approach was applied to five publicly available datasets from the NASA Metrics Data Program repository. Accuracy, probability of detection, probability of false alarm, balance, Area Under Curve (AUC), and Normalized Expected Cost of Misclassification (NECM) are the main performance indicators of our classification approach. In order to prevent random results, the dataset was shuffled and the algorithm was executed 10 times with the use of\u00a0n-fold cross-validation in each iteration. Our experimental results showed that a cost-sensitive neural network can be created successfully by using the ABC optimization algorithm for the purpose of software defect prediction."
},
{
    "py/object": "data.DataClassPaper",
    "Title": "Software defect prediction using tree-based ensembles",
    "year": 2020,
    "ML_Techniques": "RF, ET, AB, GB, XG, CB",
    "Category": "Testing",
    "Sub_category": "Defect prediction",
    "Venue": "ICSE",
    "Link": "https://dl.acm.org/doi/abs/10.1145/3416508.3417114",
    "bibtex": "inproceedings{675_Aljamaan2020,\n    author = \"Aljamaan, Hamoud and Alazba, Amal\",\n    title = \"Software defect prediction using tree-based ensembles\",\n    booktitle = \"Proceedings of the 16th ACM international conference on predictive models and data analytics in software engineering\",\n    pages = \"1--10\",\n    year = \"2020\"\n}\n\n",
    "abstract": "Software defect prediction is an active research area in software engineering. Accurate prediction of software defects assists software engineers in guiding software quality assurance activities. In machine learning, ensemble learning has been proven to improve the prediction performance over individual machine learning models. Recently, many Tree-based ensembles have been proposed in the literature, and their prediction capabilities were not investigated in defect prediction. In this paper, we will empirically investigate the prediction performance of seven Tree-based ensembles in defect prediction. Two ensembles are classified as bagging ensembles: Random Forest and Extra Trees, while the other five ensembles are boosting ensembles: Ada boost, Gradient Boosting, Hist Gradient Boosting, XGBoost and CatBoost. The study utilized 11 publicly available MDP NASA software defect datasets. Empirical results indicate the superiority of Tree-based bagging ensembles: Random Forest and Extra Trees ensembles over other Tree-based boosting ensembles. However, none of the investigated Tree-based ensembles was significantly lower than individual decision trees in prediction performance. Finally, Adaboost ensemble was the worst performing ensemble among all Tree-based ensembles."
},
{
    "py/object": "data.DataClassPaper",
    "Title": "A Comprehensive Investigation of the Role of Imbalanced Learning for Software Defect Prediction",
    "year": 2019,
    "ML_Techniques": "LOG, NB, DT, KNN, RIPPER, SVM, RF",
    "Category": "Testing",
    "Sub_category": "Defect prediction",
    "Venue": "TSE",
    "Link": "https://ieeexplore.ieee.org/abstract/document/8359087",
    "bibtex": "ARTICLE{676_Song2019,\n    author = \"Song, Qinbao and Guo, Yuchen and Shepperd, Martin\",\n    journal = \"IEEE Transactions on Software Engineering\",\n    title = \"A Comprehensive Investigation of the Role of Imbalanced Learning for Software Defect Prediction\",\n    year = \"2019\",\n    volume = \"45\",\n    number = \"12\",\n    pages = \"1253-1269\",\n    doi = \"10.1109/TSE.2018.2836442\"\n}\n\n",
    "abstract": "Context: Software defect prediction (SDP) is an important challenge in the field of software engineering, hence much research work has been conducted, most notably through the use of machine learning algorithms. However, class-imbalance typified by few defective components and many non-defective ones is a common occurrence causing difficulties for these methods. Imbalanced learning aims to deal with this problem and has recently been deployed by some researchers, unfortunately with inconsistent results. Objective: We conduct a comprehensive experiment to explore (a) the basic characteristics of this problem; (b) the effect of imbalanced learning and its interactions with (i) data imbalance, (ii) type of classifier, (iii) input metrics and (iv) imbalanced learning method. Method: We systematically evaluate 27 data sets, 7 classifiers, 7 types of input metrics and 17 imbalanced learning methods (including doing nothing) using an experimental design that enables exploration of interactions between these factors and individual imbalanced learning algorithms. This yields 27 \u00d7 7 \u00d7 7 \u00d7 17 = 22491 results. The Matthews correlation coefficient (MCC) is used as an unbiased performance measure (unlike the more widely used F1 and AUC measures). Results: (a) we found a large majority (87 percent) of 106 public domain data sets exhibit moderate or low level of imbalance (imbalance ratio <; 10; median = 3.94); (b) anything other than low levels of imbalance clearly harm the performance of traditional learning for SDP; (c) imbalanced learning is more effective on the data sets with moderate or higher imbalance, however negative results are always possible; (d) type of classifier has most impact on the improvement in classification performance followed by the imbalanced learning method itself. Type of input metrics is not influential. (e) only 52% of the combinations of Imbalanced Learner and Classifier have a significant positive effect. Conclusion: This paper offers two practical guidelines. First, imbalanced learning should only be considered for moderate or highly imbalanced SDP data sets. Second, the appropriate combination of imbalanced method and classifier needs to be carefully chosen to ameliorate the imbalanced learning problem for SDP. In contrast, the indiscriminate application of imbalanced learning can be harmful."
},
{
    "py/object": "data.DataClassPaper",
    "Title": "Multiple kernel ensemble learning for software defect prediction",
    "year": 2015,
    "ML_Techniques": "MKEL",
    "Category": "Testing",
    "Sub_category": "Defect prediction",
    "Venue": "ASE",
    "Link": "https://link.springer.com/article/10.1007/s10515-015-0179-1",
    "bibtex": "article{678_Wang2016,\n    author = \"Wang, Tiejian and Zhang, Zhiwu and Jing, Xiaoyuan and Zhang, Liqiang\",\n    title = \"Multiple kernel ensemble learning for software defect prediction\",\n    journal = \"Automated Software Engineering\",\n    volume = \"23\",\n    number = \"4\",\n    pages = \"569--590\",\n    year = \"2016\",\n    publisher = \"Springer\"\n}\n\n",
    "abstract": "Software defect prediction aims to predict the defect proneness of new software modules with the historical defect data so as to improve the quality of a software system. Software historical defect data has a complicated structure and a marked characteristic of class-imbalance; how to fully analyze and utilize the existing historical defect data and build more precise and effective classifiers has attracted considerable researchers\u2019 interest from both academia and industry. Multiple kernel learning and ensemble learning are effective techniques in the field of machine learning. Multiple kernel learning can map the historical defect data to a higher-dimensional feature space and make them express better, and ensemble learning can use a series of weak classifiers to reduce the bias generated by the majority class and obtain better predictive performance. In this paper, we propose to use the multiple kernel learning to predict software defect. By using the characteristics of the metrics mined from the open source software, we get a multiple kernel classifier through ensemble learning method, which has the advantages of both multiple kernel learning and ensemble learning. We thus propose a multiple kernel ensemble learning (MKEL) approach for software defect classification and prediction. Considering the cost of risk in software defect prediction, we design a new sample weight vector updating strategy to reduce the cost of risk caused by misclassifying defective modules as non-defective ones. We employ the widely used NASA MDP datasets as test data to evaluate the performance of all compared methods; experimental results show that MKEL outperforms several representative state-of-the-art defect prediction methods."
},
{
    "py/object": "data.DataClassPaper",
    "Title": "Software defect prediction techniques using metrics based on neural network classifier",
    "year": 2019,
    "ML_Techniques": "NND",
    "Category": "Testing",
    "Sub_category": "Defect prediction",
    "Venue": "CC",
    "Link": "https://link.springer.com/article/10.1007/s10586-018-1730-1",
    "bibtex": "article{679_Jayanthi2019,\n    author = \"Jayanthi, R and Florence, Lilly\",\n    title = \"Software defect prediction techniques using metrics based on neural network classifier\",\n    journal = \"Cluster Computing\",\n    volume = \"22\",\n    number = \"1\",\n    pages = \"77--88\",\n    year = \"2019\",\n    publisher = \"Springer\"\n}\n\n",
    "abstract": "Software industries strive for software quality improvement by consistent bug prediction, bug removal and prediction of fault-prone module. This area has attracted researchers due to its significant involvement in software industries. Various techniques have been presented for software defect prediction. Recent researches have recommended data-mining using machine learning as an important paradigm for software bug prediction. state-of-art software defect prediction task suffer from various issues such as classification accuracy. However, software defect datasets are imbalanced in nature and known fault prone due to its huge dimension. To address this issue, here we present a combined approach for software defect prediction and prediction of software bugs. Proposed approach delivers a concept of feature reduction and artificial intelligence where feature reduction is carried out by well-known principle component analysis (PCA) scheme which is further improved by incorporating maximum-likelihood estimation for error reduction in PCA data reconstruction. Finally, neural network based classification technique is applied which shows prediction results. A framework is formulated and implemented on NASA software dataset where four datasets i.e., KC1, PC3, PC4 and JM1 are considered for performance analysis using MATLAB simulation tool. An extensive experimental study is performed where confusion, precision, recall, classification accuracy etc. parameters are computed and compared with existing software defect prediction techniques. Experimental study shows that proposed approach can provide better performance for software defect prediction."
},
{
    "py/object": "data.DataClassPaper",
    "Title": "An Improved CNN Model for Within-Project Software Defect Prediction",
    "year": 2019,
    "ML_Techniques": "CNN",
    "Category": "Testing",
    "Sub_category": "Defect prediction",
    "Venue": "Applied Sciences",
    "Link": "https://www.mdpi.com/2076-3417/9/10/2138",
    "bibtex": "article{680_Pan2019,\n    author = \"Pan, Cong and Lu, Minyan and Xu, Biao and Gao, Houleng\",\n    title = \"An improved CNN model for within-project software defect prediction\",\n    journal = \"Applied Sciences\",\n    volume = \"9\",\n    number = \"10\",\n    pages = \"2138\",\n    year = \"2019\",\n    publisher = \"Multidisciplinary Digital Publishing Institute\"\n}\n\n",
    "abstract": "To improve software reliability, software defect prediction is used to find software bugs and prioritize testing efforts. Recently, some researchers introduced deep learning models, such as the deep belief network (DBN) and the state-of-the-art convolutional neural network (CNN), and used automatically generated features extracted from abstract syntax trees (ASTs) and deep learning models to improve defect prediction performance. However, the research on the CNN model failed to reveal clear conclusions due to its limited dataset size, insufficiently repeated experiments, and outdated baseline selection. To solve these problems, we built the PROMISE Source Code (PSC) dataset to enlarge the original dataset in the CNN research, which we named the Simplified PROMISE Source Code (SPSC) dataset. Then, we proposed an improved CNN model for within-project defect prediction (WPDP) and compared our results to existing CNN results and an empirical study. Our experiment was based on a 30-repetition holdout validation and a 10 * 10 cross-validation. Experimental results showed that our improved CNN model was comparable to the existing CNN model, and it outperformed the state-of-the-art machine learning models significantly for WPDP. Furthermore, we defined hyperparameter instability and examined the threat and opportunity it presents for deep learning models on defect prediction."
},
{
    "py/object": "data.DataClassPaper",
    "Title": "An empirical study to investigate oversampling methods for improving software defect prediction using imbalanced data",
    "year": 2019,
    "ML_Techniques": "DT, NB, AB, B",
    "Category": "Testing",
    "Sub_category": "Defect prediction",
    "Venue": "IJCAI",
    "Link": "https://www.sciencedirect.com/science/article/abs/pii/S0925231219301651",
    "bibtex": "article{681_Malhotra2019,\n    author = \"Malhotra, Ruchika and Kamal, Shine\",\n    title = \"An empirical study to investigate oversampling methods for improving software defect prediction using imbalanced data\",\n    journal = \"Neurocomputing\",\n    volume = \"343\",\n    pages = \"120--140\",\n    year = \"2019\",\n    publisher = \"Elsevier\"\n}\n\n",
    "abstract": "Software\u00a0defect prediction\u00a0is important to identify defects in the early phases of\u00a0software development life cycle. This early identification and thereby removal of\u00a0software defects\u00a0is crucial to yield a cost-effective and good quality software product. Though, previous studies have successfully used\u00a0machine learning\u00a0techniques for software defect prediction, these techniques yield biased results when applied on\u00a0imbalanced data\u00a0sets. An imbalanced data set has non-uniform class distribution with very few instances of a specific class as compared to that of the other class. Use of imbalanced datasets leads to off-target predictions of the minority class, which is generally considered to be more important than the majority class. Thus, handling imbalanced data effectively is crucial for successful development of a competent defect prediction model. This study evaluates the effectiveness of machine learning\u00a0classifiers\u00a0for software defect prediction on twelve imbalanced NASA datasets by application of sampling methods and cost sensitive classifiers. We investigate five existing oversampling methods, which replicate the instances of minority class and also propose a new method SPIDER3 by suggesting modifications in SPIDER2 oversampling method. Furthermore, the work evaluates the performance of MetaCost learners for cost sensitive learning on imbalanced datasets. The results show improvement in the prediction capability of machine learning classifiers with the use of oversampling methods. Furthermore, the proposed SPIDER3 method shows promising results."
},
{
    "py/object": "data.DataClassPaper",
    "Title": "Deep learning based software defect prediction",
    "year": 2020,
    "ML_Techniques": "",
    "Category": "Testing",
    "Sub_category": "Defect prediction",
    "Venue": "Neurocomputing",
    "Link": "https://www.sciencedirect.com/science/article/abs/pii/S0925231219316698",
    "bibtex": "article{682_Qiao2020,\n    author = \"Qiao, Lei and Li, Xuesong and Umer, Qasim and Guo, Ping\",\n    title = \"Deep learning based software defect prediction\",\n    journal = \"Neurocomputing\",\n    volume = \"385\",\n    pages = \"100--110\",\n    year = \"2020\",\n    publisher = \"Elsevier\"\n}\n\n",
    "abstract": "Software systems have become larger and more complex than ever. Such characteristics make it very challengeable to prevent\u00a0software defects. Therefore, automatically predicting the number of defects in software modules is necessary and may help developers efficiently to allocate limited resources. Various approaches have been proposed to identify and fix such defects at minimal cost. However, the performance of these approaches require significant improvement. Therefore, in this paper, we propose a novel approach that leverages\u00a0deep learning techniques\u00a0to predict the number of defects in software systems. First, we preprocess a publicly available dataset, including log transformation and data normalization. Second, we perform\u00a0data modeling\u00a0to prepare the data input for the\u00a0deep learning model. Third, we pass the modeled data to a specially designed deep neural network-based model to predict the number of defects. We also evaluate the proposed approach on two well-known datasets. The evaluation results illustrate that the proposed approach is accurate and can improve upon the state-of-the-art approaches. On average, the proposed method significantly reduces the mean square error by more than 14% and increases the squared correlation coefficient by more than 8%."
},
{
    "py/object": "data.DataClassPaper",
    "Title": "Deep neural network based hybrid approach for software defect prediction using software metrics",
    "year": 2018,
    "ML_Techniques": "DNN ",
    "Category": "Testing",
    "Sub_category": "Defect prediction",
    "Venue": "CC",
    "Link": "https://link.springer.com/article/10.1007/s10586-018-1696-z",
    "bibtex": "article{684_Manjula2019,\n    author = \"Manjula, C and Florence, Lilly\",\n    title = \"Deep neural network based hybrid approach for software defect prediction using software metrics\",\n    journal = \"Cluster Computing\",\n    volume = \"22\",\n    number = \"4\",\n    pages = \"9847--9863\",\n    year = \"2019\",\n    publisher = \"Springer\"\n}\n\n",
    "abstract": "In the field of early prediction of software defects, various techniques have been developed such as data mining techniques, machine learning techniques. Still early prediction of defects is a challenging task which needs to be addressed and can be improved by getting higher classification rate of defect prediction. With the aim of addressing this issue, we introduce a hybrid approach by combining genetic algorithm (GA) for feature optimization with deep neural network (DNN) for classification. An improved version of GA is incorporated which includes a new technique for chromosome designing and fitness function computation. DNN technique is also improvised using adaptive auto-encoder which provides better representation of selected software features. The improved efficiency of the proposed hybrid approach due to deployment of optimization technique is demonstrated through case studies. An experimental study is carried out for software defect prediction by considering PROMISE dataset using MATLAB tool. In this study, we have used the proposed novel method for classification and defect prediction. Comparative study shows that the proposed approach of prediction of software defects performs better when compared with other techniques where 97.82% accuracy is obtained for KC1 dataset, 97.59% accuracy is obtained for CM1 dataset, 97.96% accuracy is obtained for PC3 dataset and 98.00% accuracy is obtained for PC4 dataset."
},
{
    "py/object": "data.DataClassPaper",
    "Title": "A systematic review of unsupervised learning techniques for software defect prediction",
    "year": 2020,
    "ML_Techniques": "",
    "Category": "Testing",
    "Sub_category": "Defect prediction",
    "Venue": "IST",
    "Link": "https://www.sciencedirect.com/science/article/abs/pii/S0950584920300379",
    "bibtex": "article{685_Li2020,\n    author = \"Li, Ning and Shepperd, Martin and Guo, Yuchen\",\n    title = \"A systematic review of unsupervised learning techniques for software defect prediction\",\n    journal = \"Information and Software Technology\",\n    volume = \"122\",\n    pages = \"106287\",\n    year = \"2020\",\n    publisher = \"Elsevier\"\n}\n\n",
    "abstract": "Background\nUnsupervised machine learners have been increasingly applied to software defect prediction. It is an approach that may be valuable for software practitioners because it reduces the need for labeled training data.\n\nObjective\nInvestigate the use and performance of unsupervised learning techniques in software defect prediction.\n\nMethod\nWe conducted a systematic literature review that identified 49 studies containing 2456 individual experimental results, which satisfied our inclusion criteria published between January 2000 and March 2018. In order to compare prediction performance across these studies in a consistent way, we (re-)computed the confusion matrices and employed the Matthews Correlation Coefficient (MCC) as our main performance measure.\n\nResults\nOur meta-analysis shows that unsupervised models are comparable with supervised models for both within-project and cross-project prediction. Among the 14 families of unsupervised model, Fuzzy CMeans (FCM) and Fuzzy SOMs (FSOMs) perform best. In addition, where we were able to check, we found that almost 11% (262/2456) of published results (contained in 16 papers) were internally inconsistent and a further 33% (823/2456) provided insufficient details for us to check.\n\nConclusion\nAlthough many factors impact the performance of a classifier, e.g., dataset characteristics, broadly speaking, unsupervised classifiers do not seem to perform worse than the supervised classifiers in our review. However, we note a worrying prevalence of (i) demonstrably erroneous experimental results, (ii) undemanding benchmarks and (iii) incomplete reporting. We therefore encourage researchers to be comprehensive in their reporting."
},
{
    "py/object": "data.DataClassPaper",
    "Title": "A Survey on Software Defect Prediction Using Deep Learning",
    "year": 2021,
    "ML_Techniques": "",
    "Category": "Testing",
    "Sub_category": "Defect prediction",
    "Venue": "Mathematics",
    "Link": "https://www.mdpi.com/2227-7390/9/11/1180",
    "bibtex": "article{689_Akimova2021,\n    author = \"Akimova, Elena N and Bersenev, Alexander Yu and Deikov, Artem A and Kobylkin, Konstantin S and Konygin, Anton V and Mezentsev, Ilya P and Misilov, Vladimir E\",\n    title = \"A survey on software defect prediction using deep learning\",\n    journal = \"Mathematics\",\n    volume = \"9\",\n    number = \"11\",\n    pages = \"1180\",\n    year = \"2021\",\n    publisher = \"Multidisciplinary Digital Publishing Institute\"\n}\n\n",
    "abstract": "Defect prediction is one of the key challenges in software development and programming language research for improving software quality and reliability. The problem in this area is to properly identify the defective source code with high accuracy. Developing a fault prediction model is a challenging problem, and many approaches have been proposed throughout history. The recent breakthrough in machine learning technologies, especially the development of deep learning techniques, has led to many problems being solved by these methods. Our survey focuses on the deep learning techniques for defect prediction. We analyse the recent works on the topic, study the methods for automatic learning of the semantic and structural features from the code, discuss the open problems and present the recent trends in the field."
},
{
    "py/object": "data.DataClassPaper",
    "Title": "Using Coding-Based Ensemble Learning to Improve Software Defect Prediction",
    "year": 2012,
    "ML_Techniques": "",
    "Category": "Testing",
    "Sub_category": "Defect prediction",
    "Venue": "Transactions on Systems, Man, and Cybernetics",
    "Link": "https://ieeexplore.ieee.org/abstract/document/6392473",
    "bibtex": "article{690_Sun2012,\n    author = \"Sun, Zhongbin and Song, Qinbao and Zhu, Xiaoyan\",\n    title = \"Using coding-based ensemble learning to improve software defect prediction\",\n    journal = \"IEEE Transactions on Systems, Man, and Cybernetics, Part C (Applications and Reviews)\",\n    volume = \"42\",\n    number = \"6\",\n    pages = \"1806--1817\",\n    year = \"2012\",\n    publisher = \"IEEE\"\n}\n\n",
    "abstract": "Using classification methods to predict software defect proneness with static code attributes has attracted a great deal of attention. The class-imbalance characteristic of software defect data makes the prediction much difficult; thus, a number of methods have been employed to address this problem. However, these conventional methods, such as sampling, cost-sensitive learning, Bagging, and Boosting, could suffer from the loss of important information, unexpected mistakes, and overfitting because they alter the original data distribution. This paper presents a novel method that first converts the imbalanced binary-class data into balanced multiclass data and then builds a defect predictor on the multiclass data with a specific coding scheme. A thorough experiment with four different types of classification algorithms, three data coding schemes, and six conventional imbalance data-handling methods was conducted over the 14 NASA datasets. The experimental results show that the proposed method with a one-against-one coding scheme is averagely superior to the conventional methods."
},
{
    "py/object": "data.DataClassPaper",
    "Title": "Automation of Android applications functional testing using machine learning activities classification",
    "year": 2018,
    "ML_Techniques": "KS",
    "Category": "Testing",
    "Sub_category": "Defect prediction",
    "Venue": "MOBILESoft",
    "Link": "https://dl.acm.org/doi/abs/10.1145/3197231.3197241",
    "bibtex": "inproceedings{697_Rosenfeld2018,\n    author = \"Rosenfeld, Ariel and Kardashov, Odaya and Zang, Orel\",\n    title = \"Automation of android applications functional testing using machine learning activities classification\",\n    booktitle = \"Proceedings of the 5th International Conference on Mobile Software Engineering and Systems\",\n    pages = \"122--132\",\n    year = \"2018\"\n}\n\n",
    "abstract": "Following the ever-growing demand for mobile applications, researchers are constantly developing new test automation solutions for mobile developers. However, researchers have yet to produce an automated functional testing approach, resulting in many developers relying on a resource consuming manual testing. In this paper, we present a novel approach for the automation of functional testing in mobile software by leveraging machine learning techniques and reusing generic test scenarios. Our approach aims at relieving some of the manual functional testing burden by automatically classifying each of the application's screens to a set of common screen behaviors for which generic test scripts can be instantiated and reused. We empirically demonstrate the potential benefits of our approach in two experiments: First, using 26 randomly selected Android applications, we show that our approach can successfully instantiate and reuse generic functional tests and discover functional bugs. Second, in a human study with two experienced human mobile testers, we show that our approach can automatically cover a large portion of the human testers' work suggesting a significant potential relief in the manual testing efforts."
},
{
    "py/object": "data.DataClassPaper",
    "Title": "Machine learning based methods for software fault prediction: A survey",
    "year": 2021,
    "ML_Techniques": "",
    "Category": "Testing",
    "Sub_category": "Defect prediction",
    "Venue": "ESA",
    "Link": "https://www.sciencedirect.com/science/article/abs/pii/S0957417421000361",
    "bibtex": "article{702_Pandey2021,\n    author = \"Pandey, Sushant Kumar and Mishra, Ravi Bhushan and Tripathi, Anil Kumar\",\n    title = \"Machine learning based methods for software fault prediction: A survey\",\n    journal = \"Expert Systems with Applications\",\n    volume = \"172\",\n    pages = \"114595\",\n    year = \"2021\",\n    publisher = \"Elsevier\"\n}\n\n",
    "abstract": "Several prediction approaches are contained in the arena of software engineering such as prediction of effort, security, quality, fault, cost, and re-usability. All these prediction approaches are still in the rudimentary phase. Experiments and research are conducting to build a robust model. Software Fault Prediction (SFP) is the process to develop the model which can be utilized by software practitioners to detect faulty classes/module before the testing phase. Prediction of defective modules before the testing phase will help the software development team leader to allocate resources more optimally and it reduces the testing effort. In this article, we present a Systematic Literature Review (SLR) of various studies from 1990 to June 2019 towards applying machine learning and statistical method over software fault prediction. We have cited 208 research articles, in which we studied 154 relevant articles. We investigated the competence of machine learning in existing datasets and research projects. To the best of our knowledge, the existing SLR considered only a few parameters over SFP\u2019s performance, and they partially examined the various threats and challenges of SFP techniques. In this article, we aggregated those parameters and analyzed them accordingly, and we also illustrate the different challenges in the SFP domain. We also compared the performance between machine learning and statistical techniques based on SFP models. Our empirical study and analysis demonstrate that the prediction ability of machine learning techniques for classifying class/module as fault/non-fault prone is better than classical statistical models. The performance of machine learning-based SFP methods over fault susceptibility is better than conventional statistical purposes. The empirical evidence of our survey reports that the machine learning techniques have the capability, which can be used to identify fault proneness, and able to form well-generalized result. We have also investigated a few challenges in fault prediction discipline, i.e., quality of data, over-fitting of models, and class imbalance problem. We have also summarized 154 articles in a tabular form for quick identification."
},
{
    "py/object": "data.DataClassPaper",
    "Title": "A Combined-Learning Based Framework for Improved Software Fault Prediction",
    "year": 2017,
    "ML_Techniques": "NB, NND, SVM, RF, KNN, DTab, DT, RT",
    "Category": "Testing",
    "Sub_category": "Defect prediction",
    "Venue": "IJCIS",
    "Link": "https://www.researchgate.net/profile/Wondaferaw-Yohannese-Chubato/publication/315960451_A_Combined-Learning_Based_Framework_for_Improved_Software_Fault_Prediction/links/5a68ea8daca2728d0f5e0a91/A-Combined-Learning-Based-Framework-for-Improved-Software-Fault-Prediction.pdf",
    "bibtex": "article{705_Yohannese2017,\n    author = \"Yohannese, Chubato Wondaferaw and Li, Tianrui\",\n    title = \"A combined-learning based framework for improved software fault prediction\",\n    journal = \"International Journal of Computational Intelligence Systems\",\n    volume = \"10\",\n    number = \"1\",\n    pages = \"647\",\n    year = \"2017\",\n    publisher = \"Atlantis Press BV\"\n}\n\n",
    "abstract": "Software Fault Prediction (SFP) is found to be vital to predict the fault-proneness of software modules, which allows software engineers to focus development activities on fault-prone modules, thereby prioritize and optimize tests, improve software quality and make better use of resources. In this regard, machine learning has been successfully applied to solve classification problems for SFP. Nevertheless, the presence of different software metrics, the redundant and irrelevant features and the imbalanced nature of software datasets have created more and more challenges for the classification problems. Therefore, the objective of this study is to independently examine software metrics with multiple Feature Selection (FS) combined with Data Balancing (DB) using Synthetic Minority Oversampling Techniques for improving classification performance. Accordingly, a new framework that efficiently handles those challenges in a combined form on both Object Oriented Metrics (OOM) and Static Code Metrics (SCM) datasets is proposed. The experimental results confirm that the prediction performance could be compromised without suitable Feature Selection Techniques (FST). To mitigate that, data must be balanced. Thus our combined technique assures the robust performance. Furthermore, a combination of Random Forts (RF) with Information Gain (IG) FS yields the highest Receiver Operating Characteristic (ROC) curve (0.993) value, which is found to be the best combination when SCM are used, whereas the combination of RF with Correlation-based Feature Selection (CFS) guarantees the highest ROC (0.909) value, which is found to be the best choice when OOM are used. Therefore, as shown in this study, software metrics used to predict the fault proneness of the software modules must be carefully examined and suitable FST for software metrics must be cautiously selected. Moreover, DB must be applied in order to obtain robust performance. In addition to that, dealing with the challenges mentioned above, the proposed framework ensures the remarkable classification performance and lays the pathway to quality assurance of software."
},
{
    "py/object": "data.DataClassPaper",
    "Title": "Taxonomy of machine learning algorithms in software fault prediction using object oriented metrics",
    "year": 2018,
    "ML_Techniques": "",
    "Category": "Testing",
    "Sub_category": "Defect prediction",
    "Venue": "Procedia computer science",
    "Link": "https://www.sciencedirect.com/science/article/pii/S1877050918308470",
    "bibtex": "article{710_Singh2018,\n    author = \"Singh, Ajmer and Bhatia, Rajesh and Singhrova, Anita\",\n    title = \"Taxonomy of machine learning algorithms in software fault prediction using object oriented metrics\",\n    journal = \"Procedia computer science\",\n    volume = \"132\",\n    pages = \"993--1001\",\n    year = \"2018\",\n    publisher = \"Elsevier\"\n}\n\n",
    "abstract": "Prediction of Fault proneness of a software component is the compelling field of investigations in software testing arena. Software coupling plays a vital role in assessing the software quality through fault prediction and complexity measures. Various fault prediction models, have used the object oriented metrics for the predicting and localizing the faults. Many of these metrics have direct influence on the quality of software. More over prior knowledge of the fault proneness of a component may significantly reduce the testing effort and time. The measures of object oriented features like inheritance, polymorphism and encapsulation etc may be used to estimate fault proneness. Many researchers have investigated the usage of object oriented metrics in the software fault prediction. In this study we present taxonomy of usage these metrics in the fault prediction. We also present the analysis of machine learning techniques in fault prediction."
},
{
    "py/object": "data.DataClassPaper",
    "Title": "Statistical and Machine Learning Methods for Software Fault Prediction Using CK Metric Suite: A Comparative Analysis",
    "year": 2014,
    "ML_Techniques": "LR, LOG, ANN, FLANN, RBFN, PNN",
    "Category": "Testing",
    "Sub_category": "Defect prediction",
    "Venue": "ISRN",
    "Link": "https://downloads.hindawi.com/archive/2014/251083.pdf",
    "bibtex": "article{717_Suresh2014,\n    author = \"Suresh, Yeresime and Kumar, Lov and Rath, Santanu Ku\",\n    title = \"Statistical and machine learning methods for software fault prediction using CK metric suite: a comparative analysis\",\n    journal = \"International Scholarly Research Notices\",\n    volume = \"2014\",\n    year = \"2014\",\n    publisher = \"Hindawi\"\n}\n\n",
    "abstract": "Experimental validation of software metrics in fault prediction for object-oriented methods using statistical and machine learning methods is necessary. By the process of validation the quality of software product in a software organization is ensured. Objectoriented metrics play a crucial role in predicting faults. This paper examines the application of linear regression, logistic regression, and artificial neural network methods for software fault prediction using Chidamber and Kemerer (CK) metrics. Here, fault is considered as dependent variable and CK metric suite as independent variables. Statistical methods such as linear regression, logistic regression, and machine learning methods such as neural network (and its different forms) are being applied for detecting faults associated with the classes. The comparison approach was applied for a case study, that is, Apache integration framework (AIF) version 1.6. The analysis highlights the significance of weighted method per class (WMC) metric for fault classification, and also the analysis shows that the hybrid approach of radial basis function network obtained better fault prediction rate when compared with other three neural network models."
},
{
    "py/object": "data.DataClassPaper",
    "Title": "Toward Comprehensible Software Fault Prediction Models Using Bayesian Network Classifiers",
    "year": 2012,
    "ML_Techniques": "BN",
    "Category": "Testing",
    "Sub_category": "Defect prediction",
    "Venue": "TSE",
    "Link": "https://ieeexplore.ieee.org/abstract/document/6175912",
    "bibtex": "article{718_Dejaeger2012,\n    author = \"Dejaeger, Karel and Verbraken, Thomas and Baesens, Bart\",\n    title = \"Toward comprehensible software fault prediction models using bayesian network classifiers\",\n    journal = \"IEEE Transactions on Software Engineering\",\n    volume = \"39\",\n    number = \"2\",\n    pages = \"237--257\",\n    year = \"2012\",\n    publisher = \"IEEE\"\n}\n\n",
    "abstract": "Software testing is a crucial activity during software development and fault prediction models assist practitioners herein by providing an upfront identification of faulty software code by drawing upon the machine learning literature. While especially the Naive Bayes classifier is often applied in this regard, citing predictive performance and comprehensibility as its major strengths, a number of alternative Bayesian algorithms that boost the possibility of constructing simpler networks with fewer nodes and arcs remain unexplored. This study contributes to the literature by considering 15 different Bayesian Network (BN) classifiers and comparing them to other popular machine learning techniques. Furthermore, the applicability of the Markov blanket principle for feature selection, which is a natural extension to BN theory, is investigated. The results, both in terms of the AUC and the recently introduced H-measure, are rigorously tested using the statistical framework of Dem\u0161ar. It is concluded that simple and comprehensible networks with less nodes can be constructed using BN classifiers other than the Naive Bayes classifier. Furthermore, it is found that the aspects of comprehensibility and predictive performance need to be balanced out, and also the development context is an item which should be taken into account during model selection."
},
{
    "py/object": "data.DataClassPaper",
    "Title": "Empirical analysis of change metrics for software fault prediction\u2606",
    "year": 2018,
    "ML_Techniques": "",
    "Category": "Testing",
    "Sub_category": "Defect prediction",
    "Venue": "Computers & Electrical Engineering",
    "Link": "https://www.sciencedirect.com/science/article/abs/pii/S0045790617336121",
    "bibtex": "article{720_Choudhary2018,\n    author = \"Choudhary, Garvit Rajesh and Kumar, Sandeep and Kumar, Kuldeep and Mishra, Alok and Catal, Cagatay\",\n    title = \"Empirical analysis of change metrics for software fault prediction\",\n    journal = \"Computers \\\\& Electrical Engineering\",\n    volume = \"67\",\n    pages = \"15--24\",\n    year = \"2018\",\n    publisher = \"Elsevier\"\n}\n\n",
    "abstract": "A quality assurance activity, known as software fault prediction, can reduce development costs and improve software quality. The objective of this study is to investigate change metrics in conjunction with\u00a0code metrics\u00a0to improve the performance of fault prediction models. Experimental studies are performed on different versions of Eclipse projects and change metrics are extracted from the GIT repositories. In addition to the existing change metrics, several new change metrics are defined and collected from the Eclipse project repository.\u00a0Machine learning algorithms\u00a0are applied in conjunction with the change and source\u00a0code metrics\u00a0to build fault prediction models. The\u00a0classification model\u00a0with new change metrics performs better than the models using existing change metrics. In this work, the experimental results demonstrate that change metrics have a positive impact on the performance of fault prediction models, and high-performance models can be built with several change metrics."
},
{
    "py/object": "data.DataClassPaper",
    "Title": "A comparison of some soft computing methods for software fault prediction",
    "year": 2015,
    "ML_Techniques": "ANFIS, SVM, ANN",
    "Category": "Testing",
    "Sub_category": "Defect prediction",
    "Venue": "ESA",
    "Link": "https://www.sciencedirect.com/science/article/abs/pii/S0957417414006496",
    "bibtex": "article{722_Erturk2015,\n    author = \"Erturk, Ezgi and Sezer, Ebru Akcapinar\",\n    title = \"A comparison of some soft computing methods for software fault prediction\",\n    journal = \"Expert systems with applications\",\n    volume = \"42\",\n    number = \"4\",\n    pages = \"1872--1879\",\n    year = \"2015\",\n    publisher = \"Elsevier\"\n}\n\n",
    "abstract": "The main expectation from reliable software is the minimization of the number of failures that occur when the program runs. Determining whether software modules are prone to fault is important because doing so assists in identifying modules that require refactoring or detailed testing. Software fault prediction is a discipline that predicts the fault proneness of future modules by using essential prediction metrics and historical fault data. This study presents the first application of the Adaptive Neuro Fuzzy Inference System (ANFIS) for the software fault prediction problem. Moreover, Artificial Neural Network (ANN) and Support Vector Machine (SVM) methods, which were experienced previously, are built to discuss the performance of ANFIS. Data used in this study are collected from the PROMISE Software Engineering Repository, and McCabe metrics are selected because they comprehensively address the programming effort. ROC-AUC is used as a performance measure. The results achieved were 0.7795, 0.8685, and 0.8573 for the SVM, ANN and ANFIS methods, respectively."
},
{
    "py/object": "data.DataClassPaper",
    "Title": "Software fault prediction based on the dynamic selection of learning technique: findings from the eclipse project study",
    "year": 2021,
    "ML_Techniques": "",
    "Category": "Testing",
    "Sub_category": "Defect prediction",
    "Venue": "Applied Intelligence",
    "Link": "https://link.springer.com/article/10.1007/s10489-021-02346-x",
    "bibtex": "article{725_Rathore2021,\n    author = \"Rathore, Santosh S and Kumar, Sandeep\",\n    title = \"Software fault prediction based on the dynamic selection of learning technique: findings from the eclipse project study\",\n    journal = \"Applied Intelligence\",\n    volume = \"51\",\n    number = \"12\",\n    pages = \"8945--8960\",\n    year = \"2021\",\n    publisher = \"Springer\"\n}\n\n",
    "abstract": "An effective software fault prediction (SFP) model could help developers in the quick and prompt detection of faults and thus help enhance the overall reliability and quality of the software project. Variations in the prediction performance of learning techniques for different software systems make it difficult to select a suitable learning technique for fault prediction modeling. The evaluation of previously presented SFP approaches has shown that single machine learning-based models failed to provide the best accuracy in any context, highlighting the need to use multiple techniques to build the SFP model. To solve this problem, we present and discuss a software fault prediction approach based on selecting the most appropriate learning techniques from a set of competitive and accurate learning techniques for building a fault prediction model. In work, we apply the discussed SFP approach for the five Eclipse project datasets and nine Object-oriented (OO) project datasets and report the findings of the experimental study. We have used different performance measures, i.e., AUC, accuracy, sensitivity, and specificity, to assess the discussed approach\u2019s performance. Further, we have performed a cost-benefit analysis to evaluate the economic viability of the approach. Results showed that the presented approach predicted the software\u2019s faults effectively for the used accuracy, AUC, sensitivity, and specificity measures with the highest achieved values of 0.816, 0.835, 0.98, and 0.903 for AUC, accuracy, sensitivity, and specificity, respectively. The cost-benefit analysis of the approach showed that it could help reduce the overall software testing cost."
},
{
    "py/object": "data.DataClassPaper",
    "Title": "The Influence of Deep Learning Algorithms Factors in Software Fault Prediction",
    "year": 2020,
    "ML_Techniques": "MLP, CNN",
    "Category": "Testing",
    "Sub_category": "Defect prediction",
    "Venue": "IEEE Access",
    "Link": "https://ieeexplore.ieee.org/abstract/document/9055422",
    "bibtex": "article{729_Al2020,\n    author = \"Al Qasem, Osama and Akour, Mohammed and Alenezi, Mamdouh\",\n    title = \"The influence of deep learning algorithms factors in software fault prediction\",\n    journal = \"IEEE Access\",\n    volume = \"8\",\n    pages = \"63945--63960\",\n    year = \"2020\",\n    publisher = \"IEEE\"\n}\n\n",
    "abstract": "The discovery of software faults at early stages plays an important role in improving software quality; reduce the costs, time, and effort that should be spent on software development. Machine learning (ML) have been widely used in the software faults prediction (SFP), ML algorithms provide varying results in terms of predicting software fault. Deep learning achieves remarkable performance in various areas such as computer vision, natural language processing, speech recognition, and other fields. In this study, two deep learning algorithms are studied, Multi-layer perceptron's (MLPs) and Convolutional Neural Network (CNN) to address the factors that might have an influence on the performance of both algorithms. The experiment results show how modifying parameters is directly affecting the resulting improvement, these parameters are manipulated until the optimal number for each of them is reached. Moreover, the experiments show that the effect of modifying parameters had an important role in prediction performance, which reached a high rate in comparison with the traditional ML algorithm. To validate our assumptions, the experiments are conducted on four common NASA datasets. The result shows how the addressed factors might increase or decrease the fault detection rate measurement. The improvement rate was as follows up to 43.5% for PC1, 8% for KC1, 18% for KC2 and 76.5% for CM1."
},
{
    "py/object": "data.DataClassPaper",
    "Title": "A survey on software fault detection based on different prediction approaches",
    "year": 2013,
    "ML_Techniques": "",
    "Category": "Testing",
    "Sub_category": "Defect prediction",
    "Venue": "Vietnam Journal of Computer Science",
    "Link": "https://link.springer.com/article/10.1007/s40595-013-0008-z",
    "bibtex": "article{730_Abaei2014,\n    author = \"Abaei, Golnoush and Selamat, Ali\",\n    title = \"A survey on software fault detection based on different prediction approaches\",\n    journal = \"Vietnam Journal of Computer Science\",\n    volume = \"1\",\n    number = \"2\",\n    pages = \"79--95\",\n    year = \"2014\",\n    publisher = \"Springer\"\n}\n\n",
    "abstract": "One of the software engineering interests is quality assurance activities such as testing, verification and validation, fault tolerance and fault prediction. When any company does not have sufficient budget and time for testing the entire application, a project manager can use some fault prediction algorithms to identify the parts of the system that are more defect prone. There are so many prediction approaches in the field of software engineering such as test effort, security and cost prediction. Since most of them do not have a stable model, software fault prediction has been studied in this paper based on different machine learning techniques such as decision trees, decision tables, random forest, neural network, Na\u00efve Bayes and distinctive classifiers of artificial immune systems (AISs) such as artificial immune recognition system, CLONALG and Immunos. We use four public NASA datasets to perform our experiment. These datasets are different in size and number of defective data. Distinct parameters such as method-level metrics and two feature selection approaches which are principal component analysis and correlation based feature selection are used to evaluate the finest performance among the others. According to this study, random forest provides the best prediction performance for large data sets and Na\u00efve Bayes is a trustable algorithm for small data sets even when one of the feature selection techniques is applied. Immunos99 performs well among AIS classifiers when feature selection technique is applied, and AIRSParallel performs better without any feature selection techniques. The performance evaluation has been done based on three different metrics such as area under receiver operating characteristic curve, probability of detection and probability of false alarm. These three evaluation metrics could give the reliable prediction criteria together."
},
{
    "py/object": "data.DataClassPaper",
    "Title": "Comparing Commit Messages and Source Code Metrics for the Prediction Refactoring Activities",
    "year": 2021,
    "ML_Techniques": "LSTM",
    "Category": "Refactoring",
    "Sub_category": "",
    "Venue": "Algorithms",
    "Link": "https://www.mdpi.com/1999-4893/14/10/289",
    "bibtex": "Article{733_Sagar2021,\n    AUTHOR = \"Sagar, Priyadarshni Suresh and AlOmar, Eman Abdulah and Mkaouer, Mohamed Wiem and Ouni, Ali and Newman, Christian D.\",\n    TITLE = \"Comparing Commit Messages and Source Code Metrics for the Prediction Refactoring Activities\",\n    JOURNAL = \"Algorithms\",\n    VOLUME = \"14\",\n    YEAR = \"2021\",\n    NUMBER = \"10\",\n    ARTICLE-NUMBER = \"289\",\n    URL = \"https://www.mdpi.com/1999-4893/14/10/289\",\n    ISSN = \"1999-4893\",\n    ABSTRACT = \"Understanding how developers refactor their code is critical to support the design improvement process of software. This paper investigates to what extent code metrics are good indicators for predicting refactoring activity in the source code. In order to perform this, we formulated the prediction of refactoring operation types as a multi-class classification problem. Our solution relies on measuring metrics extracted from committed code changes in order to extract the corresponding features (i.e., metric variations) that better represent each class (i.e., refactoring type) in order to automatically predict, for a given commit, the method-level type of refactoring being applied, namely Move Method, Rename Method, Extract Method, Inline Method, Pull-up Method, and Push-down Method. We compared various classifiers, in terms of their prediction performance, using a dataset of 5004 commits and extracted 800 Java projects. Our main findings show that the random forest model trained with code metrics resulted in the best average accuracy of 75\\%. However, we detected a variation in the results per class, which means that some refactoring types are harder to detect than others.\",\n    DOI = \"10.3390/733_Sagar2021\"\n}\n\n",
    "abstract": "Understanding how developers refactor their code is critical to support the design improvement process of software. This paper investigates to what extent code metrics are good indicators for predicting refactoring activity in the source code. In order to perform this, we formulated the prediction of refactoring operation types as a multi-class classification problem. Our solution relies on measuring metrics extracted from committed code changes in order to extract the corresponding features (i.e., metric variations) that better represent each class (i.e., refactoring type) in order to automatically predict, for a given commit, the method-level type of refactoring being applied, namely\u00a0Move Method,\u00a0Rename Method,\u00a0Extract Method,\u00a0Inline Method,\u00a0Pull-up Method, and\u00a0Push-down Method. We compared various classifiers, in terms of their prediction performance, using a dataset of 5004 commits and extracted 800 Java projects. Our main findings show that the random forest model trained with code metrics resulted in the best average accuracy of 75%. However, we detected a variation in the results per class, which means that some refactoring types are harder to detect than others.\u00a0"
},
{
    "py/object": "data.DataClassPaper",
    "Title": "A machine learning approach to software model refactoring",
    "year": 2019,
    "ML_Techniques": "DNN",
    "Category": "Refactoring",
    "Sub_category": "",
    "Venue": "IJCA",
    "Link": "https://www.tandfonline.com/doi/abs/10.1080/1206212X.2020.1711616",
    "bibtex": "article{734_Sidhu2022,\n    author = \"Sidhu, Brahmaleen Kaur and Singh, Kawaljeet and Sharma, Neeraj\",\n    title = \"A machine learning approach to software model refactoring\",\n    journal = \"International Journal of Computers and Applications\",\n    volume = \"44\",\n    number = \"2\",\n    pages = \"166-177\",\n    year = \"2022\",\n    publisher = \"Taylor \\& Francis\",\n    doi = \"10.1080/1206212X.2020.1711616\",\n    URL = \"https://doi.org/10.1080/1206212X.2020.1711616\",\n    eprint = \"https://doi.org/10.1080/1206212X.2020.1711616\"\n}\n\n",
    "abstract": "Good software quality is a consequence of good design. Model refactoring counteracts erosion of the software design at an early stage in the software development project complying with the model-driven engineering paradigm. Traditional model refactoring approaches work at the surface level by using threshold values of model metrics as indicators of suboptimal design and carry out localized corrections. Through this paper, it is proposed that identifying design flaws at a higher level of granularity will save from the vicious cycle of small refactoring operations and their cascaded side-effects. The notion of functional decomposition, as an anomalous design tendency and a dominant cause of design, smells in object-oriented software, is introduced. It is suggested that refactoring operations targeted at signs of functional decomposition instead of atomic smells achieve substantial improvement in design within a concise quality assurance procedure. The idea is realized using a deep neural network that learns to recognize the presence of functional decomposition in UML models of object-oriented software. The presented approach uses data science methods to gain insight into multidimensional software design features and uses the experience gained to generalize subtle relationships among architectural components."
},
{
    "py/object": "data.DataClassPaper",
    "Title": "Software Change Proneness Prediction Using Machine Learning",
    "year": 2020,
    "ML_Techniques": "",
    "Category": "Program comprehension",
    "Sub_category": "Change analysis",
    "Venue": "3ICT",
    "Link": "https://ieeexplore.ieee.org/abstract/document/9311978",
    "bibtex": "inproceedings{738_Abbas2020,\n    author = \"Abbas, Raja and Albalooshi, Fawzi Abdulaziz and Hammad, Mustafa\",\n    title = \"Software change proneness prediction using machine learning\",\n    booktitle = \"2020 International Conference on Innovation and Intelligence for Informatics, Computing and Technologies (3ICT)\",\n    pages = \"1--7\",\n    year = \"2020\",\n    organization = \"IEEE\"\n}\n\n",
    "abstract": "Software change-proneness is one of the vital quality metrics that represents the extent of change of a class across versions of the system. This change may occur due to evolving requirements, bug fixing, or code refactoring. Consequently, change-proneness may have a negative impact on software evolution. For instance, modules that are change-prone tend to produce more defects and accumulate more technical debt. This research work applies different Machine Learning (ML) techniques on a large dataset from a wide commercial software system to investigate the relationships between object-oriented (OO) metrics and change-proneness, and determine which OO metrics are necessary to predict change-prone classes. Moreover, several state-of-the-art combining methods were evaluated that were constructed by combining several heterogeneous single and ensemble classifiers with voting, Select-Best, and staking scheme. The result of the study indicates a high prediction performance of many of the ensemble classifiers as well as the combining methods selected and proved that ML methods are very beneficial for predicting change-prone classes in software. The study also proved that software metrics are significant indicators of class change-proneness and should be monitored regularly during software development and maintenance."
},
{
    "py/object": "data.DataClassPaper",
    "Title": "Bad Smell Detection Using Machine Learning Techniques: A Systematic Literature Review",
    "year": 2020,
    "ML_Techniques": "",
    "Category": "Quality assessment",
    "Sub_category": "Code smell detection",
    "Venue": "AJSE",
    "Link": "https://link.springer.com/article/10.1007/s13369-019-04311-w",
    "bibtex": "article{740_Al-Shaaby2020,\n    author = \"Al-Shaaby, Ahmed and Aljamaan, Hamoud and Alshayeb, Mohammad\",\n    title = \"Bad smell detection using machine learning techniques: a systematic literature review\",\n    journal = \"Arabian Journal for Science and Engineering\",\n    volume = \"45\",\n    number = \"4\",\n    pages = \"2341--2369\",\n    year = \"2020\",\n    publisher = \"Springer\"\n}\n\n",
    "abstract": "Code smells are indicators of potential problems in software. They tend to have a negative impact on software quality. Several studies use machine learning techniques to detect bad smells. The objective of this study is to systematically review and analyze machine learning techniques used to detect code smells to provide interested research community with knowledge about the adopted techniques and practices for code smells detection. We use a systematic literature review approach to review studies that use machine learning techniques to detect code smells. Seventeen primary studies were identified. We found that 27 code smells were used in the identified studies; God Class and Long Method, Feature Envy, and Data Class are the most frequently detected code smells. In addition, we found that 16 machine learning algorithms were employed to detect code smells with acceptable prediction accuracy. Furthermore, we the results also indicate that support vector machine techniques were investigated the most. Moreover, we observed that J48 and Random Forest algorithms outperform the other algorithms. We also noticed that, in some cases, the use of boosting techniques on the models does not always enhance their performance. More studies are needed to consider the use of ensemble learning techniques, multiclassification, and feature selection technique for code smells detection. Thus, the application of machine learning algorithms to detect code smells in systems is still in its infancy and needs more research to facilitate the employment of machine learning algorithms in detecting code smells."
},
{
    "py/object": "data.DataClassPaper",
    "Title": "Using source code metrics to predict change-prone web services: A case-study on ebay services",
    "year": 2017,
    "ML_Techniques": "SVM",
    "Category": "Program comprehension",
    "Sub_category": "Change analysis",
    "Venue": "MaLTeSQuE",
    "Link": "https://ieeexplore.ieee.org/abstract/document/7882009",
    "bibtex": "inproceedings{742_Kumar2017,\n    author = \"Kumar, Lov and Rath, Santanu Kumar and Sureka, Ashish\",\n    title = \"Using source code metrics to predict change-prone web services: A case-study on ebay services\",\n    booktitle = \"2017 IEEE workshop on machine learning techniques for software quality evaluation (MaLTeSQuE)\",\n    pages = \"1--7\",\n    year = \"2017\",\n    organization = \"IEEE\"\n}\n\n",
    "abstract": "Predicting change-prone object-oriented software using source code metrics is an area that has attracted several researchers attention. However, predicting change-prone web services in terms of changes in the WSDL (Web Service Description Language) Interface using source code metrics implementing the services is a relatively unexplored area. We conduct a case-study on change proneness prediction on an experimental dataset consisting of several versions of eBay web services wherein we compute the churn between different versions of the WSDL interfaces using the WSDLDiff Tool. We compute 21 source code metrics using Chidamber and Kemerer Java Metrics (CKJM) extended tool serving as predictors and apply Least Squares Support Vector Machines (LSSVM) based technique to develop a change proneness estimator. Our experimental results demonstrates that a predictive model developed using all 21 metrics and linear kernel yields the best results."
},
{
    "py/object": "data.DataClassPaper",
    "Title": "GEMS: An Extract Method Refactoring Recommender",
    "year": 2017,
    "ML_Techniques": "PNN",
    "Category": "Refactoring",
    "Sub_category": "",
    "Venue": "ISSRE",
    "Link": "https://ieeexplore.ieee.org/abstract/document/8109070",
    "bibtex": "INPROCEEDINGS{745_Xu2017,\n    author = \"Xu, Sihan and Sivaraman, Aishwarya and Khoo, Siau-Cheng and Xu, Jing\",\n    booktitle = \"2017 IEEE 28th International Symposium on Software Reliability Engineering (ISSRE)\",\n    title = \"GEMS: An Extract Method Refactoring Recommender\",\n    year = \"2017\",\n    volume = \"\",\n    number = \"\",\n    pages = \"24-34\",\n    doi = \"10.1109/ISSRE.2017.35\"\n}\n\n",
    "abstract": "Extract Method is a widely used refactoring operation to improve method comprehension and maintenance. Much research has been done to extract codefragments within the method body to form a new method. Criteria used for identifying extractable code is usually centered around degrees of cohesiveness, coupling and length of the method. However, automatic method extraction techniques have not been highly successful, since it can be hard to concretizethe criteria. In this work, we present a novel system that learns these criteria for Extract Method refactorings from open source repositories. We extractstructural and functional features, which encode the concepts of complexity, cohesion and coupling in our learning model, and train it to extract suitablecode fragments from a given source of a method. Our tool, GEMS, recommends a ranked list of code fragments with high accuracy and greatspeed. We evaluated our approach on several open source repositories and compared it against three state-of-the-art approaches-SEMI, JExtract andJDeodorant. The results on these open-source data show the superiority of our machine-learning-based approach in terms of effectiveness. We develop GEMS asan Eclipse plugin, with the intention to support software reliability through method extraction."
},
{
    "py/object": "data.DataClassPaper",
    "Title": "An Empirical Framework for Web Service Anti-pattern Prediction using Machine Learning Techniques",
    "year": 2019,
    "ML_Techniques": "LOG, ANN, SVM, SVM, SVM, RF",
    "Category": "Quality assessment",
    "Sub_category": "Code smell detection",
    "Venue": "IEMECON",
    "Link": "https://ieeexplore.ieee.org/abstract/document/8877008",
    "bibtex": "inproceedings{749_Tummalapalli2019,\n    author = \"Tummalapalli, Sahithi and Kumar, Lov and Neti, Lalita Bhanu Murthy\",\n    title = \"An empirical framework for web service anti-pattern prediction using machine learning techniques\",\n    booktitle = \"2019 9th Annual Information Technology, Electromechanical Engineering and Microelectronics Conference (IEMECON)\",\n    pages = \"137--143\",\n    year = \"2019\",\n    organization = \"IEEE\"\n}\n\n",
    "abstract": "In todays software industries, the concepts of Web Services are applied to design and develop distributed software system. These distributed software system can be designed and developed by integrating different Web Services provided by different parties. Similar to other software systems, Web Services based system also suffers from bad or poor design i.e., bad design selection, anti-pattern, poor planning etc.. Early prediction of anti-patterns can help developer and tester in fixing design issue and also effectively utilize the resources. The work in this paper empirically investigates and evaluates six classification techniques, 8 feature selection techniques (7 feature ranking techniques and 1 feature subset evaluation technique), and 1 data sampling technique to handle imbalance data in predicting 5 different types of anti-patterns. These all techniques are validated on 226 real-world web-services across several domains. The performance of the developed models using these techniques are evaluated using AUC value. Our analysis reveals that the model developed using these techniques able to predict different anti-patterns using source code metrics. Our analysis also reveals that the best feature selection technique is OneR, data sample is better that without sampling and Random Forest is best classification algorithm for anti-pattern predictions."
},
{
    "py/object": "data.DataClassPaper",
    "Title": "Machine Learning Techniques for Code Smells Detection: A Systematic Mapping Study",
    "year": 2019,
    "ML_Techniques": "",
    "Category": "Quality assessment",
    "Sub_category": "Code smell detection",
    "Venue": "IJSEKE",
    "Link": "https://www.worldscientific.com/doi/abs/10.1142/S021819401950013X",
    "bibtex": "article{751_Caram2019,\n    author = \"Caram, Frederico Luiz and Rodrigues, Bruno Rafael De Oliveira and Campanelli, Amadeu Silveira and Parreiras, Fernando Silva\",\n    title = \"Machine learning techniques for code smells detection: a systematic mapping study\",\n    journal = \"International Journal of Software Engineering and Knowledge Engineering\",\n    volume = \"29\",\n    number = \"02\",\n    pages = \"285--316\",\n    year = \"2019\",\n    publisher = \"World Scientific\"\n}\n\n",
    "abstract": "Code smells or bad smells are an accepted approach to identify design flaws in the source code. Although it has been explored by researchers, the interpretation of programmers is rather subjective. One way to deal with this subjectivity is to use machine learning techniques. This paper provides the reader with an overview of machine learning techniques and code smells found in the literature, aiming at determining which methods and practices are used when applying machine learning for code smells identification and which machine learning techniques have been used for code smells identification. A mapping study was used to identify the techniques used for each smell. We found that the Bloaters was the main kind of smell studied, addressed by 35% of the papers. The most commonly used technique was Genetic Algorithms (GA), used by 22.22% of the papers. Regarding the smells addressed by each technique, there was a high level of redundancy, in a way that the smells are covered by a wide range of algorithms. Nevertheless, Feature Envy stood out, being targeted by 63% of the techniques. When it comes to performance, the best average was provided by Decision Tree, followed by Random Forest, Semi-supervised and Support Vector Machine Classifier techniques. 5 out of the 25 analyzed smells were not handled by any machine learning techniques. Most of them focus on several code smells and in general there is no outperforming technique, except for a few specific smells. We also found a lack of comparable results due to the heterogeneity of the data sources and of the provided results. We recommend the pursuit of further empirical studies to assess the performance of these techniques in a standardized dataset to improve the comparison reliability and replicability."
},
{
    "py/object": "data.DataClassPaper",
    "Title": "An empirical study on clone consistency prediction based on machine learning",
    "year": 2021,
    "ML_Techniques": "BN, NB, SVM, KNN, DT ",
    "Category": "Quality assessment",
    "Sub_category": "Clone detection",
    "Venue": "IST",
    "Link": "https://www.sciencedirect.com/science/article/abs/pii/S0950584921000562",
    "bibtex": "article{753_Zhang2021,\n    author = \"Zhang, Fanlong and Khoo, Siau-cheng\",\n    title = \"An empirical study on clone consistency prediction based on machine learning\",\n    journal = \"Information and Software Technology\",\n    volume = \"136\",\n    pages = \"106573\",\n    year = \"2021\",\n    publisher = \"Elsevier\"\n}\n\n",
    "abstract": "Code Clones have been accepted as a common phenomenon in software, thanks to the increasing demand for rapid production of software. The existence of code clones is recognized by developers in the form of\u00a0clone group, which includes several pieces of clone fragments that are similar to one another. A change in one of these clone fragments may indicate necessary\u00a0\u201cconsistent changes\u201d\u00a0are required for the rest of the clones within the same group, which can increase extra maintenance costs. A failure in making such consistent change when it is necessary is commonly known as a \u201cclone consistency-defect\u201d, which can adversely impact software\u00a0maintainability."
},
{
    "py/object": "data.DataClassPaper",
    "Title": "Recommending Clones for Refactoring Using Design, Context, and History",
    "year": 2014,
    "ML_Techniques": "DT",
    "Category": "Refactoring",
    "Sub_category": "",
    "Venue": "ICSM",
    "Link": "https://ieeexplore.ieee.org/abstract/document/6976099",
    "bibtex": "INPROCEEDINGS{757_Wang2014,\n    author = \"Wang, Wei and Godfrey, Michael W.\",\n    booktitle = \"2014 IEEE International Conference on Software Maintenance and Evolution\",\n    title = \"Recommending Clones for Refactoring Using Design, Context, and History\",\n    year = \"2014\",\n    volume = \"\",\n    number = \"\",\n    pages = \"331-340\",\n    doi = \"10.1109/ICSME.2014.55\"\n}\n\n",
    "abstract": "Developers know that copy-pasting code (aka code cloning) is often a convenient shortcut to achieving a design goal, albeit one that carries risks to the code quality over time. However, deciding which, if any, clones should be eliminated within an existing system is a daunting task. Fixing a clone usually means performing an invasive refactoring, and not all clones may be worth the effort, cost, and risk that such a change entails. Furthermore, sometimes cloning fulfils a useful design role, and should not be refactored at al. And clone detection tools often return very large result sets, making it hard to choose which clones should be investigated and possibly removed. In this paper, we propose an automated approach to recommend clones for refactoring by training a decision tree-based classifier. We analyze more than 600 clone instances in three medium-to large-sized open source projects, and we collect features that are associated with the source code, the context, and the history of clone instances. Our approach achieves a precision of around 80% in recommending clone refactoring instances for each target system, and similarly good precision is achieved in cross-project evaluation. By recommending which clones are appropriate for refactoring, our approach allows for better resource allocation for refactoring itself after obtaining clone detection results, and can thus lead to improved clone management in practice."
},
{
    "py/object": "data.DataClassPaper",
    "Title": "Clone-advisor: recommending code tokens and clone methods with deep learning and information retrieval",
    "year": 2021,
    "ML_Techniques": "",
    "Category": "Quality assessment",
    "Sub_category": "Clone detection",
    "Venue": "PeerJ Computer Science",
    "Link": "https://peerj.com/articles/cs-737/",
    "bibtex": "article{758_Hammad2021,\n    author = {Hammad, Muhammad and Babur, {\\\"\"O}nder and Basit, Hamid Abdul and van den Brand, Mark},\n    title = \"Clone-advisor: recommending code tokens and clone methods with deep learning and information retrieval\",\n    journal = \"PeerJ Computer Science\",\n    volume = \"7\",\n    pages = \"e737\",\n    year = \"2021\",\n    publisher = \"PeerJ Inc.\"\n}\n\n",
    "abstract": "Software developers frequently reuse source code from repositories as it saves development time and effort. Code clones (similar code fragments) accumulated in these repositories represent often repeated functionalities and are candidates for reuse in an exploratory or rapid development. To facilitate code clone reuse, we previously presented DeepClone, a novel deep learning approach for modeling code clones along with non-cloned code to predict the next set of tokens (possibly a complete clone method body) based on the code written so far. The probabilistic nature of language modeling, however, can lead to code output with minor syntax or logic errors. To resolve this, we propose a novel approach called Clone-Advisor. We apply an information retrieval technique on top of DeepClone output to recommend real clone methods closely matching the predicted clone method, thus improving the original output by DeepClone. In this paper we have discussed and refined our previous work on DeepClone in much more detail. Moreover, we have quantitatively evaluated the performance and effectiveness of Clone-Advisor in clone method recommendation."
},
{
    "py/object": "data.DataClassPaper",
    "Title": "Feature requests-based recommendation of software refactorings",
    "year": 2020,
    "ML_Techniques": "LOG",
    "Category": "Refactoring",
    "Sub_category": "",
    "Venue": "ESE",
    "Link": "https://link.springer.com/article/10.1007/s10664-020-09871-2",
    "bibtex": "",
    "abstract": "Software requirements are ever-changing which often leads to software evolution. Consequently, throughout software lifetime, developers receive new requirements often expressed as feature requests. To implement the requested features, developers sometimes apply refactorings to make their systems adapt to the new requirements. However, deciding what refactorings to apply is often challenging and there is still lack of automated support to recommend refactorings given a feature request. To this end, we propose a learning-based approach that recommends refactorings based on the history of the previously requested features, applied refactorings, and code smells information. First, the state-of-the-art refactoring detection tools are leveraged to identify the previous refactorings applied to implement the past feature requests. Second, a machine classifier is trained with the history data of the feature requests, code smells, and refactorings applied on the respective commits. Consequently, the machine classifier is used to predict refactorings for new feature requests. The proposed approach is evaluated on the dataset of 55 open source Java projects and the results suggest that it can accurately recommend refactorings (accuracy is up to 83.19%)."
},
{
    "py/object": "data.DataClassPaper",
    "Title": "A Context-Based Automated Approach for Method Name Consistency Checking and Suggestion",
    "year": 2021,
    "ML_Techniques": "RNN",
    "Category": "Program comprehension",
    "Sub_category": "Code summarization",
    "Venue": "ICSE",
    "Link": "https://ieeexplore.ieee.org/abstract/document/9402103",
    "bibtex": "inproceedings{762_Li2021,\n    author = \"Li, Yi and Wang, Shaohua and Nguyen, Tien N\",\n    title = \"A Context-based Automated Approach for Method Name Consistency Checking and Suggestion\",\n    booktitle = \"2021 IEEE/ACM 43rd International Conference on Software Engineering (ICSE)\",\n    pages = \"574--586\",\n    year = \"2021\",\n    organization = \"IEEE\"\n}\n\n",
    "abstract": "Misleading method names in software projects can confuse developers, which may lead to software defects and affect code understandability. In this paper, we present DeepName, a context-based, deep learning approach to detect method name inconsistencies and suggest a proper name for a method. The key departure point is the philosophy of \"Show Me Your Friends, I'll Tell You Who You Are\". Unlike the state-of-the-art approaches, in addition to the method's body, we also consider the interactions of the current method under study with the other ones including the caller and callee methods, and the sibling methods in the same enclosing class. The sequences of sub-tokens in the program entities' names in the contexts are extracted and used as the input for an RNN-based encoder-decoder to produce the representations for the current method. We modify that RNN model to integrate the copy mechanism and our newly developed component, called the non-copy mechanism, to emphasize on the possibility of a certain sub-token not to be copied to follow the current sub-token in the currently generated method name. We conducted several experiments to evaluate DeepName on large datasets with +14M methods. For consistency checking, DeepName improves the state-of-the-art approach by 2.1%, 19.6%, and 11.9% relatively in recall, precision, and F-score, respectively. For name suggestion, DeepName improves relatively over the state-of-the-art approaches in precision (1.8%-30.5%), recall (8.8%-46.1%), and F-score (5.2%-38.2%). To assess DeepName's usefulness, we detected inconsistent methods and suggested new method names in active projects. Among 50 pull requests, 12 were merged into the main branch. In total, in 30/50 cases, the team members agree that our suggested method names are more meaningful than the current names."
},
{
    "py/object": "data.DataClassPaper",
    "Title": "Detecting bad smells with machine learning algorithms: an empirical study",
    "year": 2020,
    "ML_Techniques": "NB, LOG, DT, MLP, KNN, RF, GBM",
    "Category": "Quality assessment",
    "Sub_category": "Code smell detection",
    "Venue": "International Conference on Technical Debt",
    "Link": "https://dl.acm.org/doi/abs/10.1145/3387906.3388618",
    "bibtex": "inproceedings{767_Cruz2020,\n    author = \"Cruz, Daniel and Santana, Amanda and Figueiredo, Eduardo\",\n    title = \"Detecting bad smells with machine learning algorithms: an empirical study\",\n    booktitle = \"Proceedings of the 3rd International Conference on Technical Debt\",\n    pages = \"31--40\",\n    year = \"2020\"\n}\n\n",
    "abstract": "Bad smells are symptoms of bad design choices implemented on the source code. They are one of the key indicators of technical debts, specifically, design debt. To manage this kind of debt, it is important to be aware of bad smells and refactor them whenever possible. Therefore, several bad smell detection tools and techniques have been proposed over the years. These tools and techniques present different strategies to perform detections. More recently, machine learning algorithms have also been proposed to support bad smell detection. However, we lack empirical evidence on the accuracy and efficiency of these machine learning based techniques. In this paper, we present an evaluation of seven different machine learning algorithms on the task of detecting four types of bad smells. We also provide an analysis of the impact of software metrics for bad smell detection using a unified approach for interpreting the models' decisions. We found that with the right optimization, machine learning algorithms can achieve good performance (F1 score) for two bad smells:\u00a0God Class (0.86)\u00a0and\u00a0Refused Parent Bequest (0.67).\u00a0We also uncovered which metrics play fundamental roles for detecting each bad smell."
},
{
    "py/object": "data.DataClassPaper",
    "Title": "Enhancing Source Code Refactoring Detection with Explanations from Commit Messages",
    "year": 2020,
    "ML_Techniques": "",
    "Category": "Refactoring",
    "Sub_category": "",
    "Venue": "SANER",
    "Link": "https://ieeexplore.ieee.org/abstract/document/9054816",
    "bibtex": "INPROCEEDINGS{770_Krasniqi2020,\n    author = \"Krasniqi, Rrezarta and Cleland-Huang, Jane\",\n    booktitle = \"2020 IEEE 27th International Conference on Software Analysis, Evolution and Reengineering (SANER)\",\n    title = \"Enhancing Source Code Refactoring Detection with Explanations from Commit Messages\",\n    year = \"2020\",\n    volume = \"\",\n    number = \"\",\n    pages = \"512-516\",\n    doi = \"10.1109/SANER48275.2020.770_Krasniqi2020\"\n}\n\n",
    "abstract": "We investigate the extent to which code commit summaries provide rationales and descriptions of code refactorings. We present a refactoring description detection tool CMMiner that detects code commit messages containing refactoring information and differentiates between twelve different refactoring types. We further explore whether refactoring information mined from commit messages using CMMiner, can be combined with refactoring descriptions mined from source code using the well-known RMiner tool. For six refactoring types covered by both CMMiner and RMiner, we observed 21.96% to 38.59% overlap in refactorings detected across four diverse open-source systems. RMiner identified approximately 49.13% to 60.29% of refactorings missed by CMMiner, primarily because developers often failed to describe code refactorings that occurred alongside other code changes. However, CMMiner identified 10.30% to 19.51% of refactorings missed by RMiner, primarily when refactorings occurred across multiple commits. Our results suggest that integrating both approaches can enhance the completeness of refactoring detection and provide refactoring rationales."
},
{
    "py/object": "data.DataClassPaper",
    "Title": "A Search-Based Testing Framework for Deep Neural Networks of Source Code Embedding",
    "year": 2021,
    "ML_Techniques": "Code2vec, Code2seq, CodeBERT",
    "Category": "Code representation",
    "Sub_category": "",
    "Venue": "ICST",
    "Link": "https://ieeexplore.ieee.org/abstract/document/9438605",
    "bibtex": "inproceedings{780_Pour2021,\n    author = \"Pour, Maryam Vahdat and Li, Zhuo and Ma, Lei and Hemmati, Hadi\",\n    title = \"A search-based testing framework for deep neural networks of source code embedding\",\n    booktitle = \"2021 14th IEEE Conference on Software Testing, Verification and Validation (ICST)\",\n    pages = \"36--46\",\n    year = \"2021\",\n    organization = \"IEEE\"\n}\n\n",
    "abstract": "Over the past few years, deep neural networks (DNNs) have been continuously expanding their real-world applications for source code processing tasks across the software engineering domain, e.g., clone detection, code search, comment generation. Although quite a few recent works have been performed on testing of DNNs in the context of image and speech processing, limited progress has been achieved so far on DNN testing in the context of source code processing, that exhibits rather unique characteristics and challenges.In this paper, we propose a search-based testing framework for DNNs of source code embedding and its downstream processing tasks like Code Search. To generate new test inputs, we adopt popular source code refactoring tools to generate the semantically equivalent variants. For more effective testing, we leverage the DNN mutation testing to guide the testing direction. To demonstrate the usefulness of our technique, we perform a large-scale evaluation on popular DNNs of source code processing based on multiple state-of-the-art code embedding methods (i.e., Code2vec, Code2seq and CodeBERT). The testing results show that our generated adversarial samples can on average reduce the performance of these DNNs from 5.41% to 9.58%. Through retraining the DNNs with our generated adversarial samples, the robustness of DNN can improve by 23.05% on average. The evaluation results also show that our adversarial test generation strategy has the least negative impact (median of 3.56%), on the performance of the DNNs for regular test data, compared to the other methods."
},
{
    "py/object": "data.DataClassPaper",
    "Title": "Detection of web service anti-patterns using weighted extreme learning machine",
    "year": 2022,
    "ML_Techniques": "ELM ",
    "Category": "Quality assessment",
    "Sub_category": "Code smell detection",
    "Venue": "Computer Standards & Interfaces",
    "Link": "https://www.sciencedirect.com/science/article/abs/pii/S0920548922000022",
    "bibtex": "article{784_Tummalapalli2022,\n    author = \"Tummalapalli, Sahithi and Kumar, Lov and Murthy, NL Bhanu and Krishna, Aneesh\",\n    title = \"Detection of Web Service Anti-Patterns Using Weighted Extreme Learning Machine\",\n    journal = \"Computer Standards \\\\& Interfaces\",\n    pages = \"103621\",\n    year = \"2022\",\n    publisher = \"Elsevier\"\n}\n\n",
    "abstract": "\u2018Anti-Pattern\u2019 is a term often used by software engineers and practitioners nowadays. An anti-pattern is a supplement of the\u00a0design pattern. Similar to design patterns, an anti-pattern is a template and a repeatable way of solving a specific problem, but in a non-optimal and ineffective way. Therefore, there is a requirement for the timely identification and modification of anti-patterns to increase software systems performance and efficiency. Anti-pattern detection using the source\u00a0code metric\u00a0can be used as an initial step in the\u00a0software development life cycle, both to reduce the maintenance of the software system and to improve the quality of the software. The work in this paper empirically investigates the effectiveness of two\u00a0machine learning algorithms, i.e., Extreme Learning Machine (ELM) and Weighted Extreme Learning Machine (WELM), with four different kernels in detecting web service anti-patterns. This work also investigates the application of different aggregation techniques and data sampling techniques to handle\u00a0imbalanced data\u00a0in predicting five different anti-patterns. The inference of this research is studied over 226 WSDL (Web Service Description Language) files. The experimental findings reveal that the model developed by WELM has superior prediction accuracy compared to the model developed by ELM."
},
{
    "py/object": "data.DataClassPaper",
    "Title": "Web Service API Anti-patterns Detection as a Multi-label Learning Problem",
    "year": 2020,
    "ML_Techniques": "",
    "Category": "Quality assessment",
    "Sub_category": "Code smell detection",
    "Venue": "ICWS",
    "Link": "https://link.springer.com/chapter/10.1007/978-3-030-59618-7_8",
    "bibtex": "inproceedings{787_Saidani2020,\n    author = \"Saidani, Islem and Ouni, Ali and Mkaouer, Mohamed Wiem\",\n    title = \"Web Service API Anti-patterns Detection as a Multi-label Learning Problem\",\n    booktitle = \"International Conference on Web Services\",\n    pages = \"114--132\",\n    year = \"2020\",\n    organization = \"Springer\"\n}\n\n",
    "abstract": "Anti-patterns are symptoms of poor design and implementation solutions applied by developers during the development of their software systems. Recent studies have identified a variety of Web service anti-patterns and defined them as sub-optimal solutions that result from bad design choices, time pressure, or lack of developers experience. The existence of anti-patterns often leads to software systems that are hard to understand, reuse, and discover in practice. Indeed, it has been shown that service designers and developers tend to pay little attention to their service interfaces design. Web service antipatterns detection is a non-trivial and error-prone task as different anti-pattern types typically have interleaving symptoms that can be subjectively interpreted and hence detected in different ways. In this paper, we introduce an automated approach that learns from a set of interleaving Web service design symptoms that characterize the existence of anti-pattern instances in a service-based system. We build a multi-label learning model to detect 8 common types of Web service anti-patterns. We use the ensemble classifier chain (ECC) model that transforms multi-label problems into several single-label problems which are solved using genetic programming (GP) to find the optimal detection rules for each anti-pattern type. To evaluate the performance of our approach, we conducted an empirical study on a benchmark of 815 Web services. The statistical tests of our results show that our approach can detect the eight Web service antipattern types with an average F-measure of 93% achieving a better performance compared to different state-of-the-art techniques. Furthermore, we found that the most influential factors that best characterize Web service anti-patterns include the number of declared operations, the number of port types, and the number of simple and complex types in service interfaces."
},
{
    "py/object": "data.DataClassPaper",
    "Title": "Detection of Web Service Anti-patterns Using Neural Networks with Multiple Layers",
    "year": 2020,
    "ML_Techniques": "ANN",
    "Category": "Quality assessment",
    "Sub_category": "Code smell detection",
    "Venue": "ICONIP",
    "Link": "https://link.springer.com/chapter/10.1007/978-3-030-63823-8_65",
    "bibtex": "inproceedings{793_Tummalapalli2020,\n    author = \"Tummalapalli, Sahithi and Murthy, NL and Krishna, Aneesh and others\",\n    title = \"Detection of web service anti-patterns using neural networks with multiple layers\",\n    booktitle = \"International Conference on Neural Information Processing\",\n    pages = \"571--579\",\n    year = \"2020\",\n    organization = \"Springer\"\n}\n\n",
    "abstract": "Anti-patterns in service-oriented architecture are solutions to common issues where the solution is ineffective and may end up in undesired consequences. It is a standard exercise that initially seems like the best solution; however, it finally ends up having bad results that outweigh any benefits. Research revealed that the presence of anti-patterns leads to the demeaning of the quality and design of the software systems, which makes the process of detecting anti-patterns in web services very crucial. In this work, we empirically investigate the effectiveness of three feature sampling techniques, five data sampling techniques, and six classification algorithms in the detection of web service anti-patterns. Experiment results revealed that the model developed by considering metrics selected by Principal Component Analysis (PCA) as the input obtained better performance compared to the model developed by other metrics. Experimental results also showed that the neural network model developed with two hidden layers has outperformed all the other models developed with varying number of hidden layers."
},
{
    "py/object": "data.DataClassPaper",
    "Title": "A Novel Approach for the Detection of Web Service Anti-Patterns Using Word Embedding Techniques",
    "year": 2021,
    "ML_Techniques": "MNB, BNB GNB, DT, B, RF , ET, AB, GB",
    "Category": "Quality assessment",
    "Sub_category": "Code smell detection",
    "Venue": "ICCSA",
    "Link": "https://link.springer.com/chapter/10.1007/978-3-030-87007-2_16",
    "bibtex": "inproceedings{795_Tummalapalli2021,\n    author = \"Tummalapalli, Sahithi and Kumar, Lov and Murthy Neti, Lalitha Bhanu and Kocher, Vipul and Padmanabhuni, Srinivas\",\n    title = \"A Novel Approach for the Detection of Web Service Anti-Patterns Using Word Embedding Techniques\",\n    booktitle = \"International Conference on Computational Science and Its Applications\",\n    pages = \"217--230\",\n    year = \"2021\",\n    organization = \"Springer\"\n}\n\n",
    "abstract": "An anti-pattern is defined as a standard but ineffective solution to solve a problem. Anti-patterns in software design make it hard for software maintenance and development by making source code very complicated for understanding. Various studies revealed that the presence of anti-patterns in web services leads to maintenance and evolution-related problems. Identification of anti-patterns at the design level helps in reducing efforts, resources, and costs. This makes the identification of anti-patterns an exciting issue for researchers. This work introduces a novel approach for detecting anti-patterns using text metrics extracted from the Web Service Description Language (WSDL) file. The framework used in this paper builds on the presumption that text metrics extracted at the web service level have been considered as a predictor for anti-patterns. This paper empirically investigates the effectiveness of three feature selection techniques and the original features, three data sampling techniques, the original data, four word embedding techniques, and nine classifier techniques in detecting web service anti-patterns. Data Sampling techniques are employed to counter the class imbalance problem suffered by the data set. The results confirm the predictive ability of text metrics obtained by different word embedding techniques in predicting anti-patterns."
},
{
    "py/object": "data.DataClassPaper",
    "Title": "An Empirical Analysis on the Prediction of Web Service Anti-patterns Using Source Code Metrics and Ensemble Techniques",
    "year": 2021,
    "ML_Techniques": "B, RF, ET, AB, GB",
    "Category": "Quality assessment",
    "Sub_category": "Code smell detection",
    "Venue": "ICCSA",
    "Link": "https://link.springer.com/chapter/10.1007/978-3-030-87007-2_19",
    "bibtex": "inproceedings{796_Tummalapalli2021,\n    author = \"Tummalapalli, Sahithi and Mittal, Juhi and Kumar, Lov and Murthy Neti, Lalitha Bhanu and Rath, Santanu Kumar\",\n    title = \"An Empirical Analysis on the Prediction of Web Service Anti-patterns Using Source Code Metrics and Ensemble Techniques\",\n    booktitle = \"International Conference on Computational Science and Its Applications\",\n    pages = \"263--276\",\n    year = \"2021\",\n    organization = \"Springer\"\n}\n\n",
    "abstract": "Today\u2019s software program enterprise uses web services to construct distributed software systems based on the Service Oriented Architecture (SOA) paradigm. The web service description is posted by a web service provider, which may be observed and invoked by a distributed application. Service-Based Systems (SBS) need to conform themselves through years to fit within the new user necessities. These may result in the deterioration of the quality and design of the software systems and might reason the materialization of insufficient solutions called Anti-patterns. Anti-pattern detection using object-oriented source code metrics may be used as part of the software program improvement life cycle to lessen the maintenance of the software system and enhance the quality of the software. The work is motivated by developing an automatic predictive model for predicting web services anti-patterns using static evaluations of the source code metrics. The center ideology of this work is to empirically investigate the effectiveness of different variants of data sampling technique, Synthetic Minority Over Sampling TEchnique (SMOTE), and the ensemble learning techniques in the prediction of web service anti-patterns."
},
{
    "py/object": "data.DataClassPaper",
    "Title": "Smells Like Teen Spirit: Improving Bug Prediction Performance Using the Intensity of Code Smells",
    "year": 2016,
    "ML_Techniques": "LOG",
    "Category": "Testing",
    "Sub_category": "Defect prediction",
    "Venue": "ICSME",
    "Link": "https://ieeexplore.ieee.org/abstract/document/7816471",
    "bibtex": "inproceedings{808_Palomba2016,\n    author = \"Palomba, Fabio and Zanoni, Marco and Fontana, Francesca Arcelli and De Lucia, Andrea and Oliveto, Rocco\",\n    title = \"Smells like teen spirit: Improving bug prediction performance using the intensity of code smells\",\n    booktitle = \"2016 IEEE International Conference on Software Maintenance and Evolution (ICSME)\",\n    pages = \"244--255\",\n    year = \"2016\",\n    organization = \"IEEE\"\n}\n\n",
    "abstract": "Code smells are symptoms of poor design and implementation choices. Previous studies empirically assessed the impact of smells on code quality and clearly indicate their negative impact on maintainability, including a higher bug-proneness of components affected by code smells. In this paper we capture previous findings on bug-proneness to build a specialized bug prediction model for smelly classes. Specifically, we evaluate the contribution of a measure of the severity of code smells (i.e., code smell intensity) by adding it to existing bug prediction models and comparing the results of the new model against the baseline model. Results indicate that the accuracy of a bug prediction model increases by adding the code smell intensity as predictor. We also evaluate the actual gain provided by the intensity index with respect to the other metrics in the model, including the ones used to compute the code smell intensity. We observe that the intensity index is much more important as compared to other metrics used for predicting the buggyness of smelly classes."
},
{
    "py/object": "data.DataClassPaper",
    "Title": "Toward a Smell-Aware Bug Prediction Model",
    "year": 2017,
    "ML_Techniques": "",
    "Category": "Testing",
    "Sub_category": "Defect prediction",
    "Venue": "TSE",
    "Link": "https://ieeexplore.ieee.org/abstract/document/8097044",
    "bibtex": "article{809_Palomba2017,\n    author = \"Palomba, Fabio and Zanoni, Marco and Fontana, Francesca Arcelli and De Lucia, Andrea and Oliveto, Rocco\",\n    title = \"Toward a smell-aware bug prediction model\",\n    journal = \"IEEE Transactions on Software Engineering\",\n    volume = \"45\",\n    number = \"2\",\n    pages = \"194--218\",\n    year = \"2017\",\n    publisher = \"IEEE\"\n}\n\n",
    "abstract": "Code smells are symptoms of poor design and implementation choices. Previous studies empirically assessed the impact of smells on code quality and clearly indicate their negative impact on maintainability, including a higher bug-proneness of components affected by code smells. In this paper, we capture previous findings on bug-proneness to build a specialized bug prediction model for smelly classes. Specifically, we evaluate the contribution of a measure of the severity of code smells (i.e., code smell intensity) by adding it to existing bug prediction models based on both product and process metrics, and comparing the results of the new model against the baseline models. Results indicate that the accuracy of a bug prediction model increases by adding the code smell intensity as predictor. We also compare the results achieved by the proposed model with the ones of an alternative technique which considers metrics about the history of code smells in files, finding that our model works generally better. However, we observed interesting complementarities between the set of buggy and smelly classes correctly classified by the two models. By evaluating the actual information gain provided by the intensity index with respect to the other metrics in the model, we found that the intensity index is a relevant feature for both product and process metrics-based models. At the same time, the metric counting the average number of code smells in previous versions of a class considered by the alternative model is also able to reduce the entropy of the model. On the basis of this result, we devise and evaluate a smell-aware combined bug prediction model that included product, process, and smell-related features. We demonstrate how such model classifies bug-prone code components with an F-Measure at least 13 percent higher than the existing state-of-the-art models."
},
{
    "py/object": "data.DataClassPaper",
    "Title": "Software Defect Prediction Using Bad Code Smells: A Systematic Literature Review",
    "year": 2019,
    "ML_Techniques": "",
    "Category": "Testing",
    "Sub_category": "Defect prediction",
    "Venue": "Data-Centric Business and Applications",
    "Link": "https://link.springer.com/chapter/10.1007/978-3-030-34706-2_5",
    "bibtex": "article{810_Piotrowski2020,\n    author = \"Piotrowski, Pawe{\\l} and Madeyski, Lech\",\n    title = \"Software defect prediction using bad code smells: A systematic literature review\",\n    journal = \"Data-Centric Business and Applications\",\n    pages = \"77--99\",\n    year = \"2020\",\n    publisher = \"Springer\"\n}\n\n",
    "abstract": "The challenge of effective refactoring in the software development cycle brought forward the need to develop automated defect prediction models. Among many existing indicators of bad code,\u00a0code smells\u00a0have attracted particular interest of both the research community and practitioners in recent years. In this paper, we describe the current state-of-the-art in the field of bug prediction with the use of code smells and attempt to identify areas requiring further research. To achieve this goal, we conducted a systematic literature review of 27 research papers published between 2006 and 2019. For each paper, we (i) analysed the reported relationship between\u00a0smelliness\u00a0and\u00a0bugginess, as well as (ii) evaluated the performance of code smell data used as a defect predictor in models developed using machine learning techniques. Our investigation confirms that code smells are both positively correlated with software defects and can positively influence the performance of fault detection models. However, not all types of smells and smell-related metrics are equally useful.\u00a0God Class,\u00a0God Method,\u00a0Message Chains\u00a0smells and\u00a0Smell intensity\u00a0metric stand out as particularly effective. Smells such as\u00a0Inappropriate Intimacy,\u00a0Variable Re-assign,\u00a0Clones,\u00a0Middle Man\u00a0or\u00a0Speculative Generality\u00a0require further research to confirm their contribution. Metrics describing the introduction and evolution of anti-patterns in code present a promising opportunity for experimentation."
},
{
    "py/object": "data.DataClassPaper",
    "Title": "A Novel Four-Way Approach Designed With Ensemble Feature Selection for Code Smell Detection",
    "year": 2021,
    "ML_Techniques": "B, RF",
    "Category": "Quality assessment",
    "Sub_category": "Code smell detection",
    "Venue": "IEEE Access",
    "Link": "https://ieeexplore.ieee.org/abstract/document/9316747",
    "bibtex": "article{814_Kaur2021,\n    author = \"Kaur, Inderpreet and Kaur, Arvinder\",\n    title = \"A novel four-way approach designed with ensemble feature selection for code smell detection\",\n    journal = \"IEEE Access\",\n    volume = \"9\",\n    pages = \"8695--8707\",\n    year = \"2021\",\n    publisher = \"IEEE\"\n}\n\n",
    "abstract": "Purpose: Code smells are residuals of technical debt induced by the developers. They hinder evolution, adaptability and maintenance of the software. Meanwhile, they are very beneficial in indicating the loopholes of problems and bugs in the software. Machine learning has been extensively used to predict Code Smells in research. The current study aims to optimise the prediction using Ensemble Learning and Feature Selection techniques on three open-source Java data sets. Design and Results: The work Compares four varied approaches to detect code smells using four performance measures Accuracy(P1), G-mean1 (P2), G-mean2 (P3), and F-measure (P4). The study found out that values of the performance measures did not degrade it instead of either remained same or increased with feature selection and Ensemble Learning. Random Forest turns out to be the best classifier while Correlation-based Feature selection(BFS) is best amongst Feature Selection techniques. Ensemble Learning aggregators, i.e. ET5C2 (BFS intersection Relief with classifier Random Forest), ET6C2 (BFS union Relief with classifier Random Forest), and ET5C1 (BFS intersection Relief with Bagging) and Majority Voting give best results from all the aggregation combinations studied. Conclusion: Though the results are good, but using Ensemble learning techniques needs a lot of validation for a variety of data sets before it can be standardised. The Ensemble Learning techniques also pose a challenge concerning diversity and reliability and hence needs exhaustive studies."
},
{
    "py/object": "data.DataClassPaper",
    "Title": "An Empirical Study on Predictability of Software Code Smell Using Deep Learning Models\n",
    "year": 2021,
    "ML_Techniques": "",
    "Category": "Quality assessment",
    "Sub_category": "Code smell detection",
    "Venue": "AINA",
    "Link": "https://link.springer.com/chapter/10.1007/978-3-030-75075-6_10",
    "bibtex": "",
    "abstract": "Code Smell, similar to a bad smell, is a surface indication of something tainted but in terms of software writing practices. This metric is an indication of a deeper problem lies within the code and is associated with an issue which is prominent to experienced software developers with acceptable coding practices. Recent studies have often observed that codes having code smells are often prone to a higher probability of change in the software development cycle. In this paper, we developed code smell prediction models with the help of features extracted from source code to predict eight types of code smell. Our work also presents the application of data sampling techniques to handle class imbalance problem and feature selection techniques to find relevant feature sets. Previous studies had made use of techniques such as Naive Bayes and Random forest but had not explored deep learning methods to predict code smell. A total of 576 distinct Deep Learning models were trained using the features and datasets mentioned above. The study concluded that the deep learning models which used data from Synthetic Minority Oversampling Technique gave better results in terms of accuracy, AUC with the accuracy of some models improving from 88.47 to 96.84."
},
{
    "py/object": "data.DataClassPaper",
    "Title": "A Novel Approach for Code Smell Detection: An Empirical Study",
    "year": 2021,
    "ML_Techniques": "NB, KNN, MLP, DT, LOG, RF",
    "Category": "Quality assessment",
    "Sub_category": "Code smell detection",
    "Venue": "IEEE Access",
    "Link": "https://ieeexplore.ieee.org/abstract/document/9641807",
    "bibtex": "article{816_Dewangan2021,\n    author = \"Dewangan, Seema and Rao, Rajwant Singh and Mishra, Alok and Gupta, Manjari\",\n    title = \"A Novel Approach for Code Smell Detection: An Empirical Study\",\n    journal = \"IEEE Access\",\n    volume = \"9\",\n    pages = \"162869--162883\",\n    year = \"2021\",\n    publisher = \"IEEE\"\n}\n\n",
    "abstract": "Code smells detection helps in improving understandability and maintainability of software while reducing the chances of system failure. In this study, six machine learning algorithms have been applied to predict code smells. For this purpose, four code smell datasets (God-class, Data-class, Feature-envy, and Long-method) are considered which are generated from 74 open-source systems. To evaluate the performance of machine learning algorithms on these code smell datasets, 10-fold cross validation technique is applied that predicts the model by partitioning the original dataset into a training set to train the model and test set to evaluate it. Two feature selection techniques are applied to enhance our prediction accuracy. The Chi-squared and Wrapper-based feature selection techniques are used to improve the accuracy of total six machine learning methods by choosing the top metrics in each dataset. Results obtained by applying these two feature selection techniques are compared. To improve the accuracy of these algorithms, grid search-based parameter optimization technique is applied. In this study, 100% accuracy was obtained for the Long-method dataset by using the Logistic Regression algorithm with all features while the worst performance 95.20% was obtained by Naive Bayes algorithm for the Long-method dataset using the chi-square feature selection technique."
},
{
    "py/object": "data.DataClassPaper",
    "Title": "Generating Code-Smell Prediction Rules Using Decision Tree Algorithm and Software Metrics",
    "year": 2019,
    "ML_Techniques": "DT",
    "Category": "Quality assessment",
    "Sub_category": "Code smell detection",
    "Venue": "IJCSE",
    "Link": "https://www.researchgate.net/profile/Mohammad-Mhawish-2/publication/335807821_Generating_Code-Smell_Prediction_Rules_Using_Decision_Tree_Algorithm_and_Software_Metrics/links/5d8d78daa6fdcc25549e7c9b/Generating-Code-Smell-Prediction-Rules-Using-Decision-Tree-Algorithm-and-Software-Metrics.pdf",
    "bibtex": "article{818_Mhawish2019,\n    author = \"Mhawish, Mohammad Y and Gupta, Manjari\",\n    title = \"Generating code-smell prediction rules using decision tree algorithm and software metrics\",\n    journal = \"International Journal of Computer Sciences and Engineering\",\n    volume = \"7\",\n    number = \"5\",\n    pages = \"41--48\",\n    year = \"2019\"\n}\n\n",
    "abstract": "Code smells identified by Fowler [1] is as symptoms of possible code or design problems. Code smells have adverse affecting the quality of the software system by making software challenging to understand and consequently increasing the efforts to maintenance and evolution. The detection of code smells is the way to improve software quality by recovering code smells and perform the refactoring processes. In this paper, we propose a code- smells detection approach based on a decision tree algorithm and software metrics. The datasets we used to train the models are built by reforming the datasets used by Arcelli Fontana et al. work [2]. We use two feature selection methods based on a genetic algorithm to select the most essential features in each dataset. Moreover, we use the grid search algorithm to tuning the decision tree hyperparameters. We extract a set of detection conditions using decision tree models, that are considered as prediction rules to detect each code smell in our binary-class datasets."
},
{
    "py/object": "data.DataClassPaper",
    "Title": "Code smell detection using feature selection and stacking ensemble: An empirical investigation",
    "year": 2021,
    "ML_Techniques": "DT, SVM, BNB, GNB, MNB, LR, MLP, SGD, GP, KNN, LDA",
    "Category": "Quality assessment",
    "Sub_category": "Code smell detection",
    "Venue": "IST",
    "Link": "https://www.sciencedirect.com/science/article/abs/pii/S0950584921001129",
    "bibtex": "article{820_Alazba2021,\n    author = \"Alazba, Amal and Aljamaan, Hamoud\",\n    title = \"Code smell detection using feature selection and stacking ensemble: An empirical investigation\",\n    journal = \"Information and Software Technology\",\n    volume = \"138\",\n    pages = \"106648\",\n    year = \"2021\",\n    publisher = \"Elsevier\"\n}\n\n",
    "abstract": "Context:\nCode smell detection is the process of identifying code pieces that are poorly designed and implemented. Recently more research has been directed towards machine learning-based approaches for code smells detection. Many classifiers have been explored in the literature, yet, finding an effective model to detect different code smells types has not yet been achieved.\n\nObjective:\nThe main objective of this paper is to empirically investigate the capabilities of stacking heterogeneous ensemble model in code smell detection.\n\nMethods:\nGain feature selection technique was applied to select relevant features in code smell detection. Detection performance of 14 individual classifiers was investigated in the context of two class-level and four method-level code smells. Then, three stacking ensembles were built using all individual classifiers as base classifiers, and three different meta-classifiers (LR, SVM and DT).\n\nResults:\nGP, MLP, DT and SVM(Lin) classifiers were among the best performing classifiers in detecting most of the code smells. On the other hand, SVM(Sig), NB(B), NB(M), and SGD were among the least accurate classifiers for most smell types. The stacking ensemble with LR and SVM meta-classifiers achieved a consistent high detection performance in class-level and method-level code smells compared to all individual models.\n\nConclusion:\nThis paper concludes that the detection performance of the majority of individual classifiers varied from one code smell type to another. However, the detection performance of the stacking ensemble with LR and SVM meta-classifiers was consistently superior over all individual classifiers in detecting different code smell types."
},
{
    "py/object": "data.DataClassPaper",
    "Title": "Empirical Analysis on Effectiveness of\u00a0NLP Methods for Predicting Code Smell",
    "year": 2021,
    "ML_Techniques": "ELM",
    "Category": "Quality assessment",
    "Sub_category": "Code smell detection",
    "Venue": "ICCSA",
    "Link": "https://link.springer.com/chapter/10.1007/978-3-030-87013-3_4",
    "bibtex": "inproceedings{823_Gupta2021,\n    author = \"Gupta, Himanshu and Gulanikar, Abhiram Anand and Kumar, Lov and Neti, Lalita Bhanu Murthy\",\n    title = \"Empirical Analysis on Effectiveness of NLP Methods for Predicting Code Smell\",\n    booktitle = \"International Conference on Computational Science and Its Applications\",\n    pages = \"43--53\",\n    year = \"2021\",\n    organization = \"Springer\"\n}\n\n",
    "abstract": "A code smell is a surface indicator of an inherent problem in the system, most often due to deviation from standard coding practices on the developer\u2019s part during the development phase. Studies observe that code smells made the code more susceptible to call for modifications and corrections than code that did not contain code smells. Restructuring the code at the early stage of development saves the exponentially increasing amount of effort it would require to address the issues stemming from the presence of these code smells. Instead of using traditional features to detect code smells, we use user comments (given on the packages\u2019 repositories) to manually construct features to predict code smells. We use three Extreme learning machine kernels over 629 packages to identify eight code smells by leveraging feature engineering aspects and using sampling techniques. Our findings indicate that the radial basis functional kernel performs best out of the three kernel methods with a mean accuracy of 98.52."
},
{
    "py/object": "data.DataClassPaper",
    "Title": "Improving performance with hybrid feature selection and ensemble machine learning techniques for code smell detection",
    "year": 2021,
    "ML_Techniques": "AB, DT, GB, GNB, KNN, LDA, LOG, RF, SVM",
    "Category": "Quality assessment",
    "Sub_category": "Code smell detection",
    "Venue": "SCP",
    "Link": "https://www.sciencedirect.com/science/article/abs/pii/S0167642321001064",
    "bibtex": "article{824_Jain2021,\n    author = \"Jain, Shivani and Saha, Anju\",\n    title = \"Improving performance with hybrid feature selection and ensemble machine learning techniques for code smell detection\",\n    journal = \"Science of Computer Programming\",\n    volume = \"212\",\n    pages = \"102713\",\n    year = \"2021\",\n    publisher = \"Elsevier\"\n}\n\n",
    "abstract": "Maintaining large and complex software is a significant task in IT industry. One reason for that is the development of code smells which are design flaws that lead to future bugs and errors. Code smells can be treated with regular refactoring, and their detection is the first step in the software maintenance process. Detecting code smells with\u00a0machine learning algorithms\u00a0eliminate the need of extensive knowledge required regarding properties of code smell and threshold values. Ensemble machine learning algorithms use a combination of several same or different classifiers to further aid the performance and reduces the variance. In our study, three hybrid feature selection techniques with ensemble machine learning algorithms are employed to improve the performance in detecting code smells. Seven machine learning classifiers with different kernel variations, along with three boosting designs, two stacking methods, and bagging were implemented. For feature selection, combination of filter-wrapper, filter-embedded, and wrapper-embedded methods have been executed. Performance measures for detecting four code smells are evaluated and are compared with the performance when feature selection is not employed. It is found out that performance measure after application of hybrid feature selection increased, accuracy by 21.43%, AUC value by 53.24%, and f-measure by 76.06%. Univariate ROC with Lasso is the best hybrid feature selection technique with 90.48% accuracy and 94.5% ROC AUC value. Random Forest and Logistic regression are the best performing machine learning classifiers. Data class is most detectable code smell. Stacking always gave better results when compared with individual classifiers."
},
{
    "py/object": "data.DataClassPaper",
    "Title": "Code Smells Detection Using Artificial Intelligence Techniques: A\u00a0Business-Driven Systematic Review",
    "year": 2021,
    "ML_Techniques": "",
    "Category": "Quality assessment",
    "Sub_category": "Code smell detection",
    "Venue": "Developments in Information & Knowledge Management for Business Applications",
    "Link": "https://link.springer.com/chapter/10.1007/978-3-030-77916-0_12",
    "bibtex": "article{828_Lewowski2022,\n    author = \"Lewowski, Tomasz and Madeyski, Lech\",\n    title = \"Code smells detection using artificial intelligence techniques: A business-driven systematic review\",\n    journal = \"Developments in Information \\\\& Knowledge Management for Business Applications\",\n    pages = \"285--319\",\n    year = \"2022\",\n    publisher = \"Springer\"\n}\n\n",
    "abstract": "Context\u00a0Code smells in the software systems are indications that usually correspond to deeper problems that can negatively influence software quality characteristics. This review is a part of a R&D project aiming to improve the existing\u00a0codebeat\u00a0platform that help developers to avoid code smells and deliver quality code.\u00a0Objective\u00a0This study aims to identify and investigate the current state of the art with respect to: (1) predictors used in prediction models to detect code smells, (2) machine learning/artificial intelligence (ML/AI) methods used in prediction models to detect code smells, (3) code smells analyzed in scientific literature. Our secondary objectives were to identify (4) data sets and projects used in research papers to predict code smells, (5) performance measures used to assess prediction models and (6) improvement ideas with regard to code smell detection using ML/AI.\u00a0Method\u00a0We conducted a systematic review using a database search in Scopus and evaluated it using the quasi-gold standard procedure to identify relevant studies. In the data sheet used to obtain data from publications we factor research questions into finer-grained ones, which are then answered on a per-publication basis. Those are then merged over a set of publications using an automated script to obtain answers to the posed research questions.\u00a0Results\u00a0We have identified 45 primary studies relevant to the primary objectives of this research. The results show the prediction capability of the ML/AI techniques for predicting code smells.\u00a0Conclusion\u00a0Only a few smells\u2014Blob, Feature Envy, Long Method and Data Class\u2014have received the vast majority of interest in research community. The usage of deep learning techniques is increasing. Most researchers still use source code metrics as predictors. Precision, recall and F-measure are the go-to performance metrics. There seems to be a need for modern reference data/projects sets that reflect modern constructs of programming languages. We identified various promising paths of research that have the potential to advance the state of the art in the area of code smells prediction."
},
{
    "py/object": "data.DataClassPaper",
    "Title": "Cross-project smell-based defect prediction",
    "year": 2021,
    "ML_Techniques": "RF, SVM, MLP, DT, GNB, ELM",
    "Category": "Testing",
    "Sub_category": "Defect prediction",
    "Venue": "Soft Computing",
    "Link": "https://link.springer.com/article/10.1007/s00500-021-06254-7",
    "bibtex": "article{829_Sotto-Mayor2021,\n    author = \"Sotto-Mayor, Bruno and Kalech, Meir\",\n    title = \"Cross-project smell-based defect prediction\",\n    journal = \"Soft Computing\",\n    volume = \"25\",\n    number = \"22\",\n    pages = \"14171--14181\",\n    year = \"2021\",\n    publisher = \"Springer\"\n}\n\n",
    "abstract": "Defect prediction is a technique introduced to optimize the testing phase of the software development pipeline by predicting which components in the software may contain defects. Its methodology trains a classifier with data regarding a set of features measured on each component from the target software project to predict whether the component may be defective or not. However, suppose the defective information is not available in the training set. In that case, we need to rely on an alternate approach that uses the training set of external projects to train the classifier. This approached is called cross-project defect prediction. Bad code smells are a category of features that have been previously explored in defect prediction and have been shown to be a good predictor of defects. Code smells are patterns of poor development in the code and indicate flaws in its design and implementation. Although they have been previously studied in the context of defect prediction, they have not been studied as features for cross-project defect prediction. In our experiment, we train defect prediction models for 100 projects to evaluate the predictive performance of the bad code smells. We implemented four cross-project approaches known in the literature and compared the performance of 37 smells with 56 code metrics, commonly used for defect prediction. The results show that the cross-project defect prediction models trained with code smells significantly improved\u00a06.50%6.50%\u00a0on the ROC AUC compared against the code metrics."
},
{
    "py/object": "data.DataClassPaper",
    "Title": "Software Analytics in Practice: A Defect Prediction Model Using Code Smells",
    "year": 2016,
    "ML_Techniques": "NB, LOG",
    "Category": "Testing",
    "Sub_category": "Defect prediction",
    "Venue": "IDEAS",
    "Link": "https://dl.acm.org/doi/abs/10.1145/2938503.2938553",
    "bibtex": "inproceedings{833_Soltanifar2016,\n    author = \"Soltanifar, Behjat and Akbarinasaji, Shirin and Caglayan, Bora and Bener, Ayse Basar and Filiz, Asli and Kramer, Bryan M\",\n    title = \"Software analytics in practice: a defect prediction model using code smells\",\n    booktitle = \"Proceedings of the 20th International Database Engineering \\\\& Applications Symposium\",\n    pages = \"148--155\",\n    year = \"2016\"\n}\n\n",
    "abstract": "In software engineering, maintainability is related to investigating the defects and their causes, correcting the defects and modifying the system to meet customer requirements. Maintenance is a time consuming activity within the software life cycle. Therefore, there is a need for efficiently organizing the software resources in terms of time, cost and personnel for maintenance activity. One way of efficiently managing maintenance resources is to predict defects that may occur after the deployment. Many researchers so far have built defect prediction models using different sets of metrics such as churn and static code metrics. However, hidden causes of defects such as code smells have not been investigated thoroughly. In this study we propose using data science and analytics techniques on software data to build defect prediction models. In order to build the prediction model we used code smells metrics, churn metrics and combination of churn and code smells metrics. The results of our experiments on two different software companies show that code smells is a good indicator of defect proneness of the software product. Therefore, we recommend that code smells metrics should be used to train a defect prediction model to guide the software maintenance team."
},
{
    "py/object": "data.DataClassPaper",
    "Title": "MARS: Detecting brain class/method code smell based on metric\u2013attention mechanism and residual network",
    "year": 2021,
    "ML_Techniques": "ResNet",
    "Category": "Quality assessment",
    "Sub_category": "Code smell detection",
    "Venue": "Journal of Software: Evolution and Process",
    "Link": "https://onlinelibrary.wiley.com/doi/abs/10.1002/smr.2403",
    "bibtex": "article{835_Zhang2021,\n    author = \"Zhang, Yang and Dong, Chunhao\",\n    title = \"MARS: Detecting brain class/method code smell based on metric--attention mechanism and residual network\",\n    journal = \"Journal of Software: Evolution and Process\",\n    pages = \"e2403\",\n    year = \"2021\",\n    publisher = \"Wiley Online Library\"\n}\n\n",
    "abstract": "Code smell is the structural design defect that makes programs difficult to understand, maintain, and evolve. Existing works of code smell detection mainly focus on prevalent code smells, such as feature envy, god class, and long method. Few works have been done on detecting brain class/method. Furthermore, existing deep-learning-based approaches leverage the CNN model to improve accuracy by barely increasing the number of layers, which may cause a problem of gradient degradation. To this end, this paper proposes a novel approach called\u00a0MARS\u00a0to detect brain class/method. MARS improves the gradient degradation by employing an improved residual network. It increases the weight value of those important code metrics to label smelly samples by introducing a metric\u2013attention mechanism. To support the training of MARS, a dataset called\u00a0BrainCode\u00a0is generated by extracting more than 270,000 samples from 20 real-world applications. MARS is evaluated on\u00a0BrainCode\u00a0and compared to other machine-learning-based and deep-learning-based approaches. The experimental results demonstrate that the average accuracy of MARS is 2.01 % higher than that of the existing approaches, which improves state-of-the-art."
},
{
    "py/object": "data.DataClassPaper",
    "Title": "Predicting Design Impactful Changes in Modern Code Review: A Large-Scale Empirical Study",
    "year": 2021,
    "ML_Techniques": "",
    "Category": "Program comprehension",
    "Sub_category": "Change analysis",
    "Venue": "MSR",
    "Link": "https://ieeexplore.ieee.org/abstract/document/9463137",
    "bibtex": "inproceedings{836_Uch\\^oa2021,\n    author = \"Uch{\\^o}a, Anderson and Barbosa, Caio and Coutinho, Daniel and Oizumi, Willian and Assun{\\c{c}}ao, Wesley KG and Vergilio, Silvia Regina and Pereira, Juliana Alves and Oliveira, Anderson and Garcia, Alessandro\",\n    title = \"Predicting design impactful changes in modern code review: A large-scale empirical study\",\n    booktitle = \"2021 IEEE/ACM 18th International Conference on Mining Software Repositories (MSR)\",\n    pages = \"471--482\",\n    year = \"2021\",\n    organization = \"IEEE\"\n}\n\n",
    "abstract": "Companies have adopted modern code review as a key technique for continuously monitoring and improving the quality of software changes. One of the main motivations for this is the early detection of design impactful changes, to prevent that design-degrading ones prevail after each code review. Even though design degradation symptoms often lead to changes' rejections, practices of modern code review alone are actually not sufficient to avoid or mitigate design decay. Software design degrades whenever one or more symptoms of poor structural decisions, usually represented by smells, end up being introduced by a change. Design degradation may be related to both technical and social aspects in collaborative code reviews. Unfortunately, there is no study that investigates if code review stakeholders, e.g, reviewers, could benefit from approaches to distinguish and predict design impactful changes with technical and/or social aspects. By analyzing 57,498 reviewed code changes from seven open-source systems, we report an investigation on prediction of design impactful changes in modern code review. We evaluated the use of six ML algorithms to predict design impactful changes. We also extracted and assessed 41 different features based on both social and technical aspects. Our results show that Random Forest and Gradient Boosting are the best algorithms. We also observed that the use of technical features results in more precise predictions. However, the use of social features alone, which are available even before the code review starts (e.g., for team managers or change assigners), also leads to highly-accurate prediction. Therefore social and/or technical prediction models can be used to support further design inspection of suspicious changes early in a code review process. Finally, we provide an enriched dataset that allows researchers to investigate the context behind design impactful changes during the code review process."
},
{
    "py/object": "data.DataClassPaper",
    "Title": "Prioritizing Software Components Risk: Towards a Machine Learning-based Approach",
    "year": 2020,
    "ML_Techniques": "RF, DT, KS, NB, JR",
    "Category": "Quality assessment",
    "Sub_category": "",
    "Venue": "ICEMIS",
    "Link": "https://dl.acm.org/doi/abs/10.1145/3410352.3410730",
    "bibtex": "inproceedings{837_BenIdris2020,\n    author = \"BenIdris, Mrwan and Ammar, Hany and Dzielski, Dale and Benamer, Wisam H\",\n    title = \"Prioritizing Software components risk: towards a machine learning-based approach\",\n    booktitle = \"Proceedings of the 6th International Conference on Engineering \\\\& MIS 2020\",\n    pages = \"1--11\",\n    year = \"2020\"\n}\n\n",
    "abstract": "Technical Debt (TD) can be detected using different methods. TD is a metaphor that refers to short-term solutions in software development, which may affect the cost of the software development life-cycle. Several tools have been developed to detect, estimate, or manage TD. TD can be indicated through smells, code comments, and software metrics. Machine learning Techniques (MLTs) are used in many software engineering topics such as fault-proneness, bug severity, and code smell. In this paper we use four internal structure metrics to identify and classify Architecture Technical Debt (ATD) risk by using MLTs. We show that MLTs can identify and classify the risk of ATD on software components to help the decision-makers to prioritizing the refactoring decisions based on the level of the risk."
},
{
    "py/object": "data.DataClassPaper",
    "Title": "Deep Representation Learning for Code Smells Detection using Variational Auto-Encoder",
    "year": 2019,
    "ML_Techniques": "LOG",
    "Category": "Quality assessment",
    "Sub_category": "Code smell detection",
    "Venue": "IJCNN",
    "Link": "https://ieeexplore.ieee.org/abstract/document/8851854",
    "bibtex": "inproceedings{840_Hadj-Kacem2019,\n    author = \"Hadj-Kacem, Mouna and Bouassida, Nadia\",\n    title = \"Deep representation learning for code smells detection using variational auto-encoder\",\n    booktitle = \"2019 International Joint Conference on Neural Networks (IJCNN)\",\n    pages = \"1--8\",\n    year = \"2019\",\n    organization = \"IEEE\"\n}\n\n",
    "abstract": "Detecting code smells is an important research problem in the software maintenance. It assists the subsequent steps of the refactoring process so as to improve the quality of the software system. However, most of existing approaches have been limited to the use of structural information. There have been few researches to detect code smells using semantic information although its proven effectiveness in many software engineering problems. In addition, they do not capture entirely the semantic embedded in the source code. This paper attempts to fill this gap by proposing a semantic-based approach that detects bad smells which are scattered at different levels of granularity in the source code. To this end, we use an Abstract Syntax Tree with a Variational Auto-Encoder in the detection of three code smells. The code smells are Blob, Feature Envy and Long Method. We have performed our experimental evaluation on nine open-source projects and the results have achieved a considerable overall accuracy. To further evaluate the performance of our approach, we compare our results with a state-of-the-art method on the same publicly available dataset."
},
{
    "py/object": "data.DataClassPaper",
    "Title": "Tracing Bad Code Smells Behavior Using Machine Learning with Software Metrics",
    "year": 2021,
    "ML_Techniques": "NB, JR, DT, RF",
    "Category": "Quality assessment",
    "Sub_category": "Code smell detection",
    "Venue": "Smart and Sustainable Intelligent Systems",
    "Link": "https://onlinelibrary.wiley.com/doi/abs/10.1002/9781119752134.ch18",
    "bibtex": "article{847_Gupta2021,\n    author = \"Gupta, Aakanshi and Suri, Bharti and Lamba, Lakshay\",\n    title = \"Tracing Bad Code Smells Behavior Using Machine Learning with Software Metrics\",\n    journal = \"Smart and Sustainable Intelligent Systems\",\n    pages = \"245--257\",\n    year = \"2021\",\n    publisher = \"Wiley Online Library\"\n}\n\n",
    "abstract": "The inappropriate symptoms in the code design pattern which are developed by the developers at the software development phase are termed as bad code smells. Bad code smells concur to deep rooted and serious issues in the software during maintenance phase. Using a various combination of object-oriented metrics; bad smell detection tools and techniques provide different results in many ways. In this study, four different machine learning algorithms namely J48, JRip, Random Forest and Naive Bayes, have been considered to detect three types of bad smells God Class, Long Method and Feature Envy. The prime attribute to extract the bad smells features is software metrics. These metrics names are: Lines of Code, Depth of Inheritance, Coupling between objects and many others that have been put to identify the quality of code at different levels. The results demonstrated that the machine learning algorithms achieved high accuracy with the validation method of 10-fold cross-validation. The bad smell detection through machine learning can come up with efficiency up to 90% and more in a few test cases."
},
{
    "py/object": "data.DataClassPaper",
    "Title": "Software Fault Prediction and Classification using Cost based Random Forest in Spiral Life Cycle Model",
    "year": 2018,
    "ML_Techniques": "RF",
    "Category": "Testing",
    "Sub_category": "Defect prediction",
    "Venue": "system",
    "Link": "http://www.inass.org/2018/2018043002.pdf",
    "bibtex": "article{866_Premalatha2017,\n    author = \"Premalatha, Hosahalli Mahalingappa and Srikrishna, Chimanahalli Venkateshavittalachar\",\n    title = \"Software Fault Prediction and Classification using Cost based Random Forest in Spiral Life Cycle Model\",\n    journal = \"system\",\n    volume = \"11\",\n    year = \"2017\"\n}\n\n",
    "abstract": "In the domain of software engineering many new techniques are deployed for identifying the fault in software modules. This part of software design plays a fundamental role cause of its assurance towards higher reliability and stability. Many existing techniques like Bayesian approach have been employed to minimize the software faults but they can\u2019t able to predict efficiently within limited resources. In this paper, a new classification and prediction methodology is put forth to progress the accuracy of defect forecast based on Cost Random Forest algorithm (CRF) which reduces the effects of faults in irrelevant software modules. The proposed algorithm predicts the quantity of faults present in the modules of software in less time and classify based on measures of similarity obtained from Robust Similarity clustering technique. The overall results inferred from this methodology proven that this CRF can be capable to rank the module\u2019s faults in order to enhance the software development quality."
},
{
    "py/object": "data.DataClassPaper",
    "Title": "Deep Learning Approach for Software Maintainability Metrics Prediction",
    "year": 2019,
    "ML_Techniques": "LSTM",
    "Category": "Quality assessment",
    "Sub_category": "",
    "Venue": "IEEE Access",
    "Link": "https://ieeexplore.ieee.org/abstract/document/8698760",
    "bibtex": "article{875_Jha2019,\n    author = \"Jha, Sudan and Kumar, Raghvendra and Abdel-Basset, Mohamed and Priyadarshini, Ishaani and Sharma, Rohit and Long, Hoang Viet and others\",\n    title = \"Deep learning approach for software maintainability metrics prediction\",\n    journal = \"Ieee Access\",\n    volume = \"7\",\n    pages = \"61840--61855\",\n    year = \"2019\",\n    publisher = \"IEEE\"\n}\n\n",
    "abstract": "Software maintainability predicts changes or failures that may occur in software after it has been deployed. Since it deals with the degree to which an application may be understood, repaired, or enhanced, it also takes into account the overall cost of the project. In the past, several measures have been taken into account for predicting metrics that influence software maintainability. However, deep learning is yet to be explored for the same. In this paper, we perform deep learning for software maintainability metrics' prediction on a large number of datasets. Unlike the previous research works, we have relied on large datasets from 299 software and subsequently applied various metrics and functions to the same; 29 object-oriented metrics have been considered along with their impact on software maintainability of open source software. Several metrics have been analyzed and descriptive statistics of these metrics have been pointed out. The proposed long short term memory has been evaluated using measures, such as mean absolute error, root mean square error and accuracy. Five machine learning algorithms, namely, ridge regression with variable selection, decision tree, quantile regression forest, support vector machine, and principal component analysis have been applied to the original datasets, as well as, to the refined datasets. It was found that this paper provides results in the form of metrics that may be used in the prediction of software maintenance and the proposed deep learning model outperforms all of the other methods that were considered. Furthermore, the results of experiment affirm the efficiency of the proposed deep learning model for software maintainability prediction."
},
{
    "py/object": "data.DataClassPaper",
    "Title": "Applying CodeBERT for Automated Program Repair of Java Simple Bugs",
    "year": 2021,
    "ML_Techniques": "CodeBERT",
    "Category": "Program synthesis",
    "Sub_category": "Program repair",
    "Venue": "MSR",
    "Link": "https://ieeexplore.ieee.org/abstract/document/9463106",
    "bibtex": "inproceedings{888_Mashhadi2021,\n    author = \"Mashhadi, Ehsan and Hemmati, Hadi\",\n    title = \"Applying codebert for automated program repair of java simple bugs\",\n    booktitle = \"2021 IEEE/ACM 18th International Conference on Mining Software Repositories (MSR)\",\n    pages = \"505--509\",\n    year = \"2021\",\n    organization = \"IEEE\"\n}\n\n",
    "abstract": "Software debugging, and program repair are among the most time-consuming and labor-intensive tasks in software engineering that would benefit a lot from automation. In this paper, we propose a novel automated program repair approach based on CodeBERT, which is a transformer-based neural architecture pre-trained on large corpus of source code. We fine-tune our model on the ManySStuBs4J small and large datasets to automatically generate the fix codes. The results show that our technique accurately predicts the fixed codes implemented by the developers in 19-72% of the cases, depending on the type of datasets, in less than a second per bug. We also observe that our method can generate varied-length fixes (short and long) and can fix different types of bugs, even if only a few instances of those types of bugs exists in the training dataset."
},
{
    "py/object": "data.DataClassPaper",
    "Title": "Sorting and Transforming Program Repair Ingredients via Deep Learning Code Similarities",
    "year": 2019,
    "ML_Techniques": "",
    "Category": "Program synthesis",
    "Sub_category": "Program Repair",
    "Venue": "SANER",
    "Link": "https://ieeexplore.ieee.org/abstract/document/8668043",
    "bibtex": "inproceedings{889_White2019,\n    author = \"White, Martin and Tufano, Michele and Martinez, Matias and Monperrus, Martin and Poshyvanyk, Denys\",\n    title = \"Sorting and transforming program repair ingredients via deep learning code similarities\",\n    booktitle = \"2019 IEEE 26th International Conference on Software Analysis, Evolution and Reengineering (SANER)\",\n    pages = \"479--490\",\n    year = \"2019\",\n    organization = \"IEEE\"\n}\n\n",
    "abstract": "In the field of automated program repair, the redundancy assumption claims large programs contain the seeds of their own repair. However, most redundancy-based program repair techniques do not reason about the repair ingredients- the code that is reused to craft a patch. We aim to reason about the repair ingredients by using code similarities to prioritize and transform statements in a codebase for patch generation. Our approach, DeepRepair, relies on deep learning to reason about code similarities. Code fragments at well-defined levels of granularity in a codebase can be sorted according to their similarity to suspicious elements (i.e., code elements that contain suspicious statements) and statements can be transformed by mapping out-of-scope identifiers to similar identifiers in scope. We examined these new search strategies for patch generation with respect to effectiveness from the viewpoint of a software maintainer. Our comparative experiments were executed on six open-source Java projects including 374 buggy program revisions and consisted of 19,949 trials spanning 2,616 days of computation time. Deep-Repair's search strategy using code similarities generally found compilable ingredients faster than the baseline, jGenProg, but this improvement neither yielded test-adequate patches in fewer attempts (on average) nor found significantly more patches (on average) than the baseline. Although the patch counts were not statistically different, there were notable differences between the nature of DeepRepair patches and jGenProg patches. The results show that our learning-based approach finds patches that cannot be found by existing redundancy-based repair techniques."
},
{
    "py/object": "data.DataClassPaper",
    "Title": "CURE: Code-Aware Neural Machine Translation for Automatic Program Repair",
    "year": 2021,
    "ML_Techniques": "",
    "Category": "Program synthesis",
    "Sub_category": "Program repair",
    "Venue": "ICSE",
    "Link": "https://ieeexplore.ieee.org/abstract/document/9401997",
    "bibtex": "inproceedings{890_Jiang2021,\n    author = \"Jiang, Nan and Lutellier, Thibaud and Tan, Lin\",\n    title = \"CURE: Code-aware neural machine translation for automatic program repair\",\n    booktitle = \"2021 IEEE/ACM 43rd International Conference on Software Engineering (ICSE)\",\n    pages = \"1161--1173\",\n    year = \"2021\",\n    organization = \"IEEE\"\n}\n\n",
    "abstract": "Automatic program repair (APR) is crucial to improve software reliability. Recently, neural machine translation (NMT) techniques have been used to automatically fix software bugs. While promising, these approaches have two major limitations. Their search space often does not contain the correct fix, and their search strategy ignores software knowledge such as strict code syntax. Due to these limitations, existing NMT-based techniques underperform the best template-based approaches. We propose CURE, a new NMT-based APR technique with three major novelties. First, CURE pre-trains a programming language (PL) model on a large software codebase to learn developer-like source code before the APR task. Second, CURE designs a new code-aware search strategy that finds more correct fixes by focusing on searching for compilable patches and patches that are close in length to the buggy code. Finally, CURE uses a subword tokenization technique to generate a smaller search space that contains more correct fixes. Our evaluation on two widely-used benchmarks shows that CURE correctly fixes 57 Defects4J bugs and 26 QuixBugs bugs, outperforming all existing APR techniques on both benchmarks."
},
{
    "py/object": "data.DataClassPaper",
    "Title": "E-APR: Mapping the effectiveness of automated program repair techniques",
    "year": 2021,
    "ML_Techniques": "RF, SVM, DT, MLP",
    "Category": "Program synthesis",
    "Sub_category": "Program repair",
    "Venue": "ESE",
    "Link": "https://link.springer.com/article/10.1007/s10664-021-09989-x",
    "bibtex": "article{893_Aleti2021,\n    author = \"Aleti, Aldeida and Martinez, Matias\",\n    title = \"E-APR: mapping the effectiveness of automated program repair techniques\",\n    journal = \"Empirical Software Engineering\",\n    volume = \"26\",\n    number = \"5\",\n    pages = \"1--30\",\n    year = \"2021\",\n    publisher = \"Springer\"\n}\n\n",
    "abstract": "Automated Program Repair (APR) is a fast growing area with numerous new techniques being developed to tackle one of the most challenging software engineering problems. APR techniques have shown promising results, giving us hope that one day it will be possible for software to repair itself. In this paper, we focus on the problem of objective performance evaluation of APR techniques. We introduce a new approach, Explaining Automated Program Repair (E-APR), which identifies features of buggy programs that explain why a particular instance is difficult for an APR technique. E-APR is used to examine the diversity and quality of the buggy programs used by most researchers, and analyse the strengths and weaknesses of existing APR techniques. E-APR visualises an instance space of buggy programs, with each buggy program represented as a point in the space. The instance space is constructed to reveal areas of hard and easy buggy programs, and enables the strengths and weaknesses of APR techniques to be identified."
},
{
    "py/object": "data.DataClassPaper",
    "Title": "Can automated program repair refine fault localization? a unified debugging approach",
    "year": 2019,
    "ML_Techniques": "",
    "Category": "Program synthesis",
    "Sub_category": "Program repair",
    "Venue": "SIGSOFT",
    "Link": "https://dl.acm.org/doi/abs/10.1145/3395363.3397351",
    "bibtex": "inproceedings{896_Lou2020,\n    author = \"Lou, Yiling and Ghanbari, Ali and Li, Xia and Zhang, Lingming and Zhang, Haotian and Hao, Dan and Zhang, Lu\",\n    title = \"Can automated program repair refine fault localization? a unified debugging approach\",\n    booktitle = \"Proceedings of the 29th ACM SIGSOFT International Symposium on Software Testing and Analysis\",\n    pages = \"75--87\",\n    year = \"2020\"\n}\n\n",
    "abstract": "A large body of research efforts have been dedicated to automated software debugging, including both automated fault localization and program repair. However, existing fault localization techniques have limited effectiveness on real-world software systems while even the most advanced program repair techniques can only fix a small ratio of real-world bugs. Although fault localization and program repair are inherently connected, their only existing connection in the literature is that program repair techniques usually use off-the-shelf fault localization techniques (e.g., Ochiai) to determine the potential candidate statements/elements for patching. In this work, we propose the unified debugging approach to unify the two areas in the other direction for the first time, i.e., can program repair in turn help with fault localization? In this way, we not only open a new dimension for more powerful fault localization, but also extend the application scope of program repair to all possible bugs (not only the bugs that can be directly automatically fixed). We have designed ProFL to leverage patch-execution results (from program repair) as the feedback information for fault localization. The experimental results on the widely used Defects4J benchmark show that the basic ProFL can already at least localize 37.61% more bugs within Top-1 than state-of-the-art spectrum and mutation based fault localization. Furthermore, ProFL can boost state-of-the-art fault localization via both unsupervised and supervised learning. Meanwhile, we have demonstrated ProFL's effectiveness under different settings and through a case study within Alipay, a popular online payment system with over 1 billion global users."
},
{
    "py/object": "data.DataClassPaper",
    "Title": "Graph-based, Self-Supervised Program Repair from Diagnostic Feedback",
    "year": 2020,
    "ML_Techniques": "LSTM",
    "Category": "Program synthesis",
    "Sub_category": "Program repair",
    "Venue": "PMLR",
    "Link": "https://proceedings.mlr.press/v119/yasunaga20a.html",
    "bibtex": "inproceedings{899_Yasunaga2020,\n    author = \"Yasunaga, Michihiro and Liang, Percy\",\n    title = \"Graph-based, self-supervised program repair from diagnostic feedback\",\n    booktitle = \"International Conference on Machine Learning\",\n    pages = \"10799--10808\",\n    year = \"2020\",\n    organization = \"PMLR\"\n}\n\n",
    "abstract": "We consider the problem of learning to repair programs from diagnostic feedback (e.g., compiler error messages). Program repair is challenging for two reasons: First, it requires reasoning and tracking symbols across source code and diagnostic feedback. Second, labeled datasets available for program repair are relatively small. In this work, we propose novel solutions to these two challenges. First, we introduce a program-feedback graph, which connects symbols relevant to program repair in source code and diagnostic feedback, and then apply a graph neural network on top to model the reasoning process. Second, we present a self-supervised learning paradigm for program repair that leverages unlabeled programs available online to create a large amount of extra program repair examples, which we use to pre-train our models. We evaluate our proposed approach on two applications: correcting introductory programming assignments (DeepFix dataset) and correcting the outputs of program synthesis (SPoC dataset). Our final system, DrRepair, significantly outperforms prior work, achieving 68.2% full repair rate on DeepFix (+22.9% over the prior best), and 48.4% synthesis success rate on SPoC (+3.7% over the prior best)."
},
{
    "py/object": "data.DataClassPaper",
    "Title": "A critical review on the evaluation of automated program repair systems",
    "year": 2021,
    "ML_Techniques": "",
    "Category": "Program synthesis",
    "Sub_category": "Program repair",
    "Venue": "JSS",
    "Link": "https://www.sciencedirect.com/science/article/abs/pii/S0164121220302156",
    "bibtex": "article{900_Liu2021,\n    author = \"Liu, Kui and Li, Li and Koyuncu, Anil and Kim, Dongsun and Liu, Zhe and Klein, Jacques and Bissyand{\\'e}, Tegawend{\\'e} F\",\n    title = \"A critical review on the evaluation of automated program repair systems\",\n    journal = \"Journal of Systems and Software\",\n    volume = \"171\",\n    pages = \"110817\",\n    year = \"2021\",\n    publisher = \"Elsevier\"\n}\n\n",
    "abstract": "Automated Program Repair (APR) has attracted significant attention from software engineering research and practice communities in the last decade. Several teams have recorded promising performance in fixing real bugs and there is a race in the literature to fix as many bugs as possible from established benchmarks. Gradually, repair performance of APR tools in the literature has gone from being evaluated with a metric on the number of generated plausible patches to the number of correct patches. This evolution is necessary after a study highlighting the overfitting issue in test suite-based automatic patch generation. Simultaneously, some researchers are also insisting on providing time cost in the repair scenario as a metric for comparing state-of-the-art systems.\n\nIn this paper, we discuss how the latest evaluation metrics of APR systems could be biased. Since design decisions (both in approach and evaluation setup) are not always fully disclosed, the impact on repair performance is unknown and computed metrics are often misleading. To reduce notable biases of design decisions in program repair approaches, we conduct a critical review on the evaluation of patch generation systems and propose eight evaluation metrics for fairly assessing the performance of APR tools. Eventually, we show with experimental data on 11 baseline program repair systems that the proposed metrics allow to highlight some caveats in the literature. We expect wide adoption of these metrics in the community to contribute to boosting the development of practical, and reliably performable program repair tools."
},
{
    "py/object": "data.DataClassPaper",
    "Title": "On the efficiency of test suite based program repair: A Systematic Assessment of 16 Automated Repair Systems for Java Programs",
    "year": 2020,
    "ML_Techniques": "",
    "Category": "Program synthesis",
    "Sub_category": "Program repair",
    "Venue": "ICSE",
    "Link": "https://dl.acm.org/doi/abs/10.1145/3377811.3380338",
    "bibtex": "inproceedings{907_Liu2020,\n    author = \"Liu, Kui and Wang, Shangwen and Koyuncu, Anil and Kim, Kisub and Bissyand{\\'e}, Tegawend{\\'e} F and Kim, Dongsun and Wu, Peng and Klein, Jacques and Mao, Xiaoguang and Traon, Yves Le\",\n    title = \"On the efficiency of test suite based program repair: A systematic assessment of 16 automated repair systems for java programs\",\n    booktitle = \"Proceedings of the ACM/IEEE 42nd International Conference on Software Engineering\",\n    pages = \"615--627\",\n    year = \"2020\"\n}\n\n",
    "abstract": "Test-based automated program repair has been a prolific field of research in software engineering in the last decade. Many approaches have indeed been proposed, which leverage test suites as a weak, but affordable, approximation to program specifications. Although the literature regularly sets new records on the number of benchmark bugs that can be fixed, several studies increasingly raise concerns about the limitations and biases of state-of-the-art approaches. For example, the\u00a0correctness\u00a0of generated patches has been questioned in a number of studies, while other researchers pointed out that evaluation schemes may be misleading with respect to the processing of fault localization results. Nevertheless, there is little work addressing the efficiency of patch generation, with regard to the practicality of program repair. In this paper, we fill this gap in the literature, by providing an extensive review on the efficiency of test suite based program repair. Our objective is to assess the number of generated patch candidates, since this information is correlated to (1) the strategy to traverse the search space efficiently in order to select\u00a0sensical\u00a0repair attempts, (2) the strategy to minimize the test effort for identifying a\u00a0plausible\u00a0patch, (3) as well as the strategy to prioritize the generation of a\u00a0correct\u00a0patch. To that end, we perform a large-scale empirical study on the efficiency, in terms of quantity of generated patch candidates of the 16 open-source repair tools for Java programs. The experiments are carefully conducted under the same fault localization configurations to limit biases. Eventually, among other findings, we note that: (1) many irrelevant patch candidates are generated by changing wrong code locations; (2) however, if the search space is carefully triaged, fault localization noise has little impact on patch generation efficiency; (3) yet, current template-based repair systems, which are known to be most effective in fixing a large number of bugs, are actually least efficient as they tend to generate majoritarily irrelevant patch candidates."
},
{
    "py/object": "data.DataClassPaper",
    "Title": "The Coming Era of AlphaHacking?: A Survey of Automatic Software Vulnerability Detection, Exploitation and Patching Techniques",
    "year": 2018,
    "ML_Techniques": "",
    "Category": "Vulnerability analysis",
    "Sub_category": "",
    "Venue": "DSC",
    "Link": "https://ieeexplore.ieee.org/abstract/document/8411838",
    "bibtex": "INPROCEEDINGS{911_Ji2018,\n    author = \"Ji, Tiantian and Wu, Yue and Wang, Chang and Zhang, Xi and Wang, Zhongru\",\n    booktitle = \"2018 IEEE Third International Conference on Data Science in Cyberspace (DSC)\",\n    title = \"The Coming Era of AlphaHacking?: A Survey of Automatic Software Vulnerability Detection, Exploitation and Patching Techniques\",\n    year = \"2018\",\n    volume = \"\",\n    number = \"\",\n    pages = \"53-60\",\n    doi = \"10.1109/DSC.2018.00017\"\n}\n\n",
    "abstract": "With the success of the Cyber Grand Challenge (CGC) sponsored by DARPA, the topic of Autonomous Cyber Reasoning System (CRS) has recently attracted extensive attention from both industry and academia. Utilizing automated system to detect, exploit and patch software vulnerabilities seems so attractive because of its scalability and cost-efficiency compared with the human expert based solution. In this paper, we give an extensive survey of former representative works related to the underlying technologies of a CRS, including vulnerability detection, exploitation and patching. As an important supplement, we then review several pioneer studies that explore the potential of machine learning technologies in this field, and point out that the future development of Autonomous CRS is inseparable from machine learning."
},
{
    "py/object": "data.DataClassPaper",
    "Title": "A Comparative Study of Automatic Program Repair Techniques for Security Vulnerabilities",
    "year": 2021,
    "ML_Techniques": "",
    "Category": "Program synthesis",
    "Sub_category": "Program repair",
    "Venue": "ISSRE",
    "Link": "https://ieeexplore.ieee.org/abstract/document/9700400",
    "bibtex": "inproceedings{915_Pinconschi2021,\n    author = \"Pinconschi, Eduard and Abreu, Rui and Ad{\\\\textasciitilde a}o, Pedro\",\n    title = \"A Comparative Study of Automatic Program Repair Techniques for Security Vulnerabilities\",\n    booktitle = \"2021 IEEE 32nd International Symposium on Software Reliability Engineering (ISSRE)\",\n    pages = \"196--207\",\n    year = \"2021\",\n    organization = \"IEEE\"\n}\n\n",
    "abstract": "In the past years, research on automatic program repair (APR), in particular on test-suite-based approaches, has significantly attracted the attention of researchers. Despite the advances in the field, it remains unclear how these techniques fare in the context of security\u2014most approaches are evaluated using benchmarks of bugs that do not (only) contain security vulnerabilities. In this paper, we present our observations using 10 state-of-the-art test-suite-based automatic program repair tools on the DARPA Cyber Grand Challenge benchmark of vulnerabilities in C/C++. Our intention is to have a better understanding of the current state of automatic program repair tools when addressing security issues. In particular, our study is guided by the hypothesis that the efficiency of repair tools may not generalize to security vulnerabilities. We found that the 10 analyzed tools can only fix 30 out of 55 vulnerable programs\u201454.6 % of the considered issues. In particular, we found that APR tools with atomic change operators and brute-force search strategy (AE and GenProg) and brute-force functionality deletion (Kali) overall perform better at repairing security vulnerabilities (considering both efficiency and effectiveness). AE is the tool that individually repairs most programs with 20 out of 55 programs (36.4%). The causes for failing to repair are discussed in the paper, which can help repair tool designers to improve their techniques and tools."
},
{
    "py/object": "data.DataClassPaper",
    "Title": "Investigation of relationship between object-oriented metrics and change proneness",
    "year": 2013,
    "ML_Techniques": "MLP, RF",
    "Category": "Program comprehension",
    "Sub_category": "Change analysis",
    "Venue": "",
    "Link": "https://link.springer.com/article/10.1007/s13042-012-0095-7",
    "bibtex": "article{918_Malhotra2013,\n    author = \"Malhotra, Ruchika and Khanna, Megha\",\n    title = \"Investigation of relationship between object-oriented metrics and change proneness\",\n    journal = \"International Journal of Machine Learning and Cybernetics\",\n    volume = \"4\",\n    number = \"4\",\n    pages = \"273--286\",\n    year = \"2013\",\n    publisher = \"Springer\"\n}\n\n",
    "abstract": "Software is the heartbeat of modern day technology. In order to keep up with the pace of modern day expansion, change in any software is inevitable. Defects and enhancements are the two main reasons for a software change. The aim of this paper is to study the relationship between object oriented metrics and change proneness. Software prediction models based on these results can help us identify change prone classes of a software which would lead to more rigorous testing and better results. In the previous research, the use of machine learning methods for predicting faulty classes was found. However till date no study determines the effectiveness of machine learning methods for predicting change prone classes. Statistical and machine learning methods are two different techniques for software quality prediction. We evaluate and compare the performance of these machine learning methods with statistical method (logistic regression). The results are based on three chosen open source software, written in java language. The performance of the predicted models was evaluated using receiver operating characteristic analysis. The study shows that machine learning methods are comparable to regression techniques. Testing based on change proneness of a software leads to better quality by targeting the most change prone classes. Thus, the developed models can be used to reduce the probability of defect occurrence and we commit ourselves to better maintenance."
},
{
    "py/object": "data.DataClassPaper",
    "Title": "Software Quality Prediction: An Investigation Based on Machine Learning",
    "year": 2019,
    "ML_Techniques": "DT, RF, NB, BN,  KNN, SVM, ANN",
    "Category": "Quality assessment",
    "Sub_category": "Quality prediction",
    "Venue": "IRI",
    "Link": "https://ieeexplore.ieee.org/abstract/document/8843447",
    "bibtex": "inproceedings{920_Reddivari2019,\n    author = \"Reddivari, Sandeep and Raman, Jayalakshmi\",\n    title = \"Software quality prediction: an investigation based on machine learning\",\n    booktitle = \"2019 IEEE 20th International Conference on Information Reuse and Integration for Data Science (IRI)\",\n    pages = \"115--122\",\n    year = \"2019\",\n    organization = \"IEEE\"\n}\n\n",
    "abstract": "Irrespective of the type of software system that is being developed, producing and delivering high-quality software within the specified time and budget is crucial for many software businesses. The software process model has a major impact on the quality of the overall system - the longer a defect remains in the system undetected, the harder it becomes to fix. However, predicting the quality of the software in the early phases would immensely assist developers in software maintenance and quality assurance activities, and to allocate effort and resources more efficiently. This paper presents an evaluation of eight machine learning techniques in the context of reliability and maintainability. Reliability is investigated as the number of defects in a system and the maintainability is analyzed as the number of changes made in the system. Software metrics are direct reflections of various characteristics of software and are used in our study as the major attributes for training the models for both defect and maintainability prediction. Among the eight different techniques we experimented with, Random Forest provided the best results with an AUC of over 0.8 during both defect and maintenance prediction."
},
{
    "py/object": "data.DataClassPaper",
    "Title": "Soware Maintainability Prediction using Machine Learning Algorithms",
    "year": 2021,
    "ML_Techniques": "GP, PNN",
    "Category": "Quality assessment",
    "Sub_category": "Quality prediction",
    "Venue": "SEIJ",
    "Link": "https://link.springer.com/chapter/10.1007/978-981-16-3067-5_51",
    "bibtex": "article{924_Malhotra$^1$2012,\n    author = \"Malhotra$^1$, Ruchika and Chug, Anuradha\",\n    title = \"Software maintainability prediction using machine learning algorithms\",\n    journal = \"Software engineering: an international Journal (SeiJ)\",\n    volume = \"2\",\n    number = \"2\",\n    year = \"2012\"\n}\n\n",
    "abstract": "Software maintainability is a prime trait of software, measured as the ease with which new code lines can be added, obsolete ones can be deleted, and those having errors can be corrected. The significance of software maintenance is increasing in today\u2019s digital era leading to the use of advanced machine learning (ML) algorithms for building efficient models to predict maintainability, although several baseline ML algorithms are already in use for software maintainability prediction (SMP). However, in the current study, an effort has been made to improve the existing baseline models using hyperparameter tuning. Hyperparameter tuning chooses the best set of hyperparameters for an algorithm, where a hyperparameter is that parameter that uses its value for controlling the training process. This study employs default hyperparameter tuning as well as the grid search-based hyperparameter tuning. Five regression-based ML algorithms, i.e., Random Forest, Ridge Regression, Support Vector Regression, Stochastic Gradient Descent, and Gaussian Process Regression, have been implemented using two commercial object-oriented datasets, namely QUES and UIMS for SMP. To evaluate the performance, a comparison has been made between the baseline models and the models developed after hyperparameter tuning based on the three accuracy measures, viz., R-Squared, Mean Absolute Error (MAE), and Root Mean Squared Logarithmic Error (RMSLE). The results depict that the performance of all the five baseline ML algorithms improved after applying hyperparameter tuning. This conclusion is supported by the improved R-squared, MAE, and RMSLE values obtained in this study. Best results are obtained when the grid search method is used for the tuning purpose. On average, the values of R-squared, MAE, and RMSLE measures improved by 20.24%, 12.26%, and 30.28%, respectively, for the QUES dataset. On the other hand, in the case of the UIMS dataset, an average improvement of 6.27%, 15.71%, and 16.39% has been achieved in terms of R-squared, MAE, and RMSLE, respectively."
},
{
    "py/object": "data.DataClassPaper",
    "Title": "Fault Prediction Using Statistical and Machine Learning Methods for Improving Software Quality",
    "year": 2012,
    "ML_Techniques": "RF, AB, B, MLP, SVM, GP",
    "Category": "Testing",
    "Sub_category": "Defect prediction",
    "Venue": "JIPS",
    "Link": "https://www.koreascience.or.kr/article/JAKO201222340312043.page",
    "bibtex": "article{925_Malhotra2012,\n    author = \"Malhotra, Ruchika and Jain, Ankita\",\n    title = \"Fault prediction using statistical and machine learning methods for improving software quality\",\n    journal = \"Journal of Information Processing Systems\",\n    volume = \"8\",\n    number = \"2\",\n    pages = \"241--262\",\n    year = \"2012\",\n    publisher = \"Korea Information Processing Society\"\n}\n\n",
    "abstract": "An understanding of quality attributes is relevant for the software organization to deliver high software reliability. An empirical assessment of metrics to predict the quality attributes is essential in order to gain insight about the quality of software in the early phases of software development and to ensure corrective actions. In this paper, we predict a model to estimate fault proneness using Object Oriented CK metrics and QMOOD metrics. We apply one statistical method and six machine learning methods to predict the models. The proposed models are validated using dataset collected from Open Source software. The results are analyzed using Area Under the Curve (AUC) obtained from Receiver Operating Characteristics (ROC) analysis. The results show that the model predicted using the random forest and bagging methods outperformed all the other models. Hence, based on these results it is reasonable to claim that quality models have a significant relevance with Object Oriented metrics and that machine learning methods have a comparable performance with statistical methods."
},
{
    "py/object": "data.DataClassPaper",
    "Title": "Towards machine learning based design pattern recognition",
    "year": 2013,
    "ML_Techniques": "",
    "Category": "Program comprehension",
    "Sub_category": "Entity identification/recommendation",
    "Venue": "UKCI",
    "Link": "https://ieeexplore.ieee.org/abstract/document/6651312",
    "bibtex": "inproceedings{927_Alhusain2013,\n    author = \"Alhusain, Sultan and Coupland, Simon and John, Robert and Kavanagh, Maria\",\n    title = \"Towards machine learning based design pattern recognition\",\n    booktitle = \"2013 13th UK Workshop on Computational Intelligence (UKCI)\",\n    pages = \"244--251\",\n    year = \"2013\",\n    organization = \"IEEE\"\n}\n\n",
    "abstract": "Software design patterns are abstract descriptions of best practice solutions for recurring design problems. The information about which design pattern is implemented where in a software design is very helpful and important for software maintenance and evolution. This information is usually lost due to poor, obsolete or lack of documentation, which raises the importance of automatic recognition techniques. However, their vague and abstract nature allows them to be implemented in various ways, which gives them resistance to be automatically and accurately recognized. This paper presents the first recognition approach to be solely based on machine learning methods. We build a training dataset by using several existing recognition tools and we use feature selection methods to select the input feature vectors. Artificial neural networks are then trained to perform the whole recognition process. Our approach is evaluated by conducting an experiment to recognize six design patterns in an open source application."
},
{
    "py/object": "data.DataClassPaper",
    "Title": "Automated patch correctness assessment: how far are we?",
    "year": 2020,
    "ML_Techniques": "",
    "Category": "Program synthesis",
    "Sub_category": "Program repair",
    "Venue": "ASE",
    "Link": "https://dl.acm.org/doi/abs/10.1145/3324884.3416590",
    "bibtex": "inproceedings{931_Wang2020,\n    author = \"Wang, Shangwen and Wen, Ming and Lin, Bo and Wu, Hongjun and Qin, Yihao and Zou, Deqing and Mao, Xiaoguang and Jin, Hai\",\n    title = \"Automated patch correctness assessment: How far are we?\",\n    booktitle = \"Proceedings of the 35th IEEE/ACM International Conference on Automated Software Engineering\",\n    pages = \"968--980\",\n    year = \"2020\"\n}\n\n",
    "abstract": "Test-based automated program repair (APR) has attracted huge attention from both industry and academia. Despite the significant progress made in recent studies, the overfitting problem (i.e., the generated patch is plausible but overfitting) is still a major and long-standing challenge. Therefore, plenty of techniques have been proposed to assess the correctness of patches either in the patch generation phase or in the evaluation of APR techniques. However, the effectiveness of existing techniques has not been systematically compared and little is known to their advantages and disadvantages. To fill this gap, we performed a large-scale empirical study in this paper. Specifically, we systematically investigated the effectiveness of existing automated patch correctness assessment techniques, including both static and dynamic ones, based on 902 patches automatically generated by 21 APR tools from 4 different categories. Our empirical study revealed the following major findings: (1) static code features with respect to patch syntax and semantics are generally effective in differentiating overfitting patches over correct ones; (2) dynamic techniques can generally achieve high precision while heuristics based on static code features are more effective towards recall; (3) existing techniques are more effective towards certain projects and types of APR techniques while less effective to the others; (4) existing techniques are highly complementary to each other. For instance, a single technique can only detect at most 53.5% of the overfitting patches while 93.3% of them can be detected by at least one technique when the oracle information is available. Based on our findings, we designed an integration strategy to first integrate static code features via learning, and then combine with others by the\u00a0majority voting\u00a0strategy. Our experiments show that the strategy can enhance the performance of existing patch correctness assessment techniques significantly."
},
{
    "py/object": "data.DataClassPaper",
    "Title": "Context-Aware Code Change Embedding for Better Patch Correctness Assessment",
    "year": 2021,
    "ML_Techniques": "",
    "Category": "Program synthesis",
    "Sub_category": "Program repair",
    "Venue": "TOSEM",
    "Link": "https://www.researchgate.net/profile/Bo-Lin-5/publication/356977095_Context-Aware_Code_Change_Embedding_for_Better_Patch_Correctness_Assessment/links/61b579f11d88475981e29dd7/Context-Aware-Code-Change-Embedding-for-Better-Patch-Correctness-Assessment.pdf",
    "bibtex": "article{933_LIN2021,\n    author = \"LIN, BO and WANG, SHANGWEN and WEN, MING and MAO, XIAOGUANG\",\n    title = \"Context-Aware Code Change Embedding for Better Patch Correctness Assessment\",\n    journal = \"J. ACM\",\n    volume = \"1\",\n    number = \"1\",\n    year = \"2021\"\n}\n\n",
    "abstract": "Despite the capability in successfully fixing more and more real-world bugs, existing Automated Program Repair (APR) techniques are still challenged by the long-standing overfitting problem (i.e., a generated patch that passes all tests is actually incorrect). Plenty of approaches have been proposed for automated patch correctness assessment (APCA). Nonetheless, dynamic ones (i.e., those need to execute tests) are time-consuming while static ones (i.e., those built on top of static code features) are less precise. Therefore, embedding techniques have been proposed recently, which assess patch correctness via embedding token sequences extracted from the changed code of a generated patch. However, existing techniques rarely considered the context information and program structures of a generated patch, which are crucial for patch correctness assessment as revealed by existing studies. In this study, we explore the idea of context-aware code change embedding considering program structures for patch correctness assessment. Specifically, given a patch, we not only focus on the changed code but also take the correlated unchanged part into consideration, through which the context information can be extracted and leveraged. We then utilize the AST path technique for representation where the structure information from AST node can be captured. Finally, based on several pre-defined heuristics, we build a deep learning based classifier to predict the correctness of the patch. We implemented this idea as Cache and performed extensive experiments to assess its effectiveness. Our results demonstrate that Cache can (1) perform better than previous representation learning based techniques (e.g., Cache relatively outperforms existing techniques by \u22486%, \u22483%, and \u224816%, respectively under three diverse experiment settings), and (2) achieve overall higher performance than existing APCA techniques while even being more precise than certain dynamic ones including PATCH-SIM (92.9% vs. 83.0%). Further results reveal that the context information and program structures leveraged by Cache contributed significantly to its outstanding performance."
},
{
    "py/object": "data.DataClassPaper",
    "Title": "A syntax-guided edit decoder for neural program repair",
    "year": 2021,
    "ML_Techniques": "",
    "Category": "Program synthesis",
    "Sub_category": "Program repair",
    "Venue": "FSE",
    "Link": "https://dl.acm.org/doi/abs/10.1145/3468264.3468544",
    "bibtex": "inproceedings{934_Zhu2021,\n    author = \"Zhu, Qihao and Sun, Zeyu and Xiao, Yuan-an and Zhang, Wenjie and Yuan, Kang and Xiong, Yingfei and Zhang, Lu\",\n    title = \"A syntax-guided edit decoder for neural program repair\",\n    booktitle = \"Proceedings of the 29th ACM Joint Meeting on European Software Engineering Conference and Symposium on the Foundations of Software Engineering\",\n    pages = \"341--353\",\n    year = \"2021\"\n}\n\n",
    "abstract": "Automated Program Repair (APR) helps improve the efficiency of software development and maintenance. Recent APR techniques use deep learning, particularly the encoder-decoder architecture, to generate patches. Though existing DL-based APR approaches have proposed different encoder architectures, the decoder remains to be the standard one, which generates a sequence of tokens one by one to replace the faulty statement. This decoder has multiple limitations: 1) allowing to generate syntactically incorrect programs, 2) inefficiently representing small edits, and 3) not being able to generate project-specific identifiers.\n\nIn this paper, we propose Recoder, a syntax-guided edit decoder with placeholder generation. Recoder is novel in multiple aspects: 1) Recoder generates edits rather than modified code, allowing efficient representation of small edits; 2) Recoder is syntax-guided, with the novel provider/decider architecture to ensure the syntactic correctness of the patched program and accurate generation; 3) Recoder generates placeholders that could be instantiated as project-specific identifiers later.\n\nWe conduct experiments to evaluate Recoder on 395 bugs from Defects4J v1.2, 420 additional bugs from Defects4J v2.0, 297 bugs from IntroClassJava and 40 bugs from QuixBugs. Our results show that Recoder repairs 53 bugs on Defects4J v1.2, which achieves 26.2% (11 bugs) improvement over the previous state-of-the-art approach for single-hunk bugs (TBar). Importantly, to our knowledge, Recoder is the first DL-based APR approach that has outperformed the traditional APR approaches on this benchmark. Furthermore, Recoder repairs 19 bugs on the additional bugs from Defects4J v2.0, which is 137.5% (11 bugs) more than TBar and 850% (17 bugs) more than SimFix. Recoder also achieves 775% (31 bugs) and 30.8% (4 bugs) improvement on IntroClassJava and QuixBugs over the baselines respectively. These results suggest that Recoder has better generalizability than existing APR approaches."
},
{
    "py/object": "data.DataClassPaper",
    "Title": "CODIT: Code Editing with Tree-Based Neural Models",
    "year": 2021,
    "ML_Techniques": "LSTM",
    "Category": "Code representation",
    "Sub_category": "",
    "Venue": "TSE",
    "Link": "https://ieeexplore.ieee.org/abstract/document/9181462",
    "bibtex": "ARTICLE{937_Chakraborty2022,\n    author = \"Chakraborty, Saikat and Ding, Yangruibo and Allamanis, Miltiadis and Ray, Baishakhi\",\n    journal = \"IEEE Transactions on Software Engineering\",\n    title = \"CODIT: Code Editing With Tree-Based Neural Models\",\n    year = \"2022\",\n    volume = \"48\",\n    number = \"4\",\n    pages = \"1385-1399\",\n    doi = \"10.1109/TSE.2020.3020502\"\n}\n\n",
    "abstract": "The way developers edit day-to-day code tends to be repetitive, often using existing code elements. Many researchers have tried to automate repetitive code changes by learning from specific change templates which are applied to limited scope. The advancement of deep neural networks and the availability of vast open-source evolutionary data opens up the possibility of automatically learning those templates from the wild. However, deep neural network based modeling for code changes and code in general introduces some specific problems that needs specific attention from research community. For instance, compared to natural language, source code vocabulary can be significantly larger. Further, good changes in code do not break its syntactic structure. Thus, deploying state-of-the-art neural network models without adapting the methods to the source code domain yields sub-optimal results. To this end, we propose a novel tree-based neural network system to model source code changes and learn code change patterns from the wild. Specifically, we propose a tree-based neural machine translation model to learn the probability distribution of changes in code. We realize our model with a change suggestion engine, Codit , and train the model with more than 24k real-world changes and evaluate it on 5k patches. Our evaluation shows the effectiveness of Codit in learning and suggesting patches. Codit can also learn specific bug fix pattern from bug fixing patches and can fix 25 bugs out of 80 bugs in Defects4J."
},
{
    "py/object": "data.DataClassPaper",
    "Title": "Multiplicative Weights Algorithms for Parallel Automated Software Repair",
    "year": 2021,
    "ML_Techniques": "",
    "Category": "Program synthesis",
    "Sub_category": "Program repair",
    "Venue": "IPDPS",
    "Link": "https://ieeexplore.ieee.org/abstract/document/9460525",
    "bibtex": "inproceedings{939_Renzullo2021,\n    author = \"Renzullo, Joseph and Weimer, Westley and Forrest, Stephanie\",\n    title = \"Multiplicative Weights Algorithms for Parallel Automated Software Repair\",\n    booktitle = \"2021 IEEE International Parallel and Distributed Processing Symposium (IPDPS)\",\n    pages = \"984--993\",\n    year = \"2021\",\n    organization = \"IEEE\"\n}\n\n",
    "abstract": "Multiplicative Weights Update (MWU) algorithms are a form of online learning that is applied to multi-armed bandit problems. Such problems involve allocating a fixed number of trials among multiple options to maximize cumulative payoff. MWU is a popular and effective method for dynamically balancing the trade-off between exploring the value of new options and exploiting the information already gained. However, no clear strategy exists to help practitioners choose which of the several algorithmic designs within this family to deploy. In this paper, three variants of parallel MWU algorithms are considered: Two parallel variants that rely on global memory, and one variant that uses distributed memory. The three variants are first analyzed theoretically, and then their effectiveness is assessed empirically on the task of estimating distributions in the context of stochastic search for repairs to bugs in software. Earlier work on APR suffers from various inefficiencies, and the paper shows how to decompose the problem into two stages: one that is embarrassingly parallel and one that is amenable to MWU. We then model the cost of each MWU variant and derive the conditions under which it is likely to be preferred in practice. We find that all three MWU algorithms achieve accuracy above 90% but that there are significant differences in runtime and total cost. When 90% accuracy is sufficient and evaluating options is expensive, such as in our use case, we find that the algorithm that uses global memory and has high communication cost outperforms the other two. We analyze the reasons for this surprising result."
},
{
    "py/object": "data.DataClassPaper",
    "Title": "AL: autogenerating supervised learning programs",
    "year": 2019,
    "ML_Techniques": "XG",
    "Category": "Program synthesis",
    "Sub_category": "Program repair",
    "Venue": "OOPSLA",
    "Link": "https://dl.acm.org/doi/abs/10.1145/3360601",
    "bibtex": "article{943_Cambronero2019,\n    author = \"Cambronero, Jos{\\'e} P and Rinard, Martin C\",\n    title = \"AL: autogenerating supervised learning programs\",\n    journal = \"Proceedings of the ACM on Programming Languages\",\n    volume = \"3\",\n    number = \"OOPSLA\",\n    pages = \"1--28\",\n    year = \"2019\",\n    publisher = \"ACM New York, NY, USA\"\n}\n\n",
    "abstract": "We present AL, a novel automated machine learning system that learns to generate new supervised learning pipelines from an existing corpus of supervised learning programs. In contrast to existing automated machine learning tools, which typically implement a search over manually selected machine learning functions and classes, AL learns to identify the relevant classes in an API by analyzing dynamic program traces that use the target machine learning library. AL constructs a conditional probability model from these traces to estimate the likelihood of the generated supervised learning pipelines and uses this model to guide the search to generate pipelines for new datasets. Our evaluation shows that AL can produce successful pipelines for datasets that previous systems fail to process and produces pipelines with comparable predictive performance for datasets that previous systems process successfully."
},
{
    "py/object": "data.DataClassPaper",
    "Title": "A Machine Learning Approach to Improve the Detection of CI Skip Commits",
    "year": 2020,
    "ML_Techniques": "DT",
    "Category": "Program comprehension",
    "Sub_category": "Program classification",
    "Venue": "TSE",
    "Link": "https://ieeexplore.ieee.org/abstract/document/8961089",
    "bibtex": "article{947_Abdalkareem2020,\n    author = \"Abdalkareem, Rabe and Mujahid, Suhaib and Shihab, Emad\",\n    title = \"A machine learning approach to improve the detection of ci skip commits\",\n    journal = \"IEEE Transactions on Software Engineering\",\n    year = \"2020\",\n    publisher = \"IEEE\"\n}\n\n",
    "abstract": "Continuous integration (CI) frameworks, such as Travis CI, are growing in popularity, encouraged by market trends towards speeding up the release cycle and building higher-quality software. A key facilitator of CI is to automatically build and run tests whenever a new commit is submitted/pushed. Despite the many advantages of using CI, it is known that the CI process can take a very long time to complete. One of the core causes for such delays is the fact that some commits (e.g., cosmetic changes) unnecessarily kick off the CI process. Therefore, the main goal of this paper is to automate the process of determining which commits can be CI skipped through the use of machine learning techniques. We first extracted 23 features from historical data of ten software repositories. Second, we conduct a study on the detection of CI skip commits using machine learning where we built a decision tree classifier. We then examine the accuracy of using the decision tree in detecting CI skip commits. Our results show that the decision tree can identify CI skip commits with an average AUC equal to 0.89. Furthermore, the top node analysis shows that the number of developers who changed the modified files, the CI-Skip rules, and commit message are the most important features to detect CI skip commits. Finally, we investigate the generalizability of identifying CI skip commits through applying cross-project validation, and our results show that the general classifier achieves an average 0.74 of AUC values."
},
{
    "py/object": "data.DataClassPaper",
    "Title": "A Practical Approach to the Automatic Classification of Security-Relevant Commits",
    "year": 2018,
    "ML_Techniques": "LOG, RF, SVM ",
    "Category": "Program comprehension",
    "Sub_category": "Program classification",
    "Venue": "ICSME",
    "Link": "https://ieeexplore.ieee.org/abstract/document/8530068",
    "bibtex": "inproceedings{949_Sabetta2018,\n    author = \"Sabetta, Antonino and Bezzi, Michele\",\n    title = \"A practical approach to the automatic classification of security-relevant commits\",\n    booktitle = \"2018 IEEE International conference on software maintenance and evolution (ICSME)\",\n    pages = \"579--582\",\n    year = \"2018\",\n    organization = \"IEEE\"\n}\n\n",
    "abstract": "The lack of reliable sources of detailed information on the vulnerabilities of open-source software (OSS) components is a major obstacle to maintaining a secure software supply chain and an effective vulnerability management process. Standard sources of advisories and vulnerability data, such as the National Vulnerability Database (NVD), are known to suffer from poor coverage and inconsistent quality. To reduce our dependency on these sources, we propose an approach that uses machine-learning to analyze source code repositories and to automatically identify commits that are security-relevant (i.e., that are likely to fix a vulnerability). We treat the source code changes introduced by commits as documents written in natural language, classifying them using standard document classification methods. Combining independent classifiers that use information from different facets of commits, our method can yield high precision (80%) while ensuring acceptable recall (43%). In particular, the use of information extracted from the source code changes yields a substantial improvement over the best known approach in state of the art, while requiring a significantly smaller amount of training data and employing a simpler architecture."
},
{
    "py/object": "data.DataClassPaper",
    "Title": "Towards Automatic Generation of Short Summaries of Commits",
    "year": 2017,
    "ML_Techniques": "NB",
    "Category": "Program comprehension",
    "Sub_category": "Code summarization",
    "Venue": "ICPC",
    "Link": "https://ieeexplore.ieee.org/abstract/document/7961530",
    "bibtex": "inproceedings{952_Jiang2017,\n    author = \"Jiang, Siyuan and McMillan, Collin\",\n    title = \"Towards automatic generation of short summaries of commits\",\n    booktitle = \"2017 IEEE/ACM 25th International Conference on Program Comprehension (ICPC)\",\n    pages = \"320--323\",\n    year = \"2017\",\n    organization = \"IEEE\"\n}\n\n",
    "abstract": "Committing to a version control system means submitting a software change to the system. Each commit can have a message to describe the submission. Several approaches have been proposed to automatically generate the content of such messages. However, the quality of the automatically generated messages falls far short of what humans write. In studying the differences between auto-generated and human-written messages, we found that 82% of the human-written messages have only one sentence, while the automatically generated messages often have multiple lines. Furthermore, we found that the commit messages often begin with a verb followed by an direct object. This finding inspired us to use a \"verb+object\" format in this paper to generate short commit summaries. We split the approach into two parts: verb generation and object generation. As our first try, we trained a classifier to classify a diff to a verb. We are seeking feedback from the community before we continue to work on generating direct objects for the commits."
},
{
    "py/object": "data.DataClassPaper",
    "Title": "Boosting Neural Commit Message Generation with Code Semantic Analysis",
    "year": 2019,
    "ML_Techniques": "",
    "Category": "Program comprehension",
    "Sub_category": "Code summarization",
    "Venue": "ASE",
    "Link": "https://ieeexplore.ieee.org/abstract/document/8952539",
    "bibtex": "inproceedings{955_Jiang2019,\n    author = \"Jiang, Shuyao\",\n    title = \"Boosting neural commit message generation with code semantic analysis\",\n    booktitle = \"2019 34th IEEE/ACM International Conference on Automated Software Engineering (ASE)\",\n    pages = \"1280--1282\",\n    year = \"2019\",\n    organization = \"IEEE\"\n}\n\n",
    "abstract": "It has been long suggested that commit messages can greatly facilitate code comprehension. However, developers may not write good commit messages in practice. Neural machine translation (NMT) has been suggested to automatically generate commit messages. Despite the efforts in improving NMT algorithms, the quality of the generated commit messages is not yet satisfactory. This paper, instead of improving NMT algorithms, suggests that proper preprocessing of code changes into concise inputs is quite critical to train NMT. We approach it with semantic analysis of code changes. We collect a real-world dataset with 50k+ commits of popular Java projects, and verify our idea with comprehensive experiments. The results show that preprocessing inputs with code semantic analysis can improve NMT significantly. This work sheds light to how to apply existing DNNs designed by the machine learning community, e.g., NMT models, to complete software engineering tasks."
},
{
    "py/object": "data.DataClassPaper",
    "Title": "Characterizing and identifying reverted commits",
    "year": 2019,
    "ML_Techniques": "RF",
    "Category": "Program comprehension",
    "Sub_category": "Entity identification/recommendation",
    "Venue": "Empirical Software Engineering",
    "Link": "https://link.springer.com/article/10.1007/s10664-019-09688-8",
    "bibtex": "article{959_Yan2019,\n    author = \"Yan, Meng and Xia, Xin and Lo, David and Hassan, Ahmed E and Li, Shanping\",\n    title = \"Characterizing and identifying reverted commits\",\n    journal = \"Empirical Software Engineering\",\n    volume = \"24\",\n    number = \"4\",\n    pages = \"2171--2208\",\n    year = \"2019\",\n    publisher = \"Springer\"\n}\n\n",
    "abstract": "In practice, a popular and coarse-grained approach for recovering from a problematic commit is to revert it (i.e., undoing the change). However, reverted commits could induce some issues for software development, such as impeding the development progress and increasing the difficulty for maintenance. In order to mitigate these issues, we set out to explore the following central question: can we characterize and identify which commits will be reverted? In this paper, we characterize commits using 27 commit features and build an identification model to identify commits that will be reverted. We first identify reverted commits by analyzing commit messages and comparing the changed content, and extract 27 commit features that can be divided into three dimensions, namely change, developer and message, respectively. Then, we build an identification model (e.g., random forest) based on the extracted features. To evaluate the effectiveness of our proposed model, we perform an empirical study on ten open source projects including a total of 125,241 commits. Our experimental results show that our model outperforms two baselines in terms of AUC-ROC and cost-effectiveness (i.e., percentage of detected reverted commits when inspecting 20% of total changed LOC). In terms of the average performance across the ten studied projects, our model achieves an AUC-ROC of 0.756 and a cost-effectiveness of 0.746, significantly improving the baselines by substantial margins. In addition, we found that \u201cdeveloper\u201d is the most discriminative dimension among the three dimensions of features for the identification of reverted commits. However, using all the three dimensions of commit features leads to better performance."
},
{
    "py/object": "data.DataClassPaper",
    "Title": "DeepLink: Recovering issue-commit links based on deep learning",
    "year": 2019,
    "ML_Techniques": "RNN, LSTM",
    "Category": "Program comprehension",
    "Sub_category": "",
    "Venue": "JSS",
    "Link": "https://www.sciencedirect.com/science/article/abs/pii/S0164121219301803",
    "bibtex": "article{960_Ruan2019,\n    author = \"Ruan, Hang and Chen, Bihuan and Peng, Xin and Zhao, Wenyun\",\n    title = \"DeepLink: Recovering issue-commit links based on deep learning\",\n    journal = \"Journal of Systems and Software\",\n    volume = \"158\",\n    pages = \"110406\",\n    year = \"2019\",\n    publisher = \"Elsevier\"\n}\n\n",
    "abstract": "The links between issues in an issue-tracking system and commits resolving the issues in a version control system are important for a variety of software engineering tasks (e.g., bug prediction, bug localization and feature location). However, only a small portion of such links are established by manually including issue identifiers in commit logs, leaving a large portion of them lost in the evolution history. To recover issue-commit links, heuristic-based and learning-based techniques leverage the metadata and text/code similarity in issues and commits; however, they fail to capture the embedded semantics in issues and commits and the hidden semantic correlations between issues and commits. As a result, this semantic gap inhibits the accuracy of link recovery.\n\nTo bridge this gap, we propose a semantically-enhanced link recovery approach, named DeepLink, which is built on top of deep learning techniques. Specifically, we develop a neural network architecture, using word embedding and recurrent neural network, to learn the semantic representation of natural language descriptions and code in issues and commits as well as the semantic correlation between issues and commits. In experiments, to quantify the prevalence of missing issue-commit links, we analyzed 1078 highly-starred GitHub Java projects (i.e., 583,795 closed issues) and found that only 42.2% of issues were linked to corresponding commits. To evaluate the effectiveness of DeepLink, we compared DeepLink with a state-of-the-art link recovery approach FRLink using ten GitHub Java projects and demonstrated that DeepLink can outperform FRLink in terms of F-measure."
},
{
    "py/object": "data.DataClassPaper",
    "Title": "Classifying Code Commits with Convolutional Neural Networks",
    "year": 2021,
    "ML_Techniques": "CNN",
    "Category": "Program comprehension",
    "Sub_category": "Program classification",
    "Venue": "IJCNN",
    "Link": "https://ieeexplore.ieee.org/abstract/document/9533534",
    "bibtex": "inproceedings{964_Meng2021,\n    author = \"Meng, Na and Jiang, Zijian and Zhong, Hao\",\n    title = \"Classifying Code Commits with Convolutional Neural Networks\",\n    booktitle = \"2021 International Joint Conference on Neural Networks (IJCNN)\",\n    pages = \"1--8\",\n    year = \"2021\",\n    organization = \"IEEE\"\n}\n\n",
    "abstract": "Developers change software programs for various purposes (e.g., bug fixes, feature additions, and code refactorings), but the intents of code changes are often not recorded or are poorly documented. To automatically infer the change intent of each program commit (i.e., a set of code changes), existing work classifies commits based on commit messages and/or the sheer counts of edited files, lines, or abstract syntax tree (AST) nodes. However, none of these tools reason about the syntactic or semantic dependencies between co-applied changes, neither do they adopt any deep learning method. To better characterize program commits, in this paper, we present CClassifier\u2014a new approach that classifies commits by (1) using advanced static program analysis to comprehend relationship between co-applied edits, (2) representing edits and their relationship via graphs, and (3) applying convolutional neural networks (CNN) to classify those graphs. Compared with prior work, CClassifier extracts a richer set of features from program changes; it is the first to classify program commits using CNN. For evaluation, we prepared a benchmark that contains 7,414 code changes from 5 open-source Java projects. On this benchmark, we empirically compared CClassifier and the state-of-the-art approach with five-fold cross validation. On average, when predicting bug-fixing commits within the same projects, CClassifier improved the prediction accuracy from 70% to 72%. More importantly, prior work seldom identifies feature-addition commits; CClassifier can successfully identify such commits in a lot more scenarios. Our evaluation shows that CClassifier outperforms prior work due to its usage of advanced program analysis and CNN."
},
{
    "py/object": "data.DataClassPaper",
    "Title": "Boosting Automatic Commit Classification Into Maintenance Activities By Utilizing Source Code Changes",
    "year": 2017,
    "ML_Techniques": "RF, GBM",
    "Category": "Program comprehension",
    "Sub_category": "Program classification",
    "Venue": "ICSE",
    "Link": "https://dl.acm.org/doi/abs/10.1145/3127005.3127016",
    "bibtex": "inproceedings{965_Levin2017,\n    author = \"Levin, Stanislav and Yehudai, Amiram\",\n    title = \"Boosting automatic commit classification into maintenance activities by utilizing source code changes\",\n    booktitle = \"Proceedings of the 13th International Conference on Predictive Models and Data Analytics in Software Engineering\",\n    pages = \"97--106\",\n    year = \"2017\"\n}\n\n",
    "abstract": "Background: Understanding maintenance activities performed in a source code repository could help practitioners reduce uncertainty and improve cost-effectiveness by planning ahead and pre-allocating resources towards source code maintenance. The research community uses 3 main classification categories for maintenance activities: Corrective: fault fixing; Perfective: system improvements; Adaptive: new feature introduction. Previous work in this area has mostly concentrated on evaluating commit classification (into maintenance activities) models in the scope of a single software project.\n\nAims: In this work we seek to design a commit classification model capable of providing high accuracy and Kappa across different projects. In addition, we wish to compare the accuracy and kappa characteristics of classification models that utilize word frequency analysis, source code changes, and combination thereof.\n\nMethod: We suggest a novel method for automatically classifying commits into maintenance activities by utilizing source code changes (e.g, statement added, method removed, etc.). The results we report are based on studying 11 popular open source projects from various professional domains from which we had manually classified 1151 commits, over 100 from each of the studied projects. Our models were trained using 85% of the dataset, while the remaining 15% were used as a test set.\n\nResults: Our method shows a promising accuracy of 76% and Cohen's kappa of 63% (considered \"Good\" in this context) for the test dataset, an improvement of over 20 percentage points, and a relative boost of ~40% in the context of cross-project classification.\n\nConclusions: We show that by using source code changes in combination with commit message word frequency analysis we are able to considerably boost classification quality in a project agnostic manner."
},
{
    "py/object": "data.DataClassPaper",
    "Title": "Watch out for this commit! A study of influential software changes",
    "year": 2019,
    "ML_Techniques": "RF, NB",
    "Category": "Program comprehension",
    "Sub_category": "Program classification",
    "Venue": "Journal of Software: Evolution and Process",
    "Link": "https://onlinelibrary.wiley.com/doi/abs/10.1002/smr.2181",
    "bibtex": "article{967_Li2019,\n    author = \"Li, Daoyuan and Li, Li and Kim, Dongsun and Bissyand{\\'e}, Tegawend{\\'e} F and Lo, David and Le Traon, Yves\",\n    title = \"Watch out for this commit! a study of influential software changes\",\n    journal = \"Journal of Software: Evolution and Process\",\n    volume = \"31\",\n    number = \"12\",\n    pages = \"e2181\",\n    year = \"2019\",\n    publisher = \"Wiley Online Library\"\n}\n\n",
    "abstract": "One single code change can significantly influence a wide range of software systems and their users. For example, (a) adding a new feature can spread defects in several modules, while (b) changing an API method can improve the performance of all client programs. Unfortunately, developers often may not clearly know whether code changes are influential at commit time. This paper investigates influential software changes and proposes an approach to identify them immediately when they are applied. Our goals are to (a) identify existing influential changes (ICs) in software projects, (b) understand their characteristics, and (c) build a classification model of ICs to help developers find and address them early. We first conduct a post-mortem analysis to discover existing influential changes by using intuitions (eg, changes referred by other changes). Then, we re-categorize all identified changes through an open-card sorting process. Subsequently, we conduct a survey with about 100 developers to finalize a taxonomy. Finally, from our ground truth, we extract features, including metrics such as the complexity of changes and file centrality in co-change graphs to build machine learning classifiers. The experiment results show that our classification model with random samples achieves 86.8% precision, 74% recall, and 80.4% F-measure, respectively."
},
{
    "py/object": "data.DataClassPaper",
    "Title": "Improve Classification of Commits Maintenance Activities with Quantitative Changes in Source Code",
    "year": 2021,
    "ML_Techniques": "XG",
    "Category": "Program comprehension",
    "Sub_category": "Program classification",
    "Venue": "ICEIS",
    "Link": "https://www.scitepress.org/Papers/2021/104017/104017.pdf",
    "bibtex": "article{970_Mariano2021,\n    author = \"Mariano, Richard VR and dos Santos, Geanderson E and Brandao, Wladmir Cardoso\",\n    title = \"Improve Classification of Commits Maintenance Activities with Quantitative Changes in Source Code\",\n    year = \"2021\"\n}\n\n",
    "abstract": "Software maintenance is an important stage of software development, contributing to the quality of the software. Previous studies have shown that maintenance activities spend more than 40% of the development effort,\nconsuming most part of the software budget. Understanding how these activities are performed can support\nmanagers to previously plan and allocate resources. Despite previous studies, there is still a lack of accurate models to classify software commits into maintenance activities. In this work, we deepen our previous\nwork, in which we proposed improvements in one of the state-of-art techniques to classify software commits.\nFirst, we include three additional features that concern the size of the commit, from the state-of-art technique.\nSecond, we propose the use of the XGBoost, one of the most advanced implementations of boosting tree algorithms, and tends to outperform other machine learning models. Additionally, we present a deep analysis\nof our model to understand their decisions. Our findings show that our model outperforms the state-of-art\ntechnique achieving more than 77% of accuracy and more than 64% in the Kappa metric."
},
{
    "py/object": "data.DataClassPaper",
    "Title": "Feature Changes in Source Code for Commit Classification Into Maintenance Activities",
    "year": 2019,
    "ML_Techniques": "XG, RF",
    "Category": "Program comprehension",
    "Sub_category": "Program classification",
    "Venue": "ICMLA",
    "Link": "https://ieeexplore.ieee.org/abstract/document/8999295",
    "bibtex": "inproceedings{971_Mariano2019,\n    author = \"Mariano, Richard VR and dos Santos, Geanderson E and de Almeida, Markos V and Brand{\\\\textasciitilde a}o, Wladmir C\",\n    title = \"Feature changes in source code for commit classification into maintenance activities\",\n    booktitle = \"2019 18th IEEE International Conference On Machine Learning And Applications (ICMLA)\",\n    pages = \"515--518\",\n    year = \"2019\",\n    organization = \"IEEE\"\n}\n\n",
    "abstract": "Software maintenance plays an important role during software development and life cycle. Indeed, previous works show that maintenance activities consume most of the software budget. Therefore, understanding how these activities are performed can help software managers to previously plan and allocate resources in projects. Despite previous works, there is still a lack in accurate models to classify developers commits into maintenance activities. In the present article, we propose improvements in a state-of-the-art approach used to classify commits. Particularly, we include three additional features in the classification model and we use XGBoost, a boosting tree learning algorithm, for classification. Experimental results show that our approach outperforms the state-of-the-art baseline achieving more than 77% of accuracy and more than 64% in Kappa metric."
},
{
    "py/object": "data.DataClassPaper",
    "Title": "R2Fix: Automatically Generating Bug Fixes from Bug Reports",
    "year": 2013,
    "ML_Techniques": "",
    "Category": "Program synthesis",
    "Sub_category": "Program Repair",
    "Venue": "ICST",
    "Link": "https://ieeexplore.ieee.org/abstract/document/6569740",
    "bibtex": "inproceedings{975_Liu2013,\n    author = \"Liu, Chen and Yang, Jinqiu and Tan, Lin and Hafiz, Munawar\",\n    title = \"R2Fix: Automatically generating bug fixes from bug reports\",\n    booktitle = \"2013 IEEE Sixth international conference on software testing, verification and validation\",\n    pages = \"282--291\",\n    year = \"2013\",\n    organization = \"IEEE\"\n}\n\n",
    "abstract": "Many bugs, even those that are known and documented in bug reports, remain in mature software for a long time due to the lack of the development resources to fix them. We propose a general approach, R2Fix, to automatically generate bug-fixing patches from free-form bug reports. R2Fix combines past fix patterns, machine learning techniques, and semantic patch generation techniques to fix bugs automatically. We evaluate R2Fix on three projects, i.e., the Linux kernel, Mozilla, and Apache, for three important types of bugs: buffer overflows, null pointer bugs, and memory leaks. R2Fix generates 57 patches correctly, 5 of which are new patches for bugs that have not been fixed by developers yet. We reported all 5 new patches to the developers; 4 have already been accepted and committed to the code repositories. The 57 correct patches generated by R2Fix could have shortened and saved up to an average of 63 days of bug diagnosis and patch generation time."
},
{
    "py/object": "data.DataClassPaper",
    "Title": "A Survey of Automatic Source Code Summarization",
    "year": 2022,
    "ML_Techniques": "",
    "Category": "Program comprehension",
    "Sub_category": "Code summarization",
    "Venue": "Symmetry",
    "Link": "https://www.mdpi.com/2073-8994/14/3/471",
    "bibtex": "article{981_Zhang2022,\n    author = \"Zhang, Chunyan and Wang, Junchao and Zhou, Qinglei and Xu, Ting and Tang, Ke and Gui, Hairen and Liu, Fudong\",\n    title = \"A Survey of Automatic Source Code Summarization\",\n    journal = \"Symmetry\",\n    volume = \"14\",\n    number = \"3\",\n    pages = \"471\",\n    year = \"2022\",\n    publisher = \"MDPI\"\n}\n\n",
    "abstract": "ource code summarization refers to the natural language description of the source code\u2019s function. It can help developers easily understand the semantics of the source code. We can think of the source code and the corresponding summarization as being symmetric. However, the existing source code summarization is mismatched with the source code, missing, or out of date. Manual source code summarization is inefficient and requires a lot of human efforts. To overcome such situations, many studies have been conducted on Automatic Source Code Summarization (ASCS). Given a set of source code, the ASCS techniques can automatically generate a summary described with natural language. In this paper, we give a review of the development of ASCS technology. Almost all ASCS technology involves the following stages: source code modeling, code summarization generation, and quality evaluation. We further categorize the existing ASCS techniques based on the above stages and analyze their advantages and shortcomings. We also draw a clear map on the development of the existing algorithms."
},
{
    "py/object": "data.DataClassPaper",
    "Title": "Automatic source code summarization with Graph Attention Networks",
    "year": 2022,
    "ML_Techniques": "GNN",
    "Category": "Program comprehension",
    "Sub_category": "Code summarization",
    "Venue": "Journal of Systems and Software",
    "Link": "https://www.sciencedirect.com/science/article/abs/pii/S0164121222000279",
    "bibtex": "article{982_Zhou2022,\n    author = \"Zhou, Yu and Shen, Juanjuan and Zhang, Xiaoqing and Yang, Wenhua and Han, Tingting and Chen, Taolue\",\n    title = \"Automatic source code summarization with graph attention networks\",\n    journal = \"Journal of Systems and Software\",\n    volume = \"188\",\n    pages = \"111257\",\n    year = \"2022\",\n    publisher = \"Elsevier\"\n}\n\n",
    "abstract": "Source code summarization aims to generate concise descriptions for code snippets in a\u00a0natural language, thereby facilitates\u00a0program comprehension\u00a0and software maintenance. In this paper, we propose a novel approach\u2013GSCS\u2013to automatically generate summaries for Java methods, which leverages both semantic and structural information of the code snippets. To this end,\u00a0GSCS\u00a0utilizes Graph\u00a0Attention Networks\u00a0to process the tokenized\u00a0abstract syntax tree\u00a0of the program, which employ a multi-head attention mechanism to learn node features in diverse representation sub-spaces, and aggregate features by assigning different weights to its neighbor nodes.\u00a0GSCS\u00a0further harnesses an additional RNN-based sequence model to obtain the\u00a0semantic features\u00a0and optimizes the structure by combining its output with a transformed embedding layer. We evaluate our approach on two widely-adopted Java datasets; the experiment results confirm that\u00a0GSCS\u00a0outperforms the state-of-the-art"
},
{
    "py/object": "data.DataClassPaper",
    "Title": "Code Generation as a Dual Task of Code Summarization",
    "year": 2019,
    "ML_Techniques": "Seq2Seq, Bi-LSTM, LSTM",
    "Category": "Program synthesis",
    "Sub_category": "",
    "Venue": "NeurIPS",
    "Link": "https://proceedings.neurips.cc/paper/2019/hash/e52ad5c9f751f599492b4f087ed7ecfc-Abstract.html",
    "bibtex": "article{986_Wei2019,\n    author = \"Wei, Bolin and Li, Ge and Xia, Xin and Fu, Zhiyi and Jin, Zhi\",\n    title = \"Code generation as a dual task of code summarization\",\n    journal = \"Advances in neural information processing systems\",\n    volume = \"32\",\n    year = \"2019\"\n}\n\n",
    "abstract": "Code summarization (CS) and code generation (CG) are two crucial tasks in the field of automatic software development. Various neural network-based approaches are proposed to solve these two tasks separately. However, there exists a specific intuitive correlation between CS and CG, which has not been exploited in previous work. In this paper, we apply the relations between two tasks to improve the performance of both tasks. In other words, exploiting the duality between the two tasks, we propose a dual training framework to train the two tasks simultaneously. In this framework, we consider the dualities on probability and attention weights, and design corresponding regularization terms to constrain the duality. We evaluate our approach on two datasets collected from GitHub, and experimental results show that our dual framework can improve the performance of CS and CG tasks over baselines.\n\n"
},
{
    "py/object": "data.DataClassPaper",
    "Title": "Why My Code Summarization Model Does Not Work: Code Comment Improvement with Category Prediction",
    "year": 2021,
    "ML_Techniques": "RF, DT, DNN",
    "Category": "Program comprehension",
    "Sub_category": "Code summarization",
    "Venue": "TOSEM",
    "Link": "https://dl.acm.org/doi/abs/10.1145/3434280",
    "bibtex": "article{988_Chen2021,\n    author = \"Chen, Qiuyuan and Xia, Xin and Hu, Han and Lo, David and Li, Shanping\",\n    title = \"Why my code summarization model does not work: Code comment improvement with category prediction\",\n    journal = \"ACM Transactions on Software Engineering and Methodology (TOSEM)\",\n    volume = \"30\",\n    number = \"2\",\n    pages = \"1--29\",\n    year = \"2021\",\n    publisher = \"ACM New York, NY, USA\"\n}\n\n",
    "abstract": "Code summarization aims at generating a code comment given a block of source code and it is normally performed by training machine learning algorithms on existing code block-comment pairs. Code comments in practice have different intentions. For example, some code comments might explain how the methods work, while others explain why some methods are written. Previous works have shown that a relationship exists between a code block and the category of a comment associated with it. In this article, we aim to investigate to which extent we can exploit this relationship to improve code summarization performance. We first classify comments into six intention categories and manually label 20,000 code-comment pairs. These categories include \u201cwhat,\u201d \u201cwhy,\u201d \u201chow-to-use,\u201d \u201chow-it-is-done,\u201d \u201cproperty,\u201d and \u201cothers.\u201d Based on this dataset, we conduct an experiment to investigate the performance of different state-of-the-art code summarization approaches on the categories. We find that the performance of different code summarization approaches varies substantially across the categories. Moreover, the category for which a code summarization model performs the best is different for the different models. In particular, no models perform the best for \u201cwhy\u201d and \u201cproperty\u201d comments among the six categories. We design a composite approach to demonstrate that comment category prediction can boost code summarization to reach better results. The approach leverages classified code-category labeled data to train a classifier to infer categories. Then it selects the most suitable models for inferred categories and outputs the composite results. Our composite approach outperforms other approaches that do not consider comment categories and obtains a relative improvement of 8.57% and 16.34% in terms of ROUGE-L and BLEU-4 score, respectively."
},
{
    "py/object": "data.DataClassPaper",
    "Title": "Improved Automatic Summarization of Subroutines via Attention to File Context",
    "year": 2020,
    "ML_Techniques": "RNN",
    "Category": "Program comprehension",
    "Sub_category": "Code summarization",
    "Venue": "MSR",
    "Link": "https://dl.acm.org/doi/abs/10.1145/3379597.3387449",
    "bibtex": "inproceedings{989_Haque2020,\n    author = \"Haque, Sakib and LeClair, Alexander and Wu, Lingfei and McMillan, Collin\",\n    title = \"Improved automatic summarization of subroutines via attention to file context\",\n    booktitle = \"Proceedings of the 17th International Conference on Mining Software Repositories\",\n    pages = \"300--310\",\n    year = \"2020\"\n}\n\n",
    "abstract": "Software documentation largely consists of short, natural language summaries of the subroutines in the software. These summaries help programmers quickly understand what a subroutine does without having to read the source code him or herself. The task of writing these descriptions is called \"source code summarization\" and has been a target of research for several years. Recently, AI-based approaches have superseded older, heuristic-based approaches. Yet, to date these AI-based approaches assume that all the content needed to predict summaries is inside subroutine itself. This assumption limits performance because many subroutines cannot be understood without surrounding context. In this paper, we present an approach that models the file context of subroutines (i.e. other subroutines in the same file) and uses an attention mechanism to find words and concepts to use in summaries. We show in an experiment that our approach extends and improves several recent baselines."
},
{
    "py/object": "data.DataClassPaper",
    "Title": "Advances in Code Summarization",
    "year": 2021,
    "ML_Techniques": "",
    "Category": "Program comprehension",
    "Sub_category": "Code summarization",
    "Venue": "ICSE",
    "Link": "https://ieeexplore.ieee.org/abstract/document/9402289",
    "bibtex": "inproceedings{991_Desai2021,\n    author = \"Desai, Utkarsh and Sridhara, Giriprasad and Tamilselvam, Srikanth G\",\n    title = \"Advances in code summarization\",\n    booktitle = \"2021 IEEE/ACM 43rd International Conference on Software Engineering: Companion Proceedings (ICSE-Companion)\",\n    pages = \"330--331\",\n    year = \"2021\",\n    organization = \"IEEE\"\n}\n\n",
    "abstract": "Several studies have suggested that comments describing source code can help mitigate the burden of program understanding. However, software systems usually lack adequate comments and even when present, the comments may be obsolete or unhelpful. Researchers have addressed this issue by automatically generating comments from source code, a task referred to as Code Summarization. In this technical presentation, we take a deeper look at some of the significant, recent works in the area of code summarization and how each of them attempts to take a new perspective of this task including methods leveraging RNNs, Transformers, Graph neural networks and Reinforcement learning."
},
{
    "py/object": "data.DataClassPaper",
    "Title": "Reinforcement-Learning-Guided Source Code Summarization Using Hierarchical Attention",
    "year": 2020,
    "ML_Techniques": "RL",
    "Category": "Program comprehension",
    "Sub_category": "Code summarization",
    "Venue": "TSE",
    "Link": "https://ieeexplore.ieee.org/abstract/document/9031440",
    "bibtex": "article{992_Wang2020,\n    author = \"Wang, Wenhua and Zhang, Yuqun and Sui, Yulei and Wan, Yao and Zhao, Zhou and Wu, Jian and Yu, Philip and Xu, Guandong\",\n    title = \"Reinforcement-learning-guided source code summarization via hierarchical attention\",\n    journal = \"IEEE Transactions on software Engineering\",\n    year = \"2020\",\n    publisher = \"IEEE\"\n}\n\n",
    "abstract": "Code summarization (aka comment generation) provides a high-level natural language description of the function performed by code, which can benefit the software maintenance, code categorization and retrieval. To the best of our knowledge, the state-of-the-art approaches follow an encoder-decoder framework which encodes source code into a hidden space and later decodes it into a natural language space. Such approaches suffer from the following drawbacks: (a) they are mainly input by representing code as a sequence of tokens while ignoring code hierarchy; (b) most of the encoders only input simple features (e.g., tokens) while ignoring the features that can help capture the correlations between comments and code; (c) the decoders are typically trained to predict subsequent words by maximizing the likelihood of subsequent ground truth words, while in real world, they are excepted to generate the entire word sequence from scratch. As a result, such drawbacks lead to inferior and inconsistent comment generation accuracy. To address the above limitations, this paper presents a new code summarization approach using hierarchical attention network by incorporating multiple code features, including type-augmented abstract syntax trees and program control flows. Such features, along with plain code sequences, are injected into a deep reinforcement learning (DRL) framework (e.g., actor-critic network) for comment generation. Our approach assigns weights (pays \u201cattention\u201d) to tokens and statements when constructing the code representation to reflect the hierarchical code structure under different contexts regarding code features (e.g., control flows and abstract syntax trees). Our reinforcement learning mechanism further strengthens the prediction results through the actor network and the critic network, where the actor network provides the confidence of predicting subsequent words based on the current state, and the critic network computes the reward values of all the possible extensions of the current state to provide global guidance for explorations. Eventually, we employ an advantage reward to train both networks and conduct a set of experiments on a real-world dataset. The experimental results demonstrate that our approach outperforms the baselines by around 22 to 45 percent in BLEU-1 and outperforms the state-of-the-art approaches by around 5 to 60 percent in terms of S-BLEU and C-BLEU."
},
{
    "py/object": "data.DataClassPaper",
    "Title": "Adversarial training and ensemble learning for automatic code summarization",
    "year": 2021,
    "ML_Techniques": "EL",
    "Category": "Program comprehension",
    "Sub_category": "Code summarization",
    "Venue": "Neural Computing and Applications",
    "Link": "https://link.springer.com/article/10.1007/s00521-021-05907-w",
    "bibtex": "article{993_Zhou2021,\n    author = \"Zhou, Ziyi and Yu, Huiqun and Fan, Guisheng\",\n    title = \"Adversarial training and ensemble learning for automatic code summarization\",\n    journal = \"Neural Computing and Applications\",\n    volume = \"33\",\n    number = \"19\",\n    pages = \"12571--12589\",\n    year = \"2021\",\n    publisher = \"Springer\"\n}\n\n",
    "abstract": "Natural language summaries of codes are important during software development and maintenance. Recently, deep learning-based models have achieved good performance on automatic code summarization, which encode token sequence or abstract syntax tree (AST) of code with neural networks. However, almost all of these models are trained using maximum likelihood estimation, which do not guarantee the quality of generated summaries. Moreover, existing models that benefit from multiple encoders lack a fined-grained selection between different encoders, and the encoders may be insufficiently optimized. To address these issues and generate better code summaries, we propose a novel code summarization framework based on adversarial training and ensemble learning. It includes two separately trained encoder-decoder models, one for source code sequence and the other for its AST. Here, an efficient approach to obtain AST node sequence is introduced. We train our models via adversarial training, where each model is guided by a well-designed discriminator that learns to evaluate its outputs. During inference, a module named mixture network is introduced to compute an adaptive combination weight of the models\u2019 outputs. We evaluate our framework on a large Java corpus and compare it to several state-of-the-art models. Experimental results show that our approach outperforms the best baseline by 22.6% on BLEU-4, 5.7% on ROUGE-L and 7.6% on METEOR."
},
{
    "py/object": "data.DataClassPaper",
    "Title": "Ensemble Models for Neural Source Code Summarization of Subroutines",
    "year": 2021,
    "ML_Techniques": "Seq2Seq",
    "Category": "Program comprehension",
    "Sub_category": "Code summarization",
    "Venue": "ICSME",
    "Link": "https://ieeexplore.ieee.org/abstract/document/9609119",
    "bibtex": "inproceedings{994_LeClair2021,\n    author = \"LeClair, Alexander and Bansal, Aakash and McMillan, Collin\",\n    title = \"Ensemble Models for Neural Source Code Summarization of Subroutines\",\n    booktitle = \"2021 IEEE International Conference on Software Maintenance and Evolution (ICSME)\",\n    pages = \"286--297\",\n    year = \"2021\",\n    organization = \"IEEE\"\n}\n\n",
    "abstract": "A source code summary of a subroutine is a brief description of that subroutine. Summaries underpin a majority of documentation consumed by programmers, such as the method summaries in JavaDocs. Source code summarization is the task of writing these summaries. At present, most state-of-the-art approaches for code summarization are neural network-based solutions akin to seq2seq, graph2seq, and other encoder-decoder architectures. The input to the encoder is source code, while the decoder helps predict the natural language summary. While these models tend to be similar in structure, evidence is emerging that different models make different contributions to prediction quality - differences in model performance are orthogonal and complementary rather than uniform over the entire dataset. In this paper, we explore the orthogonal nature of different neural code summarization approaches and propose ensemble models to exploit this orthogonality for better overall performance. We demonstrate that a simple ensemble strategy boosts performance by up to 14.8%, and provide an explanation for this boost. The takeaway from this work is that a relatively small change to the inference procedure in most neural code summarization techniques leads to outsized improvements in prediction quality."
},
{
    "py/object": "data.DataClassPaper",
    "Title": "Action Word Prediction for Neural Source Code Summarization",
    "year": 2021,
    "ML_Techniques": "code2seq",
    "Category": "Program comprehension",
    "Sub_category": "Code summarization",
    "Venue": "SANER",
    "Link": "https://ieeexplore.ieee.org/abstract/document/9425934",
    "bibtex": "inproceedings{995_Haque2021,\n    author = \"Haque, Sakib and Bansal, Aakash and Wu, Lingfei and McMillan, Collin\",\n    title = \"Action word prediction for neural source code summarization\",\n    booktitle = \"2021 IEEE International Conference on Software Analysis, Evolution and Reengineering (SANER)\",\n    pages = \"330--341\",\n    year = \"2021\",\n    organization = \"IEEE\"\n}\n\n",
    "abstract": "Source code summarization is the task of creating short, natural language descriptions of source code. Code summarization is the backbone of much software documentation such as JavaDocs, in which very brief comments such as \"adds the customer object\" help programmers quickly understand a snippet of code. In recent years, automatic code summarization has become a high value target of research, with approaches based on neural networks making rapid progress. However, as we will show in this paper, the production of good summaries relies on the production of the action word in those summaries: the meaning of the example above would be completely changed if \"removes\" were substituted for \"adds.\" In this paper, we advocate for a special emphasis on action word prediction as an important stepping stone problem towards better code summarization - current techniques try to predict the action word along with the whole summary, and yet action word prediction on its own is quite difficult. We show the value of the problem for code summaries, explore the performance of current baselines, and provide recommendations for future research."
},
{
    "py/object": "data.DataClassPaper",
    "Title": "A Mechanism for Automatically Summarizing Software Functionality from Source Code",
    "year": 2019,
    "ML_Techniques": "",
    "Category": "Program comprehension",
    "Sub_category": "Code summarization",
    "Venue": "QRS",
    "Link": "https://ieeexplore.ieee.org/abstract/document/8854713",
    "bibtex": "inproceedings{998_Psarras2019,\n    author = \"Psarras, Christos and Diamantopoulos, Themistoklis and Symeonidis, Andreas\",\n    title = \"A mechanism for automatically summarizing software functionality from source code\",\n    booktitle = \"2019 IEEE 19th International Conference on Software Quality, Reliability and Security (QRS)\",\n    pages = \"121--130\",\n    year = \"2019\",\n    organization = \"IEEE\"\n}\n\n",
    "abstract": "When developers search online to find software components to reuse, they usually first need to understand the container projects/libraries, and subsequently identify the required functionality. Several approaches identify and summarize the offerings of projects from their source code, however they often require that the developer has knowledge of the underlying topic modeling techniques; they do not provide a mechanism for tuning the number of topics, and they offer no control over the top terms for each topic. In this work, we use a vectorizer to extract information from variable/method names and comments, and apply Latent Dirichlet Allocation to cluster the source code files of a project into different semantic topics. The number of topics is optimized based on their purity with respect to project packages, while topic categories are constructed to provide further intuition and Stack Exchange tags are used to express the topics in more abstract terms."
},
{
    "py/object": "data.DataClassPaper",
    "Title": "EditSum: A Retrieve-and-Edit Framework for Source Code Summarization",
    "year": 2021,
    "ML_Techniques": "LSTM",
    "Category": "Program comprehension",
    "Sub_category": "Code summarization",
    "Venue": "ASE",
    "Link": "https://ieeexplore.ieee.org/abstract/document/9678724",
    "bibtex": "inproceedings{999_Li2021,\n    author = \"Li, Jia and Li, Yongmin and Li, Ge and Hu, Xing and Xia, Xin and Jin, Zhi\",\n    title = \"EditSum: A Retrieve-and-Edit Framework for Source Code Summarization\",\n    booktitle = \"2021 36th IEEE/ACM International Conference on Automated Software Engineering (ASE)\",\n    pages = \"155--166\",\n    year = \"2021\",\n    organization = \"IEEE\"\n}\n\n",
    "abstract": "Existing studies show that code summaries help developers understand and maintain source code. Unfortunately, these summaries are often missing or outdated in software projects. Code summarization aims to generate natural language descriptions automatically for source code. According to Gros et al., code summaries are highly structured and have repetitive patterns (e.g. \"return true if...\"). Besides the patternized words, a code summary also contains important keywords, which are the key to reflecting the functionality of the code. However, the state-of-the-art approaches perform poorly on predicting the keywords, which leads to the generated summaries suffer a loss in informativeness. To alleviate this problem, this paper proposes a novel retrieve-and-edit approach named EditSum for code summarization. Specifically, EditSum first retrieves a similar code snippet from a pre-defined corpus and treats its summary as a prototype summary to learn the pattern. Then, EditSum edits the prototype automatically to combine the pattern in the prototype with the semantic information of input code. Our motivation is that the retrieved prototype provides a good start-point for post-generation because the summaries of similar code snippets often have the same pattern. The post-editing process further reuses the patternized words in prototype and generates keywords based on the semantic information of input code. We conduct experiments on a large-scale Java corpus (2M) and experimental results demonstrate that EditSum outperforms the state-of-the-art approaches by a substantial margin. The human evaluation also proves the summaries generated by EditSum are more informative and useful. We also verify that EditSum performs well on predicting the patternized words and keywords."
},
{
    "py/object": "data.DataClassPaper",
    "Title": "A Survey of Automatic Generation of Source Code Comments: Algorithms and Techniques",
    "year": 2019,
    "ML_Techniques": "",
    "Category": "Program comprehension",
    "Sub_category": "Code summarization",
    "Venue": "IEEE Access",
    "Link": "https://ieeexplore.ieee.org/abstract/document/8778714",
    "bibtex": "article{1000_Song2019,\n    author = \"Song, Xiaotao and Sun, Hailong and Wang, Xu and Yan, Jiafei\",\n    title = \"A survey of automatic generation of source code comments: Algorithms and techniques\",\n    journal = \"IEEE Access\",\n    volume = \"7\",\n    pages = \"111411--111428\",\n    year = \"2019\",\n    publisher = \"IEEE\"\n}\n\n",
    "abstract": "As an integral part of source code files, code comments help improve program readability and comprehension. However, developers sometimes do not comment their program code adequately due to the incurred extra efforts, lack of relevant knowledge, unawareness of the importance of code commenting or some other factors. As a result, code comments can be inadequate, absent or even mismatched with source code, which affects the understanding, reusing and the maintenance of software. To solve these problems of code comments, researchers have been concerned with generating code comments automatically. In this work, we aim at conducting a survey of automatic code commenting researches. First, we generally analyze the challenges and research framework of automatic generation of program comments. Second, we present the classification of representative algorithms, the design principles, strengths and weaknesses of each category of algorithms. Meanwhile, we also provide an overview of the quality assessment of the generated comments. Finally, we summarize some future directions for advancing the techniques of automatic generation of code comments and the quality assessment of comments."
},
{
    "py/object": "data.DataClassPaper",
    "Title": "On Multi-Modal Learning of Editing Source Code",
    "year": 2021,
    "ML_Techniques": "NMT",
    "Category": "Code representation",
    "Sub_category": "",
    "Venue": "ASE",
    "Link": "https://ieeexplore.ieee.org/abstract/document/9678559",
    "bibtex": "INPROCEEDINGS{1003_Chakraborty2021,\n    author = \"Chakraborty, Saikat and Ray, Baishakhi\",\n    booktitle = \"2021 36th IEEE/ACM International Conference on Automated Software Engineering (ASE)\",\n    title = \"On Multi-Modal Learning of Editing Source Code\",\n    year = \"2021\",\n    volume = \"\",\n    number = \"\",\n    pages = \"443-455\",\n    doi = \"10.1109/ASE51524.2021.1003_Chakraborty2021\"\n}\n\n",
    "abstract": "In recent years, Neural Machine Translator (NMT) has shown promise in automatically editing source code. Typical NMT based code editor only considers the code that needs to be changed as input and suggests developers with a ranked list of patched code to choose from - where the correct one may not always be at the top of the list. While NMT based code editing systems generate a broad spectrum of plausible patches, the correct one depends on the developers\u2019 requirement and often on the context where the patch is applied. Thus, if developers provide some hints, using natural language, or providing patch context, NMT models can benefit from them.As a proof of concept, in this research, we leverage three modalities of information: edit location, edit code context, commit messages (as a proxy of developers\u2019 hint in natural language) to automatically generate edits with NMT models. To that end, we build Modit, a multi-modal NMT based code editing engine. With in-depth investigation and analysis, we show that developers\u2019 hint as an input modality can narrow the search space for patches and outperform state-of-the-art models to generate correctly patched code in top-1 position."
},
{
    "py/object": "data.DataClassPaper",
    "Title": "Improving Code Summarization with Block-wise Abstract Syntax Tree Splitting",
    "year": 2021,
    "ML_Techniques": "LSTM, TF",
    "Category": "Program comprehension",
    "Sub_category": "Code summarization",
    "Venue": "ICPC",
    "Link": "https://ieeexplore.ieee.org/abstract/document/9463007",
    "bibtex": "inproceedings{1006_Lin2021,\n    author = \"Lin, Chen and Ouyang, Zhichao and Zhuang, Junqing and Chen, Jianqiang and Li, Hui and Wu, Rongxin\",\n    title = \"Improving code summarization with block-wise abstract syntax tree splitting\",\n    booktitle = \"2021 IEEE/ACM 29th International Conference on Program Comprehension (ICPC)\",\n    pages = \"184--195\",\n    year = \"2021\",\n    organization = \"IEEE\"\n}\n\n",
    "abstract": "Automatic code summarization frees software developers from the heavy burden of manual commenting and benefits software development and maintenance. Abstract Syntax Tree (AST), which depicts the source code\u2019s syntactic structure, has been incorporated to guide the generation of code summaries. However, existing AST based methods suffer from the difficulty of training and generate inadequate code summaries. In this paper, we present the Block-wise Abstract Syntax Tree Splitting method (BASTS for short), which fully utilizes the rich tree-form syntax structure in ASTs, for improving code summarization. BASTS splits the code of a method based on the blocks in the dominator tree of the Control Flow Graph, and generates a split AST for each code split. Each split AST is then modeled by a Tree-LSTM using a pre-training strategy to capture local non-linear syntax encoding. The learned syntax encoding is combined with code encoding, and fed into Transformer to generate high-quality code summaries. Comprehensive experiments on benchmarks have demonstrated that BASTS significantly outperforms state-of-the-art approaches in terms of various evaluation metrics. To facilitate reproducibility, our implementation is available at https://github.com/XMUDM/BASTS."
},
{
    "py/object": "data.DataClassPaper",
    "Title": "CoreGen: Contextualized Code Representation Learning for Commit Message Generation",
    "year": 2021,
    "ML_Techniques": "TF",
    "Category": "Code representation",
    "Sub_category": "",
    "Venue": "Neurocomputing",
    "Link": "https://www.sciencedirect.com/science/article/abs/pii/S092523122100792X",
    "bibtex": "article{1009_Nie2021,\n    author = \"Nie, Lun Yiu and Gao, Cuiyun and Zhong, Zhicong and Lam, Wai and Liu, Yang and Xu, Zenglin\",\n    title = \"CoreGen: Contextualized Code Representation Learning for Commit Message Generation\",\n    journal = \"Neurocomputing\",\n    volume = \"459\",\n    pages = \"97--107\",\n    year = \"2021\",\n    publisher = \"Elsevier\"\n}\n\n",
    "abstract": "Automatic generation of high-quality commit messages for code commits can substantially facilitate software developers\u2019 works and coordination. However, the semantic gap between source code and\u00a0natural language\u00a0poses a major challenge for the task. Several studies have been proposed to alleviate the challenge but none explicitly involves code contextual information during commit message generation. Specifically, existing research adopts static embedding for code tokens, which maps a token to the same vector regardless of\u00a0its context. In this paper, we propose a novel\u00a0Contextualized code\u00a0representation learning strategy for commit message\u00a0Generation (CoreGen). CoreGen first learns contextualized code representations which exploit the contextual information behind code commit sequences. The learned representations of code commits built upon Transformer are then fine-tuned for downstream commit message generation. Experiments on the benchmark dataset demonstrate the superior effectiveness of our model over the\u00a0baseline models\u00a0with at least 28.18% improvement in terms of BLEU-4 score. Furthermore, we also highlight the future opportunities in training contextualized code representations on larger code corpus as a solution to low-resource tasks and adapting the contextualized code representation framework to other code-to-text generation tasks."
},
{
    "py/object": "data.DataClassPaper",
    "Title": "ATOM: Commit Message Generation Based on Abstract Syntax Tree and Hybrid Ranking",
    "year": 2020,
    "ML_Techniques": "Bi-LSTM, CNN",
    "Category": "Program comprehension",
    "Sub_category": "Code summarization",
    "Venue": "IEEE Transactions on Software Engineering",
    "Link": "https://ieeexplore.ieee.org/abstract/document/9261989",
    "bibtex": "article{1010_Liu2020,\n    author = \"Liu, Shangqing and Gao, Cuiyun and Chen, Sen and Yiu, Nie Lun and Liu, Yang\",\n    title = \"ATOM: Commit message generation based on abstract syntax tree and hybrid ranking\",\n    journal = \"IEEE Transactions on Software Engineering\",\n    year = \"2020\",\n    publisher = \"IEEE\"\n}\n\n",
    "abstract": "Commit messages record code changes (e.g., feature modifications and bug repairs) in natural language, and are useful for program comprehension. Due to the frequent updates of software and time cost, developers are generally unmotivated to write commit messages for code changes. Therefore, automating the message writing process is necessitated. Previous studies on commit message generation have been benefited from generation models or retrieval models, but the code structure of changed code, i.e., AST, which can be important for capturing code semantics, has not been explicitly involved. Moreover, although generation models have the advantages of synthesizing commit messages for new code changes, they are not easy to bridge the semantic gap between code and natural languages which could be mitigated by retrieval models. In this paper, we propose a novel commit message generation model, named ATOM, which explicitly incorporates the abstract syntax tree for representing code changes and integrates both retrieved and generated messages through hybrid ranking. Specifically, the hybrid ranking module can prioritize the most accurate message from both retrieved and generated messages regarding one code change. We evaluate the proposed model ATOM on our dataset crawled from 56 popular Java repositories. Experimental results demonstrate that ATOM increases the state-of-the-art models by 30.72 percent in terms of BLEU-4 (an accuracy measure that is widely used to evaluate text generation systems). Qualitative analysis also demonstrates the effectiveness of ATOM in generating accurate code commit messages."
},
{
    "py/object": "data.DataClassPaper",
    "Title": "On the Evaluation of Commit Message Generation Models: An Experimental Study",
    "year": 2021,
    "ML_Techniques": "",
    "Category": "Program comprehension",
    "Sub_category": "Code summarization",
    "Venue": "ICSME",
    "Link": "https://ieeexplore.ieee.org/abstract/document/9609189",
    "bibtex": "inproceedings{1011_Tao2021,\n    author = \"Tao, Wei and Wang, Yanlin and Shi, Ensheng and Du, Lun and Han, Shi and Zhang, Hongyu and Zhang, Dongmei and Zhang, Wenqiang\",\n    title = \"On the Evaluation of Commit Message Generation Models: An Experimental Study\",\n    booktitle = \"2021 IEEE International Conference on Software Maintenance and Evolution (ICSME)\",\n    pages = \"126--136\",\n    year = \"2021\",\n    organization = \"IEEE\"\n}\n\n",
    "abstract": "Commit messages are natural language descriptions of code changes, which are important for program understanding and maintenance. However, writing commit messages manually is time-consuming and laborious, especially when the code is updated frequently. Various approaches utilizing generation or retrieval techniques have been proposed to automatically generate commit messages. To achieve a better understanding of how the existing approaches perform in solving this problem, this paper conducts a systematic and in-depth analysis of the state-of-the-art models and datasets. We find that: (1) Different variants of the BLEU metric are used in previous works, which affects the evaluation and understanding of existing methods. (2) Most existing datasets are crawled only from Java repositories while repositories in other programming languages are not sufficiently explored. (3) Dataset splitting strategies can influence the performance of existing models by a large margin. Some models show better performance when the datasets are split by commit, while other models perform better when the datasets are split by timestamp or by project. Based on our findings, we conduct a human evaluation and find the BLEU metric that best correlates with the human scores for the task. We also collect a large-scale, information-rich, and multi-language commit message dataset MCMD and evaluate existing models on this dataset. Furthermore, we conduct extensive experiments under different dataset splitting strategies and suggest the suitable models under different scenarios. Based on the experimental results and findings, we provide feasible suggestions for comprehensively evaluating commit message generation models and discuss possible future research directions. We believe this work can help practitioners and researchers better evaluate and select models for automatic commit message generation. Our source code and data are available at https://github.com/DeepSoftwareAnalytics/CommitMsgEmpirical."
},
{
    "py/object": "data.DataClassPaper",
    "Title": "On the Relevance of Cross-project Learning with Nearest Neighbours for Commit Message Generation",
    "year": 2020,
    "ML_Techniques": "KNN, DNN",
    "Category": "Program comprehension",
    "Sub_category": "Code summarization",
    "Venue": "ICSEW",
    "Link": "https://dl.acm.org/doi/abs/10.1145/3387940.3391488",
    "bibtex": "inproceedings{1013_Etemadi2020,\n    author = \"Etemadi, Khashayar and Monperrus, Martin\",\n    title = \"On the Relevance of Cross-project Learning with Nearest Neighbours for Commit Message Generation\",\n    booktitle = \"Proceedings of the IEEE/ACM 42nd International Conference on Software Engineering Workshops\",\n    pages = \"470--475\",\n    year = \"2020\"\n}\n\n",
    "abstract": "Commit messages play an important role in software maintenance and evolution. Nonetheless, developers often do not produce high-quality messages. A number of commit message generation methods have been proposed in recent years to address this problem. Some of these methods are based on neural machine translation (NMT) techniques. Studies show that the nearest neighbor algorithm (NNGen) outperforms existing NMT-based methods, although NNGen is simpler and faster than NMT. In this paper, we show that NNGen does not take advantage of cross-project learning in the majority of the cases. We also show that there is an even simpler and faster variation of the existing NNGen method which outperforms it in terms of the BLEU_4 score without using cross-project learning."
},
{
    "py/object": "data.DataClassPaper",
    "Title": "Automatic Generation of Pull Request Descriptions",
    "year": 2019,
    "ML_Techniques": "RL, EN-DE",
    "Category": "Program comprehension",
    "Sub_category": "Code summarization",
    "Venue": "ASE",
    "Link": "https://ieeexplore.ieee.org/abstract/document/8952330",
    "bibtex": "inproceedings{1014_Liu2019,\n    author = \"Liu, Zhongxin and Xia, Xin and Treude, Christoph and Lo, David and Li, Shanping\",\n    title = \"Automatic generation of pull request descriptions\",\n    booktitle = \"2019 34th IEEE/ACM International Conference on Automated Software Engineering (ASE)\",\n    pages = \"176--188\",\n    year = \"2019\",\n    organization = \"IEEE\"\n}\n\n",
    "abstract": "Enabled by the pull-based development model, developers can easily contribute to a project through pull requests (PRs). When creating a PR, developers can add a free-form description to describe what changes are made in this PR and/or why. Such a description is helpful for reviewers and other developers to gain a quick understanding of the PR without touching the details and may reduce the possibility of the PR being ignored or rejected. However, developers sometimes neglect to write descriptions for PRs. For example, in our collected dataset with over 333K PRs, more than 34% of the PR descriptions are empty. To alleviate this problem, we propose an approach to automatically generate PR descriptions based on the commit messages and the added source code comments in the PRs. We regard this problem as a text summarization problem and solve it using a novel sequence-to-sequence model. To cope with out-of-vocabulary words in software artifacts and bridge the gap between the training loss function of the sequence-to-sequence model and the evaluation metric ROUGE, which has been shown to correspond to human evaluation, we integrate the pointer generator and directly optimize for ROUGE using reinforcement learning and a special loss function. We build a dataset with over 41K PRs and evaluate our approach on this dataset through ROUGE and a human evaluation. Our evaluation results show that our approach outperforms two baselines by significant margins."
},
{
    "py/object": "data.DataClassPaper",
    "Title": "Context-aware retrieval-based deep commit message ",
    "year": 2021,
    "ML_Techniques": "LSTM, EN-DE",
    "Category": "Program comprehension",
    "Sub_category": "Code summarization",
    "Venue": "TOSEM",
    "Link": "https://ink.library.smu.edu.sg/cgi/viewcontent.cgi?article=7779&context=sis_research",
    "bibtex": "article{1015_Wang2021,\n    author = \"Wang, Haoye and Xia, Xin and Lo, David and He, Qiang and Wang, Xinyu and Grundy, John\",\n    title = \"Context-aware retrieval-based deep commit message Generation\",\n    journal = \"ACM Transactions on Software Engineering and Methodology (TOSEM)\",\n    volume = \"30\",\n    number = \"4\",\n    pages = \"1--30\",\n    year = \"2021\",\n    publisher = \"ACM New York, NY, USA\"\n}\n\n",
    "abstract": "Commit messages recorded in version control systems contain valuable information for software development,\nmaintenance, and comprehension. Unfortunately, developers often commit code with empty or poor quality\ncommit messages. To address this issue, several studies have proposed approaches to generate commit messages\nfrom commit diffs. Recent studies make use of neural machine translation algorithms to try and translate\ngit diffs into commit messages and have achieved some promising results. However, these learning-based\nmethods tend to generate high-frequency words but ignore low-frequency ones. In addition, they suffer from\nexposure bias issues, which leads to a gap between training phase and testing phase.\nIn this paper, we propose CoRec to address the above two limitations. Specifically, we first train a contextaware encoder-decoder model which randomly selects the previous output of the decoder or the embedding\nvector of a ground truth word as context to make the model gradually aware of previous alignment choices.\nGiven a diff for testing, the trained model is reused to retrieve the most similar diff from the training set.\nFinally, we use the retrieval diff to guide the probability distribution for the final generated vocabulary. Our\nmethod combines the advantages of both information retrieval and neural machine translation. We evaluate\nCoRec on a dataset from Liu et al. and a large-scale dataset crawled from 10k popular Java repositories in\nGithub. Our experimental results show that CoRec significantly outperforms the state-of-the-art method\nNNGen by 19% on average in terms of BLEU."
},
{
    "py/object": "data.DataClassPaper",
    "Title": "Learning Human-Written Commit Messages to Document Code Changes",
    "year": 2020,
    "ML_Techniques": "",
    "Category": "Program comprehension",
    "Sub_category": "Code summarization",
    "Venue": "JCST",
    "Link": "https://link.springer.com/article/10.1007/s11390-020-0496-0",
    "bibtex": "article{1018_Huang2020,\n    author = \"Huang, Yuan and Jia, Nan and Zhou, Hao-Jie and Chen, Xiang-Ping and Zheng, Zi-Bin and Tang, Ming-Dong\",\n    title = \"Learning human-written commit messages to document code changes\",\n    journal = \"Journal of Computer Science and Technology\",\n    volume = \"35\",\n    number = \"6\",\n    pages = \"1258--1277\",\n    year = \"2020\",\n    publisher = \"Springer\"\n}\n\n",
    "abstract": "Commit messages are important complementary information used in understanding code changes. To address message scarcity, some work is proposed for automatically generating commit messages. However, most of these approaches focus on generating summary of the changed software entities at the superficial level, without considering the intent behind the code changes (e.g., the existing approaches cannot generate such message: \u201cfixing null pointer exception\u201d). Considering developers often describe the intent behind the code change when writing the messages, we propose ChangeDoc, an approach to reuse existing messages in version control systems for automatical commit message generation. Our approach includes syntax, semantic, pre-syntax, and pre-semantic similarities. For a given commit without messages, it is able to discover its most similar past commit from a large commit repository, and recommend its message as the message of the given commit. Our repository contains half a million commits that were collected from SourceForge. We evaluate our approach on the commits from 10 projects. The results show that 21.5% of the recommended messages by ChangeDoc can be directly used without modification, and 62.8% require minor modifications. In order to evaluate the quality of the commit messages recommended by ChangeDoc, we performed two empirical studies involving a total of 40 participants (10 professional developers and 30 students). The results indicate that the recommended messages are very good approximations of the ones written by developers and often include important intent information that is not included in the messages generated by other tools."
},
{
    "py/object": "data.DataClassPaper",
    "Title": "A Machine Learning Approach to Classify Security Patches into Vulnerability Types",
    "year": 2020,
    "ML_Techniques": "RF, SVM",
    "Category": "Vulnerability analysis",
    "Sub_category": "",
    "Venue": "CNS",
    "Link": "https://ieeexplore.ieee.org/abstract/document/9162237",
    "bibtex": "INPROCEEDINGS{1019_Wang2020,\n    author = \"Wang, Xinda and Wang, Shu and Sun, Kun and Batcheller, Archer and Jajodia, Sushil\",\n    booktitle = \"2020 IEEE Conference on Communications and Network Security (CNS)\",\n    title = \"A Machine Learning Approach to Classify Security Patches into Vulnerability Types\",\n    year = \"2020\",\n    volume = \"\",\n    number = \"\",\n    pages = \"1-9\",\n    doi = \"10.1109/CNS48642.2020.1019_Wang2020\"\n}\n\n",
    "abstract": "With the increasing usage of open source software (OSS) in both free and proprietary applications, vulnerabilities embedded in OSS are also propagated to the underlying applications. It is critical to find security patches to fix these vulnerabilities, especially those essential to reduce security risk. Unfortunately, given a security patch, currently there does not exist a way to automatically recognize the vulnerability that is fixed. In this paper, we first conduct an empirical study on security patches by type (i.e., corresponding vulnerability type), using a large-scale dataset collected from the National Vulnerability Database (NVD). Based on analysis results, we develop a machine learning-based system to help identify the vulnerability type of a given security patch. The evaluation results show that our system achieves good performance."
},
{
    "py/object": "data.DataClassPaper",
    "Title": "Generating Commit Messages from Diffs using Pointer-Generator Network",
    "year": 2019,
    "ML_Techniques": "DNN",
    "Category": "Program comprehension",
    "Sub_category": "Code summarization",
    "Venue": "MSR",
    "Link": "https://ieeexplore.ieee.org/abstract/document/8816770",
    "bibtex": "inproceedings{1020_Liu2019,\n    author = \"Liu, Qin and Liu, Zihe and Zhu, Hongming and Fan, Hongfei and Du, Bowen and Qian, Yu\",\n    title = \"Generating commit messages from diffs using pointer-generator network\",\n    booktitle = \"2019 IEEE/ACM 16th International Conference on Mining Software Repositories (MSR)\",\n    pages = \"299--309\",\n    year = \"2019\",\n    organization = \"IEEE\"\n}\n\n",
    "abstract": "The commit messages in source code repositories are valuable but not easy to be generated manually in time for tracking issues, reporting bugs, and understanding codes. Recently published works indicated that the deep neural machine translation approaches have drawn considerable attentions on automatic generation of commit messages. However, they could not deal with out-of-vocabulary (OOV) words, which are essential context-specific identifiers such as class names and method names in code diffs. In this paper, we propose PtrGNCMsg, a novel approach which is based on an improved sequence-to-sequence model with the pointer-generator network to translate code diffs into commit messages. By searching the smallest identifier set with the highest probability, PtrGNCMsg outperforms recent approaches based on neural machine translation, and first enables the prediction of OOV words. The experimental results based on the corpus of diffs and manual commit messages from the top 2,000 Java projects in GitHub show that PtrGNCMsg outperforms the state-of-the-art approach with improved BLEU by 1.02, ROUGE-1 by 4.00 and ROUGE-L by 3.78, respectively."
},
{
    "py/object": "data.DataClassPaper",
    "Title": "RCLinker: Automated Linking of Issue Reports and Commits Leveraging Rich Contextual Information",
    "year": 2015,
    "ML_Techniques": "RF",
    "Category": "Program comprehension",
    "Sub_category": "",
    "Venue": "ICPC",
    "Link": "https://ieeexplore.ieee.org/abstract/document/7181431",
    "bibtex": "inproceedings{1021_Le2015,\n    author = \"Le, Tien-Duy B and Linares-V{\\'a}squez, Mario and Lo, David and Poshyvanyk, Denys\",\n    title = \"Rclinker: Automated linking of issue reports and commits leveraging rich contextual information\",\n    booktitle = \"2015 IEEE 23rd International Conference on Program Comprehension\",\n    pages = \"36--47\",\n    year = \"2015\",\n    organization = \"IEEE\"\n}\n\n",
    "abstract": "Links between issue reports and their corresponding commits in version control systems are often missing. However, these links are important for measuring the quality of various parts of a software system, predicting defects, and many other tasks. A number of existing approaches have been designed to solve this problem by automatically linking bug reports to source code commits via comparison of textual information in commit messages with textual contents in the bug reports. Yet, the effectiveness of these techniques is oftentimes sub optimal when commit messages are empty or only contain minimum information, this particular problem makes the process of recovering trace ability links between commits and bug reports particularly challenging. In this work, we aim at improving the effectiveness of existing bug linking techniques by utilizing rich contextual information. We rely on a recently proposed tool, namely Change Scribe, which generates commit messages containing rich contextual information by using a number of code summarization techniques. Our approach then extracts features from these automatically generated commit messages and bug reports and inputs them into a classification technique that creates a discriminative model used to predict if a link exists between a commit message and a bug report. We compared our approach, coined as RCLinker (Rich Context Linker), to MLink, which is an existing state-of-the-art bug linking approach. Our experiment results on bug reports from 6 software projects show that RCLinker can outperform MLink in terms of F-measure by 138.66%."
},
{
    "py/object": "data.DataClassPaper",
    "Title": "On the classification of software change messages using multi-label active learning",
    "year": 2019,
    "ML_Techniques": "LR",
    "Category": "Program comprehension",
    "Sub_category": "Program classification",
    "Venue": "SAC",
    "Link": "https://dl.acm.org/doi/abs/10.1145/3297280.3297452",
    "bibtex": "inproceedings{1022_Gharbi2019,\n    author = \"Gharbi, Sirine and Mkaouer, Mohamed Wiem and Jenhani, Ilyes and Messaoud, Montassar Ben\",\n    title = \"On the classification of software change messages using multi-label active learning\",\n    booktitle = \"Proceedings of the 34th ACM/SIGAPP Symposium on Applied Computing\",\n    pages = \"1760--1767\",\n    year = \"2019\"\n}\n\n",
    "abstract": "In this paper, we present a multi-label active learning-based approach to handle the problem of classification of commit messages. The approach will help developers track software changes, e.g., adding or updating existing features, fixing user-reported errors, improving software performance, etc. We first constructed an unlabeled dataset of commit messages where each commit message is represented as a vector of feature values. The set of adopted features were automatically generated from the original commit messages using Term Frequency-Inverse Document Frequency (TF-IDF) technique. Because many commit messages can be assigned more than one commit class at the same time and in order to reduce the effort needed to assign labels to each instance in a large set of commit messages, we adopted an Active Learning multi-label approach. Experimentations have shown that we could train an accurate multi-label classifier model, in our case, a binary relevance with logistic regression as a base classifier, by actively querying an oracle for labels during the training process and with a reasonable number of labeled instances."
},
{
    "py/object": "data.DataClassPaper",
    "Title": "Augmenting commit classification by using fine-grained source code changes and a pre-trained deep neural language model",
    "year": 2021,
    "ML_Techniques": "BERT, DNN",
    "Category": "Program comprehension",
    "Sub_category": "Program classification",
    "Venue": "IST",
    "Link": "https://www.sciencedirect.com/science/article/abs/pii/S0950584921000495",
    "bibtex": "article{1023_Ghadhab2021,\n    author = \"Ghadhab, Lobna and Jenhani, Ilyes and Mkaouer, Mohamed Wiem and Messaoud, Montassar Ben\",\n    title = \"Augmenting commit classification by using fine-grained source code changes and a pre-trained deep neural language model\",\n    journal = \"Information and Software Technology\",\n    volume = \"135\",\n    pages = \"106566\",\n    year = \"2021\",\n    publisher = \"Elsevier\"\n}\n\n",
    "abstract": "Context:\nAnalyzing software maintenance activities is very helpful in ensuring cost-effective evolution and development activities. The categorization of commits into maintenance tasks supports practitioners in making decisions about resource allocation and managing technical debt.\n\nObjective:\nIn this paper, we propose to use a pre-trained language neural model, namely BERT (Bidirectional Encoder Representations from Transformers) for the classification of commits into three categories of maintenance tasks \u2014 corrective, perfective and adaptive. The proposed commit classification approach will help the classifier better understand the context of each word in the commit message.\n\nMethods:\nWe built a balanced dataset of 1793 labeled commits that we collected from publicly available datasets. We used several popular code change distillers to extract fine-grained code changes that we have incorporated into our dataset as additional features to BERT\u2019s word representation features. In our study, a deep neural network (DNN) classifier has been used as an additional layer to fine-tune the BERT model on the task of commit classification. Several models have been evaluated to come up with a deep analysis of the impact of code changes on the classification performance of each commit category.\n\nResults and conclusions:\nExperimental results have shown that the DNN model trained on BERT\u2019s word representations and Fixminer code changes (DNN@BERT+Fix_cc) provided the best performance and achieved 79.66% accuracy and a macro-average f1 score of 0.8. Comparison with the state-of-the-art model that combines keywords and code changes (RF@KW+CD_cc) has shown that our model achieved approximately 8% improvement in accuracy. Results have also shown that a DNN model using only BERT\u2019s word representation features achieved an improvement of 5% in accuracy compared to the RF@KW+CD_cc model."
},
{
    "py/object": "data.DataClassPaper",
    "Title": "Augmenting Java method comments generation with context information based on neural networks",
    "year": 2019,
    "ML_Techniques": "LSTM",
    "Category": "Program comprehension",
    "Sub_category": "Code summarization",
    "Venue": "JSS",
    "Link": "https://www.sciencedirect.com/science/article/abs/pii/S0164121219301529",
    "bibtex": "",
    "abstract": "Code comments are crucial to\u00a0program comprehension. In this paper, we propose a novel approach\u00a0ContextCC\u00a0to automatically generate concise comments for Java methods based on\u00a0neural networks, leveraging techniques of program analysis and\u00a0natural language processing. Firstly,\u00a0ContextCC\u00a0employs program analysis techniques, especially\u00a0abstract syntax tree\u00a0parsing, to extract context information including methods and their dependency. Secondly, it filters code and comments out of the context information to build up a high-quality data set based on a set of pre-defined templates and rules. Finally,\u00a0ContextCC\u00a0trains a code comment generation model based on\u00a0recurrent neural networks. Experiments are conducted on Java projects crawled from GitHub. We show empirically that the performance of\u00a0ContextCC\u00a0is superior to state-of-the-art\u00a0baseline methods."
},
{
    "py/object": "data.DataClassPaper",
    "Title": "Where should I comment my code?: a dataset and model for predicting locations that need comments",
    "year": 2020,
    "ML_Techniques": "RNN, MLP",
    "Category": "Program comprehension",
    "Sub_category": "",
    "Venue": "ICSE",
    "Link": "https://dl.acm.org/doi/abs/10.1145/3377816.3381736",
    "bibtex": "inproceedings{1029_Louis2020,\n    author = \"Louis, Annie and Dash, Santanu Kumar and Barr, Earl T and Ernst, Michael D and Sutton, Charles\",\n    title = \"Where should I comment my code? A dataset and model for predicting locations that need comments\",\n    booktitle = \"Proceedings of the ACM/IEEE 42nd International Conference on Software Engineering: New Ideas and Emerging Results\",\n    pages = \"21--24\",\n    year = \"2020\"\n}\n\n",
    "abstract": "Programmers should write code comments, but not on every line of code. We have created a machine learning model that suggests locations where a programmer should write a code comment. We trained it on existing commented code to learn locations that are chosen by developers. Once trained, the model can predict locations in new code. Our models achieved precision of 74% and recall of 13% in identifying comment-worthy locations. This first success opens the door to future work, both in the new\u00a0where-to-comment\u00a0problem and in guiding comment generation. Our code and data is available at http://groups.inf.ed.ac.uk/cup/comment-locator/."
},
{
    "py/object": "data.DataClassPaper",
    "Title": "A Survey of Automatic Generation of Code Comments",
    "year": 2020,
    "ML_Techniques": "",
    "Category": "Program comprehension",
    "Sub_category": "Code summarization",
    "Venue": "ICMSS",
    "Link": "https://dl.acm.org/doi/abs/10.1145/3380625.3380649",
    "bibtex": "inproceedings{1030_Zhao2020,\n    author = \"Zhao, Fengrong and Zhao, Junqi and Bai, Yang\",\n    title = \"A survey of automatic generation of code comments\",\n    booktitle = \"Proceedings of the 2020 4th International Conference on Management Engineering, Software Engineering and Service Sciences\",\n    pages = \"21--25\",\n    year = \"2020\"\n}\n\n",
    "abstract": "Code comments are a valuable form of documentation attached to code that is the most intuitive and efficient way for programmers to understand software code. Good code comments can help programmers quickly understand the role of source code and facilitate understanding of programs and software maintenance tasks. However, in practice, most programmers only pay attention to the code and ignore the comments and documents, which makes the program's readability and maintainability greatly reduced. Based on the meaning of code comments, this paper discusses the current progress in the field of code comments research, adopts the comparative analysis method, focuses on the classification research of the methods and tools for automatic generation of code comments, expounds its advantages and disadvantages, and reveals the issues that need further study."
},
{
    "py/object": "data.DataClassPaper",
    "Title": "Learning to Generate Comments for API-Based Code Snippets",
    "year": 2019,
    "ML_Techniques": "DNN, Seq2Seq",
    "Category": "Program comprehension",
    "Sub_category": "Code summarization",
    "Venue": "NASAC",
    "Link": "https://link.springer.com/chapter/10.1007/978-981-15-0310-8_1",
    "bibtex": "",
    "abstract": "Comments play an important role in software developments. They can not only improve the readability and maintainability of source code, but also provide significant resource for software reuse. However, it is common that lots of code in software projects lacks of comments. Automatic comment generation is proposed to address this issue. In this paper, we present an end-to-end approach to generate comments for API-based code snippets automatically. It takes API sequences as the core semantic representations of method-level API-based code snippets and generates comments from API sequences with sequence-to-sequence neural models. In our evaluation, we extract 217K pairs of code snippets and comments from Java projects to construct the dataset. Finally, our approach gains 36.48% BLEU-4 score and 9.90% accuracy on the test set. We also do case studies on generated comments, which presents that our approach generates reasonable and effective comments for API-based code snippets."
},
{
    "py/object": "data.DataClassPaper",
    "Title": "CodeAttention: translating source code to comments by exploiting the code constructs",
    "year": 2019,
    "ML_Techniques": "RNN",
    "Category": "Code representation",
    "Sub_category": "",
    "Venue": "FCS",
    "Link": "https://link.springer.com/article/10.1007/s11704-018-7457-6",
    "bibtex": "",
    "abstract": "Appropriate comments of code snippets provide insight for code functionality, which are helpful for program comprehension. However, due to the great cost of authoring with the comments, many code projects do not contain adequate comments. Automatic comment generation techniques have been proposed to generate comments from pieces of code in order to alleviate the human efforts in annotating the code. Most existing approaches attempt to exploit certain correlations (usually manually given) between code and generated comments, which could be easily violated if coding patterns change and hence the performance of comment generation declines. In addition, recent approaches ignore exploiting the code constructs and leveraging the code snippets like plain text. Furthermore, previous datasets are also too small to validate the methods and show their advantage. In this paper, we propose a new attention mechanism called CodeAttention to translate code to comments, which is able to utilize the code constructs, such as critical statements, symbols and keywords. By focusing on these specific points, CodeAttention could understand the semantic meanings of code better than previous methods. To verify our approach in wider coding patterns, we build a large dataset from open projects in GitHub. Experimental results in this large dataset demonstrate that the proposed method has better performance over existing approaches in both objective and subjective evaluation. We also perform ablation studies to determine effects of different parts in CodeAttention."
},
{
    "py/object": "data.DataClassPaper",
    "Title": "Towards automatically generating block comments for code snippets",
    "year": 2020,
    "ML_Techniques": "RL, EN-DE",
    "Category": "Program comprehension",
    "Sub_category": "Code summarization",
    "Venue": "IST",
    "Link": "https://www.sciencedirect.com/science/article/abs/pii/S0950584920301427",
    "bibtex": "article{1033_Huang2020,\n    author = \"Huang, Yuan and Huang, Shaohao and Chen, Huanchao and Chen, Xiangping and Zheng, Zibin and Luo, Xiapu and Jia, Nan and Hu, Xinyu and Zhou, Xiaocong\",\n    title = \"Towards automatically generating block comments for code snippets\",\n    journal = \"Information and Software Technology\",\n    volume = \"127\",\n    pages = \"106373\",\n    year = \"2020\",\n    publisher = \"Elsevier\"\n}\n\n",
    "abstract": "Code commenting is a common programming practice of practical importance to help developers review and comprehend source code. There are two main types of code comments for a method: header comments that summarize the method functionality located before a method, and block comments that describe the functionality of the code snippets within a method. Inspired by the effectiveness of\u00a0deep learning techniques\u00a0in the NLP field, many studies focus on using the machine translation model to automatically generate comment for the source code. Because the data set of block comments is difficult to collect, current studies focus more on the automatic generation of header comments than that of block comments. However, block comments are important for\u00a0program comprehension\u00a0due to their explanation role for the code snippets in a method. To fill the gap, we have proposed an approach that combines heuristic rules and learning-based method to collect a large number of comment-code pairs from 1,032\u00a0open source projects\u00a0in our previous study. In this paper, we propose a reinforcement learning-based method,\u00a0RL-BlockCom, to automatically generate block comments for code snippets based on the collected comment-code pairs. Specifically, we utilize the\u00a0abstract syntax tree\u00a0(i.e., AST) of a code snippet to generate a token sequence with a statement-based traversal way. Then we propose a composite learning model, which combines the actor-critic algorithm of\u00a0reinforcement learning\u00a0with the encoder-decoder algorithm, to generate block comments. On the data set of the comment-code pairs, the BLEU-4 score of our method is 24.28, which outperforms the baselines and state-of-the-art in comment generation."
},
{
    "py/object": "data.DataClassPaper",
    "Title": "Automatic Generation of Program Comments Based on Problem Statements for Computational Thinking",
    "year": 2019,
    "ML_Techniques": "EN-DE, LSTM",
    "Category": "Program comprehension",
    "Sub_category": "Code summarization",
    "Venue": "AAI",
    "Link": "https://ieeexplore.ieee.org/abstract/document/8992608",
    "bibtex": "inproceedings{1034_Takahashi2019,\n    author = \"Takahashi, Akiyoshi and Shiina, Hiromitsu and Kobayashi, Nobuyuki\",\n    title = \"Automatic Generation of Program Comments based on Problem Statements for Computational Thinking\",\n    booktitle = \"2019 8th International Congress on Advanced Applied Informatics (IIAI-AAI)\",\n    pages = \"629--634\",\n    year = \"2019\",\n    organization = \"IEEE\"\n}\n\n",
    "abstract": "To support the understanding of programs and understanding of procedures, we think need to automatically generate comments from source code. As a method, we learn the source code and comment pair by Encoder-Decoder translation model using LSTM, thereby generating comments of the source code that was the target of learning. Though, since it is difficult to increase the amount of learning data when generating comment for problem description, generated comments have some incorrect word for problem sentence. We use program problem sentence to generate comments for source code more suitable for users."
},
{
    "py/object": "data.DataClassPaper",
    "Title": "Automatically detecting the scopes of source code comments",
    "year": 2019,
    "ML_Techniques": "RF",
    "Category": "Program comprehension",
    "Sub_category": "",
    "Venue": "Journal of Systems and Software",
    "Link": "https://www.sciencedirect.com/science/article/pii/S016412121930055X",
    "bibtex": "article{1036_Chen2019,\n    author = \"Chen, Huanchao and Huang, Yuan and Liu, Zhiyong and Chen, Xiangping and Zhou, Fan and Luo, Xiaonan\",\n    title = \"Automatically detecting the scopes of source code comments\",\n    journal = \"Journal of Systems and Software\",\n    volume = \"153\",\n    pages = \"45--63\",\n    year = \"2019\",\n    publisher = \"Elsevier\"\n}\n\n",
    "abstract": "Comments convey useful information about the system functionalities and many methods for software engineering tasks take comments as an important source for many software engineering tasks such as code semantic analysis, code reuse and so on. However, unlike structural doc comments, it is challenging to identify the relationship between the functional semantics of the code and its corresponding textual descriptions nested inside the code and apply it to automatic analyzing and mining approaches in software engineering tasks efficiently.\n\nIn this paper, we propose a general method for the detection of source code comment scopes. Based on machine learning, our method utilized features of code snippets and comments to detect the scopes of source code comments automatically in Java programs. On the dataset of comment-statement pairs from 4 popular open source projects, our method achieved a high accuracy of 81.45% in detecting the scopes of comments. Furthermore, the results demonstrated the feasibility and effectiveness of our comment scope detection method on new projects.\n\nMoreover, our method was applied to two specific software engineering tasks in our studies: analyzing software repositories for outdated comment detection and mining software repositories for comment generation. As a general approach, our method provided a solution to comment-code mapping. It improved the performance of baseline methods in both tasks, which demonstrated that our method is conducive to automatic analyzing and mining approaches on software repositories."
},
{
    "py/object": "data.DataClassPaper",
    "Title": "Detecting and Removing Web Application Vulnerabilities with Static Analysis and Data Mining",
    "year": 2016,
    "ML_Techniques": "ID3, DT, RT, RF, NB, KNN, LOG, MLP, SVM",
    "Category": "Vulnerability analysis",
    "Sub_category": "",
    "Venue": "T-RL",
    "Link": "https://ieeexplore.ieee.org/abstract/document/7206620",
    "bibtex": "ARTICLE{1046_Medeiros2016,\n    author = \"Medeiros, Ib\u00e9ria and Neves, Nuno and Correia, Miguel\",\n    journal = \"IEEE Transactions on Reliability\",\n    title = \"Detecting and Removing Web Application Vulnerabilities with Static Analysis and Data Mining\",\n    year = \"2016\",\n    volume = \"65\",\n    number = \"1\",\n    pages = \"54-69\",\n    doi = \"10.1109/TR.2015.2457411\"\n}\n\n",
    "abstract": "Although a large research effort on web application security has been going on for more than a decade, the security of web applications continues to be a challenging problem. An important part of that problem derives from vulnerable source code, often written in unsafe languages like PHP. Source code static analysis tools are a solution to find vulnerabilities, but they tend to generate false positives, and require considerable effort for programmers to manually fix the code. We explore the use of a combination of methods to discover vulnerabilities in source code with fewer false positives. We combine taint analysis, which finds candidate vulnerabilities, with data mining, to predict the existence of false positives. This approach brings together two approaches that are apparently orthogonal: humans coding the knowledge about vulnerabilities (for taint analysis), joined with the seemingly orthogonal approach of automatically obtaining that knowledge (with machine learning, for data mining). Given this enhanced form of detection, we propose doing automatic code correction by inserting fixes in the source code. Our approach was implemented in the WAP tool, and an experimental evaluation was performed with a large set of PHP applications. Our tool found 388 vulnerabilities in 1.4 million lines of code. Its accuracy and precision were approximately 5% better than PhpMinerII's and 45% better than Pixy's."
},
{
    "py/object": "data.DataClassPaper",
    "Title": "On applying machine learning techniques for design pattern detection",
    "year": 2015,
    "ML_Techniques": "SVM",
    "Category": "Program comprehension",
    "Sub_category": "Entity identification/recommendation",
    "Venue": "JSS",
    "Link": "https://www.sciencedirect.com/science/article/abs/pii/S0164121215000217",
    "bibtex": "article{1049_Zanoni2015,\n    author = \"Zanoni, Marco and Fontana, Francesca Arcelli and Stella, Fabio\",\n    title = \"On applying machine learning techniques for design pattern detection\",\n    journal = \"Journal of Systems and Software\",\n    volume = \"103\",\n    pages = \"102--117\",\n    year = \"2015\",\n    publisher = \"Elsevier\"\n}\n\n",
    "abstract": "The detection of design patterns is a useful activity giving support to the comprehension and maintenance of software systems. Many approaches and tools have been proposed in the literature providing different results. In this paper, we extend a previous work regarding the application of machine learning techniques for design pattern detection, by adding a more extensive experimentation and enhancements in the analysis method. Here we exploit a combination of graph matching and machine learning techniques, implemented in a tool we developed, called MARPLE-DPD. Our approach allows the application of machine learning techniques, leveraging a modeling of design patterns that is able to represent pattern instances composed of a variable number of classes. We describe the experimentations for the detection of five design patterns on 10 open source software systems, compare the performances obtained by different learning models with respect to a baseline, and discuss the encountered issues."
},
{
    "py/object": "data.DataClassPaper",
    "Title": "Software design pattern recognition using machine learning techniques",
    "year": 2016,
    "ML_Techniques": "RNN, DT",
    "Category": "Program comprehension",
    "Sub_category": "Entity identification/recommendation",
    "Venue": "TENCON",
    "Link": "https://ieeexplore.ieee.org/abstract/document/7847994",
    "bibtex": "inproceedings{1051_Dwivedi2016,\n    author = \"Dwivedi, Ashish Kumar and Tirkey, Anand and Ray, Ransingh Biswajit and Rath, Santanu Kumar\",\n    title = \"Software design pattern recognition using machine learning techniques\",\n    booktitle = \"2016 ieee region 10 conference (tencon)\",\n    pages = \"222--227\",\n    year = \"2016\",\n    organization = \"IEEE\"\n}\n\n",
    "abstract": "Design patterns helpful for software development are the reusable abstract documents which provide acceptable solutions for the recurring design problems. But in the process of reverse engineering, it is often desired to identify as well as recognize design pattern from source code, as it improves maintainability and documentation of the source code. In this study, the process of software design pattern recognition is presented which is based on machine learning techniques. Firstly, a training dataset is developed which is based on software metrics. Subsequently, machine learning algorithms such as Layer Recurrent Neural Network and Decision Tree are applied for patterns detection process. In order to evaluate the proposed study, an open source software i.e., JHotDraw 7.0.6 has been used for the recognition of design patterns."
},
{
    "py/object": "data.DataClassPaper",
    "Title": "Design Pattern Detection using Machine Learning Techniques",
    "year": 2018,
    "ML_Techniques": "SVM, NN, LR",
    "Category": "Program comprehension",
    "Sub_category": "Entity identification/recommendation",
    "Venue": "ICRITO",
    "Link": "https://ieeexplore.ieee.org/abstract/document/8748282",
    "bibtex": "inproceedings{1052_Chaturvedi2018,\n    author = \"Chaturvedi, Shivam and Chaturvedi, Amrita and Tiwari, Anurag and Agarwal, Shalini\",\n    title = \"Design pattern detection using machine learning techniques\",\n    booktitle = \"2018 7th International Conference on Reliability, Infocom Technologies and Optimization (Trends and Future Directions)(ICRITO)\",\n    pages = \"1--6\",\n    year = \"2018\",\n    organization = \"IEEE\"\n}\n\n",
    "abstract": "Finding Design Patterns inside the code gives a hint to software engineer about the methodologies adopted and the problems found during its design phases and helps the engineer to evolve and maintain the system. The maintainability and reliability of object-oriented programs can be improved by automatic detection of known design patterns. This paper demonstrates the recognition approach entirely based on Machine Learning Techniques. In this paper we have built the datasets by using existing recognition tools and we have used the feature compilation methods to select the input features."
},
{
    "py/object": "data.DataClassPaper",
    "Title": "Root cause analysis of software bugs using machine learning techniques",
    "year": 2017,
    "ML_Techniques": "",
    "Category": "Testing",
    "Sub_category": "",
    "Venue": "Confluence",
    "Link": "https://ieeexplore.ieee.org/abstract/document/7943132",
    "bibtex": "inproceedings{1060_Lal2017,\n    author = \"Lal, Harsh and Pahwa, Gaurav\",\n    title = \"Root cause analysis of software bugs using machine learning techniques\",\n    booktitle = \"2017 7th International Conference on Cloud Computing, Data Science \\\\& Engineering-Confluence\",\n    pages = \"105--111\",\n    year = \"2017\",\n    organization = \"IEEE\"\n}\n\n",
    "abstract": "Root cause analysis (RCA) is a systematic process for identifying \u201croot causes\u201d of problems or events and an approach for responding to them. The factor that caused a problem or defect should be permanently eliminated through process improvement. In the context of Software development process it may be used to refer to a specific module or a category of bug which in turn can be useful for tackling the problem at its root. In this paper we propose a machine learning approach for finding root cause of a newly filed software bugs which in turn would help in the faster and cleaner resolution of software bugs. This proposed approach is evaluated for feasibility study on an open source system eclipse. [7], [6]"
},
{
    "py/object": "data.DataClassPaper",
    "Title": "COMPARATIVE PERFORMANCE ANALYSIS OF MACHINE LEARNING TECHNIQUES FOR SOFTWARE BUG DETECTION",
    "year": 2015,
    "ML_Techniques": "",
    "Category": "Testing",
    "Sub_category": "Defect prediction",
    "Venue": "IJSEA",
    "Link": "https://www.researchgate.net/publication/307763296_Comparative_Performance_Analysis_of_Machine_Learning_Techniques_for_Software_Bug_Detection",
    "bibtex": "inproceedings{1062_Aleem2015,\n    author = \"Aleem, Saiqa and Capretz, Luiz Fernando and Ahmed, Faheem and others\",\n    title = \"Comparative performance analysis of machine learning techniques for software bug detection\",\n    booktitle = \"Proceedings of the 4th International Conference on Software Engineering and Applications\",\n    number = \"1\",\n    pages = \"71--79\",\n    year = \"2015\",\n    organization = \"AIRCC Press Chennai, Tamil Nadu, India\"\n}\n\n",
    "abstract": "Machine learning techniques can be used to analyse data from different perspectives and enable developers to retrieve useful information. Machine learning techniques are proven to be useful in terms of software bug prediction. In this paper, a comparative performance analysis of different machine learning techniques is explored f or software bug prediction on public available data sets. Results showed most of the mac hine learning methods performed well on software bug datasets."
},
{
    "py/object": "data.DataClassPaper",
    "Title": "Re-evaluating method-level bug prediction",
    "year": 2018,
    "ML_Techniques": "",
    "Category": "Testing",
    "Sub_category": "Defect prediction",
    "Venue": "SANER",
    "Link": "https://ieeexplore.ieee.org/abstract/document/8330264",
    "bibtex": "inproceedings{1065_Pascarella2018,\n    author = \"Pascarella, Luca and Palomba, Fabio and Bacchelli, Alberto\",\n    title = \"Re-evaluating method-level bug prediction\",\n    booktitle = \"2018 IEEE 25th International Conference on Software Analysis, Evolution and Reengineering (SANER)\",\n    pages = \"592--601\",\n    year = \"2018\",\n    organization = \"IEEE\"\n}\n\n",
    "abstract": "Bug prediction is aimed at supporting developers in the identification of code artifacts more likely to be defective. Researchers have proposed prediction models to identify bug prone methods and provided promising evidence that it is possible to operate at this level of granularity. Particularly, models based on a mixture of product and process metrics, used as independent variables, led to the best results. In this study, we first replicate previous research on method-level bug prediction on different systems/timespans. Afterwards, we reflect on the evaluation strategy and propose a more realistic one. Key results of our study show that the performance of the method-level bug prediction model is similar to what previously reported also for different systems/timespans, when evaluated with the same strategy. However-when evaluated with a more realistic strategy-all the models show a dramatic drop in performance exhibiting results close to that of a random classifier. Our replication and negative results indicate that method-level bug prediction is still an open challenge."
},
{
    "py/object": "data.DataClassPaper",
    "Title": "Semantic Source Code Models Using Identifier Embeddings",
    "year": 2019,
    "ML_Techniques": "VSM",
    "Category": "Code representation",
    "Sub_category": "",
    "Venue": "MSR",
    "Link": "https://ieeexplore.ieee.org/abstract/document/8816775",
    "bibtex": "INPROCEEDINGS{1068_Efstathiou2019,\n    author = \"Efstathiou, Vasiliki and Spinellis, Diomidis\",\n    booktitle = \"2019 IEEE/ACM 16th International Conference on Mining Software Repositories (MSR)\",\n    title = \"Semantic Source Code Models Using Identifier Embeddings\",\n    year = \"2019\",\n    volume = \"\",\n    number = \"\",\n    pages = \"29-33\",\n    doi = \"10.1109/MSR.2019.00015\"\n}\n\n",
    "abstract": "The emergence of online open source repositories in the recent years has led to an explosion in the volume of openly available source code, coupled with metadata that relate to a variety of software development activities. As an effect, in line with recent advances in machine learning research, software maintenance activities are switching from symbolic formal methods to data-driven methods. In this context, the rich semantics hidden in source code identifiers provide opportunities for building semantic representations of code which can assist tasks of code search and reuse. To this end, we deliver in the form of pretrained vector space models, distributed code representations for six popular programming languages, namely, Java, Python, PHP, C, C++, and C#. The models are produced using fastText, a state-of-the-art library for learning word representations. Each model is trained on data from a single programming language; the code mined for producing all models amounts to over 13.000 repositories. We indicate dissimilarities between natural language and source code, as well as variations in coding conventions in between the different programming languages we processed. We describe how these heterogeneities guided the data preprocessing decisions we took and the selection of the training parameters in the released models. Finally, we propose potential applications of the models and discuss limitations of the models."
},
{
    "py/object": "data.DataClassPaper",
    "Title": "Natural Language Models for Predicting Programming Comments",
    "year": 2017,
    "ML_Techniques": "LDA",
    "Category": "Code representation",
    "Sub_category": "",
    "Venue": "ACL",
    "Link": "https://aclanthology.org/P13-2007.pdf",
    "bibtex": "1073_Movshovitz-Attias2013{1073_Movshovitz-Attias2013,\n    author = \"Movshovitz-Attias, Dana and Cohen, William\",\n    year = \"2013\",\n    month = \"08\",\n    pages = \"35-40\",\n    title = \"Natural Language Models for Predicting Programming Comments\",\n    volume = \"2\",\n    journal = \"ACL 2013 - 51st Annual Meeting of the Association for Computational Linguistics, Proceedings of the Conference\"\n}\n\n",
    "abstract": "Statistical language models have successfully been used to describe and analyze natural language documents. Recent work applying language models to programming languages is focused on the task of predicting code, while mainly ignoring the prediction of programmer comments. In this work, we predict comments from JAVA source files of open source projects, using topic models and n-grams, and we analyze the performance of the models given varying amounts of background data on the project being predicted. We evaluate models on their comment-completion capability in a setting similar to codecompletion tools built into standard code editors, and show that using a comment completion tool can save up to 47% of the comment typing."
},
{
    "py/object": "data.DataClassPaper",
    "Title": "IdBench: Evaluating Semantic Representations of Identifier Names in Source Code",
    "year": 2021,
    "ML_Techniques": "",
    "Category": "Program comprehension",
    "Sub_category": "",
    "Venue": "ICSE",
    "Link": "https://ieeexplore.ieee.org/abstract/document/9401986",
    "bibtex": "inproceedings{1074_Wainakh2021,\n    author = \"Wainakh, Yaza and Rauf, Moiz and Pradel, Michael\",\n    title = \"Idbench: Evaluating semantic representations of identifier names in source code\",\n    booktitle = \"2021 IEEE/ACM 43rd International Conference on Software Engineering (ICSE)\",\n    pages = \"562--573\",\n    year = \"2021\",\n    organization = \"IEEE\"\n}\n\n",
    "abstract": "Identifier names convey useful information about the intended semantics of code. Name-based program analyses use this information, e.g., to detect bugs, to predict types, and to improve the readability of code. At the core of name-based analyses are semantic representations of identifiers, e.g., in the form of learned embeddings. The high-level goal of such a representation is to encode whether two identifiers, e.g., len and size, are semantically similar. Unfortunately, it is currently unclear to what extent semantic representations match the semantic relatedness and similarity perceived by developers. This paper presents IdBench, the first benchmark for evaluating semantic representations against a ground truth created from thousands of ratings by 500 software developers. We use IdBench to study state-of-the-art embedding techniques proposed for natural language, an embedding technique specifically designed for source code, and lexical string distance functions. Our results show that the effectiveness of semantic representations varies significantly and that the best available embeddings successfully represent semantic relatedness. On the downside, no existing technique provides a satisfactory representation of semantic similarities, among other reasons because identifiers with opposing meanings are incorrectly considered to be similar, which may lead to fatal mistakes, e.g., in a refactoring tool. Studying the strengths and weaknesses of the different techniques shows that they complement each other. As a first step toward exploiting this complementarity, we present an ensemble model that combines existing techniques and that clearly outperforms the best available semantic representation."
},
{
    "py/object": "data.DataClassPaper",
    "Title": "Source Code Authorship Attribution Using Long Short-Term Memory Based Networks",
    "year": 2017,
    "ML_Techniques": "LSTM",
    "Category": "Program comprehension",
    "Sub_category": "",
    "Venue": "ESORICS",
    "Link": "https://link.springer.com/chapter/10.1007/978-3-319-66402-6_6",
    "bibtex": "inproceedings{1075_Alsulami2017,\n    author = \"Alsulami, Bander and Dauber, Edwin and Harang, Richard and Mancoridis, Spiros and Greenstadt, Rachel\",\n    title = \"Source code authorship attribution using long short-term memory based networks\",\n    booktitle = \"European Symposium on Research in Computer Security\",\n    pages = \"65--82\",\n    year = \"2017\",\n    organization = \"Springer\"\n}\n\n",
    "abstract": "Machine learning approaches to source code authorship attribution attempt to find statistical regularities in human-generated source code that can identify the author or authors of that code. This has applications in plagiarism detection, intellectual property infringement, and post-incident forensics in computer security. The introduction of features derived from the Abstract Syntax Tree (AST) of source code has recently set new benchmarks in this area, significantly improving over previous work that relied on easily obfuscatable lexical and format features of program source code. However, these AST-based approaches rely on hand-constructed features derived from such trees, and often include ancillary information such as function and variable names that may be obfuscated or manipulated.\n\nIn this work, we provide novel contributions to AST-based source code authorship attribution using deep neural networks. We implement Long Short-Term Memory (LSTM) and Bidirectional Long Short-Term Memory (BiLSTM) models to automatically extract relevant features from the AST representation of programmers\u2019 source code. We show that our models can automatically learn efficient representations of AST-based features without needing hand-constructed ancillary information used by previous methods. Our empirical study on multiple datasets with different programming languages shows that our proposed approach achieves the state-of-the-art performance for source code authorship attribution on AST-based features, despite not leveraging information that was previously thought to be required for high-confidence classification."
},
{
    "py/object": "data.DataClassPaper",
    "Title": "NL2Type: Inferring JavaScript Function Types from Natural Language Information",
    "year": 2019,
    "ML_Techniques": "LSTM",
    "Category": "Program comprehension",
    "Sub_category": "",
    "Venue": "ICSE",
    "Link": "https://ieeexplore.ieee.org/abstract/document/8811893",
    "bibtex": "inproceedings{1077_Malik2019,\n    author = \"Malik, Rabee Sohail and Patra, Jibesh and Pradel, Michael\",\n    title = \"NL2Type: inferring JavaScript function types from natural language information\",\n    booktitle = \"2019 IEEE/ACM 41st International Conference on Software Engineering (ICSE)\",\n    pages = \"304--315\",\n    year = \"2019\",\n    organization = \"IEEE\"\n}\n\n",
    "abstract": "avaScript is dynamically typed and hence lacks the type safety of statically typed languages, leading to suboptimal IDE support, difficult to understand APIs, and unexpected runtime behavior. Several gradual type systems have been proposed, e.g., Flow and TypeScript, but they rely on developers to annotate code with types. This paper presents NL2Type, a learning-based approach for predicting likely type signatures of JavaScript functions. The key idea is to exploit natural language information in source code, such as comments, function names, and parameter names, a rich source of knowledge that is typically ignored by type inference algorithms. We formulate the problem of predicting types as a classification problem and train a recurrent, LSTM-based neural model that, after learning from an annotated code base, predicts function types for unannotated code. We evaluate the approach with a corpus of 162,673 JavaScript files from real-world projects. NL2Type predicts types with a precision of 84.1% and a recall of 78.9% when considering only the top-most suggestion, and with a precision of 95.5% and a recall of 89.6% when considering the top-5 suggestions. The approach outperforms both JSNice, a state-of-the-art approach that analyzes implementations of functions instead of natural language information, and DeepTyper, a recent type prediction approach that is also based on deep learning. Beyond predicting types, NL2Type serves as a consistency checker for existing type annotations. We show that it discovers 39 inconsistencies that deserve developer attention (from a manual analysis of 50 warnings), most of which are due to incorrect type annotations."
},
{
    "py/object": "data.DataClassPaper",
    "Title": "Code Prediction by Feeding Trees to Transformers",
    "year": 2021,
    "ML_Techniques": "TF",
    "Category": "Program comprehension",
    "Sub_category": "",
    "Venue": "ICSE",
    "Link": "https://ieeexplore.ieee.org/abstract/document/9402114",
    "bibtex": "inproceedings{1078_Kim2021,\n    author = \"Kim, Seohyun and Zhao, Jinman and Tian, Yuchi and Chandra, Satish\",\n    title = \"Code prediction by feeding trees to transformers\",\n    booktitle = \"2021 IEEE/ACM 43rd International Conference on Software Engineering (ICSE)\",\n    pages = \"150--162\",\n    year = \"2021\",\n    organization = \"IEEE\"\n}\n\n",
    "abstract": "Code prediction, more specifically autocomplete, has become an essential feature in modern IDEs. Autocomplete is more effective when the desired next token is at (or close to) the top of the list of potential completions offered by the IDE at cursor position. This is where the strength of the underlying machine learning system that produces a ranked order of potential completions comes into play. We advance the state-of-the-art in the accuracy of code prediction (next token prediction) used in autocomplete systems. Our work uses Transformers as the base neural architecture. We show that by making the Transformer architecture aware of the syntactic structure of code, we increase the margin by which a Transformer-based system outperforms previous systems. With this, it outperforms the accuracy of several state-of-the-art next token prediction systems by margins ranging from 14% to 18%. We present in the paper several ways of communicating the code structure to the Transformer, which is fundamentally built for processing sequence data. We provide a comprehensive experimental evaluation of our proposal, along with alternative design choices, on a standard Python dataset, as well as on Facebook internal Python corpus. Our code and data preparation pipeline will be available in open source."
},
{
    "py/object": "data.DataClassPaper",
    "Title": "Learning How to Mutate Source Code from Bug-Fixes",
    "year": 2019,
    "ML_Techniques": "NMT",
    "Category": "Testing",
    "Sub_category": "Defect prediction",
    "Venue": "ICSME",
    "Link": "https://ieeexplore.ieee.org/abstract/document/8919234",
    "bibtex": "inproceedings{1080_Tufano2019,\n    author = \"Tufano, Michele and Watson, Cody and Bavota, Gabriele and Di Penta, Massimiliano and White, Martin and Poshyvanyk, Denys\",\n    title = \"Learning how to mutate source code from bug-fixes\",\n    booktitle = \"2019 IEEE International Conference on Software Maintenance and Evolution (ICSME)\",\n    pages = \"301--312\",\n    year = \"2019\",\n    organization = \"IEEE\"\n}\n\n",
    "abstract": "Mutation testing has been widely accepted as an approach to guide test case generation or to assess the effectiveness of test suites. Empirical studies have shown that mutants are representative of real faults; yet they also indicated a clear need for better, possibly customized, mutation operators and strategies. While methods to devise domain-specific or general-purpose mutation operators from real faults exist, they are effort-and error-prone, and do not help the tester to decide whether and how to mutate a given source code element. We propose a novel approach to automatically learn mutants from faults in real programs. First, our approach processes bug fixing changes using fine-grained differencing, code abstraction, and change clustering. Then, it learns mutation models using a deep learning strategy. We have trained and evaluated our technique on a set of ~787k bug fixes mined from GitHub. Our empirical evaluation showed that our models are able to predict mutants that resemble the actual fixed bugs in between 9% and 45% of the cases, and over 98% of the automatically generated mutants are lexically and syntactically correct."
},
{
    "py/object": "data.DataClassPaper",
    "Title": "Lancer: Your Code Tell Me What You Need",
    "year": 2019,
    "ML_Techniques": "",
    "Category": "Program comprehension",
    "Sub_category": "",
    "Venue": "ASE",
    "Link": "https://ieeexplore.ieee.org/abstract/document/8952168",
    "bibtex": "inproceedings{1082_Zhou2019,\n    author = \"Zhou, Shufan and Shen, Beijun and Zhong, Hao\",\n    title = \"Lancer: Your code tell me what you need\",\n    booktitle = \"2019 34th IEEE/ACM International Conference on Automated Software Engineering (ASE)\",\n    pages = \"1202--1205\",\n    year = \"2019\",\n    organization = \"IEEE\"\n}\n\n",
    "abstract": "Programming is typically a difficult and repetitive task. Programmers encounter endless problems during programming, and they often need to write similar code over and over again. To prevent programmers from reinventing wheels thus increase their productivity, we propose a context-aware code-to-code recommendation tool named Lancer. With the support of a Library-Sensitive Language Model (LSLM) and the BERT model, Lancer is able to automatically analyze the intention of the incomplete code and recommend relevant and reusable code samples in real-time. A video demonstration of Lancer can be found at https://youtu.be/tO9nhqZY35g. Lancer is open source and the code is available at https://github.com/sfzhou5678/Lancer."
},
{
    "py/object": "data.DataClassPaper",
    "Title": "DeepCPDP: Deep Learning Based Cross-Project Defect Prediction",
    "year": 2019,
    "ML_Techniques": "Bi-LSTM, LOG",
    "Category": "Testing",
    "Sub_category": "Defect prediction",
    "Venue": "IEEE Access",
    "Link": "https://ieeexplore.ieee.org/abstract/document/8937501",
    "bibtex": "article{1083_Chen2019,\n    author = \"Chen, Deyu and Chen, Xiang and Li, Hao and Xie, Junfeng and Mu, Yanzhou\",\n    title = \"Deepcpdp: Deep learning based cross-project defect prediction\",\n    journal = \"IEEE Access\",\n    volume = \"7\",\n    pages = \"184832--184848\",\n    year = \"2019\",\n    publisher = \"IEEE\"\n}\n\n",
    "abstract": "Cross-project defect prediction (CPDP) is an active research topic in the domain of software defect prediction, since CPDP can be applied to the following scenarios: the target project for software defect prediction is a new project or the target project does not have enough labeled modules. Most of the previous work tried to utilize the labeled dataset gathered from other projects (i.e., the source projects) and then proposed transfer learning based methods to reduce the data distribution difference between different projects. In this article, we propose a deep learning based CPDP method DeepCPDP. For this method, we represent source code of each extracted program module by using simplified abstract syntax tree (SimAST). For a node of SimAST, we only keep its node type, since this is project-independent, while we ignore the name of method and variable, since these information are project-specific. Therefore, SimAST is project-independent and especially suitable for the task of CPDP. Then, we extract the token vector from each module after it is modeled via SimAST. Moreover, we design a new unsupervised based embedding method SimASTToken2Vec to learn meaningful representation for these extracted token vectors. Later, we employ Bi-directional Long Short-Term Memory (BiLSTM) neural network to automatically learn semantic features from embedded token vectors. In addition, we use attention mechanism over the BiLSTM layer to learn the weight of the vectors from the learned semantic features. Finally, we construct CPDP models via Logistic regression classifier. To show the effectiveness of DeepCPDP, ten large-scale projects from different application domains are used and AUC measure is used to measure the prediction performance of trained models. By using Scott-Knott test, we can find DeepCPDP can significantly outperform eight state-of-the-art baselines. Moreover, we also verify that the usage of SimASTToken2Vec, BiLSTM and attention mechanism is competitive in our proposed method."
},
{
    "py/object": "data.DataClassPaper",
    "Title": "Assessing the Generalizability of Code2vec Token Embeddings",
    "year": 2019,
    "ML_Techniques": "Seq2Seq",
    "Category": "Code representation",
    "Sub_category": "",
    "Venue": "ASE",
    "Link": "https://ieeexplore.ieee.org/abstract/document/8952475",
    "bibtex": "INPROCEEDINGS{1084_Kang2019,\n    author = \"Kang, Hong Jin and Bissyand\u00e9, Tegawend\u00e9 F. and Lo, David\",\n    booktitle = \"2019 34th IEEE/ACM International Conference on Automated Software Engineering (ASE)\",\n    title = \"Assessing the Generalizability of Code2vec Token Embeddings\",\n    year = \"2019\",\n    volume = \"\",\n    number = \"\",\n    pages = \"1-12\",\n    doi = \"10.1109/ASE.2019.00011\"\n}\n\n",
    "abstract": "Many Natural Language Processing (NLP) tasks, such as sentiment analysis or syntactic parsing, have benefited from the development of word embedding models. In particular, regardless of the training algorithms, the learned embeddings have often been shown to be generalizable to different NLP tasks. In contrast, despite recent momentum on word embeddings for source code, the literature lacks evidence of their generalizability beyond the example task they have been trained for. In this experience paper, we identify 3 potential downstream tasks, namely code comments generation, code authorship identification, and code clones detection, that source code token embedding models can be applied to. We empirically assess a recently proposed code token embedding model, namely code2vec's token embeddings. Code2vec was trained on the task of predicting method names, and while there is potential for using the vectors it learns on other tasks, it has not been explored in literature. Therefore, we fill this gap by focusing on its generalizability for the tasks we have identified. Eventually, we show that source code token embeddings cannot be readily leveraged for the downstream tasks. Our experiments even show that our attempts to use them do not result in any improvements over less sophisticated methods. We call for more research into effective and general use of code embeddings."
},
{
    "py/object": "data.DataClassPaper",
    "Title": "A statistical semantic language model for source code",
    "year": 2013,
    "ML_Techniques": "VSM",
    "Category": "Code representation",
    "Sub_category": "",
    "Venue": "FSE",
    "Link": "https://dl.acm.org/doi/abs/10.1145/2491411.2491458",
    "bibtex": "inproceedings{1086_Nguyen2013,\n    author = \"Nguyen, Tung Thanh and Nguyen, Anh Tuan and Nguyen, Hoan Anh and Nguyen, Tien N.\",\n    title = \"A Statistical Semantic Language Model for Source Code\",\n    year = \"2013\",\n    isbn = \"9781450322379\",\n    publisher = \"Association for Computing Machinery\",\n    address = \"New York, NY, USA\",\n    url = \"https://doi.org/1086_Nguyen2013\",\n    doi = \"1086_Nguyen2013\",\n    abstract = \"Recent research has successfully applied the statistical n-gram language model to show that source code exhibits a good level of repetition. The n-gram model is shown to have good predictability in supporting code suggestion and completion. However, the state-of-the-art n-gram approach to capture source code regularities/patterns is based only on the lexical information in a local context of the code units. To improve predictability, we introduce SLAMC, a novel statistical semantic language model for source code. It incorporates semantic information into code tokens and models the regularities/patterns of such semantic annotations, called sememes, rather than their lexemes. It combines the local context in semantic n-grams with the global technical concerns/functionality into an n-gram topic model, together with pairwise associations of program elements. Based on SLAMC, we developed a new code suggestion method, which is empirically evaluated on several projects to have relatively 18-68\\% higher accuracy than the state-of-the-art approach.\",\n    booktitle = \"Proceedings of the 2013 9th Joint Meeting on Foundations of Software Engineering\",\n    pages = \"532\u2013542\",\n    numpages = \"11\",\n    keywords = \"Code Completion, Statistical Semantic Language Model\",\n    location = \"Saint Petersburg, Russia\",\n    series = \"ESEC/FSE 2013\"\n}\n\n",
    "abstract": "Recent research has successfully applied the statistical n-gram language model to show that source code exhibits a good level of repetition. The n-gram model is shown to have good predictability in supporting code suggestion and completion. However, the state-of-the-art n-gram approach to capture source code regularities/patterns is based only on the lexical information in a local context of the code units. To improve predictability, we introduce SLAMC, a novel statistical semantic language model for source code. It incorporates semantic information into code tokens and models the regularities/patterns of such semantic annotations, called sememes, rather than their lexemes. It combines the local context in semantic n-grams with the global technical concerns/functionality into an n-gram topic model, together with pairwise associations of program elements. Based on SLAMC, we developed a new code suggestion method, which is empirically evaluated on several projects to have relatively 18-68% higher accuracy than the state-of-the-art approach."
},
{
    "py/object": "data.DataClassPaper",
    "Title": "Learning and Evaluating Contextual Embedding of Source Code",
    "year": 2021,
    "ML_Techniques": "LSTM",
    "Category": "Code representation",
    "Sub_category": "",
    "Venue": "PMLR",
    "Link": "https://proceedings.mlr.press/v119/kanade20a.html",
    "bibtex": "InProceedings{1087_Kanade2020,\n    author = \"Kanade, Aditya and Maniatis, Petros and Balakrishnan, Gogul and Shi, Kensen\",\n    editor = \"III, Hal Daum\u00e9 and Singh, Aarti\",\n    title = \"Learning and Evaluating Contextual Embedding of Source Code\",\n    booktitle = \"Proceedings of the 37th International Conference on Machine Learning\",\n    pages = \"5110--5121\",\n    year = \"2020\",\n    volume = \"119\",\n    series = \"Proceedings of Machine Learning Research\",\n    month = \"13--18 Jul\",\n    publisher = \"PMLR\",\n    pdf = \"http://proceedings.mlr.press/v119/kanade20a/kanade20a.pdf\",\n    url = \"https://proceedings.mlr.press/v119/kanade20a.html\",\n    abstract = \"Recent research has achieved impressive results on understanding and improving source code by building up on machine-learning techniques developed for natural languages. A significant advancement in natural-language understanding has come with the development of pre-trained contextual embeddings, such as BERT, which can be fine-tuned for downstream tasks with less labeled data and training budget, while achieving better accuracies. However, there is no attempt yet to obtain a high-quality contextual embedding of source code, and to evaluate it on multiple program-understanding tasks simultaneously; that is the gap that this paper aims to mitigate. Specifically, first, we curate a massive, deduplicated corpus of 7.4M Python files from GitHub, which we use to pre-train CuBERT, an open-sourced code-understanding BERT model; and, second, we create an open-sourced benchmark that comprises five classification tasks and one program-repair task, akin to code-understanding tasks proposed in the literature before. We fine-tune CuBERT on our benchmark tasks, and compare the resulting models to different variants of Word2Vec token embeddings, BiLSTM and Transformer models, as well as published state-of-the-art models, showing that CuBERT outperforms them all, even with shorter training, and with fewer labeled examples. Future work on source-code embedding can benefit from reusing our benchmark, and from comparing against CuBERT models as a strong baseline.\"\n}\n\n",
    "abstract": "Recent research has achieved impressive results on understanding and improving source code by building up on machine-learning techniques developed for natural languages. A significant advancement in natural-language understanding has come with the development of pre-trained contextual embeddings, such as BERT, which can be fine-tuned for downstream tasks with less labeled data and training budget, while achieving better accuracies. However, there is no attempt yet to obtain a high-quality contextual embedding of source code, and to evaluate it on multiple program-understanding tasks simultaneously; that is the gap that this paper aims to mitigate. Specifically, first, we curate a massive, deduplicated corpus of 7.4M Python files from GitHub, which we use to pre-train CuBERT, an open-sourced code-understanding BERT model; and, second, we create an open-sourced benchmark that comprises five classification tasks and one program-repair task, akin to code-understanding tasks proposed in the literature before. We fine-tune CuBERT on our benchmark tasks, and compare the resulting models to different variants of Word2Vec token embeddings, BiLSTM and Transformer models, as well as published state-of-the-art models, showing that CuBERT outperforms them all, even with shorter training, and with fewer labeled examples. Future work on source-code embedding can benefit from reusing our benchmark, and from comparing against CuBERT models as a strong baseline."
},
{
    "py/object": "data.DataClassPaper",
    "Title": "Fast and Memory-Efficient Neural Code Completion",
    "year": 2021,
    "ML_Techniques": "",
    "Category": "Program synthesis",
    "Sub_category": "Program repair",
    "Venue": "MSR",
    "Link": "https://ieeexplore.ieee.org/abstract/document/9463109",
    "bibtex": "inproceedings{1092_Svyatkovskiy2021,\n    author = \"Svyatkovskiy, Alexey and Lee, Sebastian and Hadjitofi, Anna and Riechert, Maik and Franco, Juliana Vicente and Allamanis, Miltiadis\",\n    title = \"Fast and memory-efficient neural code completion\",\n    booktitle = \"2021 IEEE/ACM 18th International Conference on Mining Software Repositories (MSR)\",\n    pages = \"329--340\",\n    year = \"2021\",\n    organization = \"IEEE\"\n}\n\n",
    "abstract": "Code completion is one of the most widely used features of modern integrated development environments (IDEs). While deep learning has made significant progress in the statistical prediction of source code, state-of-the-art neural network models consume hundreds of megabytes of memory, bloating the development environment. We address this in two steps: first we present a modular neural framework for code completion. This allows us to explore the design space and evaluate different techniques. Second, within this framework we design a novel reranking neural completion model that combines static analysis with granular token encodings. The best neural reranking model consumes just 6 MB of RAM, - 19x less than previous models - computes a single completion in 8 ms, and achieves 90% accuracy in its top five suggestions."
},
{
    "py/object": "data.DataClassPaper",
    "Title": "Seml: A Semantic LSTM Model for Software Defect Prediction",
    "year": 2019,
    "ML_Techniques": "LSTM",
    "Category": "Testing",
    "Sub_category": "Defect prediction",
    "Venue": "IEEE Access",
    "Link": "https://ieeexplore.ieee.org/abstract/document/8747001",
    "bibtex": "article{1094_Liang2019,\n    author = \"Liang, Hongliang and Yu, Yue and Jiang, Lin and Xie, Zhuosi\",\n    title = \"Seml: A semantic LSTM model for software defect prediction\",\n    journal = \"IEEE Access\",\n    volume = \"7\",\n    pages = \"83812--83824\",\n    year = \"2019\",\n    publisher = \"IEEE\"\n}\n\n",
    "abstract": "Software defect prediction can assist developers in finding potential bugs and reducing maintenance cost. Traditional approaches usually utilize software metrics (Lines of Code, Cyclomatic Complexity, etc.) as features to build classifiers and identify defective software modules. However, software metrics often fail to capture programs' syntax and semantic information. In this paper, we propose Seml, a novel framework that combines word embedding and deep learning methods for defect prediction. Specifically, for each program source file, we first extract a token sequence from its abstract syntax tree. Then, we map each token in the sequence to a real-valued vector using a mapping table, which is trained with an unsupervised word embedding model. Finally, we use the vector sequences and their labels (defective or non-defective) to build a Long Short Term Memory (LSTM) network. The LSTM model can automatically learn the semantic information of programs and perform defect prediction. The evaluation results on eight open source projects show that Seml outperforms three state-of-the-art defect prediction approaches on most of the datasets for both within-project defect prediction and cross-project defect prediction."
},
{
    "py/object": "data.DataClassPaper",
    "Title": "Convolutional Neural Networks over Control Flow Graphs for Software Defect Prediction",
    "year": 2017,
    "ML_Techniques": "GNN",
    "Category": "Testing",
    "Sub_category": "Defect prediction",
    "Venue": "ICTAI",
    "Link": "https://ieeexplore.ieee.org/abstract/document/8371922",
    "bibtex": "inproceedings{1095_Phan2017,\n    author = \"Phan, Anh Viet and Le Nguyen, Minh and Bui, Lam Thu\",\n    title = \"Convolutional neural networks over control flow graphs for software defect prediction\",\n    booktitle = \"2017 IEEE 29th International Conference on Tools with Artificial Intelligence (ICTAI)\",\n    pages = \"45--52\",\n    year = \"2017\",\n    organization = \"IEEE\"\n}\n\n",
    "abstract": "Existing defects in software components is unavoidable and leads to not only a waste of time and money but also many serious consequences. To build predictive models, previous studies focus on manually extracting features or using tree representations of programs, and exploiting different machine learning algorithms. However, the performance of the models is not high since the existing features and tree structures often fail to capture the semantics of programs. To explore deeply programs\u2019 semantics, this paper proposes to leverage precise graphs representing program execution flows, and deep neural networks for automatically learning defect features. Firstly, control flow graphs are constructed from the assembly instructions obtained by compiling source code; we thereafter apply multi-view multi-layer directed graph-based convolutional neural networks (DGCNNs) to learn semantic features. The experiments on four real-world datasets show that our method significantly outperforms the baselines including several other deep learning approaches."
},
{
    "py/object": "data.DataClassPaper",
    "Title": "Deep-AutoCoder: Learning to Complete Code Precisely with Induced Code Tokens",
    "year": 2019,
    "ML_Techniques": "LSTM",
    "Category": "Program comprehension",
    "Sub_category": "",
    "Venue": "COMPSAC",
    "Link": "https://ieeexplore.ieee.org/abstract/document/8754502",
    "bibtex": "inproceedings{1097_Hu2019,\n    author = \"Hu, Xing and Men, Rui and Li, Ge and Jin, Zhi\",\n    title = \"Deep-autocoder: Learning to complete code precisely with induced code tokens\",\n    booktitle = \"2019 IEEE 43rd Annual Computer Software and Applications Conference (COMPSAC)\",\n    volume = \"1\",\n    pages = \"159--168\",\n    year = \"2019\",\n    organization = \"IEEE\"\n}\n\n",
    "abstract": "Code completion is an essential part of modern IDEs. It assists the developers to speed up the process of coding and reducing typos. In this paper, we exploit the deep learning technique called LSTM to learn language models over large code corpus and make predictions of code elements. Unlike natural language, the innumerable identifiers lead to the vocabulary explosion and more difficult to predict. Therefore, we propose a new approach, the Induced Token based LSTM, to deal with the massive identifiers, thus decrease the vocabulary size. In order to induce the code tokens, we present two approaches, one is a constraint character-level LSTM and the other one is encoding identifiers with various preceding context before feeding them into a token-level LSTM. Based on the two approaches, a tool named Deep-AutoCoder is developed and evaluated in two classic completion scenarios, that is, method invocation completion and random completion. The experiment results indicate that Deep-AutoCoder outperforms the state-of-the-arts on method invocation completion and random code completion. Additionally, the empirical results of Deep-AutoCoder indicate that reducing the size of vocabulary can effectively improve the precision of code completion."
},
{
    "py/object": "data.DataClassPaper",
    "Title": "A survey on deep learning for software engineering",
    "year": 2022,
    "ML_Techniques": "",
    "Category": "General",
    "Sub_category": "",
    "Venue": "CSUR",
    "Link": "https://dl.acm.org/doi/full/10.1145/3505243",
    "bibtex": "@article{1102_Yang2022, author = {Yang, Yanming and Xia, Xin and Lo, David and Grundy, John}, title = {A Survey on Deep Learning for Software Engineering}, year = {2022}, issue_date = {January 2022}, publisher = {Association for Computing Machinery}, address = {New York, NY, USA}, volume = {54}, number = {10s}, issn = {0360-0300}, url = {https://doi.org/10.1145/3505243}, doi = {10.1145/3505243}, journal = {ACM Comput. Surv.}, month = {sep}, articleno = {206}, numpages = {73}, keywords = {Deep learning, neural network, survey, machine learning, software engineering} }",
    "abstract": "In 2006, Geoffrey Hinton proposed the concept of training “Deep Neural Networks (DNNs)” and an improved model training method to break the bottleneck of neural network development. More recently, the introduction of AlphaGo in 2016 demonstrated the powerful learning ability of deep learning and its enormous potential. Deep learning has been increasingly used to develop state-of-the-art software engineering (SE) research tools due to its ability to boost performance for various SE tasks. There are many factors, e.g., deep learning model selection, internal structure differences, and model optimization techniques, that may have an impact on the performance of DNNs applied in SE. Few works to date focus on summarizing, classifying, and analyzing the application of deep learning techniques in SE. To fill this gap, we performed a survey to analyze the relevant studies published since 2006. We first provide an example to illustrate how deep learning techniques are used in SE. We then conduct a background analysis (BA) of primary studies and present four research questions to describe the trend of DNNs used in SE (BA), summarize and classify different deep learning techniques (RQ1), and analyze the data processing including data collection, data classification, data pre-processing, and data representation (RQ2). In RQ3, we depicted a range of key research topics using DNNs and investigated the relationships between DL-based model adoption and multiple factors (i.e., DL architectures, task types, problem types, and data types). We also summarized commonly used datasets for different SE tasks. In RQ4, we summarized the widely used optimization algorithms and provided important evaluation metrics for different problem types, including regression, classification, recommendation, and generation. Based on our findings, we present a set of current challenges remaining to be investigated and outline a proposed research road map highlighting key opportunities for future work."
},
{
    "py/object": "data.DataClassPaper",
    "Title": "Machine learning to evaluate evolvability defects: Code metrics thresholds for a given context",
    "year": 2018,
    "ML_Techniques": "LR",
    "Category": "Quality assessment",
    "Sub_category": "",
    "Venue": "QRS",
    "Link": "https://ieeexplore.ieee.org/document/8424961",
    "bibtex": "@INPROCEEDINGS{1103_Tsuda2018, author={Tsuda, Naohiko and Washizaki, Hironori and Fukazawa, Yoshiaki and Yasuda, Yuichiro and Sugimura, Shunsuke}, booktitle={2018 IEEE International Conference on Software Quality, Reliability and Security (QRS)}, title={Machine Learning to Evaluate Evolvability Defects: Code Metrics Thresholds for a Given Context}, year={2018}, volume={}, number={}, pages={83-94}, doi={10.1109/QRS.2018.00022}}",
    "abstract": "Software insecurity is being identified as one of the leading causes of security breaches. In this paper, we revisited one of the strategies in solving software insecurity, which is the use of software quality metrics. We utilized a multilayer deep feedforward network in examining whether there is a combination of metrics that can predict the appearance of security-related bugs. We also applied the traditional machine learning algorithms such as decision tree, random forest, naïve bayes, and support vector machines and compared the results with that of the Deep Learning technique. The results have successfully demonstrated that it was possible to develop an effective predictive model to forecast software insecurity based on the software metrics and using Deep Learning. All the models generated have shown an accuracy of more than sixty percent with Deep Learning leading the list. This finding proved that utilizing Deep Learning methods and a combination of software metrics can be tapped to create a better forecasting model thereby aiding software developers in predicting security bugs."
},
{
    "py/object": "data.DataClassPaper",
    "Title": "Building program vector representations for deep learning",
    "year": 2015,
    "ML_Techniques": "DNN",
    "Category": "Code representation",
    "Sub_category": "",
    "Venue": "KSEM",
    "Link": "https://link.springer.com/chapter/10.1007/978-3-319-25159-2_49",
    "bibtex": "@inproceedings{1104_Peng2015,   title={Building program vector representations for deep learning},   author={Peng, Hao and Mou, Lili and Li, Ge and Liu, Yuxuan and Zhang, Lu and Jin, Zhi},   booktitle={International conference on knowledge science, engineering and management},   pages={547--553},   year={2015},   organization={Springer} }",
    "abstract": "Deep learning has made significant breakthroughs in various fields of artificial intelligence. However, it is still virtually impossible to use deep learning to analyze programs since deep architectures cannot be trained effectively with pure back propagation. In this pioneering paper, we propose the “coding criterion” to build program vector representations, which are the premise of deep learning for program analysis. We evaluate the learned vector representations both qualitatively and quantitatively. We conclude, based on the experiments, the coding criterion is successful in building program representations. To evaluate whether deep learning is beneficial for program analysis, we feed the representations to deep neural networks, and achieve higher accuracy in the program classification task than “shallow” methods. This result confirms the feasibility of deep learning to analyze programs."
},
{
    "py/object": "data.DataClassPaper",
    "Title": "Integrating tree path in transformer for code representation",
    "year": 2021,
    "ML_Techniques": "TF, GRU",
    "Category": "Code representation",
    "Sub_category": "",
    "Venue": "NeurIPS",
    "Link": "https://proceedings.neurips.cc/paper/2021/hash/4e0223a87610176ef0d24ef6d2dcde3a-Abstract.html",
    "bibtex": "@inproceedings{1105_Peng2021,  author = {Peng, Han and Li, Ge and Wang, Wenhan and Zhao, YunFei and Jin, Zhi},  booktitle = {Advances in Neural Information Processing Systems},  editor = {M. Ranzato and A. Beygelzimer and Y. Dauphin and P.S. Liang and J. Wortman Vaughan},  pages = {9343--9354},  publisher = {Curran Associates, Inc.},  title = {Integrating Tree Path in Transformer for Code Representation},  url = {https://proceedings.neurips.cc/paper/2021/file/4e0223a87610176ef0d24ef6d2dcde3a-Paper.pdf},  volume = {34},  year = {2021} }",
    "abstract": "Learning distributed representation of source code requires modelling its syntax and semantics. Recent state-of-the-art models leverage highly structured source code representations, such as the syntax trees and paths therein. In this paper, we investigate two representative path encoding methods shown in previous research work and integrate them into the attention module of Transformer. We draw inspiration from the ideas of positional encoding and modify them to incorporate these path encoding. Specifically, we encode both the pairwise path between tokens of source code and the path from the leaf node to the tree root for each token in the syntax tree. We explore the interaction between these two kinds of paths by integrating them into the unified Transformer framework. The detailed empirical study for path encoding methods also leads to our novel state-of-the-art representation model TPTrans, which finally outperforms strong baselines. Extensive experiments and ablation studies on code summarization across four different languages demonstrate the effectiveness of our approaches. We release our code at \\url{https://github.com/AwdHanPeng/TPTrans}."
},
{
    "py/object": "data.DataClassPaper",
    "Title": "Towards automating code review activities",
    "year": 2021,
    "ML_Techniques": "RF, DT, BN",
    "Category": "Code review",
    "Sub_category": "",
    "Venue": "ICSE",
    "Link": "https://ieeexplore.ieee.org/abstract/document/9402025",
    "bibtex": "@inproceedings{1108_Tufano2021,   title={Towards automating code review activities},   author={Tufano, Rosalia and Pascarella, Luca and Tufano, Michele and Poshyvanyk, Denys and Bavota, Gabriele},   booktitle={2021 IEEE/ACM 43rd International Conference on Software Engineering (ICSE)},   pages={163--174},   year={2021},   organization={IEEE} }",
    "abstract": "Code reviews are popular in both industrial and open source projects. The benefits of code reviews are widely recognized and include better code quality and lower likelihood of introducing bugs. However, since code review is a manual activity it comes at the cost of spending developers' time on reviewing their teammates' code. Our goal is to make the first step towards partially automating the code review process, thus, possibly reducing the manual costs associated with it. We focus on both the contributor and the reviewer sides of the process, by training two different Deep Learning architectures. The first one learns code changes performed by developers during real code review activities, thus providing the contributor with a revised version of her code implementing code transformations usually recommended during code review before the code is even submitted for review. The second one automatically provides the reviewer commenting on a submitted code with the revised code implementing her comments expressed in natural language. The empirical evaluation of the two models shows that, on the contributor side, the trained model succeeds in replicating the code transformations applied during code reviews in up to 16% of cases. On the reviewer side, the model can correctly implement a comment provided in natural language in up to 31% of cases. While these results are encouraging, more research is needed to make these models usable by developers."
},
{
    "py/object": "data.DataClassPaper",
    "Title": "Using Pre-Trained Models to Boost Code Review Automation",
    "year": 2022,
    "ML_Techniques": "TF",
    "Category": "Code review",
    "Sub_category": "",
    "Venue": "ICSE",
    "Link": "https://arxiv.org/abs/2201.06850",
    "bibtex": "@article{1109_Tufano2022,   title={Using Pre-Trained Models to Boost Code Review Automation},   author={Tufano, Rosalia and Masiero, Simone and Mastropaolo, Antonio and Pascarella, Luca and Poshyvanyk, Denys and Bavota, Gabriele},   journal={arXiv preprint arXiv:2201.06850},   year={2022} }",
    "abstract": "Code review is a practice widely adopted in open source and industrial projects. Given the non-negligible cost of such a process, researchers started investigating the possibility of automating specific code review tasks. We recently proposed Deep Learning (DL) models targeting the automation of two tasks: the first model takes as input a code submitted for review and implements in it changes likely to be recommended by a reviewer; the second takes as input the submitted code and a reviewer comment posted in natural language and automatically implements the change required by the reviewer. While the preliminary results we achieved are encouraging, both models had been tested in rather simple code review scenarios, substantially simplifying the targeted problem. This was also due to the choices we made when designing both the technique and the experiments. In this paper, we build on top of that work by demonstrating that a pre-trained Text-To-Text Transfer Transformer (T5) model can outperform previous DL models for automating code review tasks. Also, we conducted our experiments on a larger and more realistic (and challenging) dataset of code review activities."
},

{
    "py/object": "data.DataClassPaper",
    "Title": "AutoTransform: Automated Code Transformation to Support Modern Code Review Process",
    "year": 2022,
    "ML_Techniques": "TF",
    "Category": "Code review",
    "Sub_category": "",
    "Venue": "ICSE",
    "Link": "https://www.researchgate.net/publication/358486098_AutoTransform_Automated_Code_Transformation_to_Support_Modern_Code_Review_Process",
    "bibtex": "@article{1110_Thongtanunam2022,   title={AutoTransform: Automated Code Transformation to Support Modern Code Review Process},   author={Thongtanunam, Patanamon and Pornprasit, Chanathip and Tantithamthavorn, Chakkrit},   year={2022} }",
    "abstract": "Code review is effective, but human-intensive (e.g., developers need to manually modify source code until it is approved). Recently, prior work proposed a Neural Machine Translation (NMT) approach to automatically transform source code to the version that is reviewed and approved (i.e., the after version). Yet, its performance is still suboptimal when the after version has new identifiers or liter-als (e.g., renamed variables) or has many code tokens. To address these limitations, we propose AutoTransform which leverages a Byte-Pair Encoding (BPE) approach to handle new tokens and a Transformer-based NMT architecture to handle long sequences. We evaluate our approach based on 14,750 changed methods with and without new tokens for both small and medium sizes. The results show that when generating one candidate for the after version (i.e., beam width = 1), our AutoTransform can correctly transform 1,413 changed methods, which is 567% higher than the prior work, highlighting the substantial improvement of our approach for code transformation in the context of code review. This work contributes towards automated code transformation for code reviews, which could help developers reduce their effort in modifying source code during the code review process."
},
{
    "py/object": "data.DataClassPaper",
    "Title": "Unsupervised translation of programming languages",
    "year": 2020,
    "ML_Techniques": "Seq2Seq, TF",
    "Category": "Program synthesis",
    "Sub_category": "Program translation",
    "Venue": "NeurIPS",
    "Link": "https://proceedings.neurips.cc/paper/2020/hash/ed23fbf18c2cd35f8c7f8de44f85c08d-Abstract.html",
    "bibtex": "@article{1111_Roziere2020,   title={Unsupervised translation of programming languages},   author={Roziere, Baptiste and Lachaux, Marie-Anne and Chanussot, Lowik and Lample, Guillaume},   journal={Advances in Neural Information Processing Systems},   volume={33},   pages={20601--20611},   year={2020} }",
    "abstract": "A transcompiler, also known as source-to-source translator, is a system that converts source code from a high-level programming language (such as C++ or Python) to another. Transcompilers are primarily used for interoperability, and to port codebases written in an obsolete or deprecated language (e.g. COBOL, Python 2) to a modern one. They typically rely on handcrafted rewrite rules, applied to the source code abstract syntax tree. Unfortunately, the resulting translations often lack readability, fail to respect the target language conventions, and require manual modifications in order to work properly. The overall translation process is time-consuming and requires expertise in both the source and target languages, making code-translation projects expensive. Although neural models significantly outperform their rule-based counterparts in the context of natural language translation, their applications to transcompilation have been limited due to the scarcity of parallel data in this domain. In this paper, we propose to leverage recent approaches in unsupervised machine translation to train a fully unsupervised neural transcompiler. We train our model on source code from open source GitHub projects, and show that it can translate functions between C++, Java, and Python with high accuracy. Our method relies exclusively on monolingual source code, requires no expertise in the source or target languages, and can easily be generalized to other programming languages. We also build and release a test set composed of 852 parallel functions, along with unit tests to check the correctness of translations. We show that our model outperforms rule-based commercial baselines by a significant margin."
},
{
    "py/object": "data.DataClassPaper",
    "Title": "A survey on deep learning for software engineering",
    "year": 2018,
    "ML_Techniques": "EN-DE, LSTM",
    "Category": "Program synthesis",
    "Sub_category": "Code generation",
    "Venue": "EMNLP",
    "Link": "https://arxiv.org/abs/1810.02720",
    "bibtex": "@article{1102_Yang2022, author = {Yang, Yanming and Xia, Xin and Lo, David and Grundy, John}, title = {A Survey on Deep Learning for Software Engineering}, year = {2022}, issue_date = {January 2022}, publisher = {Association for Computing Machinery}, address = {New York, NY, USA}, volume = {54}, number = {10s}, issn = {0360-0300}, url = {https://doi.org/10.1145/3505243}, doi = {10.1145/3505243}, journal = {ACM Comput. Surv.}, month = {sep}, articleno = {206}, numpages = {73}, keywords = {Deep learning, neural network, survey, machine learning, software engineering} }",
    "abstract": "We present TRANX, a transition-based neural semantic parser that maps natural language (NL) utterances into formal meaning representations (MRs). TRANX uses a transition system based on the abstract syntax description language for the target MR, which gives it two major advantages: (1) it is highly accurate, using information from the syntax of the target MR to constrain the output space and model the information flow, and (2) it is highly generalizable, and can easily be applied to new types of MR by just writing a new abstract syntax description corresponding to the allowable structures in the MR. Experiments on four different semantic parsing and code generation tasks show that our system is generalizable, extensible, and effective, registering strong results compared to existing neural semantic parsers."
},
{
    "py/object": "data.DataClassPaper",
    "Title": "Treegen: A tree-based transformer architecture for code generation",
    "year": 2020,
    "ML_Techniques": "TF",
    "Category": "Program synthesis",
    "Sub_category": "Code generation",
    "Venue": "AAAI",
    "Link": "https://ojs.aaai.org/index.php/AAAI/article/view/6430",
    "bibtex": "@inproceedings{1113_Sun2020,   title={Treegen: A tree-based transformer architecture for code generation},   author={Sun, Zeyu and Zhu, Qihao and Xiong, Yingfei and Sun, Yican and Mou, Lili and Zhang, Lu},   booktitle={Proceedings of the AAAI Conference on Artificial Intelligence},   volume={34},   number={05},   pages={8984--8991},   year={2020} }",
    "abstract": "A code generation system generates programming language code based on an input natural language description. State-of-the-art approaches rely on neural networks for code generation. However, these code generators suffer from two problems. One is the long dependency problem, where a code element often depends on another far-away code element. A variable reference, for example, depends on its definition, which may appear quite a few lines before. The other problem is structure modeling, as programs contain rich structural information. In this paper, we propose a novel tree-based neural architecture, TreeGen, for code generation. TreeGen uses the attention mechanism of Transformers to alleviate the long-dependency problem, and introduces a novel AST reader (encoder) to incorporate grammar rules and AST structures into the network. We evaluated TreeGen on a Python benchmark, HearthStone, and two semantic parsing benchmarks, ATIS and GEO. TreeGen outperformed the previous state-of-the-art approach by 4.5 percentage points on HearthStone, and achieved the best accuracy among neural network-based approaches on ATIS (89.1%) and GEO (89.6%). We also conducted an ablation test to better understand each component of our model."
},
{
    "py/object": "data.DataClassPaper",
    "Title": "Evaluating large language models trained on code",
    "year": 2021,
    "ML_Techniques": "",
    "Category": "Program synthesis",
    "Sub_category": "Code generation",
    "Venue": "",
    "Link": "https://arxiv.org/abs/2107.03374",
    "bibtex": "@article{1114_Chen2021,   title={Evaluating large language models trained on code},   author={Chen, Mark and Tworek, Jerry and Jun, Heewoo and Yuan, Qiming and Pinto, Henrique Ponde de Oliveira and Kaplan, Jared and Edwards, Harri and Burda, Yuri and Joseph, Nicholas and Brockman, Greg and others},   journal={arXiv preprint arXiv:2107.03374},   year={2021} }",
    "abstract": "We introduce Codex, a GPT language model fine-tuned on publicly available code from GitHub, and study its Python code-writing capabilities. A distinct production version of Codex powers GitHub Copilot. On HumanEval, a new evaluation set we release to measure functional correctness for synthesizing programs from docstrings, our model solves 28.8% of the problems, while GPT-3 solves 0% and GPT-J solves 11.4%. Furthermore, we find that repeated sampling from the model is a surprisingly effective strategy for producing working solutions to difficult prompts. Using this method, we solve 70.2% of our problems with 100 samples per problem. Careful investigation of our model reveals its limitations, including difficulty with docstrings describing long chains of operations and with binding operations to variables. Finally, we discuss the potential broader impacts of deploying powerful code generation technologies, covering safety, security, and economics."
},
{
    "py/object": "data.DataClassPaper",
    "Title": "Competition-level code generation with alphacode",
    "year": 2022,
    "ML_Techniques": "TF",
    "Category": "Program synthesis",
    "Sub_category": "Code generation",
    "Venue": "Science",
    "Link": "https://www.science.org/doi/full/10.1126/science.abq1158",
    "bibtex": "@article{1115_Li2022,   title={Competition-level code generation with alphacode},   author={Li, Yujia and Choi, David and Chung, Junyoung and Kushman, Nate and Schrittwieser, Julian and Leblond, R{'e}mi and Eccles, Tom and Keeling, James and Gimeno, Felix and Dal Lago, Agustin and others},   journal={Science},   volume={378},   number={6624},   pages={1092--1097},   year={2022},   publisher={American Association for the Advancement of Science} }",
    "abstract": "Programming is a powerful and ubiquitous problem-solving tool. Systems that can assist programmers or even generate programs themselves could make programming more productive and accessible. Recent transformer-based neural network models show impressive code generation abilities yet still perform poorly on more complex tasks requiring problem-solving skills, such as competitive programming problems. Here, we introduce AlphaCode, a system for code generation that achieved an average ranking in the top 54.3% in simulated evaluations on recent programming competitions on the Codeforces platform. AlphaCode solves problems by generating millions of diverse programs using specially trained transformer-based networks and then filtering and clustering those programs to a maximum of just 10 submissions. This result marks the first time an artificial intelligence system has performed competitively in programming competitions."
},
{
    "py/object": "data.DataClassPaper",
    "Title": "The impact of IR-based classifier configuration on the performance and the effort of method-level bug localization",
    "year": 2018,
    "ML_Techniques": "VSM, LDA, LSI",
    "Category": "Testing",
    "Sub_category": "Defect prediction",
    "Venue": "IST",
    "Link": "https://www.sciencedirect.com/science/article/abs/pii/S0950584918301058",
    "bibtex": "@article{1116_Tantithamthavorn2018,   title={The impact of IR-based classifier configuration on the performance and the effort of method-level bug localization},   author={Tantithamthavorn, Chakkrit and Abebe, Surafel Lemma and Hassan, Ahmed E and Ihara, Akinori and Matsumoto, Kenichi},   journal={Information and Software Technology},   volume={102},   pages={160--174},   year={2018},   publisher={Elsevier} }",
    "abstract": "Context IR-based bug localization is a classifier that assists developers in locating buggy source code entities (e.g., files and methods) based on the content of a bug report. Such IR-based classifiers have various parameters that can be configured differently (e.g., the choice of entity representation). Objective In this paper, we investigate the impact of the choice of the IR-based classifier configuration on the top-k performance and the required effort to examine source code entities before locating a bug at the method level. Method We execute a large space of classifier configuration, 3172 in total, on 5266 bug reports of two software systems, i.e., Eclipse and Mozilla. Results We find that (1) the choice of classifier configuration impacts the top-k performance from 0.44% to 36% and the required effort from 4395 to 50,000 LOC; (2) classifier configurations with similar top-k performance might require different efforts; (3) VSM achieves both the best top-k performance and the least required effort for method-level bug localization; (4) the likelihood of randomly picking a configuration that performs within 20% of the best top-k classifier configuration is on average 5.4% and that of the least effort is on average 1%; (5) configurations related to the entity representation of the analyzed data have the most impact on both the top-k performance and the required effort; and (6) the most efficient classifier configuration obtained at the method-level can also be used at the file-level (and vice versa). Conclusion     Our results lead us to conclude that configuration has a large impact on both the top-k performance and the required effort for method-level bug localization, suggesting that the IR-based configuration settings should be carefully selected and the required effort metric should be included in future bug localization studies."
},
{
    "py/object": "data.DataClassPaper",
    "Title": "An unsupervised approach for discovering relevant tutorial fragments for APIs",
    "year": 2017,
    "ML_Techniques": "LDA",
    "Category": "Code search",
    "Sub_category": "",
    "Venue": "ICSE",
    "Link": "https://ieeexplore.ieee.org/abstract/document/7985648",
    "bibtex": "@inproceedings{1118_Jiang2017,   title={An unsupervised approach for discovering relevant tutorial fragments for APIs},   author={Jiang, He and Zhang, Jingxuan and Ren, Zhilei and Zhang, Tao},   booktitle={2017 IEEE/ACM 39th International Conference on Software Engineering (ICSE)},   pages={38--48},   year={2017},   organization={IEEE} }",
    "abstract": "Developers increasingly rely on API tutorials to facilitate software development. However, it remains a challenging task for them to discover relevant API tutorial fragments explaining unfamiliar APIs. Existing supervised approaches suffer from the heavy burden of manually preparing corpus-specific annotated data and features. In this study, we propose a novel unsupervised approach, namely Fragment Recommender for APIs with PageRank and Topic model (FRAPT). FRAPT can well address two main challenges lying in the task and effectively determine relevant tutorial fragments for APIs. In FRAPT, a Fragment Parser is proposed to identify APIs in tutorial fragments and replace ambiguous pronouns and variables with related ontologies and API names, so as to address the pronoun and variable resolution challenge. Then, a Fragment Filter employs a set of non-explanatory detection rules to remove non-explanatory fragments, thus address the non-explanatory fragment identification challenge. Finally, two correlation scores are achieved and aggregated to determine relevant fragments for APIs, by applying both topic model and PageRank algorithm to the retained fragments. Extensive experiments over two publicly open tutorial corpora show that, FRAPT improves the state-of-the-art approach by 8.77% and 12.32% respectively in terms of F-Measure. The effectiveness of key components of FRAPT is also validated."
},
{
    "py/object": "data.DataClassPaper",
    "Title": "An empirical study on the importance of source code entities for requirements traceability",
    "year": 2015,
    "ML_Techniques": "LSI, LDA",
    "Category": "Program comprehension",
    "Sub_category": "Entity identification/recommendation",
    "Venue": "ICSE",
    "Link": "https://ieeexplore.ieee.org/abstract/document/7985648",
    "bibtex": "@article{1121_Ali2015,   title={An empirical study on the importance of source code entities for requirements traceability},   author={Ali, Nasir and Sharafi, Zohreh and Gu{\\'e}h{\\'e}neuc, Yann-Ga{\"\"e} l and Antoniol, Giuliano},   journal={Empirical software engineering},   volume={20},   number={2},   pages={442--478},   year={2015},   publisher={Springer} }",
    "abstract": "Developers increasingly rely on API tutorials to facilitate software development. However, it remains a challenging task for them to discover relevant API tutorial fragments explaining unfamiliar APIs. Existing supervised approaches suffer from the heavy burden of manually preparing corpus-specific annotated data and features. In this study, we propose a novel unsupervised approach, namely Fragment Recommender for APIs with PageRank and Topic model (FRAPT). FRAPT can well address two main challenges lying in the task and effectively determine relevant tutorial fragments for APIs. In FRAPT, a Fragment Parser is proposed to identify APIs in tutorial fragments and replace ambiguous pronouns and variables with related ontologies and API names, so as to address the pronoun and variable resolution challenge. Then, a Fragment Filter employs a set of non-explanatory detection rules to remove non-explanatory fragments, thus address the non-explanatory fragment identification challenge. Finally, two correlation scores are achieved and aggregated to determine relevant fragments for APIs, by applying both topic model and PageRank algorithm to the retained fragments. Extensive experiments over two publicly open tutorial corpora show that, FRAPT improves the state-of-the-art approach by 8.77% and 12.32% respectively in terms of F-Measure. The effectiveness of key components of FRAPT is also validated."
},
{
    "py/object": "data.DataClassPaper",
    "Title": "Lascad : Language-agnostic software categorization and similar application detection",
    "year": 2018,
    "ML_Techniques": "LDA, HC",
    "Category": "Program comprehension",
    "Sub_category": "Entity identification/recommendation",
    "Venue": "JSS",
    "Link": "https://www.sciencedirect.com/science/article/abs/pii/S0164121218300682",
    "bibtex": "",
    "abstract": "Categorizing software and detecting similar programs are useful for various purposes including expertise sharing, program comprehension, and rapid prototyping. However, existing categorization and similar software detection tools are not sufficient. Some tools only handle applications written in certain languages or belonging to specific domains like Java or Android. Other tools require significant configuration effort due to their sensitivity to parameter settings, and may produce excessively large numbers of categories. In this paper, we present a more usable and reliable approach of Language-Agnostic Software Categorization and similar Application Detection (Lascad). Our approach applies Latent Dirichlet Allocation (LDA) and hierarchical clustering to programs’ source code in order to reveal which applications implement similar functionalities. Lascad is easier to use in cases when no domain-specific tool is available or when users want to find similar software in different programming languages.    To evaluate Lascad’s capability of categorizing software, we used three labeled data sets: two sets from prior work and one larger set that we created with 103 applications implemented in 19 different languages. By comparing Lascad with prior approaches on these data sets, we found Lascad to be more usable and outperform existing tools. To evaluate Lascad’s capability of similar application detection, we reused our 103-application data set and a newly created unlabeled data set of 5220 applications. The relevance scores of the Top-1 retrieved applications within these two data sets were, separately, 70% and 71%. Overall, Lascad effectively categorizes and detects similar programs across languages."
},
{
    "py/object": "data.DataClassPaper",
    "Title": "Improving software modularization via automated analysis of latent topics and dependencies",
    "year": 2014,
    "ML_Techniques": "LDA",
    "Category": "Refactoring",
    "Sub_category": "",
    "Venue": "TOSEM",
    "Link": "https://dl.acm.org/doi/abs/10.1145/2559935",
    "bibtex": "@article{1126_Bavota2014,   title={Improving software modularization via automated analysis of latent topics and dependencies},   author={Bavota, Gabriele and Gethers, Malcom and Oliveto, Rocco and Poshyvanyk, Denys and Lucia, Andrea de},   journal={ACM Transactions on Software Engineering and Methodology (TOSEM)},   volume={23},   number={1},   pages={1--33},   year={2014},   publisher={ACM New York, NY, USA} }",
    "abstract": "Oftentimes, during software maintenance the original program modularization decays, thus reducing its quality. One of the main reasons for such architectural erosion is suboptimal placement of source-code classes in software packages. To alleviate this issue, we propose an automated approach to help developers improve the quality of software modularization. Our approach analyzes underlying latent topics in source code as well as structural dependencies to recommend (and explain) refactoring operations aiming at moving a class to a more suitable package. The topics are acquired via Relational Topic Models (RTM), a probabilistic topic modeling technique. The resulting tool, coined as R3 (Rational Refactoring via RTM), has been evaluated in two empirical studies. The results of the first study conducted on nine software systems indicate that R3 provides a coupling reduction from 10% to 30% among the software modules. The second study with 62 developers confirms that R3 is able to provide meaningful recommendations (and explanations) for move class refactoring. Specifically, more than 70% of the recommendations were considered meaningful from a functional point of view."
},
{
    "py/object": "data.DataClassPaper",
    "Title": "Methodbook: Recommending Move Method Refactorings via Relational Topic Models",
    "year": 2013,
    "ML_Techniques": "",
    "Category": "Refactoring",
    "Sub_category": "",
    "Venue": "TSE",
    "Link": "https://ieeexplore.ieee.org/abstract/document/6684534",
    "bibtex": "@article{1125_Bavota2013,   title={Methodbook: Recommending move method refactorings via relational topic models},   author={Bavota, Gabriele and Oliveto, Rocco and Gethers, Malcom and Poshyvanyk, Denys and De Lucia, Andrea},   journal={IEEE Transactions on Software Engineering},   volume={40},   number={7},   pages={671--694},   year={2013},   publisher={IEEE} }",
    "abstract": "During software maintenance and evolution the internal structure of the software system undergoes continuous changes. These modifications drift the source code away from its original design, thus deteriorating its quality, including cohesion and coupling of classes. Several refactoring methods have been proposed to overcome this problem. In this paper we propose a novel technique to identify Move Method refactoring opportunities and remove the Feature Envy bad smell from source code. Our approach, coined as Methodbook, is based on relational topic models (RTM), a probabilistic technique for representing and modeling topics, documents (in our case methods) and known relationships among these. Methodbook uses RTM to analyze both structural and textual information gleaned from software to better support move method refactoring. We evaluated Methodbook in two case studies. The first study has been executed on six software systems to analyze if the move method operations suggested by Methodbook help to improve the design quality of the systems as captured by quality metrics. The second study has been conducted with eighty developers that evaluated the refactoring recommendations produced by Methodbook. The achieved results indicate that Methodbook provides accurate and meaningful recommendations for move method refactoring operations."
},
{
    "py/object": "data.DataClassPaper",
    "Title": "Configuring latent Dirichlet allocation based feature location",
    "year": 2014,
    "ML_Techniques": "LDA",
    "Category": "Program comprehension",
    "Sub_category": "Entity identification/recommendation",
    "Venue": "ESEM",
    "Link": "https://link.springer.com/article/10.1007/s10664-012-9224-x",
    "bibtex": "@article{1126_Biggers2014,   title={Configuring latent dirichlet allocation based feature location},   author={Biggers, Lauren R and Bocovich, Cecylia and Capshaw, Riley and Eddy, Brian P and Etzkorn, Letha H and Kraft, Nicholas A},   journal={Empirical Software Engineering},   volume={19},   number={3},   pages={465--500},   year={2014},   publisher={Springer} }",
    "abstract": "Feature location is a program comprehension activity, the goal of which is to identify source code entities that implement a functionality. Recent feature location techniques apply text retrieval models such as latent Dirichlet allocation (LDA) to corpora built from text embedded in source code. These techniques are highly configurable, and the literature offers little insight into how different configurations affect their performance. In this paper we present a study of an LDA based feature location technique (FLT) in which we measure the performance effects of using different configurations to index corpora and to retrieve 618 features from 6 open source Java systems. In particular, we measure the effects of the query, the text extractor configuration, and the LDA parameter values on the accuracy of the LDA based FLT. Our key findings are that exclusion of comments and literals from the corpus lowers accuracy and that heuristics for selecting LDA parameter values in the natural language context are suboptimal in the source code context. Based on the results of our case study, we offer specific recommendations for configuring the LDA based FLT."
},
{
    "py/object": "data.DataClassPaper",
    "Title": "Detecting Java software similarities by using different clustering techniques",
    "year": 2020,
    "ML_Techniques": "",
    "Category": "Program comprehension",
    "Sub_category": "Entity identification/recommendation",
    "Venue": "IST",
    "Link": "https://www.sciencedirect.com/science/article/abs/pii/S095058492030029X",
    "bibtex": "@article{1127_Capiluppi2020,   title={Detecting java software similarities by using different clustering techniques},   author={Capiluppi, Andrea and Di Ruscio, Davide and Di Rocco, Juri and Nguyen, Phuong T and Ajienka, Nemitari},   journal={Information and Software Technology},   volume={122},   pages={106279},   year={2020},   publisher={Elsevier} }",
    "abstract": "Background     Research on empirical software engineering has increasingly been conducted by analysing and measuring vast amounts of software systems. Hundreds, thousands and even millions of systems have been (and are) considered by researchers, and often within the same study, in order to test theories, demonstrate approaches or run prediction models. A much less investigated aspect is whether the collected metrics might be context-specific, or whether systems should be better analysed in clusters.  Objective The objectives of this study are (i) to define a set of clustering techniques that might be used to group similar software systems, and (ii) to evaluate whether a suite of well-known object-oriented metrics is context-specific, and its values differ along the defined clusters.   Method  We group software systems based on three different clustering techniques, and we collect the values of the metrics suite in each cluster. We then test whether clusters are statistically different between each other, using the Kolgomorov-Smirnov (KS) hypothesis testing.   Results Our results show that, for two of the used techniques, the KS null hypothesis (e.g., the clusters come from the same population) is rejected for most of the metrics chosen: the clusters that we extracted, based on application domains, show statistically different structural properties.     Conclusions The implications for researchers can be profound: metrics and their interpretation might be more sensitive to context than acknowledged so far, and application domains represent a promising filter to cluster similar systems."
},
{
    "py/object": "data.DataClassPaper",
    "Title": "Explaining software defects using topic models.",
    "year": 2012,
    "ML_Techniques": "LDA",
    "Category": "Program comprehension",
    "Sub_category": "",
    "Venue": "MSR",
    "Link": "https://ieeexplore.ieee.org/abstract/document/6224280",
    "bibtex": "",
    "abstract": "Researchers have proposed various metrics based on measurable aspects of the source code entities (e.g., methods, classes, files, or modules) and the social structure of a software project in an effort to explain the relationships between software development and software defects. However, these metrics largely ignore the actual functionality, i.e., the conceptual concerns, of a software system, which are the main technical concepts that reflect the business logic or domain of the system. For instance, while lines of code may be a good general measure for defects, a large entity responsible for simple I/O tasks is likely to have fewer defects than a small entity responsible for complicated compiler implementation details. In this paper, we study the effect of conceptual concerns on code quality. We use a statistical topic modeling technique to approximate software concerns as topics; we then propose various metrics on these topics to help explain the defect-proneness (i.e., quality) of the entities. Paramount to our proposed metrics is that they take into account the defect history of each topic. Case studies on multiple versions of Mozilla Firefox, Eclipse, and Mylyn show that (i) some topics are much more defect-prone than others, (ii) defect-prone topics tend to remain so over time, and (iii) defect-prone topics provide additional explanatory power for code quality over existing structural and historical metrics."
},
{
    "py/object": "data.DataClassPaper",
    "Title": "Topic-based software defect explanation",
    "year": 2017,
    "ML_Techniques": "LDA",
    "Category": "Program comprehension",
    "Sub_category": "",
    "Venue": "JSS",
    "Link": "https://www.sciencedirect.com/science/article/abs/pii/S0164121216300528",
    "bibtex": "",
    "abstract": "Researchers continue to propose metrics using measurable aspects of software systems to understand software quality. However, these metrics largely ignore the functionality, i.e., the conceptual concerns, of software systems. Such concerns are the technical concepts that reflect the system’s business logic. For instance, while lines of code may be a good general measure for defects, a large file responsible for simple I/O tasks is likely to have fewer defects than a small file responsible for complicated compiler implementation details. In this paper, we study the effect of concerns on software quality. We use a statistical topic modeling approach to approximate software concerns as topics (related words in source code). We propose various metrics using these topics to help explain the file defect-proneness. Case studies on multiple versions of Firefox, Eclipse, Mylyn, and NetBeans show that (i) some topics are more defect-prone than others; (ii) defect-prone topics tend to remain so over time; (iii) our topic-based metrics provide additional explanatory power for software quality over existing structural and historical metrics; and (iv) our topic-based cohesion metric outperforms state-of-the-art topic-based cohesion and coupling metrics in terms of defect explanatory power, while being simpler to implement and more intuitive to interpret."
},
{
    "py/object": "data.DataClassPaper",
    "Title": "Labeling source code with information retrieval methods: an empirical study",
    "year": 2014,
    "ML_Techniques": "VSM, LSI, LDA",
    "Category": "Program comprehension",
    "Sub_category": "Entity identification/recommendation",
    "Venue": "ESEM",
    "Link": "https://link.springer.com/article/10.1007/s10664-013-9285-5",
    "bibtex": "@article{1131_De2014,   title={Labeling source code with information retrieval methods: an empirical study},   author={De Lucia, Andrea and Di Penta, Massimiliano and Oliveto, Rocco and Panichella, Annibale and Panichella, Sebastiano},   journal={Empirical Software Engineering},   volume={19},   number={5},   pages={1383--1420},   year={2014},   publisher={Springer} }",
    "abstract": "To support program comprehension, software artifacts can be labeled—for example within software visualization tools—with a set of representative words, hereby referred to as labels. Such labels can be obtained using various approaches, including Information Retrieval (IR) methods or other simple heuristics. They provide a bird-eye’s view of the source code, allowing developers to look over software components fast and make more informed decisions on which parts of the source code they need to analyze in detail. However, few empirical studies have been conducted to verify whether the extracted labels make sense to software developers. This paper investigates (i) to what extent various IR techniques and other simple heuristics overlap with (and differ from) labeling performed by humans; (ii) what kinds of source code terms do humans use when labeling software artifacts; and (iii) what factors—in particular what characteristics of the artifacts to be labeled—influence the performance of automatic labeling techniques. We conducted two experiments in which we asked a group of students (38 in total) to label 20 classes from two Java software systems, JHotDraw and eXVantage. Then, we analyzed to what extent the words identified with an automated technique—including Vector Space Models, Latent Semantic Indexing (LSI), latent Dirichlet allocation (LDA), as well as customized heuristics extracting words from specific source code elements—overlap with those identified by humans. Results indicate that, in most cases, simpler automatic labeling techniques—based on the use of words extracted from class and method names as well as from class comments—better reflect human-based labeling. Indeed, clustering-based approaches (LSI and LDA) are more worthwhile to be used for source code artifacts having a high verbosity, as well as for artifacts requiring more effort to be manually labeled. The obtained results help to define guidelines on how to build effective automatic labeling techniques, and provide some insights on the actual usefulness of automatic labeling techniques during program comprehension tasks."
},
{
    "py/object": "data.DataClassPaper",
    "Title": "Using structural and textual information to capture feature coupling in object-oriented software",
    "year": 2011,
    "ML_Techniques": "LSI",
    "Category": "Program comprehension",
    "Sub_category": "Entity identification/recommendation",
    "Venue": "ESEM",
    "Link": "https://link.springer.com/article/10.1007/s10664-011-9159-7",
    "bibtex": "@article{1140_Revelle2011,   title={Using structural and textual information to capture feature coupling in object-oriented software},   author={Revelle, Meghan and Gethers, Malcom and Poshyvanyk, Denys},   journal={Empirical software engineering},   volume={16},   number={6},   pages={773--811},   year={2011},   publisher={Springer} }",
    "abstract": "Previous studies have demonstrated the relationship between coupling and external software quality attributes, such as fault-proneness, and the application of coupling to software maintenance tasks, such as impact analysis. These previous studies concentrate on class coupling. However, there is a growing focus on the study of features in software, and features are often implemented across multiple classes, meaning class-level coupling measures are not applicable. We ask the pertinent question, “Is measuring coupling at the feature-level also useful?” We define new feature coupling metrics based on structural and textual source code information and extend the unified framework for coupling measurement to include these new metrics. We also conduct three extensive case studies to evaluate these new metrics and answer this research question. The first study examines the relationship between feature coupling and fault-proneness, the second assesses feature coupling in the context of impact analysis, and the third study surveys developers to determine if the metrics align with what they consider to be coupled features. All three studies provide evidence that feature coupling metrics are indeed useful new measures that capture coupling at a higher level of abstraction than classes and can be useful for finding bugs, guiding testing effort, and assessing change impact."
},
{
    "py/object": "data.DataClassPaper",
    "Title": "Can Latent Topics in Source Code Predict Missing Architectural Tactics?",
    "year": 2017,
    "ML_Techniques": "LDA, ANN, DT, RF, LOG",
    "Category": "Program comprehension",
    "Sub_category": "Entity identification/recommendation",
    "Venue": "ICSE",
    "Link": "https://ieeexplore.ieee.org/abstract/document/7985646/",
    "bibtex": "@inproceedings{1143_Gopalakrishnan2017,   title={Can latent topics in source code predict missing architectural tactics?},   author={Gopalakrishnan, Raghuram and Sharma, Palak and Mirakhorli, Mehdi and Galster, Matthias},   booktitle={2017 IEEE/ACM 39th International Conference on Software Engineering (ICSE)},   pages={15--26},   year={2017},   organization={IEEE} }",
    "abstract": "Architectural tactics such as heartbeat, resource pooling, and scheduling provide solutions to satisfy reliability, security, performance, and other critical characteristics of a software system. Current design practices advocate rigorous up-front analysis of the system's quality concerns to identify tactics and where in the code they should be used. In this paper, we explore a bottom-up approach to recommend architectural tactics based on latent topics discovered in the source code of projects. We present a recommender system developed by building predictor models which capture relationships between topical concepts in source code and the use of specific architectural tactics in that code. Based on an extensive analysis of over 116,000 open source systems, we identify significant correlations between latent topics in source code and the usage of architectural tactics. We use this information to construct a predictor for generating tactic recommendations. Our approach is validated through a series of experiments which demonstrate the ability to generate package-level tactic recommendations. We provide further validation via two large-scale studies of Apache Hive and Hadoop to illustrate that our recommender system predicts tactics that are actually implemented by developers in later releases."
},
{
    "py/object": "data.DataClassPaper",
    "Title": "Semantic topic models for source code analysis",
    "year": 2017,
    "ML_Techniques": "LDA",
    "Category": "Program comprehension",
    "Sub_category": "Entity identification/recommendation",
    "Venue": "ESEM",
    "Link": "https://link.springer.com/article/10.1007/s10664-016-9473-1",
    "bibtex": "@article{1146_Mahmoud2017,   title={Semantic topic models for source code analysis},   author={Mahmoud, Anas and Bradshaw, Gary},   journal={Empirical Software Engineering},   volume={22},   number={4},   pages={1965--2000},   year={2017},   publisher={Springer} }",
    "abstract": "Topic modeling techniques have been recently applied to analyze and model source code. Such techniques exploit the textual content of source code to provide automated support for several basic software engineering activities. Despite these advances, applications of topic modeling in software engineering are frequently suboptimal. This can be attributed to the fact that current state-of-the-art topic modeling techniques tend to be data intensive. However, the textual content of source code, embedded in its identifiers, comments, and string literals, tends to be sparse in nature. This prevents classical topic modeling techniques, typically used to model natural language texts, to generate proper models when applied to source code. Furthermore, the operational complexity and multi-parameter calibration often associated with conventional topic modeling techniques raise important concerns about their feasibility as data analysis models in software engineering. Motivated by these observations, in this paper we propose a novel approach for topic modeling designed for source code. The proposed approach exploits the basic assumptions of the cluster hypothesis and information theory to discover semantically coherent topics in software systems. Ten software systems from different application domains are used to empirically calibrate and configure the proposed approach. The usefulness of generated topics is empirically validated using human judgment. Furthermore, a case study that demonstrates thet operation of the proposed approach in analyzing code evolution is reported. The results show that our approach produces stable, more interpretable, and more expressive topics than classical topic modeling techniques without the necessity for extensive parameter calibration."
}


]
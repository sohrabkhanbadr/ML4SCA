[{
    "py/object": "data.DataClassPaper",
    "Title": "A Combination Method for Android Malware Detection Based on Control Flow Graphs and Machine Learning Algorithms",
    "year": 2019,
    "ML_Techniques": "RF, DNN, LSTM",
    "Category": "Vulnerability analysis",
    "Sub_category": ",Malware detection",
    "Venue": "IEEE Access",
    "Link": "https://ieeexplore.ieee.org/abstract/document/8629067",
    "bibtex": "ARTICLE{Ma2019_3,\n    author = \"{Ma}, Z. and {Ge}, H. and {Liu}, Y. and {Zhao}, M. and {Ma}, J.\",\n    journal = \"IEEE Access\",\n    title = \"A Combination Method for Android Malware Detection Based on Control Flow Graphs and Machine Learning Algorithms\",\n    year = \"2019\",\n    volume = \"7\",\n    number = \"\",\n    pages = \"21235-21245\",\n    doi = \"10.1109/ACCESS.2019.2896003\"\n}\n\n",
    "abstract": "Android malware severely threaten system and user security in terms of privilege escalation, remote control, tariff theft, and privacy leakage. Therefore, it is of great importance and necessity to detect Android malware. In this paper, we present a combination method for Android malware detection based on the machine learning algorithm. First, we construct the control flow graph of the application to obtain API information. Based on the API information, we innovatively construct Boolean, frequency, and time-series data sets. Based on these three data sets, three detection models for Android malware detection regarding API calls, API frequency, and API sequence aspects are constructed. Ultimately, an ensemble model is constructed for conformity. We tested and compared the accuracy and stability of our detection models through a large number of experiments. The experiments were conducted on 10010 benign applications and 10683 malicious applications. The results show that our detection model achieves 98.98% detection precision and has high accuracy and stability. All of the results are consistent with the theoretical analysis in this paper."
}, {
    "py/object": "data.DataClassPaper",
    "Title": "A Comparative Study of Deep Learning-Based Vulnerability Detection System",
    "year": 2019,
    "ML_Techniques": "",
    "Category": "Vulnerability analysis",
    "Sub_category": ",different types of vulnerabilities",
    "Venue": "IEEE Access",
    "Link": "https://ieeexplore.ieee.org/document/8769937",
    "bibtex": "ARTICLE{Li2019_4,\n    author = \"{Li}, Z. and {Zou}, D. and {Tang}, J. and {Zhang}, Z. and {Sun}, M. and {Jin}, H.\",\n    journal = \"IEEE Access\",\n    title = \"A Comparative Study of Deep Learning-Based Vulnerability Detection System\",\n    year = \"2019\",\n    volume = \"7\",\n    number = \"\",\n    pages = \"103184-103197\",\n    doi = \"10.1109/ACCESS.2019.2930578\"\n}\n\n",
    "abstract": "Source code static analysis has been widely used to detect vulnerabilities in the development of software products. The vulnerability patterns purely based on human experts are laborious and error prone, which has motivated the use of machine learning for vulnerability detection. In order to relieve human experts of defining vulnerability rules or features, a recent study shows the feasibility of leveraging deep learning to detect vulnerabilities automatically. However, the impact of different factors on the effectiveness of vulnerability detection is unknown. In this paper, we collect two datasets from the programs involving 126 types of vulnerabilities, on which we conduct the first comparative study to quantitatively evaluate the impact of different factors on the effectiveness of vulnerability detection. The experimental results show that accommodating control dependency can increase the overall effectiveness of vulnerability detection F1-measure by 20.3%; the imbalanced data processing methods are not effective for the dataset we create; bidirectional recurrent neural networks (RNNs) are more effective than unidirectional RNNs and convolutional neural network, which in turn are more effective than multi-layer perception; using the last output corresponding to the time step for the bidirectional long short-term memory (BLSTM) can reduce the false negative rate by 2.0% at the price of increasing the false positive rate by 0.5%."
}, {
    "py/object": "data.DataClassPaper",
    "Title": "A machine learning approach to detection of JavaScript-based attacks using AST features and paragraph vectors",
    "year": 2019,
    "ML_Techniques": "Doc2Vec, SVM",
    "Category": "Vulnerability analysis",
    "Sub_category": ",Malware detection",
    "Venue": "ASC",
    "Link": "https://www.sciencedirect.com/science/article/pii/S1568494619305022",
    "bibtex": "article{Ndichu2019_5,\n    author = \"Ndichu, Samuel and Kim, Sangwook and Ozawa, Seiichi and Misu, Takeshi and Makishima, Kazuo\",\n    title = \"A machine learning approach to detection of JavaScript-based attacks using AST features and paragraph vectors\",\n    journal = \"Applied Soft Computing\",\n    volume = \"84\",\n    pages = \"105721\",\n    year = \"2019\",\n    issn = \"1568-4946\",\n    doi = \"https://doi.org/10.1016/j.asoc.2019.105721\",\n    url = \"http://www.sciencedirect.com/science/article/pii/S1568494619305022\",\n    keywords = \"Cybersecurity, Machine learning, Doc2Vec, Malicious JavaScript detection, Feature learning, Abstract Syntax Tree\",\n    abstract = \"Websites attract millions of visitors due to the convenience of services they offer, which provide for interesting targets for cyber attackers. Most of these websites use JavaScript (JS) to create dynamic content. The exploitation of vulnerabilities in servers, plugins, and other third-party systems enables the insertion of malicious codes into websites. These exploits use methods such as drive-by-downloads, pop up ads, and phishing attacks on news, porn, piracy, torrent or free software websites, among others. Many of the recent cyber-attacks exploit JS vulnerabilities, in some cases employing obfuscation to hide their maliciousness and evade detection. It is, therefore, primal to develop an accurate detection system for malicious JS to protect users from such attacks. This study adopts Abstract Syntax Tree (AST) for code structure representation and a machine learning approach to conduct feature learning called Doc2vec to address this issue. Doc2vec is a neural network model that can learn context information of texts with variable length. This model is a well-suited feature learning method for JS codes, which consist of text content ranging among single line sentences, paragraphs, and full-length documents. Besides, features learned with Doc2Vec are of low dimensions which ensure faster detections. A classifier model judges the maliciousness of a JS code using the learned features. The performance of this approach is evaluated using the D3M dataset (Drive-by-Download Data by Marionette) for malicious JS codes and the JSUNPACK plus Alexa top 100 websites datasets for benign JS codes. We then compare the performance of Doc2Vec on plain JS codes (Plain-JS) and AST form of JS codes (AST-JS) to other feature learning methods. Our experimental results show that the proposed AST features and Doc2Vec for feature learning provide better accuracy and fast classification in malicious JS codes detection compared to conventional approaches and can flag malicious JS codes previously identified as hard-to-detect.\"\n}\n\n",
    "abstract": "Websites attract millions of visitors due to the convenience of services they offer, which provide for interesting targets for cyber attackers. Most of these websites use JavaScript (JS) to create dynamic content. The exploitation of vulnerabilities in servers, plugins, and other third-party systems enables the insertion of malicious codes into websites. These exploits use methods such as drive-by-downloads, pop up ads, and phishing attacks on news, porn, piracy, torrent or free software websites, among others. Many of the recent cyber-attacks exploit JS vulnerabilities, in some cases employing obfuscation to hide their maliciousness and evade detection. It is, therefore, primal to develop an accurate detection system for malicious JS to protect users from such attacks. This study adopts Abstract Syntax Tree (AST) for code structure representation and a machine learning approach to conduct feature learning called Doc2vec to address this issue. Doc2vec is a neural network model that can learn context information of texts with variable length. This model is a well-suited feature learning method for JS codes, which consist of text content ranging among single line sentences, paragraphs, and full-length documents. Besides, features learned with Doc2Vec are of low dimensions which ensure faster detections. A classifier model judges the maliciousness of a JS code using the learned features. The performance of this approach is evaluated using the D3M dataset (Drive-by-Download Data by Marionette) for malicious JS codes and the JSUNPACK plus Alexa top 100 websites datasets for benign JS codes. We then compare the performance of Doc2Vec on plain JS codes (Plain-JS) and AST form of JS codes (AST-JS) to other feature learning methods. Our experimental results show that the proposed AST features and Doc2Vec for feature learning provide better accuracy and fast classification in malicious JS codes detection compared to conventional approaches and can flag malicious JS codes previously identified as hard-to-detect."
}, {
    "py/object": "data.DataClassPaper",
    "Title": "A Machine Learning Approach to Malicious JavaScript Detection using Fixed Length Vector Representation",
    "year": 2018,
    "ML_Techniques": "Doc2Vec, SVM",
    "Category": "Vulnerability analysis",
    "Sub_category": ",Malware detection",
    "Venue": "IJCNN",
    "Link": "https://ieeexplore.ieee.org/abstract/document/8489414",
    "bibtex": "INPROCEEDINGS{Ndichu2018_6,\n    author = \"{Ndichu}, S. and {Ozawa}, S. and {Misu}, T. and {Okada}, K.\",\n    booktitle = \"2018 International Joint Conference on Neural Networks (IJCNN)\",\n    title = \"A Machine Learning Approach to Malicious JavaScript Detection using Fixed Length Vector Representation\",\n    year = \"2018\",\n    volume = \"\",\n    number = \"\",\n    pages = \"1-8\",\n    doi = \"10.1109/IJCNN.2018.8489414\"\n}\n\n",
    "abstract": "To add more functionality and enhance usability of web applications, JavaScript (JS) is frequently used. Even with many advantages and usefulness of JS, an annoying fact is that many recent cyberattacks such as drive-by-download attacks exploit vulnerability of JS codes. In general, malicious JS codes are not easy to detect, because they sneakily exploit vulnerabilities of browsers and plugin software, and attack visitors of a web site unknowingly. To protect users from such threads, the development of an accurate detection system for malicious JS is soliciting. Conventional approaches often employ signature and heuristic-based methods, which are prone to suffer from zero-day attacks, i.e., causing many false negatives and/or false positives. For this problem, this paper adopts a machine-learning approach to feature learning called Doc2Vec, which is a neural network model that can learn context information of texts. The extracted features are given to a classifier model (e.g., SVM and neural networks) and it judges the maliciousness of a JS code. In the performance evaluation, we use the D3M Dataset (Drive-by-Download Data by Marionette) for malicious JS codes and JSUPACK for benign ones for both training and test purposes. We then compare the performance to other feature learning methods. Our experimental results show that the proposed Doc2Vec features provide better accuracy and fast classification in malicious JS code detection compared to conventional approaches."
}, {
    "py/object": "data.DataClassPaper",
    "Title": "A Proposed Approach to Build an Automated Software Security Assessment Framework using Mined Patterns and Metrics",
    "year": 2019,
    "ML_Techniques": "",
    "Category": "Vulnerability analysis",
    "Sub_category": ",Malware detection",
    "Venue": "CSE & EUC",
    "Link": "https://ieeexplore.ieee.org/document/8919532",
    "bibtex": "INPROCEEDINGS{Sultana2019_8,\n    author = \"{Sultana}, K. Z. and {Chong}, T.\",\n    booktitle = \"2019 IEEE International Conference on Computational Science and Engineering (CSE) and IEEE International Conference on Embedded and Ubiquitous Computing (EUC)\",\n    title = \"A Proposed Approach to Build an Automated Software Security Assessment Framework using Mined Patterns and Metrics\",\n    year = \"2019\",\n    volume = \"\",\n    number = \"\",\n    pages = \"176-181\",\n    doi = \"10.1109/CSE/EUC.2019.00042\"\n}\n\n",
    "abstract": "Software security is a major concern of the developers who intend to deliver a reliable software. Although there is research that focuses on vulnerability prediction and discovery, there is still a need for building security-specific metrics to measure software security and vulnerability-proneness quantitatively. The existing methods are either based on software metrics (defined on the physical characteristics of code; e.g. complexity or lines of code) which are not security-specific or some generic patterns known as nano-patterns (Java method-level traceable patterns that characterize a Java method or function). Other methods predict vulnerabilities using text mining approaches or graph algorithms which perform poorly in cross-project validation and fail to be a generalized prediction model for any system. In this paper, we envision to construct an automated framework that will assist developers to assess the security level of their code and guide them towards developing secure code. To accomplish this goal, we aim to refine and redefine the existing nano-patterns and software metrics to make them more security-centric so that they can be used for measuring the software security level of a source code (either file or function) with higher accuracy. In this paper, we present our visionary approach through a series of three consecutive studies where we (1) will study the challenges of the current software metrics and nano-patterns in vulnerability prediction, (2) will redefine and characterize the nano-patterns and software metrics so that they can capture security-specific properties of code and measure the security level quantitatively, and finally (3) will implement an automated framework for the developers to automatically extract the values of all the patterns and metrics for the given code segment and then flag the estimated security level as a feedback based on our research results. We accomplished some preliminary experiments and presented the results which indicate that our vision can be practically implemented and will have valuable implications in the community of software security."
}, {
    "py/object": "data.DataClassPaper",
    "Title": "A Survey of Automatic Software Vulnerability Detection, Program Repair, and Defect Prediction Techniques",
    "year": 2020,
    "ML_Techniques": "",
    "Category": "Vulnerability analysis",
    "Sub_category": "",
    "Venue": "SCN",
    "Link": "https://www.hindawi.com/journals/scn/2020/8858010/",
    "bibtex": "article{Shen2020_9,\n    author = \"Shen, Zhidong and Chen, S.\",\n    title = \"A Survey of Automatic Software Vulnerability Detection, Program Repair, and Defect Prediction Techniques\",\n    journal = \"Secur. Commun. Networks\",\n    year = \"2020\",\n    volume = \"2020\",\n    pages = \"8858010:1-8858010:16\"\n}\n\n",
    "abstract": "Open source software has been widely used in various industries due to its openness and flexibility, but it also brings potential software security problems. Together with the large-scale increase in the number of software and the increase in complexity, the traditional manual methods to deal with these security issues are inefficient and cannot meet the current cyberspace security requirements. Therefore, it is an important research topic for researchers in the field of software security to develop more intelligent technologies to apply to potential security issues in software. The development of deep learning technology has brought new opportunities for the study of potential security issues in software, and researchers have successively proposed many automation methods. In this paper, these automation technologies are evaluated and analysed in detail from three aspects: software vulnerability detection, software program repair, and software defect prediction. At the same time, we point out some problems of these research methods, give corresponding solutions, and finally look forward to the application prospect of deep learning technology in automated software vulnerability detection, automated program repair, and automated defect prediction."
}, {
    "py/object": "data.DataClassPaper",
    "Title": "An Exploratory Study on Machine Learning to Combine Security Vulnerability Alerts from Static Analysis Tools",
    "year": 2019,
    "ML_Techniques": "LR, DT, Lasso",
    "Category": "Vulnerability analysis",
    "Sub_category": ",XSS, SQL-injection",
    "Venue": "LADC",
    "Link": "https://ieeexplore.ieee.org/document/8995685",
    "bibtex": "INPROCEEDINGS{Pereira2019_12,\n    author = \"{Pereira}, J. D. and {Campos}, J. R. and {Vieira}, M.\",\n    booktitle = \"2019 9th Latin-American Symposium on Dependable Computing (LADC)\",\n    title = \"An Exploratory Study on Machine Learning to Combine Security Vulnerability Alerts from Static Analysis Tools\",\n    year = \"2019\",\n    volume = \"\",\n    number = \"\",\n    pages = \"1-10\",\n    doi = \"10.1109/LADC48089.2019.8995685\"\n}\n\n",
    "abstract": "Due to time-to-market needs and cost of manual validation techniques, software systems are often deployed with vulnerabilities that may be exploited to gain illegitimate access/control, ultimately resulting in non-negligible consequences. Static Analysis Tools (SATs) are widely used for vulnerability detection, where the source code is analyzed without executing it. However, the performance of SATs varies considerably and a high detection rate usually comes with significant false alarms. Recent studies considered combining various SATs to improve the overall detection ability, but they do not allow exploring different performance trade-offs, as basic and rigid rules are normally followed. Machine Learning (ML) algorithms have shown promising results in several complex problems, due to their ability to fit specific needs. This paper presents an exploratory study on the combination of the output of SATs through ML algorithms to improve vulnerability detection while trying to reduce false alarms. The dataset consists of SQL Injection (SQLi) and Cross-Site Scripting (XSS) vulnerabilities detected by five different SATs in a large set of WordPress plugins developed in PHP. Results show that, for the case of SQLi, a false alarm reduction is possible without compromising the vulnerabilities detected, and that using ML allows trade-offs (e.g., reduction in false alarms at the expense of a few vulnerabilities) that are not possible with existing techniques. The paper also proposes a regression-based approach for ranking source code files considering estimates of vulnerabilities computed using the output of SATs. Results show that the approach allows creating a ranking of the source code files that largely overlaps the real ranking (based on real known vulnerabilities)."
}, {
    "py/object": "data.DataClassPaper",
    "Title": "Android Malware Detection Using Category-Based Machine Learning Classifiers",
    "year": 2016,
    "ML_Techniques": "SVM",
    "Category": "Vulnerability analysis",
    "Sub_category": ",Malware detection",
    "Venue": "SIGITE",
    "Link": "https://dl.acm.org/doi/10.1145/2978192.2978218",
    "bibtex": "inproceedings{Ali2016_14,\n    author = \"Ali Alatwi, Huda and Oh, Tae and Fokoue, Ernest and Stackpole, Bill\",\n    title = \"Android Malware Detection Using Category-Based Machine Learning Classifiers\",\n    year = \"2016\",\n    isbn = \"9781450344524\",\n    publisher = \"Association for Computing Machinery\",\n    address = \"New York, NY, USA\",\n    url = \"https://doi.org/10.1145/2978192.2978218\",\n    doi = \"10.1145/2978192.2978218\",\n    abstract = \"Android malware growth has been increasing dramatically as well as the diversity and complicity of their developing techniques. Machine learning techniques have been applied to detect malware by modeling patterns of static features and dynamic behaviors of malware. The accuracy rates of the machine learning classifiers differ depending on the quality of the features. We increase the quality of the features by relating between the apps' features and the features that are required to deliver its category's functionality. To measure the benign app references, the features of the top rated apps in a specific category are utilized to train a malware detection classifier for that given category. Android apps stores such as Google Play organize apps into different categories. Each category has its distinct functionalities which means the apps under a specific category are similar in their static and dynamic features. In other words, benign apps under a certain category tend to share a common set of features. On the contrary, malicious apps tend to have abnormal features, which are uncommon for the category that they belong to. This paper proposes category-based machine learning classifiers to enhance the performance of classification models at detecting malicious apps under a certain category. The intensive machine learning experiments proved that category-based classifiers report a remarkable higher average performance compared to non-category based.\",\n    booktitle = \"Proceedings of the 17th Annual Conference on Information Technology Education\",\n    pages = \"54\u201359\",\n    numpages = \"6\",\n    keywords = \"android malware detection, machine learning, static analysis\",\n    location = \"Boston, Massachusetts, USA\",\n    series = \"SIGITE '16\"\n}\n\n",
    "abstract": "Android malware growth has been increasing dramatically as well as the diversity and complicity of their developing techniques. Machine learning techniques have been applied to detect malware by modeling patterns of static features and dynamic behaviors of malware. The accuracy rates of the machine learning classifiers differ depending on the quality of the features. We increase the quality of the features by relating between the apps' features and the features that are required to deliver its category's functionality. To measure the benign app references, the features of the top rated apps in a specific category are utilized to train a malware detection classifier for that given category. Android apps stores such as Google Play organize apps into different categories. Each category has its distinct functionalities which means the apps under a specific category are similar in their static and dynamic features. In other words, benign apps under a certain category tend to share a common set of features. On the contrary, malicious apps tend to have abnormal features, which are uncommon for the category that they belong to. This paper proposes category-based machine learning classifiers to enhance the performance of classification models at detecting malicious apps under a certain category. The intensive machine learning experiments proved that category-based classifiers report a remarkable higher average performance compared to non-category based."
}, {
    "py/object": "data.DataClassPaper",
    "Title": "Applying Machine Learning Techniques for Detection of Malicious Code in Network Traffic",
    "year": 2007,
    "ML_Techniques": "DT, ANN, BN",
    "Category": "Vulnerability analysis",
    "Sub_category": ",Malware detection",
    "Venue": "AAI",
    "Link": "https://link.springer.com/chapter/10.1007/978-3-540-74565-5_5",
    "bibtex": "InProceedings{Elovici2007_15,\n    author = \"Elovici, Yuval and Shabtai, Asaf and Moskovitch, Robert and Tahan, Gil and Glezer, Chanan\",\n    editor = \"Hertzberg, Joachim and Beetz, Michael and Englert, Roman\",\n    title = \"Applying Machine Learning Techniques for Detection of Malicious Code in Network Traffic\",\n    booktitle = \"KI 2007: Advances in Artificial Intelligence\",\n    year = \"2007\",\n    publisher = \"Springer Berlin Heidelberg\",\n    address = \"Berlin, Heidelberg\",\n    pages = \"44--50\",\n    abstract = \"The Early Detection, Alert and Response (eDare) system is aimed at purifying Web traffic propagating via the premises of Network Service Providers (NSP) from malicious code. To achieve this goal, the system employs powerful network traffic scanners capable of cleaning traffic from known malicious code. The remaining traffic is monitored and Machine Learning (ML) algorithms are invoked in an attempt to pinpoint unknown malicious code exhibiting suspicious morphological patterns. Decision trees, Neural Networks and Bayesian Networks are used for static code analysis in order to determine whether a suspicious executable file actually inhabits malicious code. These algorithms are being evaluated and preliminary results are encouraging.\",\n    isbn = \"978-3-540-74565-5\"\n}\n\n",
    "abstract": "The Early Detection, Alert and Response (eDare) system is aimed at purifying Web traffic propagating via the premises of Network Service Providers (NSP) from malicious code. To achieve this goal, the system employs powerful network traffic scanners capable of cleaning traffic from known malicious code. The remaining traffic is monitored and Machine Learning (ML) algorithms are invoked in an attempt to pinpoint unknown malicious code exhibiting suspicious morphological patterns. Decision trees, Neural Networks and Bayesian Networks are used for static code analysis in order to determine whether a suspicious executable file actually inhabits malicious code. These algorithms are being evaluated and preliminary results are encouraging."
}, {
    "py/object": "data.DataClassPaper",
    "Title": "Automated Vulnerability Detection in Source Code Using Deep Representation Learning",
    "year": 2018,
    "ML_Techniques": "RF, CNN, RNN",
    "Category": "Vulnerability analysis",
    "Sub_category": ",bufferoverflow, nullpointer derefernce, and so on",
    "Venue": "ICMLA",
    "Link": "https://ieeexplore.ieee.org/abstract/document/8614145",
    "bibtex": "INPROCEEDINGS{Russell2018_16,\n    author = \"{Russell}, R. and {Kim}, L. and {Hamilton}, L. and {Lazovich}, T. and {Harer}, J. and {Ozdemir}, O. and {Ellingwood}, P. and {McConley}, M.\",\n    booktitle = \"2018 17th IEEE International Conference on Machine Learning and Applications (ICMLA)\",\n    title = \"Automated Vulnerability Detection in Source Code Using Deep Representation Learning\",\n    year = \"2018\",\n    volume = \"\",\n    number = \"\",\n    pages = \"757-762\",\n    doi = \"10.1109/ICMLA.2018.00120\"\n}\n\n",
    "abstract": "Increasing numbers of software vulnerabilities are discovered every year whether they are reported publicly or discovered internally in proprietary code. These vulnerabilities can pose serious risk of exploit and result in system compromise, information leaks, or denial of service. We leveraged the wealth of C and C++ open-source code available to develop a large-scale function-level vulnerability detection system using machine learning. To supplement existing labeled vulnerability datasets, we compiled a vast dataset of millions of open-source functions and labeled it with carefully-selected findings from three different static analyzers that indicate potential exploits. The labeled dataset is available at: this https URL. Using these datasets, we developed a fast and scalable vulnerability detection tool based on deep feature representation learning that directly interprets lexed source code. We evaluated our tool on code from both real software packages and the NIST SATE IV benchmark dataset. Our results demonstrate that deep feature representation learning on source code is a promising approach for automated software vulnerability detection."
}, {
    "py/object": "data.DataClassPaper",
    "Title": "Automatic detection and correction of web application vulnerabilities using data mining to predict false positives",
    "year": 2014,
    "ML_Techniques": "DT, RF, KNN, NB, BN, MLP, SVM, LOG",
    "Category": "Vulnerability analysis",
    "Sub_category": ",SQL-injections, XSS",
    "Venue": "WWW ",
    "Link": "https://dl.acm.org/doi/10.1145/2566486.2568024",
    "bibtex": "INPROCEEDINGS{Russell2018_16,\n    author = \"{Russell}, R. and {Kim}, L. and {Hamilton}, L. and {Lazovich}, T. and {Harer}, J. and {Ozdemir}, O. and {Ellingwood}, P. and {McConley}, M.\",\n    booktitle = \"2018 17th IEEE International Conference on Machine Learning and Applications (ICMLA)\",\n    title = \"Automated Vulnerability Detection in Source Code Using Deep Representation Learning\",\n    year = \"2018\",\n    volume = \"\",\n    number = \"\",\n    pages = \"757-762\",\n    doi = \"10.1109/ICMLA.2018.00120\"\n}\n\n",
    "abstract": "Web application security is an important problem in today's internet. A major cause of this status is that many programmers do not have adequate knowledge about secure coding, so they leave applications with vulnerabilities. An approach to solve this problem is to use source code static analysis to find these bugs, but these tools are known to report many false positives that make hard the task of correcting the application. This paper explores the use of a hybrid of methods to detect vulnerabilities with less false positives. After an initial step that uses taint analysis to flag candidate vulnerabilities, our approach uses data mining to predict the existence of false positives. This approach reaches a trade-off between two apparently opposite approaches: humans coding the knowledge about vulnerabilities (for taint analysis) versus automatically obtaining that knowledge (with machine learning, for data mining). Given this more precise form of detection, we do automatic code correction by inserting fixes in the source code. The approach was implemented in the WAP tool and an experimental evaluation was performed with a large set of open source PHP applications."
}, {
    "py/object": "data.DataClassPaper",
    "Title": "Challenging machine learning algorithms in predicting vulnerable JavaScript functions",
    "year": 2019,
    "ML_Techniques": "DNN, KNN, DT, RF, SVM, LR, NB",
    "Category": "Vulnerability analysis",
    "Sub_category": ",different types of vulnerabilities",
    "Venue": "RAISE",
    "Link": "https://dl.acm.org/doi/10.1109/RAISE.2019.00010",
    "bibtex": "INPROCEEDINGS{Russell2018_16,\n    author = \"{Russell}, R. and {Kim}, L. and {Hamilton}, L. and {Lazovich}, T. and {Harer}, J. and {Ozdemir}, O. and {Ellingwood}, P. and {McConley}, M.\",\n    booktitle = \"2018 17th IEEE International Conference on Machine Learning and Applications (ICMLA)\",\n    title = \"Automated Vulnerability Detection in Source Code Using Deep Representation Learning\",\n    year = \"2018\",\n    volume = \"\",\n    number = \"\",\n    pages = \"757-762\",\n    doi = \"10.1109/ICMLA.2018.00120\"\n}\n\n",
    "abstract": "The rapid rise of cyber-crime activities and the growing number of devices threatened by them place software security issues in the spotlight. As around 90% of all attacks exploit known types of security issues, finding vulnerable components and applying existing mitigation techniques is a viable practical approach for fighting against cyber-crime. In this paper, we investigate how the state-of-the-art machine learning techniques, including a popular deep learning algorithm, perform in predicting functions with possible security vulnerabilities in JavaScript programs.\n\nWe applied 8 machine learning algorithms to build prediction models using a new dataset constructed for this research from the vulnerability information in public databases of the Node Security Project and the Snyk platform, and code fixing patches from GitHub. We used static source code metrics as predictors and an extensive grid-search algorithm to find the best performing models. We also examined the effect of various re-sampling strategies to handle the imbalanced nature of the dataset.\n\nThe best performing algorithm was KNN, which created a model for the prediction of vulnerable functions with an F-measure of 0.76 (0.91 precision and 0.66 recall). Moreover, deep learning, tree and forest based classifiers, and SVM were competitive with F-measures over 0.70. Although the F-measures did not vary significantly with the re-sampling strategies, the distribution of precision and recall did change. No re-sampling seemed to produce models preferring high precision, while resampling strategies balanced the IR measures."
}, {
    "py/object": "data.DataClassPaper",
    "Title": "Classification of malicious web code by machine learning",
    "year": 2011,
    "ML_Techniques": "SVM, NB, KNN",
    "Category": "Vulnerability analysis",
    "Sub_category": ",SQL-injections, XSS",
    "Venue": "iCAST",
    "Link": "",
    "bibtex": "INPROCEEDINGS{Komiya2011_19,\n    author = \"{Komiya}, R. and {Paik}, I. and {Hisada}, M.\",\n    booktitle = \"2011 3rd International Conference on Awareness Science and Technology (iCAST)\",\n    title = \"Classification of malicious web code by machine learning\",\n    year = \"2011\",\n    volume = \"\",\n    number = \"\",\n    pages = \"406-411\"\n}\n\n",
    "abstract": "Web applications make life more convenient through on the activities. Many web applications have several kind of user input (e.g. personal information, a user's comment of commercial goods, etc.) for the activities. However, there are various vulnerabilities in input functions of web applications. It is possible to try malicious actions using free accessibility of the web applications. The attacks by exploitation of these input vulnerabilities enable to be performed by injecting malicious web code; it enables one to perform various illegal actions, such as SQL Injection Attacks (SQLIAs) and Cross Site Scripting (XSS). These actions come down to theft, replacing personal information, or phishing. Many solutions have devised for the malicious web code, such as AMNESIA [1] and SQL Check [2], etc. The methods use parser for the code, and limited to fixed and very small patterns, and are difficult to adapt to variations. Machine learning method can give leverage to cover far broader range of malicious web code and is easy to adapt to variations and changes. Therefore, we suggests adaptable classification of malicious web code by machine learning approach such as Support Vector Machine (SVM) [3], Na\u00efve-Bayes [4], and k-Nearest Neighbor Algorithm [5] for detecting the exploitation user inputs."
}, {
    "py/object": "data.DataClassPaper",
    "Title": "Codebase-adaptive detection of security-relevant methods",
    "year": 2019,
    "ML_Techniques": "SVM, BN, LOG, DT, DS, Ripper",
    "Category": "Vulnerability analysis",
    "Sub_category": "",
    "Venue": "ISSTA",
    "Link": "https://dl.acm.org/doi/10.1145/3293882.3330556",
    "bibtex": "INPROCEEDINGS{Komiya2011_19,\n    author = \"{Komiya}, R. and {Paik}, I. and {Hisada}, M.\",\n    booktitle = \"2011 3rd International Conference on Awareness Science and Technology (iCAST)\",\n    title = \"Classification of malicious web code by machine learning\",\n    year = \"2011\",\n    volume = \"\",\n    number = \"\",\n    pages = \"406-411\"\n}\n\n",
    "abstract": "More and more companies use static analysis to perform regular code reviews to detect security vulnerabilities in their code, configuring them to detect various types of bugs and vulnerabilities such as the SANS top 25 or the OWASP top 10. For such analyses to be as precise as possible, they must be adapted to the code base they scan. The particular challenge we address in this paper is to provide analyses with the correct security-relevant methods (Srm): sources, sinks, etc. We present SWAN, a fully-automated machine-learning approach to detect sources, sinks, validators, and authentication methods for Java programs. SWAN further classifies the Srm into specific vulnerability classes of the SANS top 25. To further adapt the lists detected by SWAN to the code base and to improve its precision, we also introduce SWANAssist, an extension to SWAN that allows analysis users to refine the classifications. On twelve popular Java frameworks, SWAN achieves an average precision of 0.826, which is better or comparable to existing approaches. Our experiments show that SWANAssist requires a relatively low effort from the developer to significantly improve its precision."
}, {
    "py/object": "data.DataClassPaper",
    "Title": "Detection of malicious code by applying machine learning classifiers on static features: A state-of-the-art survey",
    "year": 2009,
    "ML_Techniques": "",
    "Category": "Vulnerability analysis",
    "Sub_category": ",survey",
    "Venue": "ISTR",
    "Link": "",
    "bibtex": "article{Shabtai2009_25,\n    author = \"Shabtai, Asaf and Moskovitch, Robert and Elovici, Yuval and Glezer, Chanan\",\n    title = \"Detection of malicious code by applying machine learning classifiers on static features: A state-of-the-art survey\",\n    journal = \"Information Security Technical Report\",\n    volume = \"14\",\n    number = \"1\",\n    pages = \"16 - 29\",\n    year = \"2009\",\n    note = \"Malware\",\n    issn = \"1363-4127\",\n    doi = \"https://doi.org/10.1016/j.istr.2009.03.003\",\n    url = \"http://www.sciencedirect.com/science/article/pii/S1363412709000041\"\n}\n\n",
    "abstract": "This research synthesizes a taxonomy for classifying detection methods of new malicious code by Machine Learning (ML) methods based on static features extracted from executables. The taxonomy is then operationalized to classify research on this topic and pinpoint critical open research issues in light of emerging threats. The article addresses various facets of the detection challenge, including: file representation and feature selection methods, classification algorithms, weighting ensembles, as well as the imbalance problem, active learning, and chronological evaluation. From the survey we conclude that a framework for detecting new malicious code in executable files can be designed to achieve very high accuracy while maintaining low false positives (i.e. misclassifying benign files as malicious). The framework should include training of multiple classifiers on various types of features (mainly OpCode and byte n-grams and Portable Executable Features), applying weighting algorithm on the classification results of the individual classifiers, as well as an active learning mechanism to maintain high detection accuracy. The training of classifiers should also consider the imbalance problem by generating classifiers that will perform accurately in a real-life situation where the percentage of malicious files among all files is estimated to be approximately 10%."
}, {
    "py/object": "data.DataClassPaper",
    "Title": "Discovering software vulnerabilities using data-flow analysis and machine learning",
    "year": 2018,
    "ML_Techniques": "DT, RF, NB, BN, LR",
    "Category": "Vulnerability analysis",
    "Sub_category": ",SQL-injections, XSS",
    "Venue": "ARES",
    "Link": "https://dl.acm.org/doi/abs/10.1145/3230833.3230856",
    "bibtex": "article{Shabtai2009_25,\n    author = \"Shabtai, Asaf and Moskovitch, Robert and Elovici, Yuval and Glezer, Chanan\",\n    title = \"Detection of malicious code by applying machine learning classifiers on static features: A state-of-the-art survey\",\n    journal = \"Information Security Technical Report\",\n    volume = \"14\",\n    number = \"1\",\n    pages = \"16 - 29\",\n    year = \"2009\",\n    note = \"Malware\",\n    issn = \"1363-4127\",\n    doi = \"https://doi.org/10.1016/j.istr.2009.03.003\",\n    url = \"http://www.sciencedirect.com/science/article/pii/S1363412709000041\"\n}\n\n",
    "abstract": "We present a novel method for static analysis in which we combine data-flow analysis with machine learning to detect SQL injection (SQLi) and Cross-Site Scripting (XSS) vulnerabilities in PHP applications. We assembled a dataset from the National Vulnerability Database and the SAMATE project, containing vulnerable PHP code samples and their patched versions in which the vulnerability is solved. We extracted features from the code samples by applying data-flow analysis techniques, including reaching definitions analysis, taint analysis, and reaching constants analysis. We used these features in machine learning to train various probabilistic classifiers. To demonstrate the effectiveness of our approach, we built a tool called WIRECAML, and compared our tool to other tools for vulnerability detection in PHP code. Our tool performed best for detecting both SQLi and XSS vulnerabilities. We also tried our approach on a number of open-source software applications, and found a previously unknown vulnerability in a photo-sharing web application."
}, {
    "py/object": "data.DataClassPaper",
    "Title": "Early Identification of Vulnerable Software Components via Ensemble Learning",
    "year": 2016,
    "ML_Techniques": "SVM",
    "Category": "Vulnerability analysis",
    "Sub_category": "",
    "Venue": "ICMLA",
    "Link": " https://ieeexplore.ieee.org/document/7838188",
    "bibtex": "INPROCEEDINGS{Pang2016_27,\n    author = \"{Pang}, Y. and {Xue}, X. and {Namin}, A. S.\",\n    booktitle = \"2016 15th IEEE International Conference on Machine Learning and Applications (ICMLA)\",\n    title = \"Early Identification of Vulnerable Software Components via Ensemble Learning\",\n    year = \"2016\",\n    volume = \"\",\n    number = \"\",\n    pages = \"476-481\",\n    doi = \"10.1109/ICMLA.2016.0084\"\n}\n\n",
    "abstract": "Software components, which are vulnerable to being exploited, need to be identified and patched. Employing any prevention techniques designed for the purpose of detecting vulnerable software components in early stages can reduce the expenses associated with the software testing process significantly and thus help building a more reliable and robust software system. Although previous studies have demonstrated the effectiveness of adapting prediction techniques in vulnerability detection, the feasibility of those techniques is limited mainly because of insufficient training data sets. This paper proposes a prediction technique targeting at early identification of potentially vulnerable software components. In the proposed scheme, the potentially vulnerable components are viewed as mislabeled data that may contain true but not yet observed vulnerabilities. The proposed hybrid technique combines the supports vector machine algorithm and ensemble learning strategy to better identify potential vulnerable components. The proposed vulnerability detection scheme is evaluated using some Java Android applications. The results demonstrated that the proposed hybrid technique could identify potentially vulnerable classes with high precision and relatively acceptable accuracy and recall."
}, {
    "py/object": "data.DataClassPaper",
    "Title": "Experimental Study with Real-world Data for Android App Security Analysis using Machine Learning",
    "year": 2015,
    "ML_Techniques": "",
    "Category": "Vulnerability analysis",
    "Sub_category": ",challenges",
    "Venue": "ACSAC",
    "Link": "https://dl.acm.org/doi/abs/10.1145/2818000.2818038",
    "bibtex": "INPROCEEDINGS{Pang2016_27,\n    author = \"{Pang}, Y. and {Xue}, X. and {Namin}, A. S.\",\n    booktitle = \"2016 15th IEEE International Conference on Machine Learning and Applications (ICMLA)\",\n    title = \"Early Identification of Vulnerable Software Components via Ensemble Learning\",\n    year = \"2016\",\n    volume = \"\",\n    number = \"\",\n    pages = \"476-481\",\n    doi = \"10.1109/ICMLA.2016.0084\"\n}\n\n",
    "abstract": "Although Machine Learning (ML) based approaches have\nshown promise for Android malware detection, a set of critical challenges remain unaddressed. Some of those challenges\narise in relation to proper evaluation of the detection approach while others are related to the design decisions of the\nsame. In this paper, we systematically study the impact of\nthese challenges as a set of research questions (i.e., hypotheses). We design an experimentation framework where we can\nreliably vary several parameters while evaluating ML-based\nAndroid malware detection approaches. The results from\nthe experiments are then used to answer the research questions. Meanwhile, we also demonstrate the impact of some\nchallenges on some existing ML-based approaches. The large\n(market-scale) dataset (benign and malicious apps) we use\nin the above experiments represents the real-world Android\napp security analysis scale. We envision this study to encourage the practice of employing a better evaluation strategy and better designs of future ML-based approaches for\nAndroid malware detection."
}, {
    "py/object": "data.DataClassPaper",
    "Title": "Experimenting Machine Learning Techniques to Predict Vulnerabilities",
    "year": 2016,
    "ML_Techniques": "RF, NB, LR, DT",
    "Category": "Vulnerability analysis",
    "Sub_category": "",
    "Venue": "LADC",
    "Link": "https://ieeexplore.ieee.org/abstract/document/7781850",
    "bibtex": "INPROCEEDINGS{Alves2016_29,\n    author = \"{Alves}, H. and {Fonseca}, B. and {Antunes}, N.\",\n    booktitle = \"2016 Seventh Latin-American Symposium on Dependable Computing (LADC)\",\n    title = \"Experimenting Machine Learning Techniques to Predict Vulnerabilities\",\n    year = \"2016\",\n    volume = \"\",\n    number = \"\",\n    pages = \"151-156\",\n    doi = \"10.1109/LADC.2016.32\"\n}\n\n",
    "abstract": "Software metrics can be used as a indicator of the presence of software vulnerabilities. These metrics have been used with machine learning to predict source code prone to contain vulnerabilities. Although it is not possible to find the exact location of the flaws, the models can show which components require more attention during inspections and testing. Each new technique uses his own evaluation dataset, which many times has limited size and representativeness. In this experience report, we use a large and representative dataset to evaluate several state of the art vulnerability prediction techniques. This dataset was built with information of 2186 vulnerabilities from five widely used open source projects. Results show that the dataset can be used to distinguish which are the best techniques. It is also shown that some of the techniques can predict nearly all of the vulnerabilities present in the dataset, although with very low precisions. Finally, accuracy, precision and recall are not the most effective to characterize the effectiveness of this tools."
}, {
    "py/object": "data.DataClassPaper",
    "Title": "Extracting rules for vulnerabilities detection with static metrics using machine learning",
    "year": 2020,
    "ML_Techniques": "AB, DS, RF, DT, LB, Ripper, RT, LR, BN, NB, B",
    "Category": "Vulnerability analysis",
    "Sub_category": "",
    "Venue": "IJSAEM",
    "Link": "https://link.springer.com/article/10.1007/s13198-020-01036-0",
    "bibtex": "article{Gupta2021_30,\n    author = \"Gupta, Aakanshi and Suri, Bharti and Kumar, Vijay and Jain, Pragyashree\",\n    title = \"Extracting rules for vulnerabilities detection with static metrics using machine learning\",\n    journal = \"International Journal of System Assurance Engineering and Management\",\n    year = \"2021\",\n    volume = \"12\",\n    pages = \"65-76\"\n}\n\n",
    "abstract": "Software quality is the prime solicitude in software engineering and vulnerability is one of the major threat in this respect. Vulnerability hampers the security of the software and also impairs the quality of the software. In this paper, we have conducted experimental research on evaluating the utility of machine learning algorithms to detect the vulnerabilities. To execute this experiment; a set of software metrics was extracted using machine learning in the form of easily accessible laws. Here, 32 supervised machine learning algorithms have been considered for 3 most occurred vulnerabilities namely: Lawofdemeter, BeanMemberShouldSerialize,and LocalVariablecouldBeFinal in a software system. Using the J48 machine learning algorithm in this research, up to 96% of accurate result in vulnerability detection was achieved. The results are validated against tenfold cross validation and also, the statistical parameters like ROC curve, Kappa statistics; Recall, Precision, etc. have been used for analyzing the result."
}, {
    "py/object": "data.DataClassPaper",
    "Title": "Is Predicting Software Security Bugs Using Deep Learning Better Than the Traditional Machine Learning Algorithms?",
    "year": 2018,
    "ML_Techniques": "DT, RF, NB, SVM",
    "Category": "Vulnerability analysis",
    "Sub_category": ",operational vulnerabilities",
    "Venue": "QRS",
    "Link": "https://ieeexplore.ieee.org/abstract/document/8424961",
    "bibtex": "INPROCEEDINGS{Clemente2018_34,\n    author = \"{Clemente}, C. J. and {Jaafar}, F. and {Malik}, Y.\",\n    booktitle = \"2018 IEEE International Conference on Software Quality, Reliability and Security (QRS)\",\n    title = \"Is Predicting Software Security Bugs Using Deep Learning Better Than the Traditional Machine Learning Algorithms?\",\n    year = \"2018\",\n    volume = \"\",\n    number = \"\",\n    pages = \"95-102\",\n    doi = \"10.1109/QRS.2018.00023\"\n}\n\n",
    "abstract": "Software insecurity is being identified as one of the leading causes of security breaches. In this paper, we revisited one of the strategies in solving software insecurity, which is the use of software quality metrics. We utilized a multilayer deep feedforward network in examining whether there is a combination of metrics that can predict the appearance of security-related bugs. We also applied the traditional machine learning algorithms such as decision tree, random forest, na\u00efve bayes, and support vector machines and compared the results with that of the Deep Learning technique. The results have successfully demonstrated that it was possible to develop an effective predictive model to forecast software insecurity based on the software metrics and using Deep Learning. All the models generated have shown an accuracy of more than sixty percent with Deep Learning leading the list. This finding proved that utilizing Deep Learning methods and a combination of software metrics can be tapped to create a better forecasting model thereby aiding software developers in predicting security bugs."
}, {
    "py/object": "data.DataClassPaper",
    "Title": "Learning to Repair Software Vulnerabilities with Generative Adversarial Networks",
    "year": 2018,
    "ML_Techniques": "NMT",
    "Category": "Vulnerability analysis",
    "Sub_category": "",
    "Venue": "NIPS",
    "Link": "https://papers.nips.cc/paper/2018/hash/68abef8ee1ac9b664a90b0bbaff4f770-Abstract.html",
    "bibtex": "inproceedings{Harer2018_35,\n    author = \"Harer, Jacob and Ozdemir, Onur and Lazovich, Tomo and Reale, Christopher and Russell, Rebecca and Kim, Louis and chin, peter\",\n    editor = \"Bengio, S. and Wallach, H. and Larochelle, H. and Grauman, K. and Cesa-Bianchi, N. and Garnett, R.\",\n    booktitle = \"Advances in Neural Information Processing Systems\",\n    pages = \"7933--7943\",\n    publisher = \"Curran Associates, Inc.\",\n    title = \"Learning to Repair Software Vulnerabilities with Generative Adversarial Networks\",\n    url = \"https://proceedings.neurips.cc/paper/2018/file/68abef8ee1ac9b664a90b0bbaff4f770-Paper.pdf\",\n    volume = \"31\",\n    year = \"2018\"\n}\n\n",
    "abstract": "Motivated by the problem of automated repair of software vulnerabilities, we propose an adversarial learning approach that maps from one discrete source domain to another target domain without requiring paired labeled examples or source and target domains to be bijections. We demonstrate that the proposed adversarial learning approach is an effective technique for repairing software vulnerabilities, performing close to seq2seq approaches that require labeled pairs. The proposed Generative Adversarial Network approach is application-agnostic in that it can be applied to other problems similar to code repair, such as grammar correction or sentiment translation."
}, {
    "py/object": "data.DataClassPaper",
    "Title": "Machine learning aided Android malware classification",
    "year": 2017,
    "ML_Techniques": "SVM, NB, DT, Ripper, AB",
    "Category": "Vulnerability analysis",
    "Sub_category": ",Malware detection",
    "Venue": "Computers & Electrical Engineering",
    "Link": "https://www.sciencedirect.com/science/article/abs/pii/S0045790617303087",
    "bibtex": "article{Milosevic2017_36,\n    author = \"Milosevic, Nikola and Dehghantanha, Ali and Choo, Kim-Kwang Raymond\",\n    title = \"Machine learning aided Android malware classification\",\n    journal = \"Computers \\& Electrical Engineering\",\n    volume = \"61\",\n    pages = \"266 - 274\",\n    year = \"2017\",\n    issn = \"0045-7906\",\n    doi = \"https://doi.org/10.1016/j.compeleceng.2017.02.013\",\n    url = \"http://www.sciencedirect.com/science/article/pii/S0045790617303087\",\n    keywords = \"Static malware analysis, OWASP, Seraphimdroid Android app, OWASP Seraphimdroid Android app, Machine learning\"\n}\n\n",
    "abstract": "The widespread adoption of Android devices and their capability to access significant private and confidential information have resulted in these devices being targeted by malware developers. Existing Android malware analysis techniques can be broadly categorized into static and dynamic analysis. In this paper, we present two machine learning aided approaches for static analysis of Android malware. The first approach is based on permissions and the other is based on source code analysis utilizing a bag-of-words representation model. Our permission-based model is computationally inexpensive, and is implemented as the feature of OWASP Seraphimdroid Android app that can be obtained from Google Play Store. Our evaluations of both approaches indicate an F-score of 95.1% and F-measure of 89% for the source code-based classification and permission-based classification models, respectively."
}, {
    "py/object": "data.DataClassPaper",
    "Title": "Machine Learning Methods for Software Vulnerability Detection",
    "year": 2018,
    "ML_Techniques": "NB, KNN, KM, SVM, DT, RF",
    "Category": "Vulnerability analysis",
    "Sub_category": "",
    "Venue": "IWSPA",
    "Link": "https://dl.acm.org/doi/abs/10.1145/3180445.3180453",
    "bibtex": "inproceedings{Chernis2018_39,\n    author = \"Chernis, Boris and Verma, Rakesh\",\n    title = \"Machine Learning Methods for Software Vulnerability Detection\",\n    year = \"2018\",\n    isbn = \"9781450356343\",\n    publisher = \"Association for Computing Machinery\",\n    address = \"New York, NY, USA\",\n    url = \"https://doi.org/10.1145/3180445.3180453\",\n    doi = \"10.1145/3180445.3180453\",\n    booktitle = \"Proceedings of the Fourth ACM International Workshop on Security and Privacy Analytics\",\n    pages = \"31\u201339\",\n    numpages = \"9\",\n    keywords = \"suffix trees, machine learning, static analysis, buffer overflow, vulnerability detection, N-grams, software metrics\",\n    location = \"Tempe, AZ, USA\",\n    series = \"IWSPA '18\"\n}\n\n",
    "abstract": "Software vulnerabilities are a primary concern in the IT security industry, as malicious hackers who discover these vulnerabilities can often exploit them for nefarious purposes. However, complex programs, particularly those written in a relatively low-level language like C, are difficult to fully scan for bugs, even when both manual and automated techniques are used. Since analyzing code and making sure it is securely written is proven to be a non-trivial task, both static analysis and dynamic analysis techniques have been heavily investigated, and this work focuses on the former. The contribution of this paper is a demonstration of how it is possible to catch a large percentage of bugs by extracting text features from functions in C source code and analyzing them with a machine learning classifier. Relatively simple features (character count, character diversity, entropy, maximum nesting depth, arrow count, \"if\" count, \"if\" complexity, \"while\" count, and \"for\" count) were extracted from these functions, and so were complex features (character n-grams, word n-grams, and suffix trees). The simple features performed unexpectedly better compared to the complex features (74% accuracy compared to 69% accuracy)."
}, {
    "py/object": "data.DataClassPaper",
    "Title": "Malicious Code Detection and Acquisition Using Active Learning",
    "year": 2007,
    "ML_Techniques": "SVM",
    "Category": "Vulnerability analysis",
    "Sub_category": "",
    "Venue": "ISI",
    "Link": "https://ieeexplore.ieee.org/document/4258731",
    "bibtex": "INPROCEEDINGS{Moskovitch2007_42,\n    author = \"{Moskovitch}, R. and {Nissim}, N. and {Elovici}, Y.\",\n    booktitle = \"2007 IEEE Intelligence and Security Informatics\",\n    title = \"Malicious Code Detection and Acquisition Using Active Learning\",\n    year = \"2007\",\n    volume = \"\",\n    number = \"\",\n    pages = \"371-371\",\n    doi = \"10.1109/ISI.2007.379505\"\n}\n\n",
    "abstract": "Detection of known malicious code is commonly performed by anti-virus tools. These tools detect the known malicious code using signature detection methods. Each time a new malicious code is found the anti-virus vendors create a new signature and update their clients. During the period between the appearance of a new unknown malicious code and the update of the signature base of the anti-virus clients, millions of computers might be infected. In order to cope with this problem, new solutions must be found for detecting unknown malicious code at the entrance of a client's computer. We presented here the use of active learning in the acquisition of unknown malicious code. Preliminary Results are encouraging. We are currently in the process of creating a wide test collection of more than 30,000 benign and malicious files to evaluate several active learning criterions."
}, {
    "py/object": "data.DataClassPaper",
    "Title": "Malicious Code Detection Using Active Learning",
    "year": 2009,
    "ML_Techniques": "SVM",
    "Category": "Vulnerability analysis",
    "Sub_category": "",
    "Venue": "PST",
    "Link": "https://link.springer.com/chapter/10.1007/978-3-642-01718-6_6",
    "bibtex": "InProceedings{Moskovitch2009_43,\n    author = \"Moskovitch, Robert and Nissim, Nir and Elovici, Yuval\",\n    editor = \"Bonchi, Francesco and Ferrari, Elena and Jiang, Wei and Malin, Bradley\",\n    title = \"Malicious Code Detection Using Active Learning\",\n    booktitle = \"Privacy, Security, and Trust in KDD\",\n    year = \"2009\",\n    publisher = \"Springer Berlin Heidelberg\",\n    address = \"Berlin, Heidelberg\",\n    pages = \"74--91\",\n    abstract = \"The recent growth in network usage has motivated the creation of new malicious code for various purposes, including economic and other malicious purposes. Currently, dozens of new malicious codes are created every day and this number is expected to increase in the coming years. Today's signature-based anti-viruses and heuristic-based methods are accurate, but cannot detect new malicious code. Recently, classification algorithms were used successfully for the detection of malicious code. We present a complete methodology for the detection of unknown malicious code, inspired by text categorization concepts. However, this approach can be exploited further to achieve a more accurate and efficient acquisition method of unknown malicious files. We use an Active-Learning framework that enables the selection of the unknown files for fast acquisition. We performed an extensive evaluation of a test collection consisting of more than 30,000 files. We present a rigorous evaluation setup, consisting of real-life scenarios, in which the malicious file content is expected to be low, at about 10{\\\\%} of the files in the stream. We define specific evaluation measures based on the known precision and recall measures, which show the accuracy of the acquisition process and the improvement in the classifier resulting from the efficient acquisition process.\",\n    isbn = \"978-3-642-01718-6\"\n}\n\n",
    "abstract": "The recent growth in network usage has motivated the creation of new malicious code for various purposes, including economic and other malicious purposes. Currently, dozens of new malicious codes are created every day and this number is expected to increase in the coming years. Today\u2019s signature-based anti-viruses and heuristic-based methods are accurate, but cannot detect new malicious code. Recently, classification algorithms were used successfully for the detection of malicious code. We present a complete methodology for the detection of unknown malicious code, inspired by text categorization concepts. However, this approach can be exploited further to achieve a more accurate and efficient acquisition method of unknown malicious files. We use an Active-Learning framework that enables the selection of the unknown files for fast acquisition. We performed an extensive evaluation of a test collection consisting of more than 30,000 files. We present a rigorous evaluation setup, consisting of real-life scenarios, in which the malicious file content is expected to be low, at about 10% of the files in the stream. We define specific evaluation measures based on the known precision and recall measures, which show the accuracy of the acquisition process and the improvement in the classifier resulting from the efficient acquisition process."
}, {
    "py/object": "data.DataClassPaper",
    "Title": "Malicious web content detection by machine learning",
    "year": 2010,
    "ML_Techniques": "DT, NB, SVM",
    "Category": "Vulnerability analysis",
    "Sub_category": "",
    "Venue": "ESA",
    "Link": "https://www.sciencedirect.com/science/article/abs/pii/S095741740900445X",
    "bibtex": "article{Hou2010_44,\n    author = \"Hou, Yung-Tsung and Chang, Yimeng and Chen, Tsuhan and Laih, Chi-Sung and Chen, Chia-Mei\",\n    title = \"Malicious web content detection by machine learning\",\n    journal = \"Expert Systems with Applications\",\n    volume = \"37\",\n    number = \"1\",\n    pages = \"55 - 60\",\n    year = \"2010\",\n    issn = \"0957-4174\",\n    doi = \"https://doi.org/10.1016/j.eswa.2009.05.023\",\n    url = \"http://www.sciencedirect.com/science/article/pii/S095741740900445X\",\n    keywords = \"Dynamic HTML, Malicious webpage, Machine learning\",\n    abstract = \"The recent development of the dynamic HTML gives attackers a new and powerful technique to compromise computer systems. A malicious dynamic HTML code is usually embedded in a normal webpage. The malicious webpage infects the victim when a user browses it. Furthermore, such DHTML code can disguise itself easily through obfuscation or transformation, which makes the detection even harder. Anti-virus software packages commonly use signature-based approaches which might not be able to efficiently identify camouflaged malicious HTML codes. Therefore, our paper proposes a malicious web page detection using the technique of machine learning. Our study analyzes the characteristic of a malicious webpage systematically and presents important features for machine learning. Experimental results demonstrate that our method is resilient to code obfuscations and can correctly determine whether a webpage is malicious or not.\"\n}\n\n",
    "abstract": "The recent development of the dynamic HTML gives attackers a new and powerful technique to compromise computer systems. A malicious dynamic HTML code is usually embedded in a normal webpage. The malicious webpage infects the victim when a user browses it. Furthermore, such DHTML code can disguise itself easily through obfuscation or transformation, which makes the detection even harder. Anti-virus software packages commonly use signature-based approaches which might not be able to efficiently identify camouflaged malicious HTML codes. Therefore, our paper proposes a malicious web page detection using the technique of machine learning. Our study analyzes the characteristic of a malicious webpage systematically and presents important features for machine learning. Experimental results demonstrate that our method is resilient to code obfuscations and can correctly determine whether a webpage is malicious or not."
}, {
    "py/object": "data.DataClassPaper",
    "Title": "OPEM: A Static-Dynamic Approach for Machine-Learning-Based Malware Detection",
    "year": 2013,
    "ML_Techniques": "DT, SVM, BN, KNN",
    "Category": "Vulnerability analysis",
    "Sub_category": ",Malware detection",
    "Venue": "AISC",
    "Link": "https://link.springer.com/chapter/10.1007/978-3-642-33018-6_28",
    "bibtex": "InProceedings{Santos2013_46,\n    author = \"Santos, Igor and Devesa, Jaime and Brezo, F{\\'e}lix and Nieves, Javier and Bringas, Pablo Garcia\",\n    editor = \"Herrero, {\\'A}lvaro and Sn{\\'a}{\\v{s}}el, V{\\'a}clav and Abraham, Ajith and Zelinka, Ivan and Baruque, Bruno and Quinti{\\'a}n, H{\\'e}ctor and Calvo, Jos{\\'e} Luis and Sedano, Javier and Corchado, Emilio\",\n    title = \"OPEM: A Static-Dynamic Approach for Machine-Learning-Based Malware Detection\",\n    booktitle = \"International Joint Conference CISIS'12-ICEUTE{\\textasciiacute}12-SOCO{\\textasciiacute}12 Special Sessions\",\n    year = \"2013\",\n    publisher = \"Springer Berlin Heidelberg\",\n    address = \"Berlin, Heidelberg\",\n    pages = \"271--280\",\n    isbn = \"978-3-642-33018-6\"\n}\n\n",
    "abstract": "Malware is any computer software potentially harmful to both computers and networks. The amount of malware is growing every year and poses a serious global security threat. Signature-based detection is the most extended method in commercial antivirus software, however, it consistently fails to detect new malware. Supervised machine learning has been adopted to solve this issue. There are two types of features that supervised malware detectors use: (i) static features and (ii) dynamic features. Static features are extracted without executing the sample whereas dynamic ones requires an execution. Both approaches have their advantages and disadvantages. In this paper, we propose for the first time, OPEM, an hybrid unknown malware detector which combines the frequency of occurrence of operational codes (statically obtained) with the information of the execution trace of an executable (dynamically obtained). We show that this hybrid approach enhances the performance of both approaches when run separately."
}, {
    "py/object": "data.DataClassPaper",
    "Title": "Pre-Patch: Find Hidden Threats in Open Software Based on Machine Learning Method",
    "year": 2018,
    "ML_Techniques": "BP-ANN",
    "Category": "Vulnerability analysis",
    "Sub_category": ",Malware detection",
    "Venue": "SERVICES",
    "Link": "https://link.springer.com/chapter/10.1007/978-3-319-94472-2_4",
    "bibtex": "InProceedings{Yang2018_47,\n    author = \"Yang, Mutian and Wu, Jingzheng and Ji, Shouling and Luo, Tianyue and Wu, Yanjun\",\n    editor = \"Yang, Alvin and Kantamneni, Siva and Li, Ying and Dico, Awel and Chen, Xiangang and Subramanyan, Rajesh and Zhang, Liang-Jie\",\n    title = \"Pre-Patch: Find Hidden Threats in Open Software Based on Machine Learning Method\",\n    booktitle = \"Services -- SERVICES 2018\",\n    year = \"2018\",\n    publisher = \"Springer International Publishing\",\n    address = \"Cham\",\n    pages = \"48--65\",\n    abstract = \"The details of vulnerabilities are always kept confidential until fixed, which is an efficient way to avoid the exploitations and attacks. However, the Security Related Commits (SRCs), used to fix the vulnerabilities in open source software, usually lack proper protections. Most SRCs are released in code repositories such as Git, Github, Sourceforge, etc. earlier than the corresponding vulnerabilities published. These commits often previously disclose the vital information which can be used by the attackers to locate and exploit the vulnerable code. Therefore, we defined the pre-leaked SRC as the Pre-Patch problem and studied its hidden threats to the open source software. In this paper, we presented an Automatic Security Related Commits Detector (ASRCD) to rapidly identify the Pre-Patch problems from the numerous commits in code repositories by learning the features of SRCs. We implemented ASRCD and evaluated it with 78,218 real-world commits collected from Linux Kernel, OpenSSL, phpMyadmin and Mantisbt released between 2016 to 2017, which contain 227 confirmed SRCs. ASRCD successfully identified 206 SRCs from the 4 projects, including 140 known SRCs (recall rate: 61.7{\\\\%} on average) and 66 new high-suspicious. In addition, 5 of the SRCs have been published after our prediction. The results show that: (1) the Pre-Patch is really a hidden threat to open source software; and (2) the proposed ASRCD is effective in identifying such SRCs. Finally, we recommended the identified SRCs should be fixed as soon as possible.\",\n    isbn = \"978-3-319-94472-2\"\n}\n\n",
    "abstract": "The details of vulnerabilities are always kept confidential until fixed, which is an efficient way to avoid the exploitations and attacks. However, the Security Related Commits (SRCs), used to fix the vulnerabilities in open source software, usually lack proper protections. Most SRCs are released in code repositories such as Git, Github, Sourceforge, etc. earlier than the corresponding vulnerabilities published. These commits often previously disclose the vital information which can be used by the attackers to locate and exploit the vulnerable code. Therefore, we defined the pre-leaked SRC as the Pre-Patch problem and studied its hidden threats to the open source software. In this paper, we presented an Automatic Security Related Commits Detector (ASRCD) to rapidly identify the Pre-Patch problems from the numerous commits in code repositories by learning the features of SRCs. We implemented ASRCD and evaluated it with 78,218 real-world commits collected from Linux Kernel, OpenSSL, phpMyadmin and Mantisbt released between 2016 to 2017, which contain 227 confirmed SRCs. ASRCD successfully identified 206 SRCs from the 4 projects, including 140 known SRCs (recall rate: 61.7% on average) and 66 new high-suspicious. In addition, 5 of the SRCs have been published after our prediction. The results show that: (1) the Pre-Patch is really a hidden threat to open source software; and (2) the proposed ASRCD is effective in identifying such SRCs. Finally, we recommended the identified SRCs should be fixed as soon as possible."
}, {
    "py/object": "data.DataClassPaper",
    "Title": "Predicting Android application security and privacy risk with static code metrics",
    "year": 2017,
    "ML_Techniques": "SVM, RF, LR, KNN",
    "Category": "Vulnerability analysis",
    "Sub_category": "",
    "Venue": "MOBILESoft",
    "Link": "https://dl.acm.org/doi/10.1109/MOBILESoft.2017.14",
    "bibtex": "InProceedings{Yang2018_47,\n    author = \"Yang, Mutian and Wu, Jingzheng and Ji, Shouling and Luo, Tianyue and Wu, Yanjun\",\n    editor = \"Yang, Alvin and Kantamneni, Siva and Li, Ying and Dico, Awel and Chen, Xiangang and Subramanyan, Rajesh and Zhang, Liang-Jie\",\n    title = \"Pre-Patch: Find Hidden Threats in Open Software Based on Machine Learning Method\",\n    booktitle = \"Services -- SERVICES 2018\",\n    year = \"2018\",\n    publisher = \"Springer International Publishing\",\n    address = \"Cham\",\n    pages = \"48--65\",\n    abstract = \"The details of vulnerabilities are always kept confidential until fixed, which is an efficient way to avoid the exploitations and attacks. However, the Security Related Commits (SRCs), used to fix the vulnerabilities in open source software, usually lack proper protections. Most SRCs are released in code repositories such as Git, Github, Sourceforge, etc. earlier than the corresponding vulnerabilities published. These commits often previously disclose the vital information which can be used by the attackers to locate and exploit the vulnerable code. Therefore, we defined the pre-leaked SRC as the Pre-Patch problem and studied its hidden threats to the open source software. In this paper, we presented an Automatic Security Related Commits Detector (ASRCD) to rapidly identify the Pre-Patch problems from the numerous commits in code repositories by learning the features of SRCs. We implemented ASRCD and evaluated it with 78,218 real-world commits collected from Linux Kernel, OpenSSL, phpMyadmin and Mantisbt released between 2016 to 2017, which contain 227 confirmed SRCs. ASRCD successfully identified 206 SRCs from the 4 projects, including 140 known SRCs (recall rate: 61.7{\\\\%} on average) and 66 new high-suspicious. In addition, 5 of the SRCs have been published after our prediction. The results show that: (1) the Pre-Patch is really a hidden threat to open source software; and (2) the proposed ASRCD is effective in identifying such SRCs. Finally, we recommended the identified SRCs should be fixed as soon as possible.\",\n    isbn = \"978-3-319-94472-2\"\n}\n\n",
    "abstract": "Android applications pose security and privacy risks for end-users. These risks are often quantified by performing dynamic analysis and permission analysis of the Android applications after release. Prediction of security and privacy risks associated with Android applications at early stages of application development, e.g. when the developer (s) are writing the code of the application, might help Android application developers in releasing applications to end-users that have less security and privacy risk. The goal of this paper is to aid Android application developers in assessing the security and privacy risk associated with Android applications by using static code metrics as predictors. In our paper, we consider security and privacy risk of Android application as how susceptible the application is to leaking private information of end-users and to releasing vulnerabilities. We investigate how effectively static code metrics that are extracted from the source code of Android applications, can be used to predict security and privacy risk of Android applications. We collected 21 static code metrics of 1,407 Android applications, and use the collected static code metrics to predict security and privacy risk of the applications. As the oracle of security and privacy risk, we used Androrisk, a tool that quantifies the amount of security and privacy risk of an Android application using analysis of Android permissions and dynamic analysis. To accomplish our goal, we used statistical learners such as, radial-based support vector machine (r-SVM). For r-SVM, we observe a precision of 0.83. Findings from our paper suggest that with proper selection of static code metrics, r-SVM can be used effectively to predict security and privacy risk of Android applications."
}, {
    "py/object": "data.DataClassPaper",
    "Title": "Project Achilles: A Prototype Tool for Static Method-Level Vulnerability Detection of Java Source Code Using a Recurrent Neural Network",
    "year": 2019,
    "ML_Techniques": "LSTM",
    "Category": "Vulnerability analysis",
    "Sub_category": ",29 different CWE",
    "Venue": "ASEW",
    "Link": "https://ieeexplore.ieee.org/document/8967427",
    "bibtex": "INPROCEEDINGS{Saccente2019_50,\n    author = \"{Saccente}, N. and {Dehlinger}, J. and {Deng}, L. and {Chakraborty}, S. and {Xiong}, Y.\",\n    booktitle = \"2019 34th IEEE/ACM International Conference on Automated Software Engineering Workshop (ASEW)\",\n    title = \"Project Achilles: A Prototype Tool for Static Method-Level Vulnerability Detection of Java Source Code Using a Recurrent Neural Network\",\n    year = \"2019\",\n    volume = \"\",\n    number = \"\",\n    pages = \"114-121\",\n    doi = \"10.1109/ASEW.2019.00040\"\n}\n\n",
    "abstract": "Software has become an essential component of modern life, but when software vulnerabilities threaten the security of users, new ways of analyzing for software security must be explored. Using the National Institute of Standards and Technology's Juliet Java Suite, containing thousands of examples of defective Java methods for a variety of vulnerabilities, a prototype tool was developed implementing an array of Long-Short Term Memory Recurrent Neural Networks to detect vulnerabilities within source code. The tool employs various data preparation methods to be independent of coding style and to automate the process of extracting methods, labeling data, and partitioning the dataset. The result is a prototype command-line utility that generates an n-dimensional vulnerability prediction vector. The experimental evaluation using 44,495 test cases indicates that the tool can achieve an accuracy higher than 90% for 24 out of 29 different types of CWE vulnerabilities."
}, {
    "py/object": "data.DataClassPaper",
    "Title": "Software Vulnerability Analysis and Discovery Using Machine-Learning and Data-Mining Techniques: A Survey",
    "year": 2017,
    "ML_Techniques": "",
    "Category": "Vulnerability analysis",
    "Sub_category": "",
    "Venue": "CSUR",
    "Link": "https://dl.acm.org/doi/abs/10.1145/3092566",
    "bibtex": "article{Ghaffarian2017_52,\n    author = \"Ghaffarian, Seyed Mohammad and Shahriari, Hamid Reza\",\n    title = \"Software Vulnerability Analysis and Discovery Using Machine-Learning and Data-Mining Techniques: A Survey\",\n    year = \"2017\",\n    issue_date = \"November 2017\",\n    publisher = \"Association for Computing Machinery\",\n    address = \"New York, NY, USA\",\n    volume = \"50\",\n    number = \"4\",\n    issn = \"0360-0300\",\n    url = \"https://doi.org/10.1145/3092566\",\n    doi = \"10.1145/3092566\",\n    abstract = \"Software security vulnerabilities are one of the critical issues in the realm of computer security. Due to their potential high severity impacts, many different approaches have been proposed in the past decades to mitigate the damages of software vulnerabilities. Machine-learning and data-mining techniques are also among the many approaches to address this issue. In this article, we provide an extensive review of the many different works in the field of software vulnerability analysis and discovery that utilize machine-learning and data-mining techniques. We review different categories of works in this domain, discuss both advantages and shortcomings, and point out challenges and some uncharted territories in the field.\",\n    journal = \"ACM Comput. Surv.\",\n    month = \"August\",\n    articleno = \"56\",\n    numpages = \"36\",\n    keywords = \"software vulnerability discovery, survey, machine-learning, Software vulnerability analysis, review, software security, data-mining\"\n}\n\n",
    "abstract": "Software security vulnerabilities are one of the critical issues in the realm of computer security. Due to their potential high severity impacts, many different approaches have been proposed in the past decades to mitigate the damages of software vulnerabilities. Machine-learning and data-mining techniques are also among the many approaches to address this issue. In this article, we provide an extensive review of the many different works in the field of software vulnerability analysis and discovery that utilize machine-learning and data-mining techniques. We review different categories of works in this domain, discuss both advantages and shortcomings, and point out challenges and some uncharted territories in the field."
}, {
    "py/object": "data.DataClassPaper",
    "Title": "Survey of machine learning techniques for malware analysis",
    "year": 2019,
    "ML_Techniques": "",
    "Category": "Vulnerability analysis",
    "Sub_category": ",survey",
    "Venue": "Computers & Security",
    "Link": "https://www.sciencedirect.com/science/article/pii/S0167404818303808",
    "bibtex": "article{Ucci2019_54,\n    author = \"Ucci, Daniele and Aniello, Leonardo and Baldoni, Roberto\",\n    title = \"Survey of machine learning techniques for malware analysis\",\n    journal = \"Computers \\& Security\",\n    volume = \"81\",\n    pages = \"123 - 147\",\n    year = \"2019\",\n    issn = \"0167-4048\",\n    doi = \"https://doi.org/10.1016/j.cose.2018.11.001\",\n    url = \"http://www.sciencedirect.com/science/article/pii/S0167404818303808\",\n    keywords = \"Portable executable, Malware analysis, Machine learning, Benchmark, Malware analysis economics\"\n}\n\n",
    "abstract": "Coping with malware is getting more and more challenging, given their relentless growth in complexity and volume. One of the most common approaches in literature is using machine learning techniques, to automatically learn models and patterns behind such complexity, and to develop technologies to keep pace with malware evolution. This survey aims at providing an overview on the way machine learning has been used so far in the context of malware analysis in Windows environments, i.e. for the analysis of Portable Executables. We systematize surveyed papers according to their objectives (i.e., the expected output), what information about malware they specifically use (i.e., the features), and what machine learning techniques they employ (i.e., what algorithm is used to process the input and produce the output). We also outline a number of issues and challenges, including those concerning the used datasets, and identify the main current topical trends and how to possibly advance them. In particular, we introduce the novel concept of malware analysis economics, regarding the study of existing trade-offs among key metrics, such as analysis accuracy and economical costs."
}, {
    "py/object": "data.DataClassPaper",
    "Title": "The impact factors on the performance of machine learning-based vulnerability detection: A comparative study",
    "year": 2020,
    "ML_Techniques": "RF, GBDT, KNN, SVM, LR, BLSTM, GRU, CNN",
    "Category": "Vulnerability analysis",
    "Sub_category": "",
    "Venue": "JSS",
    "Link": "https://www.sciencedirect.com/science/article/abs/pii/S0164121220301229",
    "bibtex": "article{Zheng2020_56,\n    author = \"Zheng, Wei and Gao, Jialiang and Wu, Xiaoxue and Liu, Fengyu and Xun, Yuxing and Liu, Guoliang and Chen, Xiang\",\n    title = \"The impact factors on the performance of machine learning-based vulnerability detection: A comparative study\",\n    journal = \"Journal of Systems and Software\",\n    volume = \"168\",\n    pages = \"110659\",\n    year = \"2020\",\n    issn = \"0164-1212\",\n    doi = \"https://doi.org/10.1016/j.jss.2020.110659\",\n    url = \"http://www.sciencedirect.com/science/article/pii/S0164121220301229\",\n    keywords = \"Vulnerability detection, Machine learning, Comparative study, Deep learning, Feature extraction\",\n    abstract = \"Machine learning-based Vulnerability detection is an active research topic in software security. Different traditional machine learning-based and deep learning-based vulnerability detection methods have been proposed. To our best knowledge, we are the first to identify four impact factors and conduct a comparative study to investigate the performance influence of these factors. In particular, the quality of datasets, classification models and vectorization methods can directly affect the detection performance, in contrast function/variable name replacement can affect the features of vulnerability detection and indirectly affect the performance. We collect three different vulnerability code datasets from two various sources (i.e., NVD and SARD). These datasets can correspond to different types of vulnerabilities. Moreover, we extract and analyze the features of vulnerability code datasets to explain some experimental results. Our findings based on the experimental results can be summarized as follows: (1) Deep learning models can achieve better performance than traditional machine learning models. Of all the models, BLSTM can achieve the best performance. (2) CountVectorizer can significantly improve the performance of traditional machine learning models. (3) Features generated by the random forest algorithm include system-related functions, syntax keywords, and user-defined names. Different vulnerability types and code sources will generate different features. (4) Datasets with user-defined variable and function name replacement will decrease the performance of vulnerability detection. (5) As the proportion of code from SARD increases, the performance of vulnerability detection will increase.\"\n}\n\n",
    "abstract": "Machine learning-based Vulnerability detection is an active research topic in software security. Different traditional machine learning-based and deep learning-based vulnerability detection methods have been proposed. To our best knowledge, we are the first to identify four impact factors and conduct a comparative study to investigate the performance influence of these factors. In particular, the quality of datasets, classification models and vectorization methods can directly affect the detection performance, in contrast function/variable name replacement can affect the features of vulnerability detection and indirectly affect the performance. We collect three different vulnerability code datasets from two various sources (i.e., NVD and SARD). These datasets can correspond to different types of vulnerabilities. Moreover, we extract and analyze the features of vulnerability code datasets to explain some experimental results. Our findings based on the experimental results can be summarized as follows: (1) Deep learning models can achieve better performance than traditional machine learning models. Of all the models, BLSTM can achieve the best performance. (2) CountVectorizer can significantly improve the performance of traditional machine learning models. (3) Features generated by the random forest algorithm include system-related functions, syntax keywords, and user-defined names. Different vulnerability types and code sources will generate different features. (4) Datasets with user-defined variable and function name replacement will decrease the performance of vulnerability detection. (5) As the proportion of code from SARD increases, the performance of vulnerability detection will increase."
}, {
    "py/object": "data.DataClassPaper",
    "Title": "The rise of machine learning for detection and classification of malware: Research developments, trends and challenges",
    "year": 2020,
    "ML_Techniques": "",
    "Category": "Vulnerability analysis",
    "Sub_category": ",survey",
    "Venue": "JNCA",
    "Link": "https://www.sciencedirect.com/science/article/pii/S1084804519303868",
    "bibtex": "article{Gibert2020_57,\n    author = \"Gibert, Daniel and Mateu, Carles and Planes, Jordi\",\n    title = \"The rise of machine learning for detection and classification of malware: Research developments, trends and challenges\",\n    journal = \"Journal of Network and Computer Applications\",\n    volume = \"153\",\n    pages = \"102526\",\n    year = \"2020\",\n    issn = \"1084-8045\",\n    doi = \"https://doi.org/10.1016/j.jnca.2019.102526\",\n    url = \"http://www.sciencedirect.com/science/article/pii/S1084804519303868\",\n    keywords = \"Malware detection, Feature engineering, Machine learning, Deep learning, Multimodal learning\",\n    abstract = \"The struggle between security analysts and malware developers is a never-ending battle with the complexity of malware changing as quickly as innovation grows. Current state-of-the-art research focus on the development and application of machine learning techniques for malware detection due to its ability to keep pace with malware evolution. This survey aims at providing a systematic and detailed overview of machine learning techniques for malware detection and in particular, deep learning techniques. The main contributions of the paper are: (1) it provides a complete description of the methods and features in a traditional machine learning workflow for malware detection and classification, (2) it explores the challenges and limitations of traditional machine learning and (3) it analyzes recent trends and developments in the field with special emphasis on deep learning approaches. Furthermore, (4) it presents the research issues and unsolved challenges of the state-of-the-art techniques and (5) it discusses the new directions of research. The survey helps researchers to have an understanding of the malware detection field and of the new developments and directions of research explored by the scientific community to tackle the problem.\"\n}\n\n",
    "abstract": "The struggle between security analysts and malware developers is a never-ending battle with the complexity of malware changing as quickly as innovation grows. Current state-of-the-art research focus on the development and application of machine learning techniques for malware detection due to its ability to keep pace with malware evolution. This survey aims at providing a systematic and detailed overview of machine learning techniques for malware detection and in particular, deep learning techniques. The main contributions of the paper are: (1) it provides a complete description of the methods and features in a traditional machine learning workflow for malware detection and classification, (2) it explores the challenges and limitations of traditional machine learning and (3) it analyzes recent trends and developments in the field with special emphasis on deep learning approaches. Furthermore, (4) it presents the research issues and unsolved challenges of the state-of-the-art techniques and (5) it discusses the new directions of research. The survey helps researchers to have an understanding of the malware detection field and of the new developments and directions of research explored by the scientific community to tackle the problem."
}, {
    "py/object": "data.DataClassPaper",
    "Title": "Towards Attention Based Vulnerability Discovery Using Source Code Representation",
    "year": 2019,
    "ML_Techniques": "BLSTM",
    "Category": "Vulnerability analysis",
    "Sub_category": ",Malware detection",
    "Venue": "ICANN",
    "Link": "https://link.springer.com/chapter/10.1007/978-3-030-30490-4_58",
    "bibtex": "InProceedings{Kim2019_59,\n    author = \"Kim, Junae and Hubczenko, David and Montague, Paul\",\n    editor = \"Tetko, Igor V. and K{\\r{u}}rkov{\\'a}, V{\\v{e}}ra and Karpov, Pavel and Theis, Fabian\",\n    title = \"Towards Attention Based Vulnerability Discovery Using Source Code Representation\",\n    booktitle = \"Artificial Neural Networks and Machine Learning -- ICANN 2019: Text and Time Series\",\n    year = \"2019\",\n    publisher = \"Springer International Publishing\",\n    address = \"Cham\",\n    pages = \"731--746\",\n    abstract = \"Vulnerability discovery in software is an important task in the field of computer security. As vulnerabilities can be abused to enable cyber criminals and other malicious actors to exploit systems, it is crucial to keep software as free from vulnerabilities as is possible. Traditional approaches often comprise code scanning tasks to find specific and already-known classes of cyber vulnerabilities. However these approaches do not in general discover new classes of vulnerabilities. In this paper, we leverage a machine learning approach to model source code representation using syntax, semantics and control flow of source code and to infer vulnerable code patterns to tackle large code bases and identify potential vulnerabilities that missed by any existing static software analysis tools. In addition, our attention-based bidirectional long short-term memory framework adaptively localise regions of code illustrating where the possible vulnerable code fragment exists. The highlighted region may provide informative guidance to human developers or security experts. The experimental results demonstrate the feasibility of the proposed approach in the problem of software vulnerability discovery.\",\n    isbn = \"978-3-030-30490-4\"\n}\n\n",
    "abstract": "Vulnerability discovery in software is an important task in the field of computer security. As vulnerabilities can be abused to enable cyber criminals and other malicious actors to exploit systems, it is crucial to keep software as free from vulnerabilities as is possible. Traditional approaches often comprise code scanning tasks to find specific and already-known classes of cyber vulnerabilities. However these approaches do not in general discover new classes of vulnerabilities. In this paper, we leverage a machine learning approach to model source code representation using syntax, semantics and control flow of source code and to infer vulnerable code patterns to tackle large code bases and identify potential vulnerabilities that missed by any existing static software analysis tools. In addition, our attention-based bidirectional long short-term memory framework adaptively localise regions of code illustrating where the possible vulnerable code fragment exists. The highlighted region may provide informative guidance to human developers or security experts. The experimental results demonstrate the feasibility of the proposed approach in the problem of software vulnerability discovery."
}, {
    "py/object": "data.DataClassPaper",
    "Title": "Towards predictive analysis of android vulnerability using statistical codes and machine learning for IoT applications",
    "year": 2020,
    "ML_Techniques": "KNN, LR, RF, DT, SVM, GDBT",
    "Category": "Vulnerability analysis",
    "Sub_category": ",risk level prediction",
    "Venue": "CC",
    "Link": "https://www.sciencedirect.com/science/article/abs/pii/S0140366420300049",
    "bibtex": "article{Cui2020_60,\n    author = \"Cui, Jianfeng and Wang, Lixin and Zhao, Xin and Zhang, Hongyi\",\n    title = \"Towards predictive analysis of android vulnerability using statistical codes and machine learning for IoT applications\",\n    journal = \"Computer Communications\",\n    volume = \"155\",\n    pages = \"125 - 131\",\n    year = \"2020\",\n    issn = \"0140-3664\",\n    doi = \"https://doi.org/10.1016/j.comcom.2020.02.078\",\n    url = \"http://www.sciencedirect.com/science/article/pii/S0140366420300049\",\n    keywords = \"Android vulnerability, Prediction, IoT applications, Software metrics, Machine learning\",\n    abstract = \"Recently, the Internet of Things (IoT) technology is used for several applications for exchanging information among various devices. The intelligent IoT based system utilizes an Android operating system because it is also primarily used in mobile devices. One of the main problems for different IoT applications is associated with android vulnerability is its complicated and large size. To overcome the main issue of IoT, the existing studies have proposed several effective prediction models using machine learning algorithms and software metrics. In this paper, we are focused on conducting android vulnerability prediction analysis using machine learning for intelligent IoT applications. We conducted an empirical investigation for examining security risk prediction of 1406 Android applications with varying levels of risk using a metric set of 21 static code metrics and 6 machine learning (ML) techniques. It is observed from results that ML algorithms have different performances for predicting security risks. RF algorithm performs better for Android applications of all risk levels. By analyzing the findings of the conducted empirical study, it is suggested that developers may consider object-oriented metrics and RF algorithm in the software development process for android based intelligent IoT systems.\"\n}\n\n",
    "abstract": "Recently, the Internet of Things (IoT) technology is used for several applications for exchanging information among various devices. The intelligent IoT based system utilizes an Android operating system because it is also primarily used in mobile devices. One of the main problems for different IoT applications is associated with android vulnerability is its complicated and large size. To overcome the main issue of IoT, the existing studies have proposed several effective prediction models using machine learning algorithms and software metrics. In this paper, we are focused on conducting android vulnerability prediction analysis using machine learning for intelligent IoT applications. We conducted an empirical investigation for examining security risk prediction of 1406 Android applications with varying levels of risk using a metric set of 21 static code metrics and 6 machine learning (ML) techniques. It is observed from results that ML algorithms have different performances for predicting security risks. RF algorithm performs better for Android applications of all risk levels. By analyzing the findings of the conducted empirical study, it is suggested that developers may consider object-oriented metrics and RF algorithm in the software development process for android based intelligent IoT systems."
}, {
    "py/object": "data.DataClassPaper",
    "Title": "VCCFinder: Finding Potential Vulnerabilities in Open-Source Projects to Assist Code Audits",
    "year": 2015,
    "ML_Techniques": "SVM",
    "Category": "Vulnerability analysis",
    "Sub_category": ",commit level",
    "Venue": "CCS",
    "Link": "https://dl.acm.org/doi/10.1145/2810103.2813604",
    "bibtex": "inproceedings{Perl2015_61,\n    author = \"Perl, Henning and Dechand, Sergej and Smith, Matthew and Arp, Daniel and Yamaguchi, Fabian and Rieck, Konrad and Fahl, Sascha and Acar, Yasemin\",\n    title = \"VCCFinder: Finding Potential Vulnerabilities in Open-Source Projects to Assist Code Audits\",\n    year = \"2015\",\n    isbn = \"9781450338325\",\n    publisher = \"Association for Computing Machinery\",\n    address = \"New York, NY, USA\",\n    url = \"https://doi.org/10.1145/2810103.2813604\",\n    doi = \"10.1145/2810103.2813604\",\n    abstract = \"Despite the security community's best effort, the number of serious vulnerabilities discovered in software is increasing rapidly. In theory, security audits should find and remove the vulnerabilities before the code ever gets deployed. However, due to the enormous amount of code being produced, as well as a the lack of manpower and expertise, not all code is sufficiently audited. Thus, many vulnerabilities slip into production systems. A best-practice approach is to use a code metric analysis tool, such as Flawfinder, to flag potentially dangerous code so that it can receive special attention. However, because these tools have a very high false-positive rate, the manual effort needed to find vulnerabilities remains overwhelming. In this paper, we present a new method of finding potentially dangerous code in code repositories with a significantly lower false-positive rate than comparable systems. We combine code-metric analysis with metadata gathered from code repositories to help code review teams prioritize their work. The paper makes three contributions. First, we conducted the first large-scale mapping of CVEs to GitHub commits in order to create a vulnerable commit database. Second, based on this database, we trained a SVM classifier to flag suspicious commits. Compared to Flawfinder, our approach reduces the amount of false alarms by over 99 \\% at the same level of recall. Finally, we present a thorough quantitative and qualitative analysis of our approach and discuss lessons learned from the results. We will share the database as a benchmark for future research and will also provide our analysis tool as a web service.\",\n    booktitle = \"Proceedings of the 22nd ACM SIGSAC Conference on Computer and Communications Security\",\n    pages = \"426\u2013437\",\n    numpages = \"12\",\n    keywords = \"vulnerabilities, machine learning, static analysis\",\n    location = \"Denver, Colorado, USA\",\n    series = \"CCS '15\"\n}\n\n",
    "abstract": "Despite the security community's best effort, the number of serious vulnerabilities discovered in software is increasing rapidly. In theory, security audits should find and remove the vulnerabilities before the code ever gets deployed. However, due to the enormous amount of code being produced, as well as a the lack of manpower and expertise, not all code is sufficiently audited. Thus, many vulnerabilities slip into production systems. A best-practice approach is to use a code metric analysis tool, such as Flawfinder, to flag potentially dangerous code so that it can receive special attention. However, because these tools have a very high false-positive rate, the manual effort needed to find vulnerabilities remains overwhelming. In this paper, we present a new method of finding potentially dangerous code in code repositories with a significantly lower false-positive rate than comparable systems. We combine code-metric analysis with metadata gathered from code repositories to help code review teams prioritize their work. The paper makes three contributions. First, we conducted the first large-scale mapping of CVEs to GitHub commits in order to create a vulnerable commit database. Second, based on this database, we trained a SVM classifier to flag suspicious commits. Compared to Flawfinder, our approach reduces the amount of false alarms by over 99 % at the same level of recall. Finally, we present a thorough quantitative and qualitative analysis of our approach and discuss lessons learned from the results. We will share the database as a benchmark for future research and will also provide our analysis tool as a web service."
}, {
    "py/object": "data.DataClassPaper",
    "Title": "Vulnerability Prediction From Source Code Using Machine Learning",
    "year": 2020,
    "ML_Techniques": "CNN",
    "Category": "Vulnerability analysis",
    "Sub_category": "",
    "Venue": "IEEE Access",
    "Link": "https://ieeexplore.ieee.org/abstract/document/9167194",
    "bibtex": "ARTICLE{Bilgin2020_63,\n    author = \"{Bilgin}, Z. and {Ersoy}, M. A. and {Soykan}, E. U. and {Tomur}, E. and {\u00c7omak}, P. and {Kara\u00e7ay}, L.\",\n    journal = \"IEEE Access\",\n    title = \"Vulnerability Prediction From Source Code Using Machine Learning\",\n    year = \"2020\",\n    volume = \"8\",\n    number = \"\",\n    pages = \"150672-150684\",\n    doi = \"10.1109/ACCESS.2020.3016774\"\n}\n\n",
    "abstract": "As the role of information and communication technologies gradually increases in our lives, software security becomes a major issue to provide protection against malicious attempts and to avoid ending up with noncompensable damages to the system. With the advent of data-driven techniques, there is now a growing interest in how to leverage machine learning (ML) as a software assurance method to build trustworthy software systems. In this study, we examine how to predict software vulnerabilities from source code by employing ML prior to their release. To this end, we develop a source code representation method that enables us to perform intelligent analysis on the Abstract Syntax Tree (AST) form of source code and then investigate whether ML can distinguish vulnerable and nonvulnerable code fragments. To make a comprehensive performance evaluation, we use a public dataset that contains a large amount of function-level real source code parts mined from open-source projects and carefully labeled according to the type of vulnerability if they have any.We show the effectiveness of our proposed method for vulnerability prediction from source code by carrying out exhaustive and realistic experiments under different regimes in comparison with state-of-art methods.\n"
}, {
    "py/object": "data.DataClassPaper",
    "Title": "Web Application Vulnerability Prediction Using Hybrid Program Analysis and Machine Learning",
    "year": 2015,
    "ML_Techniques": "RF, LR, CoForest-RF",
    "Category": "Vulnerability analysis",
    "Sub_category": ",Input validation",
    "Venue": "TDSC",
    "Link": "https://ieeexplore.ieee.org/abstract/document/6963442",
    "bibtex": "ARTICLE{Shar2015_64,\n    author = \"{Shar}, L. K. and {Briand}, L. C. and {Tan}, H. B. K.\",\n    journal = \"IEEE Transactions on Dependable and Secure Computing\",\n    title = \"Web Application Vulnerability Prediction Using Hybrid Program Analysis and Machine Learning\",\n    year = \"2015\",\n    volume = \"12\",\n    number = \"6\",\n    pages = \"688-707\",\n    doi = \"10.1109/TDSC.2014.2373377\"\n}\n\n",
    "abstract": "Due to limited time and resources, web software engineers need support in identifying vulnerable code. A practical approach to predicting vulnerable code would enable them to prioritize security auditing efforts. In this paper, we propose using a set of hybrid (static+dynamic) code attributes that characterize input validation and input sanitization code patterns and are expected to be significant indicators of web application vulnerabilities. Because static and dynamic program analyses complement each other, both techniques are used to extract the proposed attributes in an accurate and scalable way. Current vulnerability prediction techniques rely on the availability of data labeled with vulnerability information for training. For many real world applications, past vulnerability data is often not available or at least not complete. Hence, to address both situations where labeled past data is fully available or not, we apply both supervised and semi-supervised learning when building vulnerability predictors based on hybrid code attributes. Given that semi-supervised learning is entirely unexplored in this domain, we describe how to use this learning scheme effectively for vulnerability prediction. We performed empirical case studies on seven open source projects where we built and evaluated supervised and semi-supervised models. When cross validated with fully available labeled data, the supervised models achieve an average of 77 percent recall and 5 percent probability of false alarm for predicting SQL injection, cross site scripting, remote code execution and file inclusion vulnerabilities. With a low amount of labeled data, when compared to the supervised model, the semi-supervised model showed an average improvement of 24 percent higher recall and 3 percent lower probability of false alarm, thus suggesting semi-supervised learning may be a preferable solution for many real world applications where vulnerability data is missing."
}, {
    "py/object": "data.DataClassPaper",
    "Title": "A Comparative Analysis for Machine Learning based Software Defect Prediction Systems",
    "year": 2020,
    "ML_Techniques": "DT, NB, KNN, SVM, RF, AB, GB, B, MLP",
    "Category": "Testing",
    "Sub_category": "Defect prediction",
    "Venue": "ICCCNT",
    "Link": "https://ieeexplore.ieee.org/document/9225352",
    "bibtex": "INPROCEEDINGS{Cetiner2020_65,\n    author = \"{Cetiner}, M. and {Sahingoz}, O. K.\",\n    booktitle = \"2020 11th International Conference on Computing, Communication and Networking Technologies (ICCCNT)\",\n    title = \"A Comparative Analysis for Machine Learning based Software Defect Prediction Systems\",\n    year = \"2020\",\n    volume = \"\",\n    number = \"\",\n    pages = \"1-7\",\n    doi = \"10.1109/ICCCNT49239.2020.9225352\"\n}\n\n",
    "abstract": "In the Software Engineering concept, the prediction of the software defects plays a vital role in increasing the quality of the software systems, which is one of the most critical and expensive phases of the software development lifecycle. While the use of software systems is increasing in our daily lives, their dependencies and complexities are also increasing, and this results in a suitable environment for defects. Due to the existence of software defects, the software produces incorrect results and behaviors. What is more critical than defects, is finding them before they occur. Therefore detection (and also prediction) of the software defects enables the managers of the software to make an efficient allocation of the resources for the maintenance and testing phases. In the literature, there are different proposals for the prediction of software defects. In this paper, we made a comparative analysis about the machine learning-based software defect prediction systems by comparing 10 learning algorithms like Decision Tree, Naive Bayes, K-Nearest Neighbor, Support Vector Machine, Random Forest, Extra Trees, Adaboost, Gradient Boosting, Bagging, and Multi-Layer Perceptron, on the public datasets CM1, KC1, KC2, JM1, and PC1 from the PROMISE warehouse. The experimental results showed that proposed models result in proper accuracy levels for software defect prediction to increase the quality of the software."
}, {
    "py/object": "data.DataClassPaper",
    "Title": "A Machine Learning Approach for Statistical Software Testing \u2217",
    "year": 2007,
    "ML_Techniques": "",
    "Category": "Testing",
    "Sub_category": ",Effort prediction",
    "Venue": "IJCAI",
    "Link": "https://www.aaai.org/Papers/IJCAI/2007/IJCAI07-366.pdf",
    "bibtex": "INPROCEEDINGS{Cetiner2020_65,\n    author = \"{Cetiner}, M. and {Sahingoz}, O. K.\",\n    booktitle = \"2020 11th International Conference on Computing, Communication and Networking Technologies (ICCCNT)\",\n    title = \"A Comparative Analysis for Machine Learning based Software Defect Prediction Systems\",\n    year = \"2020\",\n    volume = \"\",\n    number = \"\",\n    pages = \"1-7\",\n    doi = \"10.1109/ICCCNT49239.2020.9225352\"\n}\n\n",
    "abstract": "Some Statistical Software Testing approaches rely\non sampling the feasible paths in the control flow\ngraph of the program; the difficulty comes from the\ntiny ratio of feasible paths. This paper presents an\nadaptive sampling mechanism called EXIST for Exploration/eXploitation Inference for Software Testing, able to retrieve distinct feasible paths with high\nprobability. EXIST proceeds by alternatively exploiting and updating a distribution on the set of\nprogram paths. An original representation of paths,\naccommodating long-range dependencies and data\nsparsity and based on extended Parikh maps, is proposed. Experimental validation on real-world and\nartificial problems demonstrates dramatic improvements compared to the state of the art."
}, {
    "py/object": "data.DataClassPaper",
    "Title": "A machine learning approach to generate test oracles",
    "year": 2018,
    "ML_Techniques": "AB",
    "Category": "Testing",
    "Sub_category": "Test data/case generation",
    "Venue": "SBES",
    "Link": "https://dl.acm.org/doi/abs/10.1145/3266237.3266273",
    "bibtex": "INPROCEEDINGS{Cetiner2020_65,\n    author = \"{Cetiner}, M. and {Sahingoz}, O. K.\",\n    booktitle = \"2020 11th International Conference on Computing, Communication and Networking Technologies (ICCCNT)\",\n    title = \"A Comparative Analysis for Machine Learning based Software Defect Prediction Systems\",\n    year = \"2020\",\n    volume = \"\",\n    number = \"\",\n    pages = \"1-7\",\n    doi = \"10.1109/ICCCNT49239.2020.9225352\"\n}\n\n",
    "abstract": "One of the essential activities for quality assurance in software development is the software testing. Studies report that Software Testing is one of the most costly activities in the development process, can reach up to 50 percent of its total cost. One of the great challenges of conducting software testing is related to the automation of a mechanism known as \"test oracle\". This work presents an approach based on machine learning (ML) for automation of the test oracle mechanism in software. The approach uses historical usage data from an application captured by inserting a capture component into the application under test. These data go through a Knowledge Discovery in Database step and are then used for training to generate an oracle suitable for the application under test. Four experiments were executed with web applications to evaluate the proposed approach. The first and second experiments were performed with a fictitious application, with faults inserted randomly in the first experiment, inserted by a developer in the second one and inserted by mutation tests in third one. The fourth experiment was carried out with a large real application in order to assure the results of the preliminary experiments. The experiments presented indications of the suitability of the approach to the solution of the problem."
}, {
    "py/object": "data.DataClassPaper",
    "Title": "A systematic review of machine learning techniques for software fault prediction",
    "year": 2015,
    "ML_Techniques": "",
    "Category": "Testing",
    "Sub_category": "Defect prediction",
    "Venue": "ASC",
    "Link": "https://www.sciencedirect.com/science/article/abs/pii/S1568494614005857",
    "bibtex": "article{Malhotra2015_69,\n    author = \"Malhotra, Ruchika\",\n    title = \"A systematic review of machine learning techniques for software fault prediction\",\n    journal = \"Applied Soft Computing\",\n    volume = \"27\",\n    pages = \"504 - 518\",\n    year = \"2015\",\n    issn = \"1568-4946\",\n    doi = \"https://doi.org/10.1016/j.asoc.2014.11.023\",\n    url = \"http://www.sciencedirect.com/science/article/pii/S1568494614005857\",\n    keywords = \"Machine learning, Software fault proneness, Systematic literature review\",\n    abstract = \"Background Software fault prediction is the process of developing models that can be used by the software practitioners in the early phases of software development life cycle for detecting faulty constructs such as modules or classes. There are various machine learning techniques used in the past for predicting faults. Method In this study we perform a systematic review of studies from January 1991 to October 2013 in the literature that use the machine learning techniques for software fault prediction. We assess the performance capability of the machine learning techniques in existing research for software fault prediction. We also compare the performance of the machine learning techniques with the statistical techniques and other machine learning techniques. Further the strengths and weaknesses of machine learning techniques are summarized. Results In this paper we have identified 64 primary studies and seven categories of the machine learning techniques. The results prove the prediction capability of the machine learning techniques for classifying module/class as fault prone or not fault prone. The models using the machine learning techniques for estimating software fault proneness outperform the traditional statistical models. Conclusion Based on the results obtained from the systematic review, we conclude that the machine learning techniques have the ability for predicting software fault proneness and can be used by software practitioners and researchers. However, the application of the machine learning techniques in software fault prediction is still limited and more number of studies should be carried out in order to obtain well formed and generalizable results. We provide future guidelines to practitioners and researchers based on the results obtained in this work.\"\n}\n\n",
    "abstract": "Background\nSoftware fault prediction is the process of developing models that can be used by the software practitioners in the early phases of software development life cycle for detecting faulty constructs such as modules or classes. There are various machine learning techniques used in the past for predicting faults.\n\nMethod\nIn this study we perform a systematic review of studies from January 1991 to October 2013 in the literature that use the machine learning techniques for software fault prediction. We assess the performance capability of the machine learning techniques in existing research for software fault prediction. We also compare the performance of the machine learning techniques with the statistical techniques and other machine learning techniques. Further the strengths and weaknesses of machine learning techniques are summarized.\n\nResults\nIn this paper we have identified 64 primary studies and seven categories of the machine learning techniques. The results prove the prediction capability of the machine learning techniques for classifying module/class as fault prone or not fault prone. The models using the machine learning techniques for estimating software fault proneness outperform the traditional statistical models.\n\nConclusion\nBased on the results obtained from the systematic review, we conclude that the machine learning techniques have the ability for predicting software fault proneness and can be used by software practitioners and researchers. However, the application of the machine learning techniques in software fault prediction is still limited and more number of studies should be carried out in order to obtain well formed and generalizable results. We provide future guidelines to practitioners and researchers based on the results obtained in this work."
}, {
    "py/object": "data.DataClassPaper",
    "Title": "An empirical study of software entropy based bug prediction using machine learning",
    "year": 2017,
    "ML_Techniques": "GEP, RGNN, SVR, LMSR",
    "Category": "Testing",
    "Sub_category": "Defect prediction",
    "Venue": "IJSAEM",
    "Link": "https://link.springer.com/article/10.1007/s13198-016-0479-2",
    "bibtex": "article{Kaur2017_71,\n    author = \"Kaur, Arvinder and Kaur, Kamaldeep and Chopra, Deepti\",\n    title = \"An empirical study of software entropy based bug prediction using machine learning\",\n    volume = \"8\",\n    issn = \"0976-4348\",\n    url = \"https://doi.org/10.1007/s13198-016-0479-2\",\n    doi = \"10.1007/s13198-016-0479-2\",\n    abstract = \"There are many approaches for predicting bugs in software systems. A popular approach for bug prediction is using entropy of changes as proposed by Hassan (2009). This paper uses the metrics derived using entropy of changes to compare five machine learning techniques, namely Gene Expression Programming (GEP), General Regression Neural Network, Locally Weighted Regression, Support Vector Regression (SVR) and Least Median Square Regression for predicting bugs. Four software subsystems: mozilla/layout/generic, mozilla/layout/forms, apache/httpd/modules/ssl and apache/httpd/modules/mappers are used for the validation purpose. The data extraction for the validation purpose is automated by developing an algorithm that employs web scraping and regular expressions. The study suggests GEP and SVR as stable regression techniques for bug prediction using entropy of changes.\",\n    language = \"en\",\n    number = \"2\",\n    urldate = \"2021-01-01\",\n    journal = \"International Journal of System Assurance Engineering and Management\",\n    month = \"November\",\n    year = \"2017\",\n    pages = \"599--616\"\n}\n\n",
    "abstract": "There are many approaches for predicting bugs in software systems. A popular approach for bug prediction is using entropy of changes as proposed by Hassan (2009). This paper uses the metrics derived using entropy of changes to compare five machine learning techniques, namely Gene Expression Programming (GEP), General Regression Neural Network, Locally Weighted Regression, Support Vector Regression (SVR) and Least Median Square Regression for predicting bugs. Four software subsystems: mozilla/layout/generic, mozilla/layout/forms, apache/httpd/modules/ssl and apache/httpd/modules/mappers are used for the validation purpose. The data extraction for the validation purpose is automated by developing an algorithm that employs web scraping and regular expressions. The study suggests GEP and SVR as stable regression techniques for bug prediction using entropy of changes."
}, {
    "py/object": "data.DataClassPaper",
    "Title": "AppFlow: using machine learning to synthesize robust, reusable UI tests",
    "year": 2018,
    "ML_Techniques": "SVM",
    "Category": "Testing",
    "Sub_category": ",Test data/case generation",
    "Venue": "FSE",
    "Link": "https://dl.acm.org/doi/10.1145/3236024.3236055",
    "bibtex": "article{Kaur2017_71,\n    author = \"Kaur, Arvinder and Kaur, Kamaldeep and Chopra, Deepti\",\n    title = \"An empirical study of software entropy based bug prediction using machine learning\",\n    volume = \"8\",\n    issn = \"0976-4348\",\n    url = \"https://doi.org/10.1007/s13198-016-0479-2\",\n    doi = \"10.1007/s13198-016-0479-2\",\n    abstract = \"There are many approaches for predicting bugs in software systems. A popular approach for bug prediction is using entropy of changes as proposed by Hassan (2009). This paper uses the metrics derived using entropy of changes to compare five machine learning techniques, namely Gene Expression Programming (GEP), General Regression Neural Network, Locally Weighted Regression, Support Vector Regression (SVR) and Least Median Square Regression for predicting bugs. Four software subsystems: mozilla/layout/generic, mozilla/layout/forms, apache/httpd/modules/ssl and apache/httpd/modules/mappers are used for the validation purpose. The data extraction for the validation purpose is automated by developing an algorithm that employs web scraping and regular expressions. The study suggests GEP and SVR as stable regression techniques for bug prediction using entropy of changes.\",\n    language = \"en\",\n    number = \"2\",\n    urldate = \"2021-01-01\",\n    journal = \"International Journal of System Assurance Engineering and Management\",\n    month = \"November\",\n    year = \"2017\",\n    pages = \"599--616\"\n}\n\n",
    "abstract": "UI testing is known to be difficult, especially as today\u2019s development cycles become faster. Manual UI testing is tedious, costly and error- prone. Automated UI tests are costly to write and maintain. This paper presents AppFlow, a system for synthesizing highly robust, highly reusable UI tests. It leverages machine learning to automatically recognize common screens and widgets, relieving developers from writing ad hoc, fragile logic to use them in tests. It enables developers to write a library of modular tests for the main functionality of an app category (e.g., an \u201cadd to cart\u201d test for shopping apps). It can then quickly test a new app in the same category by synthesizing full tests from the modular ones in the library. By focusing on the main functionality, AppFlow provides \u201csmoke testing\u201d requiring little manual work. Optionally, developers can customize AppFlow by adding app-specific tests for completeness. We evaluated AppFlow on 60 popular apps in the shopping and the news category, two case studies on the BBC news app and the JackThreads shopping app, and a user-study of 15 subjects on the Wish shopping app. Results show that AppFlow accurately recognizes screens and widgets, synthesizes highly robust and reusable tests, covers 46.6% of all automatable tests for Jackthreads with the tests it synthesizes, and reduces the effort to test a new app by up to 90%. Interestingly, it found eight bugs in the evaluated apps, including seven functionality bugs, despite that they were publicly released and supposedly went through thorough testing."
}, {
    "py/object": "data.DataClassPaper",
    "Title": "Applying machine learning to software fault-proneness prediction",
    "year": 2008,
    "ML_Techniques": "SVM, ANN",
    "Category": "Testing",
    "Sub_category": "Defect prediction",
    "Venue": "JSS",
    "Link": "https://www.sciencedirect.com/science/article/abs/pii/S0164121207001240",
    "bibtex": "article{Gondra2008_73,\n    author = \"Gondra, Iker\",\n    title = \"Applying machine learning to software fault-proneness prediction\",\n    journal = \"Journal of Systems and Software\",\n    volume = \"81\",\n    number = \"2\",\n    pages = \"186 - 195\",\n    year = \"2008\",\n    note = \"Model-Based Software Testing\",\n    issn = \"0164-1212\",\n    doi = \"https://doi.org/10.1016/j.jss.2007.05.035\",\n    url = \"http://www.sciencedirect.com/science/article/pii/S0164121207001240\",\n    keywords = \"Software testing, Software metrics, Fault-proneness, Machine learning, Neural network, Sensitivity analysis, Support vector machine\",\n    abstract = \"The importance of software testing to quality assurance cannot be overemphasized. The estimation of a module\u2019s fault-proneness is important for minimizing cost and improving the effectiveness of the software testing process. Unfortunately, no general technique for estimating software fault-proneness is available. The observed correlation between some software metrics and fault-proneness has resulted in a variety of predictive models based on multiple metrics. Much work has concentrated on how to select the software metrics that are most likely to indicate fault-proneness. In this paper, we propose the use of machine learning for this purpose. Specifically, given historical data on software metric values and number of reported errors, an Artificial Neural Network (ANN) is trained. Then, in order to determine the importance of each software metric in predicting fault-proneness, a sensitivity analysis is performed on the trained ANN. The software metrics that are deemed to be the most critical are then used as the basis of an ANN-based predictive model of a continuous measure of fault-proneness. We also view fault-proneness prediction as a binary classification task (i.e., a module can either contain errors or be error-free) and use Support Vector Machines (SVM) as a state-of-the-art classification method. We perform a comparative experimental study of the effectiveness of ANNs and SVMs on a data set obtained from NASA\u2019s Metrics Data Program data repository.\"\n}\n\n",
    "abstract": "The importance of software testing to quality assurance cannot be overemphasized. The estimation of a module\u2019s fault-proneness is important for minimizing cost and improving the effectiveness of the software testing process. Unfortunately, no general technique for estimating software fault-proneness is available. The observed correlation between some software metrics and fault-proneness has resulted in a variety of predictive models based on multiple metrics. Much work has concentrated on how to select the software metrics that are most likely to indicate fault-proneness. In this paper, we propose the use of machine learning for this purpose. Specifically, given historical data on software metric values and number of reported errors, an Artificial Neural Network (ANN) is trained. Then, in order to determine the importance of each software metric in predicting fault-proneness, a sensitivity analysis is performed on the trained ANN. The software metrics that are deemed to be the most critical are then used as the basis of an ANN-based predictive model of a continuous measure of fault-proneness. We also view fault-proneness prediction as a binary classification task (i.e., a module can either contain errors or be error-free) and use Support Vector Machines (SVM) as a state-of-the-art classification method. We perform a comparative experimental study of the effectiveness of ANNs and SVMs on a data set obtained from NASA\u2019s Metrics Data Program data repository."
}, {
    "py/object": "data.DataClassPaper",
    "Title": "Artificial Intelligence Applied to Software Testing: A Literature Review",
    "year": 2020,
    "ML_Techniques": "",
    "Category": "Testing",
    "Sub_category": "",
    "Venue": "CISTI",
    "Link": "https://ieeexplore.ieee.org/document/9141124",
    "bibtex": "INPROCEEDINGS{Lima2020_74,\n    author = \"{Lima}, R. and {da Cruz}, A. M. R. and {Ribeiro}, J.\",\n    booktitle = \"2020 15th Iberian Conference on Information Systems and Technologies (CISTI)\",\n    title = \"Artificial Intelligence Applied to Software Testing: A Literature Review\",\n    year = \"2020\",\n    volume = \"\",\n    number = \"\",\n    pages = \"1-6\",\n    doi = \"10.23919/CISTI49556.2020.9141124\"\n}\n\n",
    "abstract": "In the last few years Artificial Intelligence (AI) algorithms and Machine Learning (ML) approaches have been successfully applied in real-world scenarios like commerce, industry and digital services, but they are not a widespread reality in Software Testing. Due to the complexity of software testing, most of the work of AI/ML applied to it is still academic. This paper briefly presents the state of the art in the field of software testing, applying ML approaches and AI algorithms. The progress analysis of the AI and ML methods used for this purpose during the last three years is based on the Scopus Elsevier, web of Science and Google Scholar databases. Algorithms used in software testing have been grouped by test types. The paper also tries to create relations between the main AI approaches and which type of tests they are applied to, in particular white-box, grey-box and black-box software testing types. We conclude that black-box testing is, by far, the preferred method of software testing, when AI is applied, and all three methods of ML (supervised, unsupervised and reinforcement) are commonly used in black-box testing being the \u201cclustering\u201d technique, Artificial Neural Networks and Genetic Algorithms applied to \u201cfuzzing\u201d and regression testing."
}, {
    "py/object": "data.DataClassPaper",
    "Title": "Assessment of machine learning algorithms for determining defective classes in an object-oriented software",
    "year": 2017,
    "ML_Techniques": "MLP,  CART, KNN",
    "Category": "Testing",
    "Sub_category": "Defect prediction",
    "Venue": "ICRITO",
    "Link": "https://ieeexplore.ieee.org/document/8342425",
    "bibtex": "INPROCEEDINGS{Singh2017_76,\n    author = \"{Singh}, P. and {Malhotra}, R.\",\n    booktitle = \"2017 6th International Conference on Reliability, Infocom Technologies and Optimization (Trends and Future Directions) (ICRITO)\",\n    title = \"Assessment of machine learning algorithms for determining defective classes in an object-oriented software\",\n    year = \"2017\",\n    volume = \"\",\n    number = \"\",\n    pages = \"204-209\",\n    doi = \"10.1109/ICRITO.2017.8342425\"\n}\n\n",
    "abstract": "Software defect prediction is a well renowned field of software engineering. Determination of defective classes early in the lifecycle of a software product helps software practitioners in effective allocation of resources. More resources are allocated to probable defective classes so that defects can be removed in the initial phases of the software product. Such a practice would lead to a good quality software product. Although, hundreds of defect prediction models have been developed and validated by researchers, there is still a need to develop and evaluate more models to draw generalized conclusions. Literature studies have found Machine Learning (ML) algorithms to be effective classifiers in this domain. Thus, this study evaluates four ML algorithms on data collected from seven open source software projects for developing software defect prediction models. The results indicate superior performance of the Multilayer Perceptron algorithm over all the other investigated algorithms. The results of the study are also statistically evaluated to establish their effectiveness."
}, {
    "py/object": "data.DataClassPaper",
    "Title": "Assessment of software testing time using soft computing techniques",
    "year": 2012,
    "ML_Techniques": "LR, ANN, SVM, DT, FIS, ANFIS",
    "Category": "Testing",
    "Sub_category": "",
    "Venue": "SEN",
    "Link": "https://dl.acm.org/doi/10.1145/2088883.2088895",
    "bibtex": "INPROCEEDINGS{Singh2017_76,\n    author = \"{Singh}, P. and {Malhotra}, R.\",\n    booktitle = \"2017 6th International Conference on Reliability, Infocom Technologies and Optimization (Trends and Future Directions) (ICRITO)\",\n    title = \"Assessment of machine learning algorithms for determining defective classes in an object-oriented software\",\n    year = \"2017\",\n    volume = \"\",\n    number = \"\",\n    pages = \"204-209\",\n    doi = \"10.1109/ICRITO.2017.8342425\"\n}\n\n",
    "abstract": "Application of a soft computing approach in place of traditional statistical techniques has shown a remarkable improvement in reliability prediction. This paper examines and compares Linear Regression (LR) and five machine learning methods: (Artificial Neural Network, Support Vector Machine, Decision Tree, Fuzzy Inference System and Adaptive Neuro-Fuzzy Inference System). These methods are explored empirically to find the effect of severity of errors for the assessment of software testing time. We use two publicly available failure datasets to analyse and compare the regression and machine learning methods for assessing the software testing time. The performance of the proposed model is compared by computing mean absolute error (MAE) and root mean square error (RMSE). Based on the results from rigours experiments, it is observed that model accuracy using FIS and ANFIS method is better and outperformed the model predicted using linear regression and other machine learning methods. Finally, we conclude that Adaptive Neuro-fuzzy Inference System is useful in constructing software quality models having better capability of generalization and less dependent on sample size."
}, {
    "py/object": "data.DataClassPaper",
    "Title": "Automatically learning semantic features for defect prediction",
    "year": 2016,
    "ML_Techniques": "DBN",
    "Category": "Testing",
    "Sub_category": "Defect prediction",
    "Venue": "ICSE",
    "Link": "https://dl.acm.org/doi/10.1145/2884781.2884804",
    "bibtex": "INPROCEEDINGS{Singh2017_76,\n    author = \"{Singh}, P. and {Malhotra}, R.\",\n    booktitle = \"2017 6th International Conference on Reliability, Infocom Technologies and Optimization (Trends and Future Directions) (ICRITO)\",\n    title = \"Assessment of machine learning algorithms for determining defective classes in an object-oriented software\",\n    year = \"2017\",\n    volume = \"\",\n    number = \"\",\n    pages = \"204-209\",\n    doi = \"10.1109/ICRITO.2017.8342425\"\n}\n\n",
    "abstract": "Software defect prediction, which predicts defective code regions, can help developers find bugs and prioritize their testing efforts. To build accurate prediction models, previous studies focus on manually designing features that encode the characteristics of programs and exploring different machine learning algorithms. Existing traditional features often fail to capture the semantic differences of programs, and such a capability is needed for building accurate prediction models. To bridge the gap between programs' semantics and defect prediction features, this paper proposes to leverage a powerful representation-learning algorithm, deep learning, to learn semantic representation of programs automatically from source code. Specifically, we leverage Deep Belief Network (DBN) to automatically learn semantic features from token vectors extracted from programs' Abstract Syntax Trees (ASTs). Our evaluation on ten open source projects shows that our automatically learned semantic features significantly improve both within-project defect prediction (WPDP) and cross-project defect prediction (CPDP) compared to traditional features. Our semantic features improve WPDP on average by 14.7% in precision, 11.5% in recall, and 14.2% in F1. For CPDP, our semantic features based approach outperforms the state-of-the-art technique TCA+ with traditional features by 8.9% in F1."
}, {
    "py/object": "data.DataClassPaper",
    "Title": "Automating Root Cause Analysis via Machine Learning in Agile Software Testing Environments",
    "year": 2019,
    "ML_Techniques": "ANN",
    "Category": "Testing",
    "Sub_category": "",
    "Venue": "ICST",
    "Link": "https://ieeexplore.ieee.org/document/8730163",
    "bibtex": "INPROCEEDINGS{Kahles2019_79,\n    author = \"{Kahles}, J. and {T\u00f6rr\u00f6nen}, J. and {Huuhtanen}, T. and {Jung}, A.\",\n    booktitle = \"2019 12th IEEE Conference on Software Testing, Validation and Verification (ICST)\",\n    title = \"Automating Root Cause Analysis via Machine Learning in Agile Software Testing Environments\",\n    year = \"2019\",\n    volume = \"\",\n    number = \"\",\n    pages = \"379-390\",\n    doi = \"10.1109/ICST.2019.00047\"\n}\n\n",
    "abstract": "We apply machine learning to automate the root cause analysis in agile software testing environments. In particular, we extract relevant features from raw log data after interviewing testing engineers (human experts). Initial efforts are put into clustering the unlabeled data, and despite obtaining weak correlations between several clusters and failure root causes, the vagueness in the rest of the clusters leads to the consideration of labeling. A new round of interviews with the testing engineers leads to the definition of five ground-truth categories. Using manually labeled data, we train artificial neural networks that either classify the data or pre-process it for clustering. The resulting method achieves an accuracy of 88.9%. The methodology of this paper serves as a prototype or baseline approach for the extraction of expert knowledge and its adaptation to machine learning techniques for root cause analysis in agile environments."
}, {
    "py/object": "data.DataClassPaper",
    "Title": "Back-to-Back Testing Framework Using a Machine Learning Method",
    "year": 2012,
    "ML_Techniques": "SVM",
    "Category": "Testing",
    "Sub_category": "Test data/case generation",
    "Venue": "SNPD",
    "Link": "https://link.springer.com/chapter/10.1007/978-3-642-32172-6_3",
    "bibtex": "InProceedings{Takagi2013_80,\n    author = \"Takagi, Tomohiko and Utsumi, Takeshi and Furukawa, Zengo\",\n    editor = \"Lee, Roger\",\n    title = \"Back-to-Back Testing Framework Using a Machine Learning Method\",\n    booktitle = \"Software Engineering, Artificial Intelligence, Networking and Parallel/Distributed Computing 2012\",\n    year = \"2013\",\n    publisher = \"Springer Berlin Heidelberg\",\n    address = \"Berlin, Heidelberg\",\n    pages = \"27--36\",\n    abstract = \"In back-to-back testing of software, expected outputs (test oracles) are generated from software that is similar to SUT (software under test), and are compared with test outputs from the SUT in order to reveal faults. The advantages of back-to-back testing are that one can automatically perform the creation of expected outputs that is one of the most costly processes in software testing, and one can obtain detailed expected outputs that are not limited to a specific aspect, such as state transitions. However, it is not easy to automatically classify the differences between the test outputs and the expected outputs into two groups, that is, one resulting from failures of the SUT and another resulting from intended functional differences between the SUT and the similar software. The manual classification is too costly and back-to-back testing can hardly be applied unless the functions of the similar software are exactly equal to the intended functions of the SUT. To solve this costly classification problem, this paper proposes a novel back-to-back testing framework in which a SVM (support vector machine) classifies them automatically.\",\n    isbn = \"978-3-642-32172-6\"\n}\n\n",
    "abstract": "In back-to-back testing of software, expected outputs (test oracles) are generated from software that is similar to SUT (software under test), and are compared with test outputs from the SUT in order to reveal faults. The advantages of back-to-back testing are that one can automatically perform the creation of expected outputs that is one of the most costly processes in software testing, and one can obtain detailed expected outputs that are not limited to a specific aspect, such as state transitions. However, it is not easy to automatically classify the differences between the test outputs and the expected outputs into two groups, that is, one resulting from failures of the SUT and another resulting from intended functional differences between the SUT and the similar software. The manual classification is too costly and back-to-back testing can hardly be applied unless the functions of the similar software are exactly equal to the intended functions of the SUT. To solve this costly classification problem, this paper proposes a novel back-to-back testing framework in which a SVM (support vector machine) classifies them automatically."
}, {
    "py/object": "data.DataClassPaper",
    "Title": "Comparative analysis of statistical and machine learning methods for predicting faulty modules",
    "year": 2014,
    "ML_Techniques": "DT, ANN, CCN, SVM, GEP",
    "Category": "Testing",
    "Sub_category": "Defect prediction",
    "Venue": "ASC",
    "Link": "https://www.sciencedirect.com/science/article/abs/pii/S1568494614001392",
    "bibtex": "article{Malhotra2014_81,\n    author = \"Malhotra, Ruchika\",\n    title = \"Comparative analysis of statistical and machine learning methods for predicting faulty modules\",\n    journal = \"Applied Soft Computing\",\n    volume = \"21\",\n    pages = \"286 - 297\",\n    year = \"2014\",\n    issn = \"1568-4946\",\n    doi = \"https://doi.org/10.1016/j.asoc.2014.03.032\",\n    url = \"http://www.sciencedirect.com/science/article/pii/S1568494614001392\",\n    keywords = \"Software quality, Static code metrics, Logistic regression, Machine learning, Receiver Operating Characteristic (ROC) curve\",\n    abstract = \"The demand for development of good quality software has seen rapid growth in the last few years. This is leading to increase in the use of the machine learning methods for analyzing and assessing public domain data sets. These methods can be used in developing models for estimating software quality attributes such as fault proneness, maintenance effort, testing effort. Software fault prediction in the early phases of software development can help and guide software practitioners to focus the available testing resources on the weaker areas during the software development. This paper analyses and compares the statistical and six machine learning methods for fault prediction. These methods (Decision Tree, Artificial Neural Network, Cascade Correlation Network, Support Vector Machine, Group Method of Data Handling Method, and Gene Expression Programming) are empirically validated to find the relationship between the static code metrics and the fault proneness of a module. In order to assess and compare the models predicted using the regression and the machine learning methods we used two publicly available data sets AR1 and AR6. We compared the predictive capability of the models using the Area Under the Curve (measured from the Receiver Operating Characteristic (ROC) analysis). The study confirms the predictive capability of the machine learning methods for software fault prediction. The results show that the Area Under the Curve of model predicted using the Decision Tree method is 0.8 and 0.9 (for AR1 and AR6 data sets, respectively) and is a better model than the model predicted using the logistic regression and other machine learning methods.\"\n}\n\n",
    "abstract": "The demand for development of good quality software has seen rapid growth in the last few years. This is leading to increase in the use of the machine learning methods for analyzing and assessing public domain data sets. These methods can be used in developing models for estimating software quality attributes such as fault proneness, maintenance effort, testing effort. Software fault prediction in the early phases of software development can help and guide software practitioners to focus the available testing resources on the weaker areas during the software development. This paper analyses and compares the statistical and six machine learning methods for fault prediction. These methods (Decision Tree, Artificial Neural Network, Cascade Correlation Network, Support Vector Machine, Group Method of Data Handling Method, and Gene Expression Programming) are empirically validated to find the relationship between the static code metrics and the fault proneness of a module. In order to assess and compare the models predicted using the regression and the machine learning methods we used two publicly available data sets AR1 and AR6. We compared the predictive capability of the models using the Area Under the Curve (measured from the Receiver Operating Characteristic (ROC) analysis). The study confirms the predictive capability of the machine learning methods for software fault prediction. The results show that the Area Under the Curve of model predicted using the Decision Tree method is 0.8 and 0.9 (for AR1 and AR6 data sets, respectively) and is a better model than the model predicted using the logistic regression and other machine learning methods."
}, {
    "py/object": "data.DataClassPaper",
    "Title": "Cross-Project Software Fault Prediction Using Data Leveraging Technique to Improve Software Quality",
    "year": 2020,
    "ML_Techniques": "LLR",
    "Category": "Testing",
    "Sub_category": "Defect prediction",
    "Venue": "EASE",
    "Link": "https://dl.acm.org/doi/10.1145/3383219.3383281",
    "bibtex": "inproceedings{Khan2020_82,\n    author = \"Khan, Bilal and Iqbal, Danish and Badshah, Sher\",\n    title = \"Cross-Project Software Fault Prediction Using Data Leveraging Technique to Improve Software Quality\",\n    year = \"2020\",\n    isbn = \"9781450377317\",\n    publisher = \"Association for Computing Machinery\",\n    address = \"New York, NY, USA\",\n    url = \"https://doi.org/10.1145/3383219.3383281\",\n    doi = \"10.1145/3383219.3383281\",\n    abstract = \"Software fault prediction is a process to detect bugs in software projects. Fault prediction in software engineering has attracted much attention from the last decade. The early prognostication of faults in software minimize the cost and effort of errors that come at later stages. Different machine learning techniques have been utilized for fault prediction, that is proven to be utilizable. Despite, the significance of fault prediction most of the companies do not consider fault prediction in practice and do not build useful models due to lack of data or lack of enough data to strengthen the power of fault predictors. However, models trained and tested on less amount of data are difficult to generalize, because they do not consider project size, project differences, and features selection. To overcome these issues, we proposed an instance-based transfer learning through data leveraging using logistic linear regression as a base proposed statistical methodology. In our study, we considered three software projects within the same domain. Finally, we performed a comparative analysis of three different experiments for building models (targeted project). The experimental results of the proposed approach show promising improvements in (SFP).\",\n    booktitle = \"Proceedings of the Evaluation and Assessment in Software Engineering\",\n    pages = \"434\u2013438\",\n    numpages = \"5\",\n    keywords = \"Instance-based learning, Software Quality, data leveraging, Cross-project, Software fault prediction, Machine learning\",\n    location = \"Trondheim, Norway\",\n    series = \"EASE '20\"\n}\n\n",
    "abstract": "Software fault prediction is a process to detect bugs in software projects. Fault prediction in software engineering has attracted much attention from the last decade. The early prognostication of faults in software minimize the cost and effort of errors that come at later stages. Different machine learning techniques have been utilized for fault prediction, that is proven to be utilizable. Despite, the significance of fault prediction most of the companies do not consider fault prediction in practice and do not build useful models due to lack of data or lack of enough data to strengthen the power of fault predictors. However, models trained and tested on less amount of data are difficult to generalize, because they do not consider project size, project differences, and features selection. To overcome these issues, we proposed an instance-based transfer learning through data leveraging using logistic linear regression as a base proposed statistical methodology. In our study, we considered three software projects within the same domain. Finally, we performed a comparative analysis of three different experiments for building models (targeted project). The experimental results of the proposed approach show promising improvements in (SFP)."
}, {
    "py/object": "data.DataClassPaper",
    "Title": "Deep Learning for Software Defect Prediction: A Survey",
    "year": 2020,
    "ML_Techniques": "",
    "Category": "Testing",
    "Sub_category": "Defect prediction",
    "Venue": "ICSE",
    "Link": "https://dl.acm.org/doi/10.1145/3387940.3391463",
    "bibtex": "inproceedings{Omri2020_83,\n    author = \"Omri, Safa and Sinz, Carsten\",\n    title = \"Deep Learning for Software Defect Prediction: A Survey\",\n    year = \"2020\",\n    isbn = \"9781450379632\",\n    publisher = \"Association for Computing Machinery\",\n    address = \"New York, NY, USA\",\n    url = \"https://doi.org/10.1145/3387940.3391463\",\n    doi = \"10.1145/3387940.3391463\",\n    abstract = \"Software fault prediction is an important and beneficial practice for improving software quality and reliability. The ability to predict which components in a large software system are most likely to contain the largest numbers of faults in the next release helps to better manage projects, including early estimation of possible release delays, and affordably guide corrective actions to improve the quality of the software. However, developing robust fault prediction models is a challenging task and many techniques have been proposed in the literature. Traditional software fault prediction studies mainly focus on manually designing features (e.g. complexity metrics), which are input into machine learning classifiers to identify defective code. However, these features often fail to capture the semantic and structural information of programs. Such information is needed for building accurate fault prediction models. In this survey, we discuss various approaches in fault prediction, also explaining how in recent studies deep learning algorithms for fault prediction help to bridge the gap between programs' semantics and fault prediction features and make accurate predictions.\",\n    booktitle = \"Proceedings of the IEEE/ACM 42nd International Conference on Software Engineering Workshops\",\n    pages = \"209\u2013214\",\n    numpages = \"6\",\n    keywords = \"software defect prediction, deep learning, machine learning, software testing, software quality assurance\",\n    location = \"Seoul, Republic of Korea\",\n    series = \"ICSEW'20\"\n}\n\n",
    "abstract": "Software fault prediction is an important and beneficial practice for improving software quality and reliability. The ability to predict which components in a large software system are most likely to contain the largest numbers of faults in the next release helps to better manage projects, including early estimation of possible release delays, and affordably guide corrective actions to improve the quality of the software. However, developing robust fault prediction models is a challenging task and many techniques have been proposed in the literature. Traditional software fault prediction studies mainly focus on manually designing features (e.g. complexity metrics), which are input into machine learning classifiers to identify defective code. However, these features often fail to capture the semantic and structural information of programs. Such information is needed for building accurate fault prediction models. In this survey, we discuss various approaches in fault prediction, also explaining how in recent studies deep learning algorithms for fault prediction help to bridge the gap between programs' semantics and fault prediction features and make accurate predictions."
}, {
    "py/object": "data.DataClassPaper",
    "Title": "DeepBugs: a learning approach to name-based bug detection",
    "year": 2018,
    "ML_Techniques": "Word2Vec",
    "Category": "Testing",
    "Sub_category": "Defect prediction",
    "Venue": "PACMPL",
    "Link": "https://dl.acm.org/doi/10.1145/3276517",
    "bibtex": "inproceedings{Omri2020_83,\n    author = \"Omri, Safa and Sinz, Carsten\",\n    title = \"Deep Learning for Software Defect Prediction: A Survey\",\n    year = \"2020\",\n    isbn = \"9781450379632\",\n    publisher = \"Association for Computing Machinery\",\n    address = \"New York, NY, USA\",\n    url = \"https://doi.org/10.1145/3387940.3391463\",\n    doi = \"10.1145/3387940.3391463\",\n    abstract = \"Software fault prediction is an important and beneficial practice for improving software quality and reliability. The ability to predict which components in a large software system are most likely to contain the largest numbers of faults in the next release helps to better manage projects, including early estimation of possible release delays, and affordably guide corrective actions to improve the quality of the software. However, developing robust fault prediction models is a challenging task and many techniques have been proposed in the literature. Traditional software fault prediction studies mainly focus on manually designing features (e.g. complexity metrics), which are input into machine learning classifiers to identify defective code. However, these features often fail to capture the semantic and structural information of programs. Such information is needed for building accurate fault prediction models. In this survey, we discuss various approaches in fault prediction, also explaining how in recent studies deep learning algorithms for fault prediction help to bridge the gap between programs' semantics and fault prediction features and make accurate predictions.\",\n    booktitle = \"Proceedings of the IEEE/ACM 42nd International Conference on Software Engineering Workshops\",\n    pages = \"209\u2013214\",\n    numpages = \"6\",\n    keywords = \"software defect prediction, deep learning, machine learning, software testing, software quality assurance\",\n    location = \"Seoul, Republic of Korea\",\n    series = \"ICSEW'20\"\n}\n\n",
    "abstract": "Natural language elements in source code, e.g., the names of variables and functions, convey useful information. However, most existing bug detection tools ignore this information and therefore miss some classes of bugs. The few existing name-based bug detection approaches reason about names on a syntactic level and rely on manually designed and tuned algorithms to detect bugs. This paper presents DeepBugs, a learning approach to name-based bug detection, which reasons about names based on a semantic representation and which automatically learns bug detectors instead of manually writing them. We formulate bug detection as a binary classification problem and train a classifier that distinguishes correct from incorrect code. To address the challenge that effectively learning a bug detector requires examples of both correct and incorrect code, we create likely incorrect code examples from an existing corpus of code through simple code transformations. A novel insight learned from our work is that learning from artificially seeded bugs yields bug detectors that are effective at finding bugs in real-world code. We implement our idea into a framework for learning-based and name-based bug detection. Three bug detectors built on top of the framework detect accidentally swapped function arguments, incorrect binary operators, and incorrect operands in binary operations. Applying the approach to a corpus of 150,000 JavaScript files yields bug detectors that have a high accuracy (between 89% and 95%), are very efficient (less than 20 milliseconds per analyzed file), and reveal 102 programming mistakes (with 68% true positive rate) in real-world code."
}, {
    "py/object": "data.DataClassPaper",
    "Title": "DeepFuzz: Automatic Generation of Syntax Valid C Programs for Fuzz Testing",
    "year": 2019,
    "ML_Techniques": "Seq2Seq",
    "Category": "Testing",
    "Sub_category": "Fuzzing",
    "Venue": "AAAI",
    "Link": "https://faculty.ist.psu.edu/wu/papers/DeepFuzz.pdf",
    "bibtex": "article{Liu2019_85,\n    author = \"Liu, Xiao and Li, Xiaoting and Prajapati, Rupesh and Wu, Dinghao\",\n    title = \"DeepFuzz: Automatic Generation of Syntax Valid C Programs for Fuzz Testing\",\n    volume = \"33\",\n    url = \"https://ojs.aaai.org/index.php/AAAI/article/view/3895\",\n    DOI = \"10.1609/aaai.v33i01.33011044\",\n    number = \"01\",\n    journal = \"Proceedings of the AAAI Conference on Artificial Intelligence\",\n    year = \"2019\",\n    month = \"Jul.\",\n    pages = \"1044-1051\"\n}\n\n",
    "abstract": "Compilers are among the most fundamental programming tools for building software. However, production compilers remain buggy. Fuzz testing is often leveraged with newlygenerated, or mutated inputs in order to find new bugs or security vulnerabilities. In this paper, we propose a grammarbased fuzzing tool called DEEPFUZZ. Based on a generative Sequence-to-Sequence model, DEEPFUZZ automatically and continuously generates well-formed C programs. We use this set of new C programs to fuzz off-the-shelf C compilers, e.g., GCC and Clang/LLVM. We present a detailed case study to analyze the success rate and coverage improvement of the generated C programs for fuzz testing. We analyze the performance of DEEPFUZZ with three types of sampling methods as well as three types of generation strategies. Consequently, DEEPFUZZ improved the testing efficacy in regards to the line, function, and branch coverage. In our preliminary study, we found and reported 8 bugs of GCC, all of which are actively being addressed by developers."
}, {
    "py/object": "data.DataClassPaper",
    "Title": "Determining Software Inter-Dependency Patterns for Integration Testing by applying Machine learning on Logs and Telemetry data",
    "year": 2020,
    "ML_Techniques": "",
    "Category": "Testing",
    "Sub_category": "",
    "Venue": "ICRITO",
    "Link": "https://ieeexplore.ieee.org/document/9197868",
    "bibtex": "INPROCEEDINGS{Rajaraman2020_86,\n    author = \"{Rajaraman}, R. and {Kapur}, P. K. and {Kumar}, D.\",\n    booktitle = \"2020 8th International Conference on Reliability, Infocom Technologies and Optimization (Trends and Future Directions) (ICRITO)\",\n    title = \"Determining Software Inter-Dependency Patterns for Integration Testing by applying Machine learning on Logs and Telemetry data\",\n    year = \"2020\",\n    volume = \"\",\n    number = \"\",\n    pages = \"1080-1084\",\n    doi = \"10.1109/ICRITO48877.2020.9197868\"\n}\n\n",
    "abstract": "Businesses running software applications are moving more towards vendor-agnostic approaches. Integration testing becoming more demanding and complex than ever. Determining integration testing requires a solid dependency pattern among different software applications. We would like to use here an NLP (Natural language processing) & Machine learning Classification model-based approach to identify the dependency graph between different component across applications. There are existing approaches eliciting about package dependencies and source code-based dependencies. In this paper, we would like to introduce an approach to understand the communication dependencies between products rather than just high-level package or install dependencies. The communication dependencies will be prioritized based on the frequency and criticality of usage. The prioritization helps us in determining the software inter-dependency patterns for Integration testing."
}, {
    "py/object": "data.DataClassPaper",
    "Title": "Empirical Assessment of Machine Learning based Software Defect Prediction Techniques",
    "year": 2008,
    "ML_Techniques": "LR, PR, SVR, NNC, SVLR, NND, LOG, NB",
    "Category": "Testing",
    "Sub_category": "Defect prediction",
    "Venue": "IJAIT",
    "Link": "https://www.worldscientific.com/doi/abs/10.1142/S0218213008003947",
    "bibtex": "INPROCEEDINGS{Rajaraman2020_86,\n    author = \"{Rajaraman}, R. and {Kapur}, P. K. and {Kumar}, D.\",\n    booktitle = \"2020 8th International Conference on Reliability, Infocom Technologies and Optimization (Trends and Future Directions) (ICRITO)\",\n    title = \"Determining Software Inter-Dependency Patterns for Integration Testing by applying Machine learning on Logs and Telemetry data\",\n    year = \"2020\",\n    volume = \"\",\n    number = \"\",\n    pages = \"1080-1084\",\n    doi = \"10.1109/ICRITO48877.2020.9197868\"\n}\n\n",
    "abstract": "The wide-variety of real-time software systems, including telecontrol/telepresence systems, robotic systems, and mission planning systems, can entail dynamic code synthesis based on runtime mission-specific requirements and operating conditions. This necessitates the need for dynamic dependability assessment to ensure that these systems perform as specified and not fail in catastrophic ways. One approach in achieving this is to dynamically assess the modules in the synthesized code using software defect prediction techniques. Statistical models; such as stepwise multi-linear regression models and multivariate models, and machine learning approaches, such as artificial neural networks, instance-based reasoning, Bayesian-belief networks, decision trees, and rule inductions, have been investigated for predicting software quality. However, there is still no consensus about the best predictor model for software defects. In this paper; we evaluate different predictor models on four different real-time software defect data sets. The results show that a combination of IR and instance-based learning along with the consistency-based subset evaluation technique provides a relatively better consistency in accuracy prediction compared to other models. The results also show that \"size\" and \"complexity\" metrics are not sufficient for accurately predicting real-time software defects."
}, {
    "py/object": "data.DataClassPaper",
    "Title": "Empirical comparison of machine learning algorithms for bug prediction in open source software",
    "year": 2017,
    "ML_Techniques": "SLP, MLP, ANN, SOM, AIS",
    "Category": "Testing",
    "Sub_category": "Defect prediction",
    "Venue": "ICBDAC",
    "Link": "https://ieeexplore.ieee.org/document/8070806",
    "bibtex": "INPROCEEDINGS{Malhotra2017_88,\n    author = \"{Malhotra}, R. and {Bahl}, L. and {Sehgal}, S. and {Priya}, P.\",\n    booktitle = \"2017 International Conference on Big Data Analytics and Computational Intelligence (ICBDAC)\",\n    title = \"Empirical comparison of machine learning algorithms for bug prediction in open source software\",\n    year = \"2017\",\n    volume = \"\",\n    number = \"\",\n    pages = \"40-45\",\n    doi = \"10.1109/ICBDACI.2017.8070806\"\n}\n\n",
    "abstract": "Bug tracking and analysis truly remains one of the most active areas of software engineering research. Bug tracking results may be employed by the software practitioners of large software projects effectively. The cost of detecting and correcting the defect becomes exponentially higher as we go from requirement analysis to the maintenance phase, where defects might even lead to loss of lives. Software metrics in conjunction with defect data can serve as basis for developing predictive models. Open source projects which encompass contributions from millions of people provide capacious dataset for testing. There have been diverse machine learning techniques proposed in the literature for analyzing complex relationships and extracting useful information from problems using optimal resources and time. However, more extensive research comparing these techniques is needed to establish superiority of one technique over another. This study aims at comparison of 14 ML techniques for development of effective defect prediction models. The issues addressed are 1) Construction of automated tool in Java to collect OO, inheritance and other metrics and detect bugs in classes extracted from open source repository, 2) Use of relevant performance measures to evaluate performance of predictive models to detect bugs in classes, 3) Statistical tests to compare predictive capability of different machine learning techniques, 4) Validation of defect prediction models. The results of the study show that Single Layer Perceptron is the best technique amongst all the techniques used in this study for development of defect prediction models. The conclusions drawn from this study can be used for practical applications by software practitioners to determine best technique for defect prediction and consequently carry out effective allocation of resources."
}, {
    "py/object": "data.DataClassPaper",
    "Title": "Feasibility of Machine Learning Algorithm for Test Partitioning",
    "year": 2019,
    "ML_Techniques": "SA, SVM",
    "Category": "Testing",
    "Sub_category": "",
    "Venue": "ITC-CSCC",
    "Link": "https://ieeexplore.ieee.org/document/8793328",
    "bibtex": "INPROCEEDINGS{Wang2019_89,\n    author = \"{Wang}, S. and {Al-Awadhi}, H. T. and {Aohagi}, M. and {Higami}, Y. and {Takahashi}, H.\",\n    booktitle = \"2019 34th International Technical Conference on Circuits/Systems, Computers and Communications (ITC-CSCC)\",\n    title = \"Feasibility of Machine Learning Algorithm for Test Partitioning\",\n    year = \"2019\",\n    volume = \"\",\n    number = \"\",\n    pages = \"1-4\",\n    doi = \"10.1109/ITC-CSCC.2019.8793328\"\n}\n\n",
    "abstract": "When a system is in idle/starting-up state, Field-Testing is a promising way to guarantee the reliability of an advanced system. However, the extremely limited test application time obstructs the implementation of field test. In this paper, we introduce a test pattern partitioning approach by using two well-known machine learning algorithms: Simulated Annealing (SA) and Support Vector Machines (SVM), to derive an optimal solution for pattern partitioning that minimizes the test latency for high reliability. From the experimental results on benchmark circuit we show that both SA and SVM based method can significantly improve the test latency of partition test, and SVM is much more efficient than SA. Those results confirm the feasibility of machine learning algorithm for the pattern partition problem."
}, {
    "py/object": "data.DataClassPaper",
    "Title": "Generating Test Input with Deep Reinforcement Learning",
    "year": 2018,
    "ML_Techniques": "DDQN",
    "Category": "Testing",
    "Sub_category": "Test data/case generation",
    "Venue": "SBST",
    "Link": "https://ieeexplore.ieee.org/document/8452812",
    "bibtex": "INPROCEEDINGS{Kim2018_90,\n    author = \"{Kim}, J. and {Kwon}, M. and {Yoo}, S.\",\n    booktitle = \"2018 IEEE/ACM 11th International Workshop on Search-Based Software Testing (SBST)\",\n    title = \"Generating Test Input with Deep Reinforcement Learning\",\n    year = \"2018\",\n    volume = \"\",\n    number = \"\",\n    pages = \"51-58\",\n    doi = \"\"\n}\n\n",
    "abstract": "Test data generation is a tedious and laborious process. Search-based Software Testing (SBST) automatically generates test data optimising structural test criteria using metaheuristic algorithms. In essence, metaheuristic algorithms are systematic trial-and-error based on the feedback of fitness function. This is similar to an agent of reinforcement learning which iteratively decides an action based on the current state to maximise the cumulative reward. Inspired by this analogy, this paper investigates the feasibility of employing reinforcement learning in SBST to replace human designed metaheuristic algorithms. We reformulate the software under test (SUT) as an environment of reinforcement learning. At the same time, we present GunPowder, a novel framework for SBST which extends SUT to the environment. We train a Double Deep Q-Networks (DDQN) agent with deep neural network and evaluate the effectiveness of our approach by conducting a small empirical study. Finally, we find that agents can learn metaheuristic algorithms for SBST, achieving 100% branch coverage for training functions. Our study sheds light on the future integration of deep neural network and SBST."
}, {
    "py/object": "data.DataClassPaper",
    "Title": "How high will it be? Using machine learning models to predict branch coverage in automated testing",
    "year": 2018,
    "ML_Techniques": "LR, SVR, MLP",
    "Category": "Testing",
    "Sub_category": "Test data/case generation",
    "Venue": "MaLTeSQuE",
    "Link": "https://ieeexplore.ieee.org/abstract/document/8368454",
    "bibtex": "INPROCEEDINGS{Grano2018_91,\n    author = \"{Grano}, G. and {Titov}, T. V. and {Panichella}, S. and {Gall}, H. C.\",\n    booktitle = \"2018 IEEE Workshop on Machine Learning Techniques for Software Quality Evaluation (MaLTeSQuE)\",\n    title = \"How high will it be? Using machine learning models to predict branch coverage in automated testing\",\n    year = \"2018\",\n    volume = \"\",\n    number = \"\",\n    pages = \"19-24\",\n    doi = \"10.1109/MALTESQUE.2018.8368454\"\n}\n\n",
    "abstract": "Software testing is a crucial component in modern continuous integration development environment. Ideally, at every commit, all the system's test cases should be executed and moreover, new test cases should be generated for the new code. This is especially true in a Continuous Test Generation (CTG) environment, where the automatic generation of test cases is integrated into the continuous integration pipeline. Furthermore, developers want to achieve a minimum level of coverage for every build of their systems. Since both executing all the test cases and generating new ones for all the classes at every commit is not feasible, they have to select which subset of classes has to be tested. In this context, knowing a priori the branch coverage that can be achieved with test data generation tools might give some useful indications for answering such a question. In this paper, we take the first steps towards the definition of machine learning models to predict the branch coverage achieved by test data generation tools. We conduct a preliminary study considering well known code metrics as a features. Despite the simplicity of these features, our results show that using machine learning to predict branch coverage in automated testing is a viable and feasible option."
}, {
    "py/object": "data.DataClassPaper",
    "Title": "Identifying and Generating Missing Tests using Machine Learning on Execution Traces",
    "year": 2020,
    "ML_Techniques": "RF, AB, KNN, NB, SVC, LOG",
    "Category": "Testing",
    "Sub_category": "Test data/case generation",
    "Venue": "AITest",
    "Link": "https://ieeexplore.ieee.org/document/9176745",
    "bibtex": "INPROCEEDINGS{Utting2020_92,\n    author = \"{Utting}, M. and {Legeard}, B. and {Dadeau}, F. and {Tamagnan}, F. and {Bouquet}, F.\",\n    booktitle = \"2020 IEEE International Conference On Artificial Intelligence Testing (AITest)\",\n    title = \"Identifying and Generating Missing Tests using Machine Learning on Execution Traces\",\n    year = \"2020\",\n    volume = \"\",\n    number = \"\",\n    pages = \"83-90\",\n    doi = \"10.1109/AITEST49225.2020.00020\"\n}\n\n",
    "abstract": "Testing IT systems has become a major bottleneck for many companies. Besides the growing complexity of such systems, shorter release cycles and increasing quality requirements have led to increased verification and validation costs. However, analysis of existing testing procedures reveals that not all artifacts are exploited to tame this cost increase. In particular, customer traces are usually ignored by validation engineers. In this paper, we use machine learning from execution traces (both customer traces and test execution traces) to identify test needs and to generate new tests in the context of web services and API testing. Log files of customer traces are split into smaller traces (user sessions) then encoded into Pandas DataFrames for data analysis and machine learning. Clustering algorithms are used to analyse the customer traces and compare them with existing system tests, and machine learning models are used to generate missing tests in the desired clusters. The tool-set is implemented in an open-source library called Agilkia."
}, {
    "py/object": "data.DataClassPaper",
    "Title": "Improved approach for software defect prediction using artificial neural networks",
    "year": 2016,
    "ML_Techniques": "ANN, FL",
    "Category": "Testing",
    "Sub_category": "Defect prediction",
    "Venue": "ICRITO",
    "Link": "https://ieeexplore.ieee.org/document/7785003",
    "bibtex": "INPROCEEDINGS{Sethi2016_93,\n    author = \"{Sethi}, T. and {Gagandeep}\",\n    booktitle = \"2016 5th International Conference on Reliability, Infocom Technologies and Optimization (Trends and Future Directions) (ICRITO)\",\n    title = \"Improved approach for software defect prediction using artificial neural networks\",\n    year = \"2016\",\n    volume = \"\",\n    number = \"\",\n    pages = \"480-485\",\n    doi = \"10.1109/ICRITO.2016.7785003\"\n}\n\n",
    "abstract": "Software defect prediction (SDP) is a most dynamic research area in software engineering. SDP is a process used to predict the deformities in the software. To identifying the defects before the arrival of item or aimed the software improvement, to make software dependable, defect prediction model is utilized. It is always desirable to predict the defects at early stages of life cycle. Hence to predict the defects before testing the SDP is done at end of each phase of SDLC. It helps to reduce the cost as well as time. To produce high quality software, the artificial neural network approach is applied to predict the defect. Nine metrics are applied to the multiple phases of SDLC and twenty genuine software projects are used. The software project data were collected from a team of organization and their responses were recorded in linguistic terms. For assessment of model the mean magnitude of relative error (MMRE) and balanced mean magnitude of relative error (BMMRE) measures are used. In this research work, the implementation of neural network based software defect prediction is compared with the results of fuzzy logic basic approach. In the proposed approach, it is found that the neural network based training model is providing better and effective results on multiple parameters.\n"
}, {
    "py/object": "data.DataClassPaper",
    "Title": "Improvement in Software Defect Prediction Outcome Using Principal Component Analysis and Ensemble Machine Learning Algorithms",
    "year": 2019,
    "ML_Techniques": "RF, AB, B",
    "Category": "Testing",
    "Sub_category": "Defect prediction",
    "Venue": "ICICI",
    "Link": "https://link.springer.com/chapter/10.1007/978-3-030-03146-6_44",
    "bibtex": "InProceedings{Dhamayanthi2019_94,\n    author = \"Dhamayanthi, N. and Lavanya, B.\",\n    editor = \"Hemanth, Jude and Fernando, Xavier and Lafata, Pavel and Baig, Zubair\",\n    title = \"Improvement in Software Defect Prediction Outcome Using Principal Component Analysis and Ensemble Machine Learning Algorithms\",\n    booktitle = \"International Conference on Intelligent Data Communication Technologies and Internet of Things (ICICI) 2018\",\n    year = \"2019\",\n    publisher = \"Springer International Publishing\",\n    address = \"Cham\",\n    pages = \"397--406\",\n    abstract = \"Improving customer experience is the focus of IT Industry. It is no longer about customer satisfaction, but it is about creating memorable experiences which will help build loyal customers. Hence it is extremely critical to release defect free software. While machine learning techniques were widely used for prediction modelling, creating a reliable predictor which can perform satisfactorily is always a challenge. In this paper, we have proposed a framework using PCA for feature selection and ensemble machine learning algorithms with stratified 10-fold cross validation for building the classification model. The proposed model is tested using 5 projects from NASA Metrics Data program and 4 ensemble machine learning algorithms. Our results show that the prediction accuracy is improved by 0.6{\\\\%} when the reduced dataset is used for classification than using the whole dataset. In comparison with previous research studies, our framework has shown an average of 4.2{\\\\%} increase in performance.\",\n    isbn = \"978-3-030-03146-6\"\n}\n\n",
    "abstract": "Improving customer experience is the focus of IT Industry. It is no longer about customer satisfaction, but it is about creating memorable experiences which will help build loyal customers. Hence it is extremely critical to release defect free software. While machine learning techniques were widely used for prediction modelling, creating a reliable predictor which can perform satisfactorily is always a challenge. In this paper, we have proposed a framework using PCA for feature selection and ensemble machine learning algorithms with stratified 10-fold cross validation for building the classification model. The proposed model is tested using 5 projects from NASA Metrics Data program and 4 ensemble machine learning algorithms. Our results show that the prediction accuracy is improved by 0.6% when the reduced dataset is used for classification than using the whole dataset. In comparison with previous research studies, our framework has shown an average of 4.2% increase in performance."
}, {
    "py/object": "data.DataClassPaper",
    "Title": "Improving bug detection and fixing via code representation learning",
    "year": 2020,
    "ML_Techniques": "CNN, RNN",
    "Category": "Testing",
    "Sub_category": "Program repair",
    "Venue": "ICSE",
    "Link": "https://dl.acm.org/doi/10.1145/3377812.3382172",
    "bibtex": "InProceedings{Dhamayanthi2019_94,\n    author = \"Dhamayanthi, N. and Lavanya, B.\",\n    editor = \"Hemanth, Jude and Fernando, Xavier and Lafata, Pavel and Baig, Zubair\",\n    title = \"Improvement in Software Defect Prediction Outcome Using Principal Component Analysis and Ensemble Machine Learning Algorithms\",\n    booktitle = \"International Conference on Intelligent Data Communication Technologies and Internet of Things (ICICI) 2018\",\n    year = \"2019\",\n    publisher = \"Springer International Publishing\",\n    address = \"Cham\",\n    pages = \"397--406\",\n    abstract = \"Improving customer experience is the focus of IT Industry. It is no longer about customer satisfaction, but it is about creating memorable experiences which will help build loyal customers. Hence it is extremely critical to release defect free software. While machine learning techniques were widely used for prediction modelling, creating a reliable predictor which can perform satisfactorily is always a challenge. In this paper, we have proposed a framework using PCA for feature selection and ensemble machine learning algorithms with stratified 10-fold cross validation for building the classification model. The proposed model is tested using 5 projects from NASA Metrics Data program and 4 ensemble machine learning algorithms. Our results show that the prediction accuracy is improved by 0.6{\\\\%} when the reduced dataset is used for classification than using the whole dataset. In comparison with previous research studies, our framework has shown an average of 4.2{\\\\%} increase in performance.\",\n    isbn = \"978-3-030-03146-6\"\n}\n\n",
    "abstract": "The software quality and reliability have been proved to be important during the program development. There are many existing studies trying to help improve it on bug detection and automated program repair processes. However, each of them has its own limitation and the overall performance still have some improvement space. In this paper, we proposed a deep learning framework to improve the software quality and reliability on these two detect-fix processes. We used advanced code modeling and AI models to have some improvements on the state-of-the-art approaches. The evaluation results show that our approach can have a relative improvement up to 206% in terms of F-1 score when comparing with baselines on bug detection and can have a relative improvement up to 19.8 times on the correct bug-fixing amount when comparing with baselines on automated program repair. These results can prove that our framework can have an outstanding performance on improving software quality and reliability in bug detection and automated program repair processes."
}, {
    "py/object": "data.DataClassPaper",
    "Title": "Improving bug detection via context-based code representation learning and attention-based neural networks",
    "year": 2019,
    "ML_Techniques": " Node2Vec",
    "Category": "Testing",
    "Sub_category": "Defect prediction",
    "Venue": "PACMPL",
    "Link": "https://dl.acm.org/doi/10.1145/3360588",
    "bibtex": "InProceedings{Dhamayanthi2019_94,\n    author = \"Dhamayanthi, N. and Lavanya, B.\",\n    editor = \"Hemanth, Jude and Fernando, Xavier and Lafata, Pavel and Baig, Zubair\",\n    title = \"Improvement in Software Defect Prediction Outcome Using Principal Component Analysis and Ensemble Machine Learning Algorithms\",\n    booktitle = \"International Conference on Intelligent Data Communication Technologies and Internet of Things (ICICI) 2018\",\n    year = \"2019\",\n    publisher = \"Springer International Publishing\",\n    address = \"Cham\",\n    pages = \"397--406\",\n    abstract = \"Improving customer experience is the focus of IT Industry. It is no longer about customer satisfaction, but it is about creating memorable experiences which will help build loyal customers. Hence it is extremely critical to release defect free software. While machine learning techniques were widely used for prediction modelling, creating a reliable predictor which can perform satisfactorily is always a challenge. In this paper, we have proposed a framework using PCA for feature selection and ensemble machine learning algorithms with stratified 10-fold cross validation for building the classification model. The proposed model is tested using 5 projects from NASA Metrics Data program and 4 ensemble machine learning algorithms. Our results show that the prediction accuracy is improved by 0.6{\\\\%} when the reduced dataset is used for classification than using the whole dataset. In comparison with previous research studies, our framework has shown an average of 4.2{\\\\%} increase in performance.\",\n    isbn = \"978-3-030-03146-6\"\n}\n\n",
    "abstract": "Bug detection has been shown to be an effective way to help developers in detecting bugs early, thus, saving much effort and time in software development process. Recently, deep learning-based bug detection approaches have gained successes over the traditional machine learning-based approaches, the rule-based program analysis approaches, and mining-based approaches. However, they are still limited in detecting bugs that involve multiple methods and suffer high rate of false positives. In this paper, we propose a combination approach with the use of contexts and attention neural network to overcome those limitations. We propose to use as the global context the Program Dependence Graph (PDG) and Data Flow Graph (DFG) to connect the method under investigation with the other relevant methods that might contribute to the buggy code. The global context is complemented by the local context extracted from the path on the AST built from the method\u2019s body. The use of PDG and DFG enables our model to reduce the false positive rate, while to complement for the potential reduction in recall, we make use of the attention neural network mechanism to put more weights on the buggy paths in the source code. That is, the paths that are similar to the buggy paths will be ranked higher, thus, improving the recall of our model. We have conducted several experiments to evaluate our approach on a very large dataset with +4.973M methods in 92 different project versions. The results show that our tool can have a relative improvement up to 160% on F-score when comparing with the state-of-the-art bug detection approaches. Our tool can detect 48 true bugs in the list of top 100 reported bugs, which is 24 more true bugs when comparing with the baseline approaches. We also reported that our representation is better suitable for bug detection and relatively improves over the other representations up to 206% in accuracy."
}, {
    "py/object": "data.DataClassPaper",
    "Title": "Integration Testing of Components Guided by Incremental State Machine Learning",
    "year": 2006,
    "ML_Techniques": "",
    "Category": "Testing",
    "Sub_category": "Test data/case generation",
    "Venue": "TAIC PART",
    "Link": "https://ieeexplore.ieee.org/abstract/document/1691670",
    "bibtex": "INPROCEEDINGS{KeqinLi2006_97,\n    author = \"{Keqin Li} and {Groz}, R. and {Shahbaz}, M.\",\n    booktitle = \"Testing: Academic Industrial Conference - Practice And Research Techniques (TAIC PART'06)\",\n    title = \"Integration Testing of Components Guided by Incremental State Machine Learning\",\n    year = \"2006\",\n    volume = \"\",\n    number = \"\",\n    pages = \"59-70\",\n    doi = \"10.1109/TAIC-PART.2006.15\"\n}\n\n",
    "abstract": "The design of complex systems, e.g., telecom services, is nowadays usually based on the integration of components (COTS), loosely coupled in distributed architectures. When components come from third party sources, their internal structure is usually unknown and the documentation is insufficient. Therefore, the system integrator faces the problem of providing a required system assembling COTS whose behaviour is barely specified and for which no model is usually available. In this paper, we address the problem of integration testing of COTS. It combines test generation techniques with machine learning algorithms. State-based models of components are built from observed behaviours. The models are alternatively used to generate tests and extended to take into account observed behaviour. This process is iterated until a satisfactory level of confidence in testing is achieved"
}, {
    "py/object": "data.DataClassPaper",
    "Title": "Investigating the Accuracy of Test Code Size Prediction using Use Case Metrics and Machine Learning Algorithms: An Empirical Study",
    "year": 2017,
    "ML_Techniques": "LR, KNN, NB, RF, MLP",
    "Category": "Testing",
    "Sub_category": ",Effort prediction",
    "Venue": "ICMLSC",
    "Link": "https://dl.acm.org/doi/10.1145/3036290.3036323",
    "bibtex": "INPROCEEDINGS{KeqinLi2006_97,\n    author = \"{Keqin Li} and {Groz}, R. and {Shahbaz}, M.\",\n    booktitle = \"Testing: Academic Industrial Conference - Practice And Research Techniques (TAIC PART'06)\",\n    title = \"Integration Testing of Components Guided by Incremental State Machine Learning\",\n    year = \"2006\",\n    volume = \"\",\n    number = \"\",\n    pages = \"59-70\",\n    doi = \"10.1109/TAIC-PART.2006.15\"\n}\n\n",
    "abstract": "Software testing plays a crucial role in software quality assurance. It is, however, a time and resource consuming process. It is, therefore, important to predict as soon as possible the effort required to test software, so that activities can be planned and resources can be optimally allocated. Test code size, in terms of Test Lines Of Code (TLOC), is an important testing effort indicator used in many empirical studies. In this paper, we investigate empirically the early prediction of TLOC for object-oriented software using use case metrics. We used different machine learning algorithms (linear regression, k-NN, Na\u00efve Bayes, C4.5, Random Forest, and Multilayer Perceptron) to build the prediction models. We performed an empirical study using data collected from five Java projects. The use case metrics have been compared to the well-known Use Case Points (UCP) method. Results show that the use case metrics-based approach gives a more accurate prediction of TLOC than the UCP method."
}, {
    "py/object": "data.DataClassPaper",
    "Title": "Learn&Fuzz: Machine learning for input fuzzing",
    "year": 2017,
    "ML_Techniques": "LSTM",
    "Category": "Testing",
    "Sub_category": "Fuzzing",
    "Venue": "ASE",
    "Link": "https://ieeexplore.ieee.org/abstract/document/8115618",
    "bibtex": "INPROCEEDINGS{KeqinLi2006_97,\n    author = \"{Keqin Li} and {Groz}, R. and {Shahbaz}, M.\",\n    booktitle = \"Testing: Academic Industrial Conference - Practice And Research Techniques (TAIC PART'06)\",\n    title = \"Integration Testing of Components Guided by Incremental State Machine Learning\",\n    year = \"2006\",\n    volume = \"\",\n    number = \"\",\n    pages = \"59-70\",\n    doi = \"10.1109/TAIC-PART.2006.15\"\n}\n\n",
    "abstract": "Fuzzing consists of repeatedly testing an application with modified, or fuzzed, inputs with the goal of finding security vulnerabilities in input-parsing code. In this paper, we show how to automate the generation of an input grammar suitable for input fuzzing using sample inputs and neural-network-based statistical machine-learning techniques. We present a detailed case study with a complex input format, namely PDF, and a large complex security-critical parser for this format, namely, the PDF parser embedded in Microsoft's new Edge browser. We discuss and measure the tension between conflicting learning and fuzzing goals: learning wants to capture the structure of well-formed inputs, while fuzzing wants to break that structure in order to cover unexpected code paths and find bugs. We also present a new algorithm for this learn&fuzz challenge which uses a learnt input probability distribution to intelligently guide where to fuzz inputs."
}, {
    "py/object": "data.DataClassPaper",
    "Title": "Lessons learned from using a deep tree-based model for software defect prediction in practice",
    "year": 2019,
    "ML_Techniques": "LTSM",
    "Category": "Testing",
    "Sub_category": "Defect prediction",
    "Venue": "MSR",
    "Link": "https://dl.acm.org/doi/10.1109/MSR.2019.00017",
    "bibtex": "INPROCEEDINGS{KeqinLi2006_97,\n    author = \"{Keqin Li} and {Groz}, R. and {Shahbaz}, M.\",\n    booktitle = \"Testing: Academic Industrial Conference - Practice And Research Techniques (TAIC PART'06)\",\n    title = \"Integration Testing of Components Guided by Incremental State Machine Learning\",\n    year = \"2006\",\n    volume = \"\",\n    number = \"\",\n    pages = \"59-70\",\n    doi = \"10.1109/TAIC-PART.2006.15\"\n}\n\n",
    "abstract": "Defects are common in software systems and cause many problems for software users. Different methods have been developed to make early prediction about the most likely defective modules in large codebases. Most focus on designing features (e.g. complexity metrics) that correlate with potentially defective code. Those approaches however do not sufficiently capture the syntax and multiple levels of semantics of source code, a potentially important capability for building accurate prediction models. In this paper, we report on our experience of deploying a new deep learning tree-based defect prediction model in practice. This model is built upon the tree-structured Long Short Term Memory network which directly matches with the Abstract Syntax Tree representation of source code. We discuss a number of lessons learned from developing the model and evaluating it on two datasets, one from open source projects contributed by our industry partner Samsung and the other from the public PROMISE repository."
}, {
    "py/object": "data.DataClassPaper",
    "Title": "Leveraging mutants for automatic prediction of metamorphic relations using machine learning",
    "year": 2019,
    "ML_Techniques": "SVM",
    "Category": "Testing",
    "Sub_category": ",Test data/case generation",
    "Venue": "MaLTeSQuE",
    "Link": "https://dl.acm.org/doi/abs/10.1145/3340482.3342741",
    "bibtex": "INPROCEEDINGS{KeqinLi2006_97,\n    author = \"{Keqin Li} and {Groz}, R. and {Shahbaz}, M.\",\n    booktitle = \"Testing: Academic Industrial Conference - Practice And Research Techniques (TAIC PART'06)\",\n    title = \"Integration Testing of Components Guided by Incremental State Machine Learning\",\n    year = \"2006\",\n    volume = \"\",\n    number = \"\",\n    pages = \"59-70\",\n    doi = \"10.1109/TAIC-PART.2006.15\"\n}\n\n",
    "abstract": "An oracle is used in software testing to derive the verdict (pass/fail) for a test case. Lack of precise test oracles is one of the major problems in software testing which can hinder judgements about quality. Metamorphic testing is an emerging technique which solves both the oracle problem and the test case generation problem by testing special forms of software requirements known as metamorphic requirements. However, manually deriving the metamorphic requirements for a given program requires a high level of domain expertise, is labor intensive and error prone. As an alternative, we consider the problem of automatic detection of metamorphic requirements using machine learning (ML). For this problem we can apply graph kernels and support vector machines (SVM). A significant problem for any ML approach is to obtain a large labeled training set of data (in this case programs) that generalises well. The main contribution of this paper is a general method to generate large volumes of synthetic training data which can improve ML assisted detection of metamorphic requirements. For training data synthesis we adopt mutation testing techniques. This research is the first to explore the area of data augmentation techniques for ML-based analysis of software code. We also have the goal to enhance black-box testing using white-box methodologies. Our results show that the mutants incorporated into the source code corpus not only efficiently scale the dataset size, but they can also improve the accuracy of classification models."
}, {
    "py/object": "data.DataClassPaper",
    "Title": "LSTM-based deep learning for spatial\u2013temporal software testing",
    "year": 2020,
    "ML_Techniques": "LSTM",
    "Category": "Testing",
    "Sub_category": ",Defect prediction",
    "Venue": "DPD",
    "Link": "https://link.springer.com/article/10.1007/s10619-020-07291-1",
    "bibtex": "article{Xiao2020_102,\n    author = \"Xiao, L. and Miao, HuaiKou and Shi, Tingting and Hong, Y.\",\n    title = \"LSTM-based deep learning for spatial\u2013temporal software testing\",\n    journal = \"Distributed and Parallel Databases\",\n    year = \"2020\",\n    pages = \"1-26\"\n}\n\n",
    "abstract": "Continuous integration (CI) software development practice has become more and more popular. Regression testing occurs very frequently in CI. Test case suites constantly change since new test cases are inserted and obsolete test case are removed in each cycle. The software developer hunts for quick-feedback of faults because of time constraint. An embedded software usually includes the spatial\u2013temporal data in CI. The efficiency of regression testing for the embedded software is related to the space\u2013time. To achieve ideal regression testing goals for the embedded software in CI, this paper proposes a novel test case prioritization approach using LSTM-Based (Long short-term memory) deep learning. LSTM is a time series prediction model. It can predict the probability of each test case detection fault in the next cycle according to the testing history information of all the previous CI cycles. The priority of test case can be obtained dynamically under the guidance of the probability. The experiments are conducted on two industrial data sets. The results verify that compared with some exiting test case prioritization approaches, our approach has better performance for embedded software as follows: (1) improve the prioritization effectiveness, (2) increase the fault detection rate in CI environment, and (3) decrease the testing execution time through automatic reduction the obsolete test cases.\n"
}, {
    "py/object": "data.DataClassPaper",
    "Title": "Machine Learning Applied to Software Testing: A Systematic Mapping Study",
    "year": 2019,
    "ML_Techniques": "",
    "Category": "Testing",
    "Sub_category": ",Test data/case generation",
    "Venue": "T-RL",
    "Link": "https://ieeexplore.ieee.org/abstract/document/8638573",
    "bibtex": "ARTICLE{Durelli2019_103,\n    author = \"{Durelli}, V. H. S. and {Durelli}, R. S. and {Borges}, S. S. and {Endo}, A. T. and {Eler}, M. M. and {Dias}, D. R. C. and {Guimar\u00e3es}, M. P.\",\n    journal = \"IEEE Transactions on Reliability\",\n    title = \"Machine Learning Applied to Software Testing: A Systematic Mapping Study\",\n    year = \"2019\",\n    volume = \"68\",\n    number = \"3\",\n    pages = \"1189-1212\",\n    doi = \"10.1109/TR.2019.2892517\"\n}\n\n",
    "abstract": "Software testing involves probing into the behavior of software systems to uncover faults. Most testing activities are complex and costly, so a practical strategy that has been adopted to circumvent these issues is to automate software testing. There has been a growing interest in applying machine learning (ML) to automate various software engineering activities, including testing-related ones. In this paper, we set out to review the state-of-the art of how ML has been explored to automate and streamline software testing and provide an overview of the research at the intersection of these two fields by conducting a systematic mapping study. We selected 48 primary studies. These selected studies were then categorized according to study type, testing activity, and ML algorithm employed to automate the testing activity. The results highlight the most widely used ML algorithms and identify several avenues for future research. We found that ML algorithms have been used mainly for test-case generation, refinement, and evaluation. Also, ML has been used to evaluate test oracle construction and to predict the cost of testing-related activities. The results of this paper outline the ML algorithms that are most commonly used to automate software-testing activities, helping researchers to understand the current state of research concerning ML applied to software testing. We also found that there is a need for better empirical studies examining how ML algorithms have been used to automate software-testing activities."
}, {
    "py/object": "data.DataClassPaper",
    "Title": "MACHINE LEARNING BASED METAMORPHIC TESTING FOR SOFTWARE QUALITY ASSESSMENT",
    "year": 2020,
    "ML_Techniques": "NB",
    "Category": "Testing",
    "Sub_category": ",Defect prediction,Test data/case generation,,Defect prediction",
    "Venue": "IJOR",
    "Link": "https://www.researchgate.net/publication/338867153_MACHINE_LEARNING_BASED_METAMORPHIC_TESTING_FOR_SOFTWARE_QUALITY_ASSESSMENT",
    "bibtex": "article{A.2020_104,\n    author = \"A., Josephine and Rao, Manjunatha Rao\",\n    year = \"2020\",\n    month = \"01\",\n    pages = \"\",\n    title = \"MACHINE LEARNING BASED METAMORPHIC TESTING FOR SOFTWARE QUALITY ASSESSMENT\",\n    journal = \"International Journal of Operational Research\"\n}\n\n",
    "abstract": "A software quality assessment is a disciplined examination of the software processes used by an organization, based on a process model. Metamorphic testing is used to verify the functional correctness of software in the absence of an ideal oracle. The ability to automatically detect failures and anomalies using MRs becomes difficult task in the day to day developing area. In this paper, the machine learning algorithm is introduced to automatically detect failures and anomalies using MRs can also provide hints for the construction of run-time self-correction mechanisms. The Naive bayes classification algorithm is used to improve the detection failures and anomalies to improve the self correction in the search engine results. The proposed technique acquires improved precision and recall when compared to conventional methods."
}, {
    "py/object": "data.DataClassPaper",
    "Title": "Machine learning based software fault prediction utilizing source code metrics",
    "year": 2018,
    "ML_Techniques": "DT, RF, NB, SVM, ANN, AB",
    "Category": "Testing",
    "Sub_category": "Defect prediction",
    "Venue": "ICCCS",
    "Link": "https://ieeexplore.ieee.org/document/8586805",
    "bibtex": "INPROCEEDINGS{Bhandari2018_105,\n    author = \"{Bhandari}, G. P. and {Gupta}, R.\",\n    booktitle = \"2018 IEEE 3rd International Conference on Computing, Communication and Security (ICCCS)\",\n    title = \"Machine learning based software fault prediction utilizing source code metrics\",\n    year = \"2018\",\n    volume = \"\",\n    number = \"\",\n    pages = \"40-45\",\n    doi = \"10.1109/CCCS.2018.8586805\"\n}\n\n",
    "abstract": "In the conventional techniques, it requires prior knowledge of faults or a special structure, which may not be realistic in practice while detecting the software faults. To deal with this problem, in this work, the proposed approach aims to predict the faults of the software utilizing the source code metrics. In addition, the purpose of this paper is to measure the capability of the software fault predictability in terms of accuracy, f-measure, precision, recall, Area Under ROC (Receiver Operating Characteristic) Curve (AUC). The study investigates the effect of the feature selection techniques for software fault prediction. As an experimental analysis, our proposed approach is validated from four publicly available datasets. The result predicted from Random Forest technique outperforms the other machine learning techniques in most of the cases. The effect of the feature selection techniques has increased the performance in few cases, however, in the maximum cases it is negligible or even the worse."
}, {
    "py/object": "data.DataClassPaper",
    "Title": "Machine learning for finding bugs: An initial report",
    "year": 2017,
    "ML_Techniques": "RF, RNN",
    "Category": "Testing",
    "Sub_category": ",Defect prediction",
    "Venue": "MaLTeSQuE",
    "Link": "https://ieeexplore.ieee.org/abstract/document/7882012",
    "bibtex": "INPROCEEDINGS{Chappelly2017_107,\n    author = \"{Chappelly}, T. and {Cifuentes}, C. and {Krishnan}, P. and {Gevay}, S.\",\n    booktitle = \"2017 IEEE Workshop on Machine Learning Techniques for Software Quality Evaluation (MaLTeSQuE)\",\n    title = \"Machine learning for finding bugs: An initial report\",\n    year = \"2017\",\n    volume = \"\",\n    number = \"\",\n    pages = \"21-26\",\n    doi = \"10.1109/MALTESQUE.2017.7882012\"\n}\n\n",
    "abstract": "Static program analysis is a technique to analyse code without executing it, and can be used to find bugs in source code. Many open source and commercial tools have been developed in this space over the past 20 years. Scalability and precision are of importance for the deployment of static code analysis tools - numerous false positives and slow runtime both make the tool hard to be used by development, where integration into a nightly build is the standard goal. This requires one to identify a suitable abstraction for the static analysis which is typically a manual process and can be expensive. In this paper we report our findings on using machine learning techniques to detect defects in C programs. We use three offthe- shelf machine learning techniques and use a large corpus of programs available for use in both the training and evaluation of the results. We compare the results produced by the machine learning technique against the Parfait static program analysis tool used internally at Oracle by thousands of developers. While on the surface the initial results were encouraging, further investigation suggests that the machine learning techniques we used are not suitable replacements for static program analysis tools due to low precision of the results. This could be due to a variety of reasons including not using domain knowledge such as the semantics of the programming language and lack of suitable data used in the training process."
}, {
    "py/object": "data.DataClassPaper",
    "Title": "Machine Learning in Value-Based Software Test Data Generation",
    "year": 2006,
    "ML_Techniques": "",
    "Category": "Testing",
    "Sub_category": "Test data/case generation",
    "Venue": "ICTAI",
    "Link": "https://ieeexplore.ieee.org/abstract/document/4031966",
    "bibtex": "INPROCEEDINGS{Zhang2006_108,\n    author = \"{Zhang}, D.\",\n    booktitle = \"2006 18th IEEE International Conference on Tools with Artificial Intelligence (ICTAI'06)\",\n    title = \"Machine Learning in Value-Based Software Test Data Generation\",\n    year = \"2006\",\n    volume = \"\",\n    number = \"\",\n    pages = \"732-736\",\n    doi = \"10.1109/ICTAI.2006.77\"\n}\n\n",
    "abstract": "Software engineering research and practice thus far are primarily conducted in a value-neutral setting where each artifact in software development such as requirement, use case, test case, and defect, is treated as equally important during a software system development process. There are a number of shortcomings of such value-neutral software engineering. Value-based software engineering is to integrate value considerations into the full range of existing and emerging software engineering principles and practices. Machine learning has been playing an increasingly important role in helping develop and maintain large and complex software systems. However, machine learning applications to software engineering have been largely confined to the value-neutral software engineering setting. In this paper, we advocate a shift to applying machine learning methods to value-based software engineering. We propose a framework for value-based software test data generation. The proposed framework incorporates some general principles in value-based software testing and can help improve return on investment"
}, {
    "py/object": "data.DataClassPaper",
    "Title": "Machine Learning Methods and Asymmetric Cost Function to Estimate Execution Effort of Software Testing",
    "year": 2010,
    "ML_Techniques": "ANN, SVM, LR, MLP",
    "Category": "Testing",
    "Sub_category": "Effort prediction",
    "Venue": "ICST",
    "Link": "https://ieeexplore.ieee.org/abstract/document/5477077",
    "bibtex": "INPROCEEDINGS{Silva2010_109,\n    author = \"e. {Silva}, D. G. and {Jino}, M. and d. {Abreu}, B. T.\",\n    booktitle = \"2010 Third International Conference on Software Testing, Verification and Validation\",\n    title = \"Machine Learning Methods and Asymmetric Cost Function to Estimate Execution Effort of Software Testing\",\n    year = \"2010\",\n    volume = \"\",\n    number = \"\",\n    pages = \"275-284\",\n    doi = \"10.1109/ICST.2010.46\"\n}\n\n",
    "abstract": "Planning and scheduling of testing activities play an important role for any independent test team that performs tests for different software systems, developed by different development teams. This work studies the application of machine learning tools and variable selection tools to solve the problem of estimating the execution effort of functional tests. An analysis of the test execution process is developed and experiments are performed on two real databases. The main contributions of this paper are the approach of selecting the significant variables for database synthesis and the use of an artificial neural network trained with an asymmetric cost function."
}, {
    "py/object": "data.DataClassPaper",
    "Title": "Machine Learning-based Software Testing: Towards a Classification Framework",
    "year": 2011,
    "ML_Techniques": "",
    "Category": "Testing",
    "Sub_category": ",Defect prediction",
    "Venue": "SEKE",
    "Link": "https://www.ee.ryerson.ca/~bagheri/papers/seke11.pdf",
    "bibtex": "inproceedings{Noorian2011_110,\n    author = \"Noorian, Mahdi and Bagheri, Ebrahim and Du, Wheichang\",\n    year = \"2011\",\n    month = \"01\",\n    pages = \"225-229\",\n    title = \"Machine Learning-based Software Testing: Towards a Classification Framework.\",\n    journal = \"SEKE 2011 - Proceedings of the 23rd International Conference on Software Engineering and Knowledge Engineering\"\n}\n\n",
    "abstract": "Software Testing (ST) processes attempt lo verify and validate the capability of a software system to meet Its required attributes and functionality. As software systems become more complex, the need for automated software testing methods emerges. Machine learning (ML) techniques have shown to be quite useful for this automation process. Various works have been presented In the Junction of ML and ST areas. The lack of general guidelines for applying appropriate learning methods for software testing purposes Is our major motivation In the current paper, in this paper, we Introduce a classification framework which can help to systematically review research work In the ML and ST domains. The proposed framework dimensions are defined using major characteristics of existing software testing and machine learning methods. Our framework am be used to effectively construct a concrete set of guidelines for choosing the most appropriate learning method and applying It to a distinct stage of the software testing life-cycle for automation purposes."
}, {
    "py/object": "data.DataClassPaper",
    "Title": "Near optimal machine learning based random test generation",
    "year": 2010,
    "ML_Techniques": "",
    "Category": "Testing",
    "Sub_category": "Test data/case generation",
    "Venue": "EWDTS",
    "Link": "https://ieeexplore.ieee.org/document/5742082",
    "bibtex": "INPROCEEDINGS{Shakeri2010_111,\n    author = \"{Shakeri}, N. and {Nemati}, N. and {Ahmadabadi}, M. N. and {Navabi}, Z.\",\n    booktitle = \"2010 East-West Design Test Symposium (EWDTS)\",\n    title = \"Near optimal machine learning based random test generation\",\n    year = \"2010\",\n    volume = \"\",\n    number = \"\",\n    pages = \"420-424\",\n    doi = \"10.1109/EWDTS.2010.5742082\"\n}\n\n",
    "abstract": "Optimized test generation techniques are required to overcome the ever increasing test cost of digital systems. In this work a near optimal machine learning based approach is proposed to improve the random test generation techniques. The improvements of the proposed method over previous works are exercised in an HDL environment and results for ISCAS benchmarks are reported."
}, {
    "py/object": "data.DataClassPaper",
    "Title": "Novel Applications of Machine Learning in Software Testing",
    "year": 2008,
    "ML_Techniques": "",
    "Category": "Testing",
    "Sub_category": "",
    "Venue": "SWQD",
    "Link": "https://ieeexplore.ieee.org/abstract/document/4601522",
    "bibtex": "INPROCEEDINGS{Briand2008_113,\n    author = \"{Briand}, L. C.\",\n    booktitle = \"2008 The Eighth International Conference on Quality Software\",\n    title = \"Novel Applications of Machine Learning in Software Testing\",\n    year = \"2008\",\n    volume = \"\",\n    number = \"\",\n    pages = \"3-10\",\n    doi = \"10.1109/QSIC.2008.29\"\n}\n\n",
    "abstract": "Machine learning techniques have long been used for various purposes in software engineering. This paper provides a brief overview of the state of the art and reports on a number of novel applications I was involved with in the area of software testing. Reflecting on this personal experience, I draw lessons learned and argue that more research should be performed in that direction as machine learning has the potential to significantly help in addressing some of the long-standing software testing problems."
}, {
    "py/object": "data.DataClassPaper",
    "Title": "On the Applicability of Machine LearningTechniques for Object Oriented SoftwareFault Prediction",
    "year": 2011,
    "ML_Techniques": "ANN, LB, RF, B, AB, NB, KS, LR",
    "Category": "Testing",
    "Sub_category": ",Defect prediction",
    "Venue": "SEIJ",
    "Link": "http://seij.dtu.ac.in/Paper%202.pdf",
    "bibtex": "INPROCEEDINGS{Briand2008_113,\n    author = \"{Briand}, L. C.\",\n    booktitle = \"2008 The Eighth International Conference on Quality Software\",\n    title = \"Novel Applications of Machine Learning in Software Testing\",\n    year = \"2008\",\n    volume = \"\",\n    number = \"\",\n    pages = \"3-10\",\n    doi = \"10.1109/QSIC.2008.29\"\n}\n\n",
    "abstract": "Software testing is a critical and essential part of software development that consumes maximum resources and effort. The construction of models to predict faulty classes can help and guide the testing community in predicting faulty classes in early phases of software development. It is important to analyze and compare the predictive accuracy of machine learning classifiers. The aim of this paper is to find the relation of object oriented metrics and fault proneness of a class. We have used seven machine learning and one logistic regression method in order to predict faulty classes. The results of our work are based on data set obtained from open source software. The results show that the predictive accuracy of machine learning technique LogitBoost is highest with AUC of 0.806."
}, {
    "py/object": "data.DataClassPaper",
    "Title": "Optimizing testing efforts based on change proneness through machine learning techniques",
    "year": 2014,
    "ML_Techniques": "LR, BN, NB, DT, RF, AB, B, KS",
    "Category": "Testing",
    "Sub_category": "Effort prediction",
    "Venue": "PIICON",
    "Link": "https://ieeexplore.ieee.org/document/7117742",
    "bibtex": "INPROCEEDINGS{Tripathi2014_115,\n    author = \"{Tripathi}, A. K. and {Sharma}, K.\",\n    booktitle = \"2014 6th IEEE Power India International Conference (PIICON)\",\n    title = \"Optimizing testing efforts based on change proneness through machine learning techniques\",\n    year = \"2014\",\n    volume = \"\",\n    number = \"\",\n    pages = \"1-4\",\n    doi = \"10.1109/POWERI.2014.7117742\"\n}\n\n",
    "abstract": "For any software organization, understanding the software quality is desirable in order to increase user experience of the software. When we talk about security software this factor becomes even more important. This paper aims to develop models for predicting the change proneness for object oriented system. The developed models may be used to predict the change prone classes at early phase of software development. Rigorous testing and allocation of some extra resources to those change prone classes may lead to better quality and it may also reduce our work at the maintenance phase. We apply one statistical and 10 machine learning techniques to predict the models. The results are analyzed from Receiver Operating Characteristics (ROC) analysis using Area under the Curve (AUC) obtained from ROC. Adaboost and Random forest method have shown the best result and hence, based on these results we can claim that quality models have a good relevance with Object Oriented systems."
}, {
    "py/object": "data.DataClassPaper",
    "Title": "PathPair2Vec: An AST path pair-based code representation method for defect prediction",
    "year": 2020,
    "ML_Techniques": "LSTM",
    "Category": "Testing",
    "Sub_category": "Defect prediction",
    "Venue": "COLA",
    "Link": "https://www.sciencedirect.com/science/article/pii/S2590118420300393",
    "bibtex": "article{Shi2020_116,\n    author = \"Shi, Ke and Lu, Yang and Chang, Jingfei and Wei, Zhen\",\n    title = \"PathPair2Vec: An AST path pair-based code representation method for defect prediction\",\n    journal = \"Journal of Computer Languages\",\n    volume = \"59\",\n    pages = \"100979\",\n    year = \"2020\",\n    issn = \"2590-1184\",\n    doi = \"https://doi.org/10.1016/j.cola.2020.100979\",\n    url = \"http://www.sciencedirect.com/science/article/pii/S2590118420300393\",\n    keywords = \"Defect prediction, AST path, Deep learning, Representation learning\",\n    abstract = \"Software project defect prediction (SDP) can predict the bug probability of software by their features and allocate their testing efforts. The existing software defect prediction methods can be divided into two categories: methods based on traditional handcrafted features and methods based on automatically made abstract features, especially those made by deep learning. The current research indicates that deep learning-based automatic features can achieve better performance than handcrafted features. Code2vec (Alon et al. 2019) is one of the best source code representation models, which leverages deep learning to learn automatic representations from code. In this paper, inspired by code2vec, we propose a new AST path pair-based source code representation method (PathPair2Vec) and apply it to software project defect prediction. We first propose the concept of the short path to describe each terminal node and its control logic. Then, we design a new sequence encoding method to code the different parts of the terminal node and its control logic. Finally, by pairs of short paths, we describe the semantic information of code and fuse them by an attention mechanism. Experiments on the PROMISE dataset show that our method improves the F1 score by 17.88\\% over the state-of-the-art SDP method, and the AST path pair-based source code representation can better identify the defect features of the source code.\"\n}\n\n",
    "abstract": "Software project defect prediction (SDP) can predict the bug probability of software by their features and allocate their testing efforts. The existing software defect prediction methods can be divided into two categories: methods based on traditional handcrafted features and methods based on automatically made abstract features, especially those made by deep learning. The current research indicates that deep learning-based automatic features can achieve better performance than handcrafted features.\n\nCode2vec (Alon et al. 2019) is one of the best source code representation models, which leverages deep learning to learn automatic representations from code. In this paper, inspired by code2vec, we propose a new AST path pair-based source code representation method (PathPair2Vec) and apply it to software project defect prediction. We first propose the concept of the short path to describe each terminal node and its control logic. Then, we design a new sequence encoding method to code the different parts of the terminal node and its control logic. Finally, by pairs of short paths, we describe the semantic information of code and fuse them by an attention mechanism. Experiments on the PROMISE dataset show that our method improves the F1 score by 17.88% over the state-of-the-art SDP method, and the AST path pair-based source code representation can better identify the defect features of the source code."
}, {
    "py/object": "data.DataClassPaper",
    "Title": "Predicting buggy changes inside an integrated development environment",
    "year": 2017,
    "ML_Techniques": "SVM",
    "Category": "Testing",
    "Sub_category": "Defect prediction",
    "Venue": "OOPSLA",
    "Link": "https://dl.acm.org/doi/10.1145/1328279.1328287",
    "bibtex": "article{Shi2020_116,\n    author = \"Shi, Ke and Lu, Yang and Chang, Jingfei and Wei, Zhen\",\n    title = \"PathPair2Vec: An AST path pair-based code representation method for defect prediction\",\n    journal = \"Journal of Computer Languages\",\n    volume = \"59\",\n    pages = \"100979\",\n    year = \"2020\",\n    issn = \"2590-1184\",\n    doi = \"https://doi.org/10.1016/j.cola.2020.100979\",\n    url = \"http://www.sciencedirect.com/science/article/pii/S2590118420300393\",\n    keywords = \"Defect prediction, AST path, Deep learning, Representation learning\",\n    abstract = \"Software project defect prediction (SDP) can predict the bug probability of software by their features and allocate their testing efforts. The existing software defect prediction methods can be divided into two categories: methods based on traditional handcrafted features and methods based on automatically made abstract features, especially those made by deep learning. The current research indicates that deep learning-based automatic features can achieve better performance than handcrafted features. Code2vec (Alon et al. 2019) is one of the best source code representation models, which leverages deep learning to learn automatic representations from code. In this paper, inspired by code2vec, we propose a new AST path pair-based source code representation method (PathPair2Vec) and apply it to software project defect prediction. We first propose the concept of the short path to describe each terminal node and its control logic. Then, we design a new sequence encoding method to code the different parts of the terminal node and its control logic. Finally, by pairs of short paths, we describe the semantic information of code and fuse them by an attention mechanism. Experiments on the PROMISE dataset show that our method improves the F1 score by 17.88\\% over the state-of-the-art SDP method, and the AST path pair-based source code representation can better identify the defect features of the source code.\"\n}\n\n",
    "abstract": "We present a tool that predicts whether the software under development inside an IDE has a bug. An IDE plugin performs this prediction, using the Change Classification technique to classify source code changes as buggy or clean during the editing session. Change Classification uses Support Vector Machines (SVM), a machine learning classifier algorithm, to classify changes to projects mined from their configuration management repository. This technique, besides being language independent and relatively accurate, can (a) classify a change immediately upon its completion and (b) use features extracted solely from the change delta (added, deleted) and the source code to predict buggy changes. Thus, integrating change classification within an IDE can predict potential bugs in the software as the developer edits the source code, ideally reducing the amount of time spent on fixing bugs later. To this end, we have developed a Change Classification plugin for Eclipse based on client-server architecture, described in this paper."
}, {
    "py/object": "data.DataClassPaper",
    "Title": "Predicting defect densities in source code files with decision tree learners",
    "year": 2006,
    "ML_Techniques": "DT",
    "Category": "Testing",
    "Sub_category": "Defect prediction",
    "Venue": "MSR",
    "Link": "https://dl.acm.org/doi/10.1145/1137983.1138012",
    "bibtex": "article{Shi2020_116,\n    author = \"Shi, Ke and Lu, Yang and Chang, Jingfei and Wei, Zhen\",\n    title = \"PathPair2Vec: An AST path pair-based code representation method for defect prediction\",\n    journal = \"Journal of Computer Languages\",\n    volume = \"59\",\n    pages = \"100979\",\n    year = \"2020\",\n    issn = \"2590-1184\",\n    doi = \"https://doi.org/10.1016/j.cola.2020.100979\",\n    url = \"http://www.sciencedirect.com/science/article/pii/S2590118420300393\",\n    keywords = \"Defect prediction, AST path, Deep learning, Representation learning\",\n    abstract = \"Software project defect prediction (SDP) can predict the bug probability of software by their features and allocate their testing efforts. The existing software defect prediction methods can be divided into two categories: methods based on traditional handcrafted features and methods based on automatically made abstract features, especially those made by deep learning. The current research indicates that deep learning-based automatic features can achieve better performance than handcrafted features. Code2vec (Alon et al. 2019) is one of the best source code representation models, which leverages deep learning to learn automatic representations from code. In this paper, inspired by code2vec, we propose a new AST path pair-based source code representation method (PathPair2Vec) and apply it to software project defect prediction. We first propose the concept of the short path to describe each terminal node and its control logic. Then, we design a new sequence encoding method to code the different parts of the terminal node and its control logic. Finally, by pairs of short paths, we describe the semantic information of code and fuse them by an attention mechanism. Experiments on the PROMISE dataset show that our method improves the F1 score by 17.88\\% over the state-of-the-art SDP method, and the AST path pair-based source code representation can better identify the defect features of the source code.\"\n}\n\n",
    "abstract": "With the advent of open source software repositories the data available for defect prediction in source files increased tremendously. Although traditional statistics turned out to derive reasonable results the sheer amount of data and the problem context of defect prediction demand sophisticated analysis such as provided by current data mining and machine learning techniques.In this work we focus on defect density prediction and present an approach that applies a decision tree learner on evolution data extracted from the Mozilla open source web browser project. The evolution data includes different source code, modification, and defect measures computed from seven recent Mozilla releases. Among the modification measures we also take into account the change coupling, a measure for the number of change-dependencies between source files. The main reason for choosing decision tree learners, instead of for example neural nets, was the goal of finding underlying rules which can be easily interpreted by humans. To find these rules, we set up a number of experiments to test common hypotheses regarding defects in software entities. Our experiments showed, that a simple tree learner can produce good results with various sets of input data."
}, {
    "py/object": "data.DataClassPaper",
    "Title": "Predicting metamorphic relations for testing scientific software: a machine learning approach using graph kernels",
    "year": 2016,
    "ML_Techniques": "SVM",
    "Category": "Testing",
    "Sub_category": "Defect prediction",
    "Venue": "STVR",
    "Link": "https://onlinelibrary.wiley.com/doi/abs/10.1002/stvr.1594",
    "bibtex": "article{Kanewala2016_120,\n    author = \"Kanewala, Upulee and Bieman, James M. and Ben-Hur, Asa\",\n    title = \"Predicting metamorphic relations for testing scientific software: a machine learning approach using graph kernels\",\n    journal = \"Software Testing, Verification and Reliability\",\n    volume = \"26\",\n    number = \"3\",\n    pages = \"245-269\",\n    keywords = \"metamorphic testing, metamorphic relations, graph kernels, support vector machines\",\n    doi = \"https://doi.org/10.1002/stvr.1594\",\n    url = \"https://onlinelibrary.wiley.com/doi/abs/10.1002/stvr.1594\",\n    eprint = \"https://onlinelibrary.wiley.com/doi/pdf/10.1002/stvr.1594\",\n    abstract = \"Summary Comprehensive, automated software testing requires an oracle to check whether the output produced by a test case matches the expected behaviour of the programme. But the challenges in creating suitable oracles limit the ability to perform automated testing in some programmes, and especially in scientific software. Metamorphic testing is a method for automating the testing process for programmes without test oracles. This technique operates by checking whether the programme behaves according to properties called metamorphic relations. A metamorphic relation describes the change in output when the input is changed in a prescribed way. Unfortunately, finding the metamorphic relations satisfied by a programme or function remains a labour-intensive task, which is generally performed by a domain expert or a programmer. In this work, we propose a machine learning approach for predicting metamorphic relations that uses a graph-based representation of a programme to represent control flow and data dependency information. In earlier work, we found that simple features derived from such graphs provide good performance. An analysis of the features used in this earlier work led us to explore the effectiveness of several representations of those graphs using the machine learning framework of graph kernels, which provide various ways of measuring similarity between graphs. Our results show that a graph kernel that evaluates the contribution of all paths in the graph has the best accuracy and that control flow information is more useful than data dependency information. The data used in this study are available for download at http://www.cs.colostate.edu/saxs/MRpred/functions.tar.gz to help researchers in further development of metamorphic relation prediction methods. Copyright \u00a9 2015 John Wiley \\\\& Sons, Ltd.\",\n    year = \"2016\"\n}\n\n",
    "abstract": "Comprehensive, automated software testing requires an oracle to check whether the output produced by a test case matches the expected behaviour of the programme. But the challenges in creating suitable oracles limit the ability to perform automated testing in some programmes, and especially in scientific software. Metamorphic testing is a method for automating the testing process for programmes without test oracles. This technique operates by checking whether the programme behaves according to properties called metamorphic relations. A metamorphic relation describes the change in output when the input is changed in a prescribed way. Unfortunately, finding the metamorphic relations satisfied by a programme or function remains a labour-intensive task, which is generally performed by a domain expert or a programmer. In this work, we propose a machine learning approach for predicting metamorphic relations that uses a graph-based representation of a programme to represent control flow and data dependency information. In earlier work, we found that simple features derived from such graphs provide good performance. An analysis of the features used in this earlier work led us to explore the effectiveness of several representations of those graphs using the machine learning framework of graph kernels, which provide various ways of measuring similarity between graphs. Our results show that a graph kernel that evaluates the contribution of all paths in the graph has the best accuracy and that control flow information is more useful than data dependency information. The data used in this study are available for download at http://www.cs.colostate.edu/saxs/MRpred/functions.tar.gz to help researchers in further development of metamorphic relation prediction methods. Copyright \u00a9 2015 John Wiley & Sons, Ltd."
}, {
    "py/object": "data.DataClassPaper",
    "Title": "Prediction & Assessment of Change Prone Classes Using Statistical & Machine Learning Techniques.",
    "year": 2017,
    "ML_Techniques": "LR, RF, AB, B, MLP, BN, NB, DT, LB",
    "Category": "Testing",
    "Sub_category": "Defect prediction",
    "Venue": "JIPS",
    "Link": "https://www.researchgate.net/publication/320045176_Prediction_Assessment_of_Change_Prone_Classes_Using_Statistical_Machine_Learning_Techniques",
    "bibtex": "article{Kanewala2016_120,\n    author = \"Kanewala, Upulee and Bieman, James M. and Ben-Hur, Asa\",\n    title = \"Predicting metamorphic relations for testing scientific software: a machine learning approach using graph kernels\",\n    journal = \"Software Testing, Verification and Reliability\",\n    volume = \"26\",\n    number = \"3\",\n    pages = \"245-269\",\n    keywords = \"metamorphic testing, metamorphic relations, graph kernels, support vector machines\",\n    doi = \"https://doi.org/10.1002/stvr.1594\",\n    url = \"https://onlinelibrary.wiley.com/doi/abs/10.1002/stvr.1594\",\n    eprint = \"https://onlinelibrary.wiley.com/doi/pdf/10.1002/stvr.1594\",\n    abstract = \"Summary Comprehensive, automated software testing requires an oracle to check whether the output produced by a test case matches the expected behaviour of the programme. But the challenges in creating suitable oracles limit the ability to perform automated testing in some programmes, and especially in scientific software. Metamorphic testing is a method for automating the testing process for programmes without test oracles. This technique operates by checking whether the programme behaves according to properties called metamorphic relations. A metamorphic relation describes the change in output when the input is changed in a prescribed way. Unfortunately, finding the metamorphic relations satisfied by a programme or function remains a labour-intensive task, which is generally performed by a domain expert or a programmer. In this work, we propose a machine learning approach for predicting metamorphic relations that uses a graph-based representation of a programme to represent control flow and data dependency information. In earlier work, we found that simple features derived from such graphs provide good performance. An analysis of the features used in this earlier work led us to explore the effectiveness of several representations of those graphs using the machine learning framework of graph kernels, which provide various ways of measuring similarity between graphs. Our results show that a graph kernel that evaluates the contribution of all paths in the graph has the best accuracy and that control flow information is more useful than data dependency information. The data used in this study are available for download at http://www.cs.colostate.edu/saxs/MRpred/functions.tar.gz to help researchers in further development of metamorphic relation prediction methods. Copyright \u00a9 2015 John Wiley \\\\& Sons, Ltd.\",\n    year = \"2016\"\n}\n\n",
    "abstract": "Software today has become an inseparable part of our life. In order to achieve the ever demanding needs of customers, it has to rapidly evolve and include a number of changes. In this paper, our aim is to study the relationship of object oriented metrics with change proneness attribute of a class. Prediction models based on this study can help us in identifying change prone classes of a software. We can then focus our efforts on these change prone classes during testing to yield a better quality software. Previously, researchers have used statistical methods for predicting change prone classes. But machine learning methods are rarely used for identification of change prone classes. In our study, we evaluate and compare the performances of ten machine learning methods with the statistical method. This evaluation is based on two open source software systems developed in Java language. We also validated the developed prediction models using other software data set in the same domain (3D modelling). The performance of the predicted models was evaluated using receiver operating characteristic analysis. The results indicate that the machine learning methods are at par with the statistical method for prediction of change prone classes. Another analysis showed that the models constructed for a software can also be used to predict change prone nature of classes of another software in the same domain. This study would help developers in performing effective regression testing at low cost and effort. It will also help the developers to design an effective model that results in less change prone classes, hence better maintenance."
}, {
    "py/object": "data.DataClassPaper",
    "Title": "Sample-based software defect prediction with active and semi-supervised learning",
    "year": 2012,
    "ML_Techniques": "CoForest-RF, DT, LOG, NB",
    "Category": "Testing",
    "Sub_category": "Defect prediction",
    "Venue": "ASE",
    "Link": "https://link.springer.com/article/10.1007/s10515-011-0092-1",
    "bibtex": "article{Li2011_124,\n    author = \"Li, M. and Zhang, H. and Wu, Rongxin and Zhou, Z.\",\n    title = \"Sample-based software defect prediction with active and semi-supervised learning\",\n    journal = \"Automated Software Engineering\",\n    year = \"2011\",\n    volume = \"19\",\n    pages = \"201-230\"\n}\n\n",
    "abstract": "Software defect prediction can help us better understand and control software quality. Current defect prediction techniques are mainly based on a sufficient amount of historical project data. However, historical data is often not available for new projects and for many organizations. In this case, effective defect prediction is difficult to achieve. To address this problem, we propose sample-based methods for software defect prediction. For a large software system, we can select and test a small percentage of modules, and then build a defect prediction model to predict defect-proneness of the rest of the modules. In this paper, we describe three methods for selecting a sample: random sampling with conventional machine learners, random sampling with a semi-supervised learner and active sampling with active semi-supervised learner. To facilitate the active sampling, we propose a novel active semi-supervised learning method ACoForest which is able to sample the modules that are most helpful for learning a good prediction model. Our experiments on PROMISE datasets show that the proposed methods are effective and have potential to be applied to industrial practice."
}, {
    "py/object": "data.DataClassPaper",
    "Title": "Shinobi: A Novel Approach for Context-Driven Testing (CDT) Using Heuristics and Machine Learning for Web Applications",
    "year": 2019,
    "ML_Techniques": "FR-CNN",
    "Category": "Testing",
    "Sub_category": ",Test data/case generation",
    "Venue": "INISCOM",
    "Link": "https://link.springer.com/chapter/10.1007/978-3-030-05873-9_8",
    "bibtex": "InProceedings{Nguyen2019_126,\n    author = \"Nguyen, Duc-Man and Do, Hoang-Nhat and Huynh, Quyet-Thang and Vo, Dinh-Thien and Ha, Nhu-Hang\",\n    editor = \"Duong, Trung Q and Vo, Nguyen-Son\",\n    title = \"Shinobi: A Novel Approach for Context-Driven Testing (CDT) Using Heuristics and Machine Learning for Web Applications\",\n    booktitle = \"Industrial Networks and Intelligent Systems\",\n    year = \"2019\",\n    publisher = \"Springer International Publishing\",\n    address = \"Cham\",\n    pages = \"86--102\",\n    abstract = \"Context-Driven Testing is widely used in the Agile World. It optimizes the testing value and provides an effective way to detect unexpected bugs. Context-driven testing requires the testing team to leverage the full knowledge and skills to solve the problem or to make a decision. In this paper, we propose an approach for Context-Driven Testing using Heuristics and Machine Learning for web applications with a framework called Shinobi. The framework can detect web controls, suggest a set of heuristic values, recognize the meaningful input data, and detect changes of application to recommend test ideas. In the context of improvising the testing performance, Shinobi is considered as Test Assistant for context-driven testers. Shinobi is a PoC to prove the idea of using Machine Learning to develop a Virtual Tester to improve the test quality and train junior testers as responsible testers. The framework is well integrated into all eCommerce projects at MeU Solutions which is a value-added advantage for testing.\",\n    isbn = \"978-3-030-05873-9\"\n}\n\n",
    "abstract": "Context-Driven Testing is widely used in the Agile World. It optimizes the testing value and provides an effective way to detect unexpected bugs. Context-driven testing requires the testing team to leverage the full knowledge and skills to solve the problem or to make a decision. In this paper, we propose an approach for Context-Driven Testing using Heuristics and Machine Learning for web applications with a framework called Shinobi. The framework can detect web controls, suggest a set of heuristic values, recognize the meaningful input data, and detect changes of application to recommend test ideas. In the context of improvising the testing performance, Shinobi is considered as Test Assistant for context-driven testers. Shinobi is a PoC to prove the idea of using Machine Learning to develop a Virtual Tester to improve the test quality and train junior testers as responsible testers. The framework is well integrated into all eCommerce projects at MeU Solutions which is a value-added advantage for testing."
}, {
    "py/object": "data.DataClassPaper",
    "Title": "Software Bug Prediction using Machine Learning Approach",
    "year": 2018,
    "ML_Techniques": "ANN, NB, DT",
    "Category": "Testing",
    "Sub_category": "Defect prediction",
    "Venue": "IJACSA",
    "Link": "https://www.researchgate.net/profile/Mustafa_Hammad/publication/323536716_Software_Bug_Prediction_using_Machine_Learning_Approach/links/5c17cdec92851c39ebf51720/Software-Bug-Prediction-using-Machine-Learning-Approach.pdf",
    "bibtex": "article{Hammouri2018_127,\n    author = \"Hammouri, Awni and Hammad, Mustafa and Alnabhan, Mohammad and Alsarayrah, Fatima\",\n    year = \"2018\",\n    month = \"01\",\n    pages = \"\",\n    title = \"Software Bug Prediction using Machine Learning Approach\",\n    volume = \"9\",\n    journal = \"International Journal of Advanced Computer Science and Applications\",\n    doi = \"10.14569/IJACSA.2018.090212\"\n}\n\n",
    "abstract": "Software Bug Prediction (SBP) is an important\nissue in software development and maintenance processes, which\nconcerns with the overall of software successes. This is because\npredicting the software faults in earlier phase improves the\nsoftware quality, reliability, efficiency and reduces the software\ncost. However, developing robust bug prediction model is a\nchallenging task and many techniques have been proposed in the\nliterature. This paper presents a software bug prediction model\nbased on machine learning (ML) algorithms. Three supervised\nML algorithms have been used to predict future software faults\nbased on historical data. These classifiers are Na\u00efve Bayes (NB),\nDecision Tree (DT) and Artificial Neural Networks (ANNs). The\nevaluation process showed that ML algorithms can be used\neffectively with high accuracy rate. Furthermore, a comparison\nmeasure is applied to compare the proposed prediction model\nwith other approaches. The collected results showed that the ML\napproach has a better performance."
}, {
    "py/object": "data.DataClassPaper",
    "Title": "Software code analysis using ensemble learning techniques",
    "year": 2019,
    "ML_Techniques": "GB, RF, B, V",
    "Category": "Testing",
    "Sub_category": ",Defect prediction",
    "Venue": "AISS",
    "Link": "https://dl.acm.org/doi/10.1145/3373477.3373486",
    "bibtex": "article{Hammouri2018_127,\n    author = \"Hammouri, Awni and Hammad, Mustafa and Alnabhan, Mohammad and Alsarayrah, Fatima\",\n    year = \"2018\",\n    month = \"01\",\n    pages = \"\",\n    title = \"Software Bug Prediction using Machine Learning Approach\",\n    volume = \"9\",\n    journal = \"International Journal of Advanced Computer Science and Applications\",\n    doi = \"10.14569/IJACSA.2018.090212\"\n}\n\n",
    "abstract": "Ensuing the advent of advancements in software systems, the probability of them containing high severity defects is exponentially on the rise. With each technological addition, the complexity of software is increasing. Reproduction and rectification of a defect requires time and effort. Current state of the art analysis tools cater to the investigation of static aspects of a production level code. However, it is imperative to assess the dynamic development process of a system so as to be able to timely detect erroneous components early on in the development life cycle of a software. A novel automated defect prediction feature enhancement is proposed that analyses the static structure of the current code and state of the software in past releases to extract relevant static and dynamic feature sets. Data generated is modelled for defect trends in the future release of the software by four ensemble classifiers. Results demonstrate the superiority of Voting algorithm for the problem of defect prediction.\n"
}, {
    "py/object": "data.DataClassPaper",
    "Title": "Software Defect Identification Using Machine Learning Techniques",
    "year": 2006,
    "ML_Techniques": "DT, MLP",
    "Category": "Testing",
    "Sub_category": ",Defect prediction",
    "Venue": "EUROMICRO",
    "Link": "https://ieeexplore.ieee.org/abstract/document/1690146",
    "bibtex": "INPROCEEDINGS{Ceylan2006_129,\n    author = \"{Ceylan}, E. and {Kutlubay}, F. O. and {Bener}, A. B.\",\n    booktitle = \"32nd EUROMICRO Conference on Software Engineering and Advanced Applications (EUROMICRO'06)\",\n    title = \"Software Defect Identification Using Machine Learning Techniques\",\n    year = \"2006\",\n    volume = \"\",\n    number = \"\",\n    pages = \"240-247\",\n    doi = \"10.1109/EUROMICRO.2006.56\"\n}\n\n",
    "abstract": "Software engineering is a tedious job that includes people, tight deadlines and limited budgets. Delivering what customer wants involves minimizing the defects in the programs. Hence, it is important to establish quality measures early on in the project life cycle. The main objective of this research is to analyze problems in software code and propose a model that will help catching those problems earlier in the project life cycle. Our proposed model uses machine learning methods. Principal component analysis is used for dimensionality reduction, and decision tree, multi layer perceptron and radial basis functions are used for defect prediction. The experiments in this research are carried out with different software metric datasets that are obtained from real-life projects of three big software companies in Turkey. We can say that, the improved method that we proposed brings out satisfactory results in terms of defect prediction"
}, {
    "py/object": "data.DataClassPaper",
    "Title": "Software defect prediction analysis using machine learning algorithms",
    "year": 2017,
    "ML_Techniques": "ANN, PSO, DT, NB, SVM",
    "Category": "Testing",
    "Sub_category": "Defect prediction",
    "Venue": "Confluence",
    "Link": "https://ieeexplore.ieee.org/abstract/document/7943255",
    "bibtex": "INPROCEEDINGS{Singh2017_130,\n    author = \"{Singh}, P. and {Chug}, A.\",\n    booktitle = \"2017 7th International Conference on Cloud Computing, Data Science Engineering - Confluence\",\n    title = \"Software defect prediction analysis using machine learning algorithms\",\n    year = \"2017\",\n    volume = \"\",\n    number = \"\",\n    pages = \"775-781\",\n    doi = \"10.1109/CONFLUENCE.2017.7943255\"\n}\n\n",
    "abstract": "Software Quality is the most important aspect of a software. Software Defect Prediction can directly affect quality and has achieved significant popularity in last few years. Defective software modules have a massive impact over software's quality leading to cost overruns, delayed timelines and much higher maintenance costs. In this paper we have analyzed the most popular and widely used Machine Learning algorithms - ANN (Artificial Neural Network), PSO(P article Swarm Optimization), DT (Decision Trees), NB(Naive Bayes) and LC (Linear classifier). The five algorithms were analyzed using KEEL tool and validated using k-fold cross validation technique. Datasets used in this research were obtained from open source NASA Promise dataset repository. Seven datasets were selected for defect prediction analysis. Classification was performed on these 7 datasets and validated using 10 fold cross validation. The results demonstrated the dominance of Linear Classifier over other algorithms in terms of defect prediction accuracy."
}, {
    "py/object": "data.DataClassPaper",
    "Title": "Software Defect Prediction Using Machine Learning Techniques",
    "year": 2020,
    "ML_Techniques": "NB, ANN, SVM, RF",
    "Category": "Testing",
    "Sub_category": "Defect prediction",
    "Venue": "ICOEI",
    "Link": "https://ieeexplore.ieee.org/document/9142909",
    "bibtex": "INPROCEEDINGS{Prabha2020_133,\n    author = \"{Prabha}, C. L. and {Shivakumar}, N.\",\n    booktitle = \"2020 4th International Conference on Trends in Electronics and Informatics (ICOEI)(48184)\",\n    title = \"Software Defect Prediction Using Machine Learning Techniques\",\n    year = \"2020\",\n    volume = \"\",\n    number = \"\",\n    pages = \"728-733\",\n    doi = \"10.1109/ICOEI48184.2020.9142909\"\n}\n\n",
    "abstract": "Software defect prediction provides development groups with observable outcomes while contributing to industrial results and development faults predicting defective code areas can help developers identify bugs and organize their test activities. The percentage of classification providing the proper prediction is essential for early identification. Moreover, software-defected data sets are supported and at least partially recognized due to their enormous dimension. This Problem is handled by hybridized approach that includes the PCA, randomforest, na\u00efve bayes and the SVM Software Framework, which as five datasets as PC3, MW1, KC1, PC4, and CM1, are listed in software analysis using the weka simulation tool. A systematic research analysis is conducted in which parameters of confusion, precision, recall, recognition accuracy, etc Are measured as well as compared with the prevailing schemes. The analytical analysis indicates that the proposed approach will provide more useful solutions for device defects prediction."
}, {
    "py/object": "data.DataClassPaper",
    "Title": "Software defect prediction using supervised learning algorithm and unsupervised learning algorithm",
    "year": 2013,
    "ML_Techniques": "DT, RF, KM, HC",
    "Category": "Testing",
    "Sub_category": "Defect prediction",
    "Venue": "JSEA",
    "Link": "https://ieeexplore.ieee.org/document/6832328",
    "bibtex": "INPROCEEDINGS{Chug2013_134,\n    author = \"{Chug}, A. and {Dhall}, S.\",\n    booktitle = \"Confluence 2013: The Next Generation Information Technology Summit (4th International Conference)\",\n    title = \"Software defect prediction using supervised learning algorithm and unsupervised learning algorithm\",\n    year = \"2013\",\n    volume = \"\",\n    number = \"\",\n    pages = \"173-179\",\n    doi = \"10.1049/cp.2013.2313\"\n}\n\n",
    "abstract": "Software defect prediction has recently attracted attention of many software quality researchers. One of the major areas in current project management software is to effectively utilize resources to make meaningful impact on time and cost. A pragmatic assessment of metrics is essential in order to comprehend the quality of software and to ensure corrective measures. Software defect prediction methods are majorly used to study the impact areas in software using different techniques which comprises of neural network (NN) techniques, clustering techniques, statistical method and machine learning methods. These techniques of Data mining are applied in building software defect prediction models which improve the software quality. The aim of this paper is to propose various classification and clustering methods with an objective to predict software defect. To predict software defect we analyzed classification and clustering techniques. The performance of three data mining classifier algorithms named J48, Random Forest, and Naive Bayesian Classifier (NBC) are evaluated based on various criteria like ROC, Precision, MAE, RAE etc. Clustering technique is then applied on the data set using k-means, Hierarchical Clustering and Make Density Based Clustering algorithm. Evaluation of results for clustering is based on criteria like Time Taken, Cluster Instance, Number of Iterations, Incorrectly Clustered Instance and Log Likelihood etc. A thorough exploration of ten real time defect datasets of NASA[1] software project, followed by various applications on them finally results in defect prediction."
}, {
    "py/object": "data.DataClassPaper",
    "Title": "Software Defect Prediction via Transformer",
    "year": 2020,
    "ML_Techniques": "LOG, TF",
    "Category": "Testing",
    "Sub_category": "Defect prediction",
    "Venue": "ITNEC",
    "Link": "https://ieeexplore.ieee.org/document/9084745",
    "bibtex": "INPROCEEDINGS{Zhang2020_135,\n    author = \"{Zhang}, Q. and {Wu}, B.\",\n    booktitle = \"2020 IEEE 4th Information Technology, Networking, Electronic and Automation Control Conference (ITNEC)\",\n    title = \"Software Defect Prediction via Transformer\",\n    year = \"2020\",\n    volume = \"1\",\n    number = \"\",\n    pages = \"874-879\",\n    doi = \"10.1109/ITNEC48623.2020.9084745\"\n}\n\n",
    "abstract": "In order to enhance software reliability, software defect prediction is used to predict potential defects and to improve efficiency of software examination. Traditional defect prediction methods mainly focus on design static code metrics, and building machine learning classifiers to predict pieces of code that potentially defective. However, these manual extracted features do not contain syntactic and semantic information of programs. These information is much more important than those metrics and can improve the accuracy of defect prediction. In this paper, we propose a framework called software defect prediction via transformer (DP-Transformer) which capture syntactic and semantic features from programs and use them to improve defect prediction. Specifically, we first parse source code into ASTs and then select representative nodes from ASTs to form token vectors. Then we employ mapping and word embedding to convert token vectors into numerical vectors and send the numerical vectors to transformer. Transformer will automatically extract syntactic and semantic features and eventually feed these features into a Logistic Regression classifier. We evaluate our method on seven open-source Java projects with certain labels and take F-measure as evaluation criteria. The experimental results show that averagely, the proposed DP-Transformer improves the state-of-art method by 8%."
}, {
    "py/object": "data.DataClassPaper",
    "Title": "Software fault classification using extreme learning machine: a cognitive approach",
    "year": 2018,
    "ML_Techniques": "ELM, SVM",
    "Category": "Testing",
    "Sub_category": ",Defect prediction",
    "Venue": "Evolutionary Intelligence",
    "Link": "https://link.springer.com/article/10.1007/s12065-018-0193-x",
    "bibtex": "article{Pandey2018_137,\n    author = \"Pandey, A. K. and Gupta, Manjari\",\n    title = \"Software fault classification using extreme learning machine: a cognitive approach\",\n    journal = \"Evolutionary Intelligence\",\n    year = \"2018\",\n    pages = \"1-8\"\n}\n\n",
    "abstract": "The software fault classification is very crucial in the development of reliable and high-quality software products. The fault classification allows determining and concentrating on fault software modules for early prediction of fault in time. As a result, it saves the time and money of the industry. Generally, various metrics are generated to represent the fault. But, selecting the dominant metrics from the available set is a challenge. Therefore, in this paper, a sequential forward search (SFS) with extreme learning machine (ELM) approach has used for fault classification. The number of features available in the metrics are selected to represent the fault using SFS and operated on ELM to verify the performance of software fault classification. Also, various activation functions of ELM have tested for the proposed work to identify the best model. The experimental result demonstrates that ELM with radial basis function achieves the good results compared to other activation function. Also, the proposed method has shown good results in comparison to support vector machine."
}, {
    "py/object": "data.DataClassPaper",
    "Title": "Software metrics for fault prediction using machine learning approaches: A literature review with PROMISE repository dataset",
    "year": 2017,
    "ML_Techniques": "",
    "Category": "Testing",
    "Sub_category": "Defect prediction",
    "Venue": "CyberneticsCom",
    "Link": "https://ieeexplore.ieee.org/abstract/document/8311708",
    "bibtex": "INPROCEEDINGS{Meiliana2017_138,\n    author = \"{Meiliana} and {Karim}, S. and {Warnars}, H. L. H. S. and {Gaol}, F. L. and {Abdurachman}, E. and {Soewito}, B.\",\n    booktitle = \"2017 IEEE International Conference on Cybernetics and Computational Intelligence (CyberneticsCom)\",\n    title = \"Software metrics for fault prediction using machine learning approaches: A literature review with PROMISE repository dataset\",\n    year = \"2017\",\n    volume = \"\",\n    number = \"\",\n    pages = \"19-23\",\n    doi = \"10.1109/CYBERNETICSCOM.2017.8311708\"\n}\n\n",
    "abstract": "Software testing is an important and critical phase of software development life cycle to find software faults or defects and then correct those faults. However, testing process is a time-consuming activity that requires good planning and a lot of resources. Therefore, technique and methodology for predicting the testing effort is important process prior the testing process to significantly increase efficiency of time, effort and cost usage. Correspond to software metric usage for measuring software quality, software metric can be used to identify the faulty modules in software. Furthermore, implementing machine learning technique will allow computer to \u201clearn\u201d and able to predict the fault prone modules. Research in this field has become a hot issue for more than ten years ago. However, considering the high importance of software quality with support of machine learning methods development, this research area is still being highlighted until this year. In this paper, a survey of various software metric used for predicting software fault by using machine learning algorithm is examined. According to our review, this is the first study of software fault prediction that focuses to PROMISE repository dataset usage. Some conducted experiments from PROMISE repository dataset are compared to contribute a consensus on what constitute effective software metrics and machine learning method in software fault prediction."
}, {
    "py/object": "data.DataClassPaper",
    "Title": "Software visualization and deep transfer learning for effective software defect prediction",
    "year": 2020,
    "ML_Techniques": "CNN",
    "Category": "Testing",
    "Sub_category": "Defect prediction",
    "Venue": "ICSE",
    "Link": "https://dl.acm.org/doi/10.1145/3377811.3380389",
    "bibtex": "INPROCEEDINGS{Meiliana2017_138,\n    author = \"{Meiliana} and {Karim}, S. and {Warnars}, H. L. H. S. and {Gaol}, F. L. and {Abdurachman}, E. and {Soewito}, B.\",\n    booktitle = \"2017 IEEE International Conference on Cybernetics and Computational Intelligence (CyberneticsCom)\",\n    title = \"Software metrics for fault prediction using machine learning approaches: A literature review with PROMISE repository dataset\",\n    year = \"2017\",\n    volume = \"\",\n    number = \"\",\n    pages = \"19-23\",\n    doi = \"10.1109/CYBERNETICSCOM.2017.8311708\"\n}\n\n",
    "abstract": "Software defect prediction aims to automatically locate defective code modules to better focus testing resources and human effort. Typically, software defect prediction pipelines are comprised of two parts: the first extracts program features, like abstract syntax trees, by using external tools, and the second applies machine learning-based classification models to those features in order to predict defective modules. Since such approaches depend on specific feature extraction tools, machine learning classifiers have to be custom-tailored to effectively build most accurate models.\n\nTo bridge the gap between deep learning and defect prediction, we propose an end-to-end framework which can directly get prediction results for programs without utilizing feature-extraction tools. To that end, we first visualize programs as images, apply the self-attention mechanism to extract image features, use transfer learning to reduce the difference in sample distributions between projects, and finally feed the image files into a pre-trained, deep learning model for defect prediction. Experiments with 10 open source projects from the PROMISE dataset show that our method can improve cross-project and within-project defect prediction. Our code and data pointers are available at https://zenodo.org/record/3373409#.XV0Oy5Mza35."
}, {
    "py/object": "data.DataClassPaper",
    "Title": "Structural Statistical Software Testing with Active Learning in a Graph",
    "year": 2008,
    "ML_Techniques": "VSL",
    "Category": "Testing",
    "Sub_category": ",Test data/case generation",
    "Venue": "ILP",
    "Link": "https://link.springer.com/chapter/10.1007/978-3-540-78469-2_9",
    "bibtex": "InProceedings{Baskiotis2008_141,\n    author = \"Baskiotis, Nicolas and Sebag, Michele\",\n    editor = \"Blockeel, Hendrik and Ramon, Jan and Shavlik, Jude and Tadepalli, Prasad\",\n    title = \"Structural Statistical Software Testing with Active Learning in a Graph\",\n    booktitle = \"Inductive Logic Programming\",\n    year = \"2008\",\n    publisher = \"Springer Berlin Heidelberg\",\n    address = \"Berlin, Heidelberg\",\n    pages = \"49--62\",\n    abstract = \"Structural Statistical Software Testing (SSST) exploits the control flow graph of the program being tested to construct test cases. Specifically, SSST exploits the feasible paths in the control flow graph, that is, paths which are actually exerted for some values of the program input; the limitation is that feasible paths are massively outnumbered by infeasible ones. Addressing this limitation, this paper presents an active learning algorithm aimed at sampling the feasible paths in the control flow graph. The difficulty comes from both the few feasible paths initially available and the nature of the feasible path concept, reflecting the long-range dependencies among the nodes of the control flow graph. The proposed approach is based on a frugal representation inspired from Parikh maps, and on the identification of the conjunctive subconcepts in the feasible path concept within a Disjunctive Version Space framework. Experimental validation on real-world and artificial problems demonstrates significant improvements compared to the state of the art.\",\n    isbn = \"978-3-540-78469-2\"\n}\n\n",
    "abstract": "Structural Statistical Software Testing (SSST) exploits the control flow graph of the program being tested to construct test cases. Specifically, SSST exploits the feasible paths in the control flow graph, that is, paths which are actually exerted for some values of the program input; the limitation is that feasible paths are massively outnumbered by infeasible ones. Addressing this limitation, this paper presents an active learning algorithm aimed at sampling the feasible paths in the control flow graph. The difficulty comes from both the few feasible paths initially available and the nature of the feasible path concept, reflecting the long-range dependencies among the nodes of the control flow graph. The proposed approach is based on a frugal representation inspired from Parikh maps, and on the identification of the conjunctive subconcepts in the feasible path concept within a Disjunctive Version Space framework. Experimental validation on real-world and artificial problems demonstrates significant improvements compared to the state of the art."
}, {
    "py/object": "data.DataClassPaper",
    "Title": "The State of Machine Learning Methodology in Software Fault Prediction",
    "year": 2012,
    "ML_Techniques": "",
    "Category": "Testing",
    "Sub_category": "Defect prediction",
    "Venue": "ICMLA",
    "Link": "https://ieeexplore.ieee.org/document/6406713",
    "bibtex": "INPROCEEDINGS{Hall2012_145,\n    author = \"{Hall}, T. and {Bowes}, D.\",\n    booktitle = \"2012 11th International Conference on Machine Learning and Applications\",\n    title = \"The State of Machine Learning Methodology in Software Fault Prediction\",\n    year = \"2012\",\n    volume = \"2\",\n    number = \"\",\n    pages = \"308-313\",\n    doi = \"10.1109/ICMLA.2012.226\"\n}\n\n",
    "abstract": "The aim of this paper is to investigate the quality of methodology in software fault prediction studies using machine learning. Over two hundred studies of fault prediction have been published in the last 10 years. There is evidence to suggest that the quality of methodology used in some of these studies does not allow us to have confidence in the predictions reported by them. We evaluate the machine learning methodology used in 21 fault prediction studies. All of these studies use NASA data sets. We score each study from 1 to 10 in terms of the quality of their machine learning methodology (e.g. whether or not studies report randomising their cross validation folds). Only 10 out of the 21 studies scored 5 or more out of 10. Furthermore 1 study scored only 1 out of 10. When we plot these scores over time there is no evidence that the quality of machine learning methodology is better in recent studies. Our results suggest that there remains much to be done by both researchers and reviewers to improve the quality of machine learning methodology used in software fault prediction. We conclude that the results reported in some studies need to be treated with caution."
}, {
    "py/object": "data.DataClassPaper",
    "Title": "Transfer Learning Code Vectorizer based Machine Learning Models for Software Defect Prediction",
    "year": 2020,
    "ML_Techniques": "SVM, RF, ANN, DT, GNB, LR, CNN",
    "Category": "Testing",
    "Sub_category": "Defect prediction",
    "Venue": "ComPE",
    "Link": "https://ieeexplore.ieee.org/document/9200076",
    "bibtex": "INPROCEEDINGS{Singh2020_146,\n    author = \"{Singh}, R. and {Singh}, J. and {Gill}, M. S. and {Malhotra}, R. and {Garima}\",\n    booktitle = \"2020 International Conference on Computational Performance Evaluation (ComPE)\",\n    title = \"Transfer Learning Code Vectorizer based Machine Learning Models for Software Defect Prediction\",\n    year = \"2020\",\n    volume = \"\",\n    number = \"\",\n    pages = \"497-502\",\n    doi = \"10.1109/ComPE49325.2020.9200076\"\n}\n\n",
    "abstract": "Software development life cycle comprises of planning, design, implementation, testing and eventually, deployment. Software defect prediction can be used in the initial stages of the development life cycle for identifying defective modules. Researchers have devised various methods that can be used for effective software defect prediction. The prediction of the presence of defects or bugs in a software module can facilitate the testing process as it would enable developers and testers to allocate their time and resources on modules that are prone to defects. Transfer learning can be used for transferring knowledge obtained from one domain into the other. In this paper, we propose Transfer Learning Code Vectorizer, a novel method that derives features from the text of the software source code itself and uses those features for defect prediction. We focus on the software code and convert it into vectors using a pre-trained deep learning language model. These code vectors are subsequently passed through machine and deep learning models. Further, we compare the results of using deep learning on the text of the software code versus the usage of software metrics for prediction of defects. In terms of weighted F1 scores, the experiments show that applying the proposed TLCV method outperforms the other machine learning techniques by 9.052%."
}, {
    "py/object": "data.DataClassPaper",
    "Title": "Transfer learning for cross-company software defect prediction",
    "year": 2012,
    "ML_Techniques": "NB, TNB, KNN",
    "Category": "Testing",
    "Sub_category": "Defect prediction",
    "Venue": "IST",
    "Link": "https://www.sciencedirect.com/science/article/abs/pii/S0950584911001996",
    "bibtex": "article{Ma2012_147,\n    author = \"Ma, Ying and Luo, Guangchun and Zeng, Xue and Chen, Aiguo\",\n    title = \"Transfer learning for cross-company software defect prediction\",\n    journal = \"Information and Software Technology\",\n    volume = \"54\",\n    number = \"3\",\n    pages = \"248 - 256\",\n    year = \"2012\",\n    issn = \"0950-5849\",\n    doi = \"https://doi.org/10.1016/j.infsof.2011.09.007\",\n    url = \"http://www.sciencedirect.com/science/article/pii/S0950584911001996\",\n    keywords = \"Machine learning, Software defect prediction, Transfer learning, Naive Bayes, Different distribution\",\n    abstract = \"Context Software defect prediction studies usually built models using within-company data, but very few focused on the prediction models trained with cross-company data. It is difficult to employ these models which are built on the within-company data in practice, because of the lack of these local data repositories. Recently, transfer learning has attracted more and more attention for building classifier in target domain using the data from related source domain. It is very useful in cases when distributions of training and test instances differ, but is it appropriate for cross-company software defect prediction? Objective In this paper, we consider the cross-company defect prediction scenario where source and target data are drawn from different companies. In order to harness cross company data, we try to exploit the transfer learning method to build faster and highly effective prediction model. Method Unlike the prior works selecting training data which are similar from the test data, we proposed a novel algorithm called Transfer Naive Bayes (TNB), by using the information of all the proper features in training data. Our solution estimates the distribution of the test data, and transfers cross-company data information into the weights of the training data. On these weighted data, the defect prediction model is built. Results This article presents a theoretical analysis for the comparative methods, and shows the experiment results on the data sets from different organizations. It indicates that TNB is more accurate in terms of AUC (The area under the receiver operating characteristic curve), within less runtime than the state of the art methods. Conclusion It is concluded that when there are too few local training data to train good classifiers, the useful knowledge from different-distribution training data on feature level may help. We are optimistic that our transfer learning method can guide optimal resource allocation strategies, which may reduce software testing cost and increase effectiveness of software testing process.\"\n}\n\n",
    "abstract": "Context\nSoftware defect prediction studies usually built models using within-company data, but very few focused on the prediction models trained with cross-company data. It is difficult to employ these models which are built on the within-company data in practice, because of the lack of these local data repositories. Recently, transfer learning has attracted more and more attention for building classifier in target domain using the data from related source domain. It is very useful in cases when distributions of training and test instances differ, but is it appropriate for cross-company software defect prediction?\n\nObjective\nIn this paper, we consider the cross-company defect prediction scenario where source and target data are drawn from different companies. In order to harness cross company data, we try to exploit the transfer learning method to build faster and highly effective prediction model.\n\nMethod\nUnlike the prior works selecting training data which are similar from the test data, we proposed a novel algorithm called Transfer Naive Bayes (TNB), by using the information of all the proper features in training data. Our solution estimates the distribution of the test data, and transfers cross-company data information into the weights of the training data. On these weighted data, the defect prediction model is built.\n\nResults\nThis article presents a theoretical analysis for the comparative methods, and shows the experiment results on the data sets from different organizations. It indicates that TNB is more accurate in terms of AUC (The area under the receiver operating characteristic curve), within less runtime than the state of the art methods.\n\nConclusion\nIt is concluded that when there are too few local training data to train good classifiers, the useful knowledge from different-distribution training data on feature level may help. We are optimistic that our transfer learning method can guide optimal resource allocation strategies, which may reduce software testing cost and increase effectiveness of software testing process."
}, {
    "py/object": "data.DataClassPaper",
    "Title": "Understanding machine learning software defect predictions",
    "year": 2020,
    "ML_Techniques": "LR, NB, KNN, SVM, NN, DT, RF ",
    "Category": "Testing",
    "Sub_category": "Defect prediction",
    "Venue": "ASE",
    "Link": "https://link.springer.com/article/10.1007/s10515-020-00277-4",
    "bibtex": "article{Santos2020_148,\n    author = \"dos Santos, Geanderson Esteves and Figueiredo, E. and Veloso, Adriano and Viggiato, Markos and Ziviani, N.\",\n    title = \"Understanding machine learning software defect predictions\",\n    journal = \"Autom. Softw. Eng.\",\n    year = \"2020\",\n    volume = \"27\",\n    pages = \"369-392\"\n}\n\n",
    "abstract": "Software defects are well-known in software development and might cause several problems for users and developers aside. As a result, researches employed distinct techniques to mitigate the impacts of these defects in the source code. One of the most notable techniques focuses on defect prediction using machine learning methods, which could support developers in handling these defects before they are introduced in the production environment. These studies provide alternative approaches to predict the likelihood of defects. However, most of these works concentrate on predicting defects from a vast set of software features. Another key issue with the current literature is the lack of a satisfactory explanation of the reasons that drive the software to a defective state. Specifically, we use a tree boosting algorithm (XGBoost) that receives as input a training set comprising records of easy-to-compute characteristics of each module and outputs whether the corresponding module is defect-prone. To exploit the link between predictive power and model explainability, we propose a simple model sampling approach that finds accurate models with the minimum set of features. Our principal idea is that features not contributing to increasing the predictive power should not be included in the model. Interestingly, the reduced set of features helps to increase model explainability, which is important to provide information to developers on features related to each module of the code which is more defect-prone. We evaluate our models on diverse projects within Jureczko datasets, and we show that (i) features that contribute most for finding best models may vary depending on the project and (ii) it is possible to find effective models that use few features leading to better understandability. We believe our results are useful to developers as we provide the specific software features that influence the defectiveness of selected projects."
}, {
    "py/object": "data.DataClassPaper",
    "Title": "Using Class Imbalance Learning for Software Defect Prediction",
    "year": 2013,
    "ML_Techniques": "AB, NB, RF, DT",
    "Category": "Testing",
    "Sub_category": "Defect prediction",
    "Venue": "T-RL",
    "Link": "https://ieeexplore.ieee.org/abstract/document/6509481",
    "bibtex": "ARTICLE{Wang2013_150,\n    author = \"{Wang}, S. and {Yao}, X.\",\n    journal = \"IEEE Transactions on Reliability\",\n    title = \"Using Class Imbalance Learning for Software Defect Prediction\",\n    year = \"2013\",\n    volume = \"62\",\n    number = \"2\",\n    pages = \"434-443\",\n    doi = \"10.1109/TR.2013.2259203\"\n}\n\n",
    "abstract": "To facilitate software testing, and save testing costs, a wide range of machine learning methods have been studied to predict defects in software modules. Unfortunately, the imbalanced nature of this type of data increases the learning difficulty of such a task. Class imbalance learning specializes in tackling classification problems with imbalanced distributions, which could be helpful for defect prediction, but has not been investigated in depth so far. In this paper, we study the issue of if and how class imbalance learning methods can benefit software defect prediction with the aim of finding better solutions. We investigate different types of class imbalance learning methods, including resampling techniques, threshold moving, and ensemble algorithms. Among those methods we studied, AdaBoost.NC shows the best overall performance in terms of the measures including balance, G-mean, and Area Under the Curve (AUC). To further improve the performance of the algorithm, and facilitate its use in software defect prediction, we propose a dynamic version of AdaBoost.NC, which adjusts its parameter automatically during training. Without the need to pre-define any parameters, it is shown to be more effective and efficient than the original AdaBoost.NC."
}, {
    "py/object": "data.DataClassPaper",
    "Title": "Using machine learning techniques to detect metamorphic relations for programs without test oracles",
    "year": 2013,
    "ML_Techniques": "DT, SVM",
    "Category": "Testing",
    "Sub_category": ",Defect prediction",
    "Venue": "ISSRE",
    "Link": "https://ieeexplore.ieee.org/abstract/document/6698899",
    "bibtex": "INPROCEEDINGS{Kanewala2013_151,\n    author = \"{Kanewala}, U. and {Bieman}, J. M.\",\n    booktitle = \"2013 IEEE 24th International Symposium on Software Reliability Engineering (ISSRE)\",\n    title = \"Using machine learning techniques to detect metamorphic relations for programs without test oracles\",\n    year = \"2013\",\n    volume = \"\",\n    number = \"\",\n    pages = \"1-10\",\n    doi = \"10.1109/ISSRE.2013.6698899\"\n}\n\n",
    "abstract": "Much software lacks test oracles, which limits automated testing. Metamorphic testing is one proposed method for automating the testing process for programs without test oracles. Unfortunately, finding the appropriate metamorphic relations required for use in metamorphic testing remains a labor intensive task, which is generally performed by a domain expert or a programmer. In this work we present a novel approach for automatically predicting metamorphic relations using machine learning techniques. Our approach uses a set of features developed using the control flow graph of a function for predicting likely metamorphic relations. We show the effectiveness of our method using a set of real world functions often used in scientific applications."
}, {
    "py/object": "data.DataClassPaper",
    "Title": "Using Machine Learning to Prioritize Automated Testing in an Agile Environment",
    "year": 2019,
    "ML_Techniques": "DT",
    "Category": "Testing",
    "Sub_category": ",Defect prediction",
    "Venue": "ICTAS",
    "Link": "https://ieeexplore.ieee.org/document/8703639",
    "bibtex": "INPROCEEDINGS{Butgereit2019_154,\n    author = \"{Butgereit}, L.\",\n    booktitle = \"2019 Conference on Information Communications Technology and Society (ICTAS)\",\n    title = \"Using Machine Learning to Prioritize Automated Testing in an Agile Environment\",\n    year = \"2019\",\n    volume = \"\",\n    number = \"\",\n    pages = \"1-6\",\n    doi = \"10.1109/ICTAS.2019.8703639\"\n}\n\n",
    "abstract": "Automated software testing is an integral part of most Agile methodologies. In the case of the Scrum Agile methodology, the definition of done includes the completion of tests. As a software project matures, however, the number of tests increases to such a point that the time required to run all the tests often hinders the speed in which artifacts can be deployed. This paper describes a technique of using machine learning to help prioritize automated testing to ensure that tests which have a higher probability of failing are executed early in the test run giving the programmers an early indication of problems. In order to do this, various metrics are collected about the software under test including Cyclomatic values, Halstead-based values, and Chidamber-Kemere values. In addition, the historical commit messages from the source code control system is accessed to see if there had been defects in the various source classes previously. From these two inputs, a data file can be created which contains various metrics and whether or not there had been defects in these source files previously. This data file can then be sent to Weka to create a decision tree indicating which measurements indicate potential defects. The model created by Weka can then then be used in future to attempt to predict where defects might be in the source files and then prioritize testing appropriately."
}, {
    "py/object": "data.DataClassPaper",
    "Title": "Using machine learning to refine Category-Partition test specifications and test suites",
    "year": 2009,
    "ML_Techniques": "DT",
    "Category": "Testing",
    "Sub_category": ",Test data/case generation",
    "Venue": "IST",
    "Link": "https://www.sciencedirect.com/science/article/abs/pii/S0950584909000974",
    "bibtex": "article{Briand2009_155,\n    author = \"Briand, Lionel C. and Labiche, Yvan and Bawar, Zaheer and Spido, Nadia Traldi\",\n    title = \"Using machine learning to refine Category-Partition test specifications and test suites\",\n    journal = \"Information and Software Technology\",\n    volume = \"51\",\n    number = \"11\",\n    pages = \"1551 - 1564\",\n    year = \"2009\",\n    note = \"Third IEEE International Workshop on Automation of Software Test (AST 2008) Eighth International Conference on Quality Software (QSIC 2008)\",\n    issn = \"0950-5849\",\n    doi = \"https://doi.org/10.1016/j.infsof.2009.06.006\",\n    url = \"http://www.sciencedirect.com/science/article/pii/S0950584909000974\",\n    keywords = \"Black box testing, Category-Partition, Machine learning, Test improvement\",\n    abstract = \"In the context of open source development or software evolution, developers often face test suites which have been developed with no apparent rationale and which may need to be augmented or refined to ensure sufficient dependability, or even reduced to meet tight deadlines. We refer to this process as the re-engineering of test suites. It is important to provide both methodological and tool support to help people understand the limitations of test suites and their possible redundancies, so as to be able to refine them in a cost effective manner. To address this problem in the case of black-box, Category-Partition testing, we propose a methodology and a tool based on machine learning that has shown promising results on a case study involving students as testers.\"\n}\n\n",
    "abstract": "In the context of open source development or software evolution, developers often face test suites which have been developed with no apparent rationale and which may need to be augmented or refined to ensure sufficient dependability, or even reduced to meet tight deadlines. We refer to this process as the re-engineering of test suites. It is important to provide both methodological and tool support to help people understand the limitations of test suites and their possible redundancies, so as to be able to refine them in a cost effective manner. To address this problem in the case of black-box, Category-Partition testing, we propose a methodology and a tool based on machine learning that has shown promising results on a case study involving students as testers.\n"
}, {
    "py/object": "data.DataClassPaper",
    "Title": "Using semi-supervised learning for predicting metamorphic relations",
    "year": 2018,
    "ML_Techniques": "SVM",
    "Category": "Testing",
    "Sub_category": ",Defect prediction",
    "Venue": "MET",
    "Link": "https://dl.acm.org/doi/10.1145/3193977.3193985",
    "bibtex": "article{Briand2009_155,\n    author = \"Briand, Lionel C. and Labiche, Yvan and Bawar, Zaheer and Spido, Nadia Traldi\",\n    title = \"Using machine learning to refine Category-Partition test specifications and test suites\",\n    journal = \"Information and Software Technology\",\n    volume = \"51\",\n    number = \"11\",\n    pages = \"1551 - 1564\",\n    year = \"2009\",\n    note = \"Third IEEE International Workshop on Automation of Software Test (AST 2008) Eighth International Conference on Quality Software (QSIC 2008)\",\n    issn = \"0950-5849\",\n    doi = \"https://doi.org/10.1016/j.infsof.2009.06.006\",\n    url = \"http://www.sciencedirect.com/science/article/pii/S0950584909000974\",\n    keywords = \"Black box testing, Category-Partition, Machine learning, Test improvement\",\n    abstract = \"In the context of open source development or software evolution, developers often face test suites which have been developed with no apparent rationale and which may need to be augmented or refined to ensure sufficient dependability, or even reduced to meet tight deadlines. We refer to this process as the re-engineering of test suites. It is important to provide both methodological and tool support to help people understand the limitations of test suites and their possible redundancies, so as to be able to refine them in a cost effective manner. To address this problem in the case of black-box, Category-Partition testing, we propose a methodology and a tool based on machine learning that has shown promising results on a case study involving students as testers.\"\n}\n\n",
    "abstract": " Software testing is difficult to automate, especially in programs which have no oracle, or method of determining which output is correct. Metamorphic testing is a solution this problem. Metamorphic testing uses metamorphic relations to define test cases and expected outputs. A large amount of time is needed for a domain expert to determine which metamorphic relations can be used to test a given program. Metamorphic relation prediction removes this need for such an expert. We propose a method using semi-supervised machine learning to detect which metamorphic relations are applicable to a given code base. We compare this semi-supervised model with a supervised model, and show that the addition of unlabeled data improves the classification accuracy of the MR prediction model."
}, {
    "py/object": "data.DataClassPaper",
    "Title": "Machine Learning Testing: Survey, Landscapes and Horizons",
    "year": 2020,
    "ML_Techniques": "",
    "Category": "Testing",
    "Sub_category": "",
    "Venue": "TSE",
    "Link": "https://ieeexplore.ieee.org/document/9000651",
    "bibtex": "ARTICLE{Zhang2020_157,\n    author = \"{Zhang}, J. M. and {Harman}, M. and {Ma}, L. and {Liu}, Y.\",\n    journal = \"IEEE Transactions on Software Engineering\",\n    title = \"Machine Learning Testing: Survey, Landscapes and Horizons\",\n    year = \"2020\",\n    volume = \"\",\n    number = \"\",\n    pages = \"1-1\",\n    doi = \"10.1109/TSE.2019.2962027\"\n}\n\n",
    "abstract": "This paper provides a comprehensive survey of Machine Learning Testing (ML testing) research. It covers 144 papers on testing properties (e.g., correctness, robustness, and fairness), testing components (e.g., the data, learning program, and framework), testing workflow (e.g., test generation and test evaluation), and application scenarios (e.g., autonomous driving, machine translation). The paper also analyses trends concerning datasets, research trends, and research focus, concluding with research challenges and promising research directions in ML testing."
}, {
    "py/object": "data.DataClassPaper",
    "Title": "Software Metrics for Fault Prediction Using Machine Learning Approaches A Literature Review with PROMISE Repository Dataset",
    "year": 2017,
    "ML_Techniques": "",
    "Category": "Testing",
    "Sub_category": "Defect prediction",
    "Venue": "CybermetricsCOM",
    "Link": "https://ieeexplore.ieee.org/document/8311708",
    "bibtex": "ARTICLE{Zhang2020_157,\n    author = \"{Zhang}, J. M. and {Harman}, M. and {Ma}, L. and {Liu}, Y.\",\n    journal = \"IEEE Transactions on Software Engineering\",\n    title = \"Machine Learning Testing: Survey, Landscapes and Horizons\",\n    year = \"2020\",\n    volume = \"\",\n    number = \"\",\n    pages = \"1-1\",\n    doi = \"10.1109/TSE.2019.2962027\"\n}\n\n",
    "abstract": "Software testing is an important and critical phase of software development life cycle to find software faults or defects and then correct those faults. However, testing process is a time-consuming activity that requires good planning and a lot of resources. Therefore, technique and methodology for predicting the testing effort is important process prior the testing process to significantly increase efficiency of time, effort and cost usage. Correspond to software metric usage for measuring software quality, software metric can be used to identify the faulty modules in software. Furthermore, implementing machine learning technique will allow computer to \u201clearn\u201d and able to predict the fault prone modules. Research in this field has become a hot issue for more than ten years ago. However, considering the high importance of software quality with support of machine learning methods development, this research area is still being highlighted until this year. In this paper, a survey of various software metric used for predicting software fault by using machine learning algorithm is examined. According to our review, this is the first study of software fault prediction that focuses to PROMISE repository dataset usage. Some conducted experiments from PROMISE repository dataset are compared to contribute a consensus on what constitute effective software metrics and machine learning method in software fault prediction."
}, {
    "py/object": "data.DataClassPaper",
    "Title": "A Novel Unsupervised Learning Approach for Assessing Web Services Refactoring",
    "year": 2019,
    "ML_Techniques": "KM, COBWEB, EM",
    "Category": "Refactoring",
    "Sub_category": "",
    "Venue": "IST",
    "Link": "https://link.springer.com/chapter/10.1007/978-3-030-30275-7_21",
    "bibtex": "InProceedings{Rodriguez2019_159,\n    author = \"Rodriguez, Guillermo and Mateos, Cristian and Listorti, Luciano and Hammer, Brian and Misra, Sanjay\",\n    editor = \"Dama{\\v{s}}evi{\\v{c}}ius, Robertas and Vasiljevien{\\.{e}}, Giedr{\\.{e}}\",\n    title = \"A Novel Unsupervised Learning Approach for Assessing Web Services Refactoring\",\n    booktitle = \"Information and Software Technologies\",\n    year = \"2019\",\n    publisher = \"Springer International Publishing\",\n    address = \"Cham\",\n    pages = \"273--284\",\n    abstract = \"During the last years, the development of Service-Oriented applications has become a trend. Given the characteristics and challenges posed by current systems, it has become essential to adopt this solution since it provides a great performance in distributed and heterogeneous environments. At the same time, the necessity of flexibility and great capacity of adaptation introduce a process of constant modifications and growth. Thus, developers easily make mistakes such as code duplication or unnecessary code, generating a negative impact on quality attributes such as performance and maintainability. Refactoring is considered a technique that greatly improves the quality of software and provides a solution to this issue. In this context, our work proposes an approach for comparing manual service groupings and automatic groupings that allows analyzing, evaluating and validating clustering techniques applied to improve service cohesion and fragmentation. We used V-Measure with homogeneity and completeness as the evaluation metrics. Additionally, we have performed improvements in existing clustering techniques of a previous work, VizSOC, that reach 20{\\\\%} of gain regarding the aforementioned metrics. Moreover, we added an implementation of the COBWEB clustering algorithm yielding fruitful results.\",\n    isbn = \"978-3-030-30275-7\"\n}\n\n",
    "abstract": "During the last years, the development of Service-Oriented\napplications has become a trend. Given the characteristics and challenges\nposed by current systems, it has become essential to adopt this solution\nsince it provides a great performance in distributed and heterogeneous\nenvironments. At the same time, the necessity of flexibility and great\ncapacity of adaptation introduce a process of constant modifications and\ngrowth. Thus, developers easily make mistakes such as code duplication\nor unnecessary code, generating a negative impact on quality attributes\nsuch as performance and maintainability. Refactoring is considered a\ntechnique that greatly improves the quality of software and provides a\nsolution to this issue. In this context, our work proposes an approach\nfor comparing manual service groupings and automatic groupings that\nallows analyzing, evaluating and validating clustering techniques applied\nto improve service cohesion and fragmentation. We used V-Measure with\nhomogeneity and completeness as the evaluation metrics. Additionally,\nwe have performed improvements in existing clustering techniques of a\nprevious work, VizSOC, that reach 20% of gain regarding the aforementioned\nmetrics. Moreover, we added an implementation of the COBWEB\nclustering algorithm yielding fruitful results."
}, {
    "py/object": "data.DataClassPaper",
    "Title": "An expert system for determining candidate software classes for refactoring",
    "year": 2009,
    "ML_Techniques": "NB",
    "Category": "Refactoring",
    "Sub_category": "",
    "Venue": "ESA",
    "Link": "https://www.sciencedirect.com/science/article/abs/pii/S0957417408009111",
    "bibtex": "article{Kosker2009_161,\n    author = \"Kosker, Yasemin and Turhan, Burak and Bener, Ayse\",\n    title = \"An expert system for determining candidate software classes for refactoring\",\n    journal = \"Expert Systems with Applications\",\n    volume = \"36\",\n    number = \"6\",\n    pages = \"10000 - 10003\",\n    year = \"2009\",\n    issn = \"0957-4174\",\n    doi = \"https://doi.org/10.1016/j.eswa.2008.12.066\",\n    url = \"http://www.sciencedirect.com/science/article/pii/S0957417408009111\",\n    keywords = \"Refactoring, Software metrics, Naive Bayes, Refactor prediction\",\n    abstract = \"In the lifetime of a software product, development costs are only the tip of the iceberg. Nearly 90\\% of the cost is maintenance due to error correction, adaptation and mainly enhancements. As Lehman and Belady [Lehman, M. M., \\& Belady, L. A. (1985). Program evolution: Processes of software change. Academic Press Professional.] state that software will become increasingly unstructured as it is changed. One way to overcome this problem is refactoring. Refactoring is an approach which reduces the software complexity by incrementally improving internal software quality. Our motivation in this research is to detect the classes that need to be rafactored by analyzing the code complexity. We propose a machine learning based model to predict classes to be refactored. We use Weighted Na\u00efve Bayes with InfoGain heuristic as the learner and we conducted experiments with metric data that we collected from the largest GSM operator in Turkey. Our results showed that we can predict 82\\% of the classes that need refactoring with 13\\% of manual inspection effort on the average.\"\n}\n\n",
    "abstract": "In the lifetime of a software product, development costs are only the tip of the iceberg. Nearly 90% of the\ncost is maintenance due to error correction, adaptation and mainly enhancements. As Lehman and Belady\n[Lehman, M. M., & Belady, L. A. (1985). Program evolution: Processes of software change. Academic Press\nProfessional.] state that software will become increasingly unstructured as it is changed. One way to\novercome this problem is refactoring. Refactoring is an approach which reduces the software complexity\nby incrementally improving internal software quality. Our motivation in this research is to detect the\nclasses that need to be rafactored by analyzing the code complexity. We propose a machine learning\nbased model to predict classes to be refactored. We use Weighted Na\u00efve Bayes with InfoGain heuristic\nas the learner and we conducted experiments with metric data that we collected from the largest GSM\noperator in Turkey. Our results showed that we can predict 82% of the classes that need refactoring with\n13% of manual inspection effort on the average."
}, {
    "py/object": "data.DataClassPaper",
    "Title": "Application of LSSVM and SMOTE on Seven Open Source Projects for Predicting Refactoring at Class Level",
    "year": 2017,
    "ML_Techniques": "SVM",
    "Category": "Refactoring",
    "Sub_category": "",
    "Venue": "APSEC",
    "Link": "https://ieeexplore.ieee.org/abstract/document/8305931",
    "bibtex": "INPROCEEDINGS{Kumar2017_162,\n    author = \"{Kumar}, L. and {Sureka}, A.\",\n    booktitle = \"2017 24th Asia-Pacific Software Engineering Conference (APSEC)\",\n    title = \"Application of LSSVM and SMOTE on Seven Open Source Projects for Predicting Refactoring at Class Level\",\n    year = \"2017\",\n    volume = \"\",\n    number = \"\",\n    pages = \"90-99\",\n    doi = \"10.1109/APSEC.2017.15\"\n}\n\n",
    "abstract": "Source code refactoring consisting of modifying the\nstructure of the source code without changing its functionality\nand external behavior.We present a method to predict refactoring\ncandidates at class level which can help developers in improving\ntheir design and structure of source code while preserving\nthe behavior. We propose a technique to predict refactoring\ncandidates based on the application of a machine learning based\nframework. We use Least Squares Support Vector Machines (LSSVM)\nas the learning algorithm, Principal Component Analysis\n(PCA) as a feature extraction technique and Synthetic Minority\nOver-sampling Technique (SMOTE) as a technique for handling\nimbalanced data.\nWe start with 102 source code metrics as input features which\nare then reduced to 31 features after removing irrelevant and\nredundant features through statistical tests. We conduct a series\nof experiments on publicly available software engineering dataset\nconsisting of seven open-source software systems in which the\nrefactored classes are manually validated. We apply LS-SVM\nwith three different functions: linear, polynomial and Radial Basis\nFunction (RBF). Statistical significance test demonstrate that\nRBF kernel outperforms linear and polynomial kernel but there is\nno statistically significant difference between the performance of\nlinear and polynomial kernel. Statistical significance test reveals\nthat with-SMOTE technique outperforms without-SMOTE and\nall metrics outperforms PCA based metrics. The mean value of\nArea Under Curve (AUC) for LS-SVM RBF kernel is 0.96."
}, {
    "py/object": "data.DataClassPaper",
    "Title": "Automated Recommendation of Software Refactorings Based on Feature Requests",
    "year": 2019,
    "ML_Techniques": "LOG, MNB, SVM, RF",
    "Category": "Refactoring",
    "Sub_category": "",
    "Venue": "RE",
    "Link": "https://ieeexplore.ieee.org/document/8920694",
    "bibtex": "INPROCEEDINGS{Nyamawe2019_163,\n    author = \"{Nyamawe}, A. S. and {Liu}, H. and {Niu}, N. and {Umer}, Q. and {Niu}, Z.\",\n    booktitle = \"2019 IEEE 27th International Requirements Engineering Conference (RE)\",\n    title = \"Automated Recommendation of Software Refactorings Based on Feature Requests\",\n    year = \"2019\",\n    volume = \"\",\n    number = \"\",\n    pages = \"187-198\",\n    doi = \"10.1109/RE.2019.00029\"\n}\n\n",
    "abstract": "During software evolution, developers often receive\nnew requirements expressed as feature requests. To implement\nthe requested features, developers have to perform necessary\nmodifications (refactorings) to prepare for new adaptation that\naccommodates the new requirements. Software refactoring is\na well-known technique that has been extensively used to improve\nsoftware quality such as maintainability and extensibility.\nHowever, it is often challenging to determine which kind of\nrefactorings should be applied. Consequently, several approaches\nbased on various heuristics have been proposed to recommend\nrefactorings. However, there is still lack of automated support\nto recommend refactorings given a feature request. To this end,\nin this paper, we propose a novel approach that recommends\nrefactorings based on the history of the previously requested\nfeatures and applied refactorings. First, we exploit the stateof-\nthe-art refactoring detection tools to identify the previous\nrefactorings applied to implement the past feature requests.\nSecond, we train a machine classifier with the history data of the\nfeature requests and refactorings applied on the commits that\nimplemented the corresponding feature requests. The machine\nclassifier is then used to predict refactorings for new feature\nrequests. We evaluate the proposed approach on the dataset\nof 43 open source Java projects and the results suggest that\nthe proposed approach can accurately recommend refactorings\n(average precision 73%)."
}, {
    "py/object": "data.DataClassPaper",
    "Title": "Automatic Clone Recommendation for Refactoring Based on the Present and the Past",
    "year": 2018,
    "ML_Techniques": "AB",
    "Category": "Refactoring",
    "Sub_category": "",
    "Venue": "ICSME",
    "Link": "https://ieeexplore.ieee.org/abstract/document/8530022",
    "bibtex": "INPROCEEDINGS{Yue2018_164,\n    author = \"{Yue}, R. and {Gao}, Z. and {Meng}, N. and {Xiong}, Y. and {Wang}, X. and {Morgenthaler}, J. D.\",\n    booktitle = \"2018 IEEE International Conference on Software Maintenance and Evolution (ICSME)\",\n    title = \"Automatic Clone Recommendation for Refactoring Based on the Present and the Past\",\n    year = \"2018\",\n    volume = \"\",\n    number = \"\",\n    pages = \"115-126\",\n    doi = \"10.1109/ICSME.2018.00021\"\n}\n\n",
    "abstract": "When many clones are detected in software programs,\nnot all clones are equally important to developers. To\nhelp developers refactor code and improve software quality,\nvarious tools were built to recommend clone-removal refactorings\nbased on the past and the present information, such as the\ncohesion degree of individual clones or the co-evolution relations\nof clone peers. The existence of these tools inspired us to\nbuild an approach that considers as many factors as possible\nto more accurately recommend clones. This paper introduces\nCREC, a learning-based approach that recommends clones by\nextracting features from the current status and past history of\nsoftware projects. Given a set of software repositories, CREC first\nautomatically extracts the clone groups historically refactored\n(R-clones) and those not refactored (NR-clones) to construct\nthe training set. CREC extracts 34 features to characterize the\ncontent and evolution behaviors of individual clones, as well as\nthe spatial, syntactical, and co-change relations of clone peers.\nWith these features, CREC trains a classifier that recommends\nclones for refactoring.\nWe designed the largest feature set thus far for clone recommendation,\nand performed an evaluation on six large projects.\nThe results show that our approach suggested refactorings\nwith 83% and 76% F-scores in the within-project and crossproject\nsettings. CREC significantly outperforms a state-of-theart\nsimilar approach on our data set, with the latter one achieving\n70% and 50% F-scores. We also compared the effectiveness of\ndifferent factors and different learning algorithms."
}, {
    "py/object": "data.DataClassPaper",
    "Title": "Method Level Refactoring Prediction on Five Open Source Java Projects using Machine Learning Techniques",
    "year": 2019,
    "ML_Techniques": "LR, LOG, NB, BN, MLP, RF, AB, LB, ANN",
    "Category": "Refactoring",
    "Sub_category": "",
    "Venue": "ISEC",
    "Link": "https://dl.acm.org/doi/abs/10.1145/3299771.3299777",
    "bibtex": "INPROCEEDINGS{Yue2018_164,\n    author = \"{Yue}, R. and {Gao}, Z. and {Meng}, N. and {Xiong}, Y. and {Wang}, X. and {Morgenthaler}, J. D.\",\n    booktitle = \"2018 IEEE International Conference on Software Maintenance and Evolution (ICSME)\",\n    title = \"Automatic Clone Recommendation for Refactoring Based on the Present and the Past\",\n    year = \"2018\",\n    volume = \"\",\n    number = \"\",\n    pages = \"115-126\",\n    doi = \"10.1109/ICSME.2018.00021\"\n}\n\n",
    "abstract": "Introduction : Identifying code segments in large and complex\nsystems in need of refactoring is non-trivial for software developers.\nOur research aim is to develop recommendation systems\nfor suggesting methods which require refactoring. Materials and\nMethods : Previous research shows that source code metrics for\nobject-oriented software systems are indicators of complexity of\na software system. We compute 25 different source code metrics\nat the method level and use it as features in a machine learning\nframework to predict the need of refactoring. We conduct a series\nof experiments on a publicly available annotated dataset of five\nsoftware systems to investigate the performance of our proposed\napproach. In this proposed solution, ten different machine learning\nclassifiers have been considered. In order to handle issues related\nto class imbalance, three different data sampling methods are also\nconsidered during implementation. Conclusion : Our analysis reveals\nthat the mean accuracy for the SMOTE and RUSBoost data\nsampling technique is 98.47% respectively. The mean accuracy for\nthe classifier AdaBoost is 98.16% and the mean accuracy for the\nclassifier ANN+GD is 98.17% respectively. Hypothesis testing results\nreveals that the performance of different classifiers and data\nsampling techniques are statistically significant in nature."
}, {
    "py/object": "data.DataClassPaper",
    "Title": "On the Use of Machine Learning and Search-Based Software Engineering for Ill-Defined Fitness Function: A Case Study on Software Refactoring",
    "year": 2014,
    "ML_Techniques": "ANN",
    "Category": "Refactoring",
    "Sub_category": "",
    "Venue": "SBSE",
    "Link": "https://link.springer.com/chapter/10.1007/978-3-319-09940-8_3",
    "bibtex": "InProceedings{Amal2014_170,\n    author = \"Amal, Boukhdhir and Kessentini, Marouane and Bechikh, Slim and Dea, Josselin and Said, Lamjed Ben\",\n    editor = \"Le Goues, Claire and Yoo, Shin\",\n    title = \"On the Use of Machine Learning and Search-Based Software Engineering for Ill-Defined Fitness Function: A Case Study on Software Refactoring\",\n    booktitle = \"Search-Based Software Engineering\",\n    year = \"2014\",\n    publisher = \"Springer International Publishing\",\n    address = \"Cham\",\n    pages = \"31--45\",\n    abstract = \"The most challenging step when adapting a search-based technique for a software engineering problem is the definition of the fitness function. For several software engineering problems, a fitness function is ill-defined, subjective, or difficult to quantify. For example, the evaluation of a software design is subjective. This paper introduces the use of a neural network-based fitness function for the problem of software refactoring. The software engineers evaluate manually the suggested refactoring solutions by a Genetic Algorithm (GA) for few iterations then an Artificial Neural Network (ANN) uses these training examples to evaluate the refactoring solutions for the remaining iterations. We evaluate the efficiency of our approach using six different open-source systems through an empirical study and compare the performance of our technique with several existing refactoring studies.\",\n    isbn = \"978-3-319-09940-8\"\n}\n\n",
    "abstract": "The most challenging step when adapting a search-based technique\nfor a software engineering problem is the definition of the fitness function. For\nseveral software engineering problems, a fitness function is ill-defined,\nsubjective, or difficult to quantify. For example, the evaluation of a software\ndesign is subjective. This paper introduces the use of a neural network-based\nfitness function for the problem of software refactoring. The software engineers\nevaluate manually the suggested refactoring solutions by a Genetic Algorithm\n(GA) for few iterations then an Artificial Neural Network (ANN) uses these\ntraining examples to evaluate the refactoring solutions for the remaining\niterations. We evaluate the efficiency of our approach using six different opensource\nsystems through an empirical study and compare the performance of our\ntechnique with several existing refactoring studies."
}, {
    "py/object": "data.DataClassPaper",
    "Title": "Prediction of Refactoring-Prone Classes Using Ensemble Learning",
    "year": 2019,
    "ML_Techniques": "ANN, SVM, BTW, MVE",
    "Category": "Refactoring",
    "Sub_category": "",
    "Venue": "NIP",
    "Link": "https://link.springer.com/chapter/10.1007/978-3-030-36802-9_27",
    "bibtex": "InProceedings{Aribandi2019_171,\n    author = \"Aribandi, Vamsi Krishna and Kumar, Lov and Bhanu Murthy Neti, Lalita and Krishna, Aneesh\",\n    editor = \"Gedeon, Tom and Wong, Kok Wai and Lee, Minho\",\n    title = \"Prediction of Refactoring-Prone Classes Using Ensemble Learning\",\n    booktitle = \"Neural Information Processing\",\n    year = \"2019\",\n    publisher = \"Springer International Publishing\",\n    address = \"Cham\",\n    pages = \"242--250\",\n    abstract = \"A considerable amount of software engineers' efforts go into maintaining code repositories, which involves identifying code whose structure can be improved. This often involves the identification of classes whose code requires refactoring. The early detection of refactoring-prone classes has the potential to reduce the costs and efforts that go into maintaining source code repositories. The purpose of this research is to develop prediction models using source code metrics for detecting patterns in object oriented source code, which are indicators of classes that are likely to be refactored in future iterations. In this study, four different sets of source code metrics have been considered as an input for refactoring prediction to evaluate the impact of these source code metrics on model performance. The impact of these source code metrics are evaluated using eleven different classification technique, and two different ensemble classes on seven different open source projects. Ensemble learning techniques have been shown to incorporate the diversity of patterns learnt by different classifiers, resulting in an augmented classifier that is more robust than any individual classifier. Our work also creates distinction between various sets of features for the task of predicting refactoring-prone classes.\",\n    isbn = \"978-3-030-36802-9\"\n}\n\n",
    "abstract": "A considerable amount of software engineers\u2019 efforts go into\nmaintaining code repositories, which involves identifying code whose\nstructure can be improved. This often involves the identification of classes\nwhose code requires refactoring. The early detection of refactoring-prone\nclasses has the potential to reduce the costs and efforts that go into\nmaintaining source code repositories. The purpose of this research is to\ndevelop prediction models using source code metrics for detecting patterns\nin object oriented source code, which are indicators of classes that\nare likely to be refactored in future iterations. In this study, four different\nsets of source code metrics have been considered as an input for\nrefactoring prediction to evaluate the impact of these source code metrics\non model performance. The impact of these source code metrics are\nevaluated using eleven different classification technique, and two different\nensemble classes on seven different open source projects. Ensemble\nlearning techniques have been shown to incorporate the diversity of patterns\nlearnt by different classifiers, resulting in an augmented classifier\nthat is more robust than any individual classifier. Our work also creates\ndistinction between various sets of features for the task of predicting\nrefactoring-prone classes."
}, {
    "py/object": "data.DataClassPaper",
    "Title": "Recommendation of Move Method Refactoring Using Path-Based Representation of Code",
    "year": 2020,
    "ML_Techniques": "SVM",
    "Category": "Refactoring",
    "Sub_category": "",
    "Venue": "ICSEW",
    "Link": "https://dl.acm.org/doi/10.1145/3387940.3392191",
    "bibtex": "inproceedings{Kurbatova2020_172,\n    author = \"Kurbatova, Zarina and Veselov, Ivan and Golubev, Yaroslav and Bryksin, Timofey\",\n    title = \"Recommendation of Move Method Refactoring Using Path-Based Representation of Code\",\n    year = \"2020\",\n    isbn = \"9781450379632\",\n    publisher = \"Association for Computing Machinery\",\n    address = \"New York, NY, USA\",\n    url = \"https://doi.org/10.1145/3387940.3392191\",\n    doi = \"10.1145/3387940.3392191\",\n    abstract = \"Software refactoring plays an important role in increasing code quality. One of the most popular refactoring types is the Move Method refactoring. It is usually applied when a method depends more on members of other classes than on its own original class. Several approaches have been proposed to recommend Move Method refactoring automatically. Most of them are based on heuristics and have certain limitations (e.g., they depend on the selection of metrics and manually-defined thresholds). In this paper, we propose an approach to recommend Move Method refactoring based on a path-based representation of code called code2vec that is able to capture the syntactic structure and semantic information of a code fragment. We use this code representation to train a machine learning classifier suggesting to move methods to more appropriate classes. We evaluate the approach on two publicly available datasets: a manually compiled dataset of well-known open-source projects and a synthetic dataset with automatically injected code smell instances. The results show that our approach is capable of recommending accurate refactoring opportunities and outperforms JDeodorant and JMove, which are state of the art tools in this field.\",\n    booktitle = \"Proceedings of the IEEE/ACM 42nd International Conference on Software Engineering Workshops\",\n    pages = \"315\u2013322\",\n    numpages = \"8\",\n    keywords = \"Feature Envy, Automatic Refactoring Recommendation, Code Smells, Path-based Representation, Move Method Refactoring\",\n    location = \"Seoul, Republic of Korea\",\n    series = \"ICSEW'20\"\n}\n\n",
    "abstract": "Software refactoring plays an important role in increasing code\nquality. One of the most popular refactoring types is the Move\nMethod refactoring. It is usually applied when a method depends\nmore on members of other classes than on its own original class. Several\napproaches have been proposed to recommend Move Method\nrefactoring automatically. Most of them are based on heuristics\nand have certain limitations (e.g., they depend on the selection of\nmetrics and manually-defined thresholds). In this paper, we propose\nan approach to recommend Move Method refactoring based\non a path-based representation of code called code2vec that is able\nto capture the syntactic structure and semantic information of a\ncode fragment. We use this code representation to train a machine\nlearning classifier suggesting to move methods to more appropriate\nclasses. We evaluate the approach on two publicly available\ndatasets: a manually compiled dataset of well-known open-source\nprojects and a synthetic dataset with automatically injected code\nsmell instances. The results show that our approach is capable of\nrecommending accurate refactoring opportunities and outperforms\nJDeodorant and JMove, which are state of the art tools in this field."
}, {
    "py/object": "data.DataClassPaper",
    "Title": "The Effectiveness of Supervised Machine Learning Algorithms in Predicting Software Refactoring",
    "year": 2020,
    "ML_Techniques": "LOG, NB,SVM, DT, RF, NN",
    "Category": "Refactoring",
    "Sub_category": "",
    "Venue": "TSE",
    "Link": "https://ieeexplore.ieee.org/document/9186715",
    "bibtex": "ARTICLE{Aniche2020_173,\n    author = \"{Aniche}, M. and {Maziero}, E. and {Durelli}, R. and {Durelli}, V.\",\n    journal = \"IEEE Transactions on Software Engineering\",\n    title = \"The Effectiveness of Supervised Machine Learning Algorithms in Predicting Software Refactoring\",\n    year = \"2020\",\n    volume = \"\",\n    number = \"\",\n    pages = \"1-1\",\n    doi = \"10.1109/TSE.2020.3021736\"\n}\n\n",
    "abstract": "Refactoring is the process of changing the internal structure of software to improve its quality without modifying its external\nbehavior. Empirical studies have repeatedly shown that refactoring has a positive impact on the understandability and maintainability of\nsoftware systems. However, before carrying out refactoring activities, developers need to identify refactoring opportunities. Currently,\nrefactoring opportunity identification heavily relies on developers\u2019 expertise and intuition. In this paper, we investigate the effectiveness of\nmachine learning algorithms in predicting software refactorings. More specifically, we train six different machine learning algorithms (i.e.,\nLogistic Regression, Naive Bayes, Support Vector Machine, Decision Trees, Random Forest, and Neural Network) with a dataset\ncomprising over two million refactorings from 11,149 real-world projects from the Apache, F-Droid, and GitHub ecosystems. The resulting\nmodels predict 20 different refactorings at class, method, and variable-levels with an accuracy often higher than 90%. Our results show\nthat (i) Random Forests are the best models for predicting software refactoring, (ii) process and ownership metrics seem to play a crucial\nrole in the creation of better models, and (iii) models generalize well in different contexts."
}, {
    "py/object": "data.DataClassPaper",
    "Title": "A large empirical assessment of the role of data balancing in machine-learning-based code smell detection",
    "year": 2020,
    "ML_Techniques": "CSC, OCC",
    "Category": "Quality assessment",
    "Sub_category": "Code smell detection",
    "Venue": "JSS",
    "Link": "https://www.sciencedirect.com/science/article/abs/pii/S0164121220301448",
    "bibtex": "article{Pecorelli2020_177,\n    author = \"Pecorelli, Fabiano and {Di Nucci}, Dario and {De Roover}, Coen and {De Lucia}, Andrea\",\n    title = \"A large empirical assessment of the role of data balancing in machine-learning-based code smell detection\",\n    journal = \"Journal of Systems and Software\",\n    volume = \"169\",\n    pages = \"110693\",\n    year = \"2020\",\n    issn = \"0164-1212\",\n    doi = \"https://doi.org/10.1016/j.jss.2020.110693\",\n    url = \"http://www.sciencedirect.com/science/article/pii/S0164121220301448\",\n    keywords = \"Code smells, Machine learning, Data balancing, Object oriented, Model view controller\",\n    abstract = \"Code smells can compromise software quality in the long term by inducing technical debt. For this reason, many approaches aimed at identifying these design flaws have been proposed in the last decade. Most of them are based on heuristics in which a set of metrics is used to detect smelly code components. However, these techniques suffer from subjective interpretations, a low agreement between detectors, and threshold dependability. To overcome these limitations, previous work applied Machine-Learning that can learn from previous datasets without needing any threshold definition. However, more recent work has shown that Machine-Learning is not always suitable for code smell detection due to the highly imbalanced nature of the problem. In this study, we investigate five approaches to mitigate data imbalance issues to understand their impact on Machine Learning-based approaches for code smell detection in Object-Oriented systems and those implementing the Model-View-Controller pattern. Our findings show that avoiding balancing does not dramatically impact accuracy. Existing data balancing techniques are inadequate for code smell detection leading to poor accuracy for Machine-Learning-based approaches. Therefore, new metrics to exploit different software characteristics and new techniques to effectively combine them are needed.\"\n}\n\n",
    "abstract": "Code smells can compromise software quality in the long term by inducing technical debt. For this\nreason, many approaches aimed at identifying these design flaws have been proposed in the last\ndecade. Most of them are based on heuristics in which a set of metrics is used to detect smelly\ncode components. However, these techniques suffer from subjective interpretations, a low agreement\nbetween detectors, and threshold dependability. To overcome these limitations, previous work applied\nMachine-Learning that can learn from previous datasets without needing any threshold definition.\nHowever, more recent work has shown that Machine-Learning is not always suitable for code smell\ndetection due to the highly imbalanced nature of the problem. In this study, we investigate five\napproaches to mitigate data imbalance issues to understand their impact on Machine Learning-based\napproaches for code smell detection in Object-Oriented systems and those implementing the Model-\nView-Controller pattern. Our findings show that avoiding balancing does not dramatically impact\naccuracy. Existing data balancing techniques are inadequate for code smell detection leading to poor\naccuracy for Machine-Learning-based approaches. Therefore, new metrics to exploit different software\ncharacteristics and new techniques to effectively combine them are needed."
}, {
    "py/object": "data.DataClassPaper",
    "Title": "A machine learning based framework for code clone validation",
    "year": 2020,
    "ML_Techniques": "NB, RF, BN, LOG, KS, DT",
    "Category": "Quality assessment",
    "Sub_category": "Clone detection",
    "Venue": "JSS",
    "Link": "https://www.sciencedirect.com/science/article/abs/pii/S0164121220301394",
    "bibtex": "article{Mostaeen2020_178,\n    author = \"Mostaeen, Golam and Roy, Banani and Roy, Chanchal K. and Schneider, Kevin and Svajlenko, Jeffrey\",\n    title = \"A machine learning based framework for code clone validation\",\n    journal = \"Journal of Systems and Software\",\n    volume = \"169\",\n    pages = \"110686\",\n    year = \"2020\",\n    issn = \"0164-1212\",\n    doi = \"https://doi.org/10.1016/j.jss.2020.110686\",\n    url = \"http://www.sciencedirect.com/science/article/pii/S0164121220301394\",\n    keywords = \"Code clones, Validation, Machine learning, Clone management\",\n    abstract = \"A code clone is a pair of code fragments, within or between software systems that are similar. Since code clones often negatively impact the maintainability of a software system, several code clone detection techniques and tools have been proposed and studied over the last decade. However, the clone detection tools are not always perfect and their clone detection reports often contain a number of false positives or irrelevant clones from specific project management or user perspective. To detect all possible similar source code patterns in general, the clone detection tools work on the syntax level while lacking user-specific preferences. This often means the clones must be manually inspected before analysis in order to remove those false positives from consideration. This manual clone validation effort is very time-consuming and often error-prone, in particular for large-scale clone detection. In this paper, we propose a machine learning approach for automating the validation process. First, a training dataset is built by taking code clones from several clone detection tools for different subject systems and then manually validating those clones. Second, several features are extracted from those clones to train the machine learning model by the proposed approach. The trained algorithm is then used to automatically validate clones without human inspection. Thus the proposed approach can be used to remove the false positive clones from the detection results, automatically evaluate the precision of any clone detectors for any given set of datasets, evaluate existing clone benchmark datasets, or even be used to build new clone benchmarks and datasets with minimum effort. In an experiment with clones detected by several clone detectors in several different software systems, we found our approach has an accuracy of up to 87.4\\% when compared against the manual validation by multiple expert judges. The proposed method also shows better results in several comparative studies with the existing related approaches for clone classification.\"\n}\n\n",
    "abstract": "A code clone is a pair of code fragments, within or between software systems that are similar. Since\ncode clones often negatively impact the maintainability of a software system, several code clone\ndetection techniques and tools have been proposed and studied over the last decade. However, the\nclone detection tools are not always perfect and their clone detection reports often contain a number\nof false positives or irrelevant clones from specific project management or user perspective. To detect\nall possible similar source code patterns in general, the clone detection tools work on the syntax level\nwhile lacking user-specific preferences. This often means the clones must be manually inspected before\nanalysis in order to remove those false positives from consideration. This manual clone validation effort\nis very time-consuming and often error-prone, in particular for large-scale clone detection. In this\npaper, we propose a machine learning approach for automating the validation process. First, a training\ndataset is built by taking code clones from several clone detection tools for different subject systems\nand then manually validating those clones. Second, several features are extracted from those clones\nto train the machine learning model by the proposed approach. The trained algorithm is then used\nto automatically validate clones without human inspection. Thus the proposed approach can be used\nto remove the false positive clones from the detection results, automatically evaluate the precision\nof any clone detectors for any given set of datasets, evaluate existing clone benchmark datasets, or\neven be used to build new clone benchmarks and datasets with minimum effort. In an experiment\nwith clones detected by several clone detectors in several different software systems, we found our\napproach has an accuracy of up to 87.4% when compared against the manual validation by multiple\nexpert judges. The proposed method also shows better results in several comparative studies with the\nexisting related approaches for clone classification."
}, {
    "py/object": "data.DataClassPaper",
    "Title": "A machine learning based tool for source code plagiarism detection",
    "year": 2011,
    "ML_Techniques": "NB, KNN, AB",
    "Category": "Quality assessment",
    "Sub_category": "Clone detection",
    "Venue": "IJMLC",
    "Link": "",
    "bibtex": "article{Mostaeen2020_178,\n    author = \"Mostaeen, Golam and Roy, Banani and Roy, Chanchal K. and Schneider, Kevin and Svajlenko, Jeffrey\",\n    title = \"A machine learning based framework for code clone validation\",\n    journal = \"Journal of Systems and Software\",\n    volume = \"169\",\n    pages = \"110686\",\n    year = \"2020\",\n    issn = \"0164-1212\",\n    doi = \"https://doi.org/10.1016/j.jss.2020.110686\",\n    url = \"http://www.sciencedirect.com/science/article/pii/S0164121220301394\",\n    keywords = \"Code clones, Validation, Machine learning, Clone management\",\n    abstract = \"A code clone is a pair of code fragments, within or between software systems that are similar. Since code clones often negatively impact the maintainability of a software system, several code clone detection techniques and tools have been proposed and studied over the last decade. However, the clone detection tools are not always perfect and their clone detection reports often contain a number of false positives or irrelevant clones from specific project management or user perspective. To detect all possible similar source code patterns in general, the clone detection tools work on the syntax level while lacking user-specific preferences. This often means the clones must be manually inspected before analysis in order to remove those false positives from consideration. This manual clone validation effort is very time-consuming and often error-prone, in particular for large-scale clone detection. In this paper, we propose a machine learning approach for automating the validation process. First, a training dataset is built by taking code clones from several clone detection tools for different subject systems and then manually validating those clones. Second, several features are extracted from those clones to train the machine learning model by the proposed approach. The trained algorithm is then used to automatically validate clones without human inspection. Thus the proposed approach can be used to remove the false positive clones from the detection results, automatically evaluate the precision of any clone detectors for any given set of datasets, evaluate existing clone benchmark datasets, or even be used to build new clone benchmarks and datasets with minimum effort. In an experiment with clones detected by several clone detectors in several different software systems, we found our approach has an accuracy of up to 87.4\\% when compared against the manual validation by multiple expert judges. The proposed method also shows better results in several comparative studies with the existing related approaches for clone classification.\"\n}\n\n",
    "abstract": "Source code plagiarism is a severe problem in\nacademia. In academia programming assignments are used to\nevaluate students in programming courses. Therefore checking\nprogramming assignments for plagiarism is essential. If a\ncourse consists of a large number of students, it is impractical to\ncheck each assignment by a human inspector. Therefore it is\nessential to have automated tools in order to assist detection of\nplagiarism in programming assignments.\nMajority of the current source code plagiarism detection\ntools are based on structured methods. Structural properties of\na plagiarized program and the original program differ\nsignificantly. Therefore it is hard to detect plagiarized\nprograms when plagiarism level is 4 or above by using tools\nwhich are based on structural methods.\nThis paper presents a new plagiarism detection method,\nwhich is based on machine learning techniques. We have\ntrained and tested three machine learning algorithms for\ndetecting source code plagiarism. Furthermore, we have\nutilized a meta-learning algorithm in order to improve the\naccuracy of our system."
}, {
    "py/object": "data.DataClassPaper",
    "Title": "A machine-learning based ensemble method for anti-patterns detection",
    "year": 2020,
    "ML_Techniques": "NN\n",
    "Category": "Quality assessment",
    "Sub_category": "Code smell detection",
    "Venue": "JSS",
    "Link": "https://www.sciencedirect.com/science/article/abs/pii/S0164121219302602",
    "bibtex": "article{Barbez2020_180,\n    author = \"Barbez, Antoine and Khomh, Foutse and Gu\u00e9h\u00e9neuc, Yann-Ga\u00ebl\",\n    title = \"A machine-learning based ensemble method for anti-patterns detection\",\n    journal = \"Journal of Systems and Software\",\n    volume = \"161\",\n    pages = \"110486\",\n    year = \"2020\",\n    issn = \"0164-1212\",\n    doi = \"https://doi.org/10.1016/j.jss.2019.110486\",\n    url = \"http://www.sciencedirect.com/science/article/pii/S0164121219302602\",\n    keywords = \"Software quality, Anti-patterns, Machine learning, Ensemble methods\",\n    abstract = \"Anti-patterns are poor solutions to recurring design problems. Several empirical studies have highlighted their negative impact on program comprehension, maintainability, as well as fault-proneness. A variety of detection approaches have been proposed to identify their occurrences in source code. However, these approaches can identify only a subset of the occurrences and report large numbers of false positives and misses. Furthermore, a low agreement is generally observed among different approaches. Recent studies have shown the potential of machine-learning models to improve this situation. However, such algorithms require large sets of manually-produced training-data, which often limits their application in practice. In this paper, we present SMAD (SMart Aggregation of Anti-patterns Detectors), a machine-learning based ensemble method to aggregate various anti-patterns detection approaches on the basis of their internal detection rules. Thus, our method uses several detection tools to produce an improved prediction from a reasonable number of training examples. We implemented SMAD for the detection of two well known anti-patterns: God Class and Feature Envy. With the results of our experiments conducted on eight java projects, we show that: (1) Our method clearly improves the so aggregated tools; (2) SMAD significantly outperforms other ensemble methods.\"\n}\n\n",
    "abstract": "Anti-patterns are poor solutions to recurring design problems. Several empirical studies have highlighted their negative impact on program comprehension, maintainability, as well as fault-proneness. A variety of detection approaches have been proposed to identify their occurrences in source code. However, these approaches can identify only a subset of the occurrences and report large numbers of false positives and misses. Furthermore, a low agreement is generally observed among different approaches. Recent studies have shown the potential of machine-learning models to improve this situation. However, such algorithms require large sets of manually-produced training-data, which often limits their application in practice. In this paper, we present SMAD (SMart Aggregation of Anti-patterns Detectors), a machine-learning based ensemble method to aggregate various anti-patterns detection approaches on the basis of their internal detection rules. Thus, our method uses several detection tools to produce an improved prediction from a reasonable number of training examples. We implemented SMAD for the detection of two well known anti-patterns: God Class and Feature Envy. With the results of our experiments conducted on eight java projects, we show that: (1) Our method clearly improves the so aggregated tools; (2) SMAD significantly outperforms other ensemble methods."
}, {
    "py/object": "data.DataClassPaper",
    "Title": "A preliminary study on the adequacy of static analysis warnings with respect to code smell prediction",
    "year": 2020,
    "ML_Techniques": "RF, DT, NB, SVM",
    "Category": "Quality assessment",
    "Sub_category": "Code smell detection",
    "Venue": "MaLTeSQuE",
    "Link": "https://dl.acm.org/doi/10.1145/3416505.3423559",
    "bibtex": "article{Barbez2020_180,\n    author = \"Barbez, Antoine and Khomh, Foutse and Gu\u00e9h\u00e9neuc, Yann-Ga\u00ebl\",\n    title = \"A machine-learning based ensemble method for anti-patterns detection\",\n    journal = \"Journal of Systems and Software\",\n    volume = \"161\",\n    pages = \"110486\",\n    year = \"2020\",\n    issn = \"0164-1212\",\n    doi = \"https://doi.org/10.1016/j.jss.2019.110486\",\n    url = \"http://www.sciencedirect.com/science/article/pii/S0164121219302602\",\n    keywords = \"Software quality, Anti-patterns, Machine learning, Ensemble methods\",\n    abstract = \"Anti-patterns are poor solutions to recurring design problems. Several empirical studies have highlighted their negative impact on program comprehension, maintainability, as well as fault-proneness. A variety of detection approaches have been proposed to identify their occurrences in source code. However, these approaches can identify only a subset of the occurrences and report large numbers of false positives and misses. Furthermore, a low agreement is generally observed among different approaches. Recent studies have shown the potential of machine-learning models to improve this situation. However, such algorithms require large sets of manually-produced training-data, which often limits their application in practice. In this paper, we present SMAD (SMart Aggregation of Anti-patterns Detectors), a machine-learning based ensemble method to aggregate various anti-patterns detection approaches on the basis of their internal detection rules. Thus, our method uses several detection tools to produce an improved prediction from a reasonable number of training examples. We implemented SMAD for the detection of two well known anti-patterns: God Class and Feature Envy. With the results of our experiments conducted on eight java projects, we show that: (1) Our method clearly improves the so aggregated tools; (2) SMAD significantly outperforms other ensemble methods.\"\n}\n\n",
    "abstract": "Code smells are poor implementation choices applied during software\nevolution that can affect source code maintainability. While\nseveral heuristic-based approaches have been proposed in the past,\nmachine learning solutions have recently gained attention since\nthey may potentially address some limitations of state-of-the-art\napproaches. Unfortunately, however, machine learning-based code\nsmell detectors still suffer from low accuracy. In this paper, we aim\nat advancing the knowledge in the field by investigating the role of\nstatic analysis warnings as features of machine learning models for\nthe detection of three code smell types.We first verify the potential\ncontribution given by these features. Then, we build code smell\nprediction models exploiting the most relevant features coming\nfrom the first analysis. The main finding of the study reports that\nthe warnings given by the considered tools lead the performance\nof code smell prediction models to drastically increase with respect\nto what reported by previous research in the field."
}, {
    "py/object": "data.DataClassPaper",
    "Title": "A Review of Machine Learning Techniques for Software Quality Prediction",
    "year": 2020,
    "ML_Techniques": "",
    "Category": "Quality assessment",
    "Sub_category": "Quality assessment/prediction,Quality prediction,Quality assessment/prediction,Quality assessment/prediction,Quality prediction,Quality assessment/prediction,Quality prediction",
    "Venue": "ACIE",
    "Link": "https://link.springer.com/chapter/10.1007/978-981-15-1483-8_45",
    "bibtex": "InProceedings{Cowlessur2020_182,\n    author = \"Cowlessur, Sanjeev K. and Pattnaik, Saumendra and Pattanayak, Binod Kumar\",\n    editor = \"Pati, Bibudhendu and Panigrahi, Chhabi Rani and Buyya, Rajkumar and Li, Kuan-Ching\",\n    title = \"A Review of Machine Learning Techniques for Software Quality Prediction\",\n    booktitle = \"Advanced Computing and Intelligent Engineering\",\n    year = \"2020\",\n    publisher = \"Springer Singapore\",\n    address = \"Singapore\",\n    pages = \"537--549\",\n    abstract = \"Successful implementation of a software product entirely depends on the quality of the software developed. However, prediction of the quality of a software product prior to its implementation in real-world applications presents significant challenges to the software developer during the process of development. A limited spectrum of research in this area has been reported in the literature as of today. Most of the researchers have concentrated their research work on software quality prediction using various machine learning techniques. Another aspect pertaining to software quality prediction is that the prediction must be achieved in the earlier stages of software development life cycle in order to reduce the amount of effort required by the developer in course of the development of a software product. In this paper, we carry out a comprehensive review of machine learning techniques which have been used to predict software quality.\",\n    isbn = \"978-981-15-1483-8\"\n}\n\n",
    "abstract": "Successful implementation of a software product entirely depends on the\nquality of the software developed. However, prediction of the quality of a software\nproduct prior to its implementation in real-world applications presents significant\nchallenges to the software developer during the process of development. A limited\nspectrum of research in this area has been reported in the literature as of today.\nMost of the researchers have concentrated their research work on software quality\nprediction using various machine learning techniques. Another aspect pertaining to\nsoftware quality prediction is that the predictionmust be achieved in the earlier stages\nof software development life cycle in order to reduce the amount of effort required\nby the developer in course of the development of a software product. In this paper,\nwe carry out a comprehensive review of machine learning techniques which have\nbeen used to predict software quality."
}, {
    "py/object": "data.DataClassPaper",
    "Title": "A Support Vector Machine Based Approach for Code Smell Detection",
    "year": 2017,
    "ML_Techniques": "SVM",
    "Category": "Quality assessment",
    "Sub_category": "Code smell detection",
    "Venue": "MLDS",
    "Link": "https://ieeexplore.ieee.org/abstract/document/8320252",
    "bibtex": "INPROCEEDINGS{Kaur2017_184,\n    author = \"{Kaur}, A. and {Jain}, S. and {Goel}, S.\",\n    booktitle = \"2017 International Conference on Machine Learning and Data Science (MLDS)\",\n    title = \"A Support Vector Machine Based Approach for Code Smell Detection\",\n    year = \"2017\",\n    volume = \"\",\n    number = \"\",\n    pages = \"9-14\",\n    doi = \"10.1109/MLDS.2017.8\"\n}\n\n",
    "abstract": "Code smells may be introduced in software due to\nmarket rivalry, work pressure deadline, improper functioning,\nskills or inexperience of software developers. Code smells indicate\nproblems in design or code which makes software hard to\nchange and maintain. Detecting code smells could reduce the\neffort of developers, resources and cost of the software. Many\nresearchers have proposed different techniques like DETEX for\ndetecting code smells which have limited precision and recall. To\novercome these limitations,a new technique named as SVMCSD\nhas been proposed for the detection of code smells, based on\nsupport vector machine learning technique. Four code smells are\nspecified namely God Class, Feature Envy,Data Class and Long\nMethod and the proposed technique is validated on two open\nsource systems namely ArgoUML and Xerces. The accuracy of\nSVMCSD is found to be better than DETEX in terms of two\nmetrics, precision and recall, when applied on a subset of a\nsystem. While considering the entire system, SVMCSD detect\nmore occurrences of code smells than DETEX."
}, {
    "py/object": "data.DataClassPaper",
    "Title": "A survey on machine learning techniques used for software quality prediction",
    "year": 2016,
    "ML_Techniques": "",
    "Category": "Quality assessment",
    "Sub_category": "Quality assessment/prediction,Quality prediction,Quality assessment/prediction,Quality assessment/prediction,Quality prediction,Quality assessment/prediction,Quality prediction",
    "Venue": "IJRIS",
    "Link": "https://www.inderscienceonline.com/doi/abs/10.1504/IJRIS.2016.080058",
    "bibtex": "article{Pattnaik2016_185,\n    author = \"Pattnaik, Saumendra and Pattanayak, Binod\",\n    year = \"2016\",\n    month = \"01\",\n    pages = \"3\",\n    title = \"A survey on machine learning techniques used for software quality prediction\",\n    volume = \"8\",\n    journal = \"International Journal of Reasoning-based Intelligent Systems\",\n    doi = \"10.1504/IJRIS.2016.080058\"\n}\n\n",
    "abstract": "In the present software development scenario, software quality prediction has become\nsignificantly important for successful implementation of the software in real world application\nand enhances the longevity of its functionality. Moreover, early identification of anticipated fault\nprone software modules in the process of development of software is crucial in saving efforts\ninvolved in this process. Machine learning techniques are considered to be the most appropriate\ntechniques for software quality prediction and a large spectrum of research work has been\nconducted in this direction by several authors. In this paper, we conduct an extensive survey on\nvarious machine learning techniques like fuzzy logic, neural network, and Bayesian model, etc.\nused for software quality prediction along with an analytical justification for each of the proposed\nsolutions."
}, {
    "py/object": "data.DataClassPaper",
    "Title": "A systematic literature review of machine learning techniques for software maintainability prediction",
    "year": 2020,
    "ML_Techniques": "",
    "Category": "Quality assessment",
    "Sub_category": "Quality assessment/prediction,Quality prediction,Quality assessment/prediction,Quality assessment/prediction,Quality prediction,Quality assessment/prediction,Quality prediction",
    "Venue": "IST",
    "Link": "https://www.sciencedirect.com/science/article/abs/pii/S0950584919302228",
    "bibtex": "article{Alsolai2020_186,\n    author = \"Alsolai, Hadeel and Roper, Marc\",\n    title = \"A systematic literature review of machine learning techniques for software maintainability prediction\",\n    journal = \"Information and Software Technology\",\n    volume = \"119\",\n    pages = \"106214\",\n    year = \"2020\",\n    issn = \"0950-5849\",\n    doi = \"https://doi.org/10.1016/j.infsof.2019.106214\",\n    url = \"http://www.sciencedirect.com/science/article/pii/S0950584919302228\",\n    keywords = \"Systematic literature review, Software maintainability prediction, Machine learning, Metric, Dataset\",\n    abstract = \"Context Software maintainability is one of the fundamental quality attributes of software engineering. The accurate prediction of software maintainability is a significant challenge for the effective management of the software maintenance process. Objective The major aim of this paper is to present a systematic review of studies related to the prediction of maintainability of object-oriented software systems using machine learning techniques. This review identifies and investigates a number of research questions to comprehensively summarize, analyse and discuss various viewpoints concerning software maintainability measurements, metrics, datasets, evaluation measures, individual models and ensemble models. Method The review uses the standard systematic literature review method applied to the most common computer science digital database libraries from January 1991 to July 2018. Results We survey 56 relevant studies in 35 journals and 21 conference proceedings. The results indicate that there is relatively little activity in the area of software maintainability prediction compared with other software quality attributes. CHANGE maintenance effort and the maintainability index were the most commonly used software measurements (dependent variables) employed in the selected primary studies, and most made use of class-level product metrics as the independent variables. Several private datasets were used in the selected studies, and there is a growing demand to publish datasets publicly. Most studies focused on regression problems and performed k-fold cross-validation. Individual prediction models were employed in the majority of studies, while ensemble models relatively rarely. Conclusion Based on the findings obtained in this systematic literature review, ensemble models demonstrated increased accuracy prediction over individual models, and have been shown to be useful models in predicting software maintainability. However, their application is relatively rare and there is a need to apply these, and other models to an extensive variety of datasets with the aim of improving the accuracy and consistency of results.\"\n}\n\n",
    "abstract": "Context: Software maintainability is one of the fundamental quality attributes of software engineering. The accurate prediction of software maintainability is a significant challenge for the effective management of the software maintenance process. Objective: The major aim of this paper is to present a systematic review of studies related to the prediction of maintainability of object-oriented software systems using machine learning techniques. This review identifies and investigates a number of research questions to comprehensively summarize, analyse and discuss various viewpoints concerning software maintainability measurements, metrics, datasets, evaluation measures, individual models and ensemble models. Method: The review uses the standard systematic literature review method applied to the most common computer science digital database libraries from January 1991 to July 2018. Results: We survey 56 relevant studies in 35 journals and 21 conference proceedings. The results indicate that there is relatively little activity in the area of software maintainability prediction compared with other software quality attributes. CHANGE maintenance effort and the maintainability index were the most commonly used software measurements (dependent variables) employed in the selected primary studies, and most made use of class-level product metrics as the independent variables. Several private datasets were used in the selected studies, and there is a growing demand to publish datasets publicly. Most studies focused on regression problems and performed k-fold cross-validation. Individual prediction models were employed in the majority of studies, while ensemble models relatively rarely. Conclusion: Based on the findings obtained in this systematic literature review, ensemble models demonstrated increased accuracy prediction over individual models, and have been shown to be useful models in predicting software maintainability. However, their application is relatively rare and there is a need to apply these, and other models to an extensive variety of datasets with the aim of improving the accuracy and consistency of results."
}, {
    "py/object": "data.DataClassPaper",
    "Title": "Adaptive on-line software aging prediction based on machine learning",
    "year": 2010,
    "ML_Techniques": "DT",
    "Category": "Quality assessment",
    "Sub_category": "Quality assessment/prediction,Quality prediction,Quality assessment/prediction,Quality assessment/prediction,Quality prediction,Quality assessment/prediction,Quality prediction",
    "Venue": "DSN",
    "Link": "https://ieeexplore.ieee.org/abstract/document/5544275",
    "bibtex": "INPROCEEDINGS{Alonso2010_188,\n    author = \"{Alonso}, J. and {Torres}, J. and {Berral}, J. L. and {Gavald\u00e0}, R.\",\n    booktitle = \"2010 IEEE/IFIP International Conference on Dependable Systems Networks (DSN)\",\n    title = \"Adaptive on-line software aging prediction based on machine learning\",\n    year = \"2010\",\n    volume = \"\",\n    number = \"\",\n    pages = \"507-516\",\n    doi = \"10.1109/DSN.2010.5544275\"\n}\n\n",
    "abstract": "The growing complexity of software systems is resulting\nin an increasing number of software faults. According\nto the literature, software faults are becoming one of\nthe main sources of unplanned system outages, and have\nan important impact on company benefits and image. For\nthis reason, a lot of techniques (such as clustering, fail-over\ntechniques, or server redundancy) have been proposed to\navoid software failures, and yet they still happen. Many\nsoftware failures are those due to the software aging phenomena.\nIn this work, first, we propose a new framework\nfor predicting in real time the time-until-crash of web applications\nwhich suffer from software aging, using machine\nlearning techniques. Our framework allows recovery of the\npotentially crashing server using a clean automatic recovery\nand avoiding losses of new and on-going user requests.\nSecond, we present a detailed evaluation of our chosen\nmachine learning prediction algorithm (M5P) in front of\ndynamic and non-deterministic software aging. We have\ntested our prediction model on a three-tier web J2EE application\nachieving acceptable prediction accuracy against\ncomplex scenarios with small training data sets. Furthermore,\nwe have found an interesting approach to help to determine\nthe root cause failure: The model generated by machine\nlearning algorithms."
}, {
    "py/object": "data.DataClassPaper",
    "Title": "An Empirical Analysis on Web Service Anti-pattern Detection Using a Machine Learning Framework",
    "year": 2018,
    "ML_Techniques": "RF, LOG, DT, LB, AB, B, MLP, NB",
    "Category": "Quality assessment",
    "Sub_category": "Code smell detection",
    "Venue": "COMPSAC",
    "Link": "https://ieeexplore.ieee.org/document/8377634",
    "bibtex": "INPROCEEDINGS{Kumar2018_189,\n    author = \"{Kumar}, L. and {Sureka}, A.\",\n    booktitle = \"2018 IEEE 42nd Annual Computer Software and Applications Conference (COMPSAC)\",\n    title = \"An Empirical Analysis on Web Service Anti-pattern Detection Using a Machine Learning Framework\",\n    year = \"2018\",\n    volume = \"01\",\n    number = \"\",\n    pages = \"2-11\",\n    doi = \"10.1109/COMPSAC.2018.00010\"\n}\n\n",
    "abstract": "Web Services are application components characterised\nby interoperability, extensibility, distributed application\ndevelopment and service oriented architecture. A complex distributed\napplication can be developed by combing several thirdparty\nweb-services. Anti-patterns are counter-productive and\npoor design and practices. Web-services suffer from a multitude\nof anti-patterns such as God object Web service and Fine grained\nWeb service. Our work is motivated by the need to build\ntechniques for automatically detecting common web-services antipatterns\nby static analysis of the source code implementing a webservice.\nOur approach is based on the premise that summary\nvalues of object oriented source code metrics computed at a\nweb-service level can be used as a predictor for anti-patterns.\nWe present an empirical analysis of 4 data sampling techniques\nto encounter the class imbalance problem, 5 feature ranking\ntechniques to identify the most informative and relevant features\nand 8 machine learning algorithms for predicting 5 different\ntypes of anti-patterns on 226 real-world web-services across\nseveral domains. We conclude that it is possible to predict antipatterns\nusing source code metrics and a machine learning framework.\nOur analysis reveals that the best performing classification\nalgorithm is Random Forest, best performing data sampling\ntechnique is SMOTE and the best performing feature ranking\nmethod is OneR."
}, {
    "py/object": "data.DataClassPaper",
    "Title": "An Empirical Framework for Code Smell Prediction using Extreme Learning Machine",
    "year": 2019,
    "ML_Techniques": "LOG, LR, DT, POLY",
    "Category": "Quality assessment",
    "Sub_category": "Code smell detection",
    "Venue": "IEMECON",
    "Link": "https://ieeexplore.ieee.org/document/8877082",
    "bibtex": "INPROCEEDINGS{Gupta2019_190,\n    author = \"{Gupta}, H. and {Kumar}, L. and {Neti}, L. B. M.\",\n    booktitle = \"2019 9th Annual Information Technology, Electromechanical Engineering and Microelectronics Conference (IEMECON)\",\n    title = \"An Empirical Framework for Code Smell Prediction using Extreme Learning Machine*\",\n    year = \"2019\",\n    volume = \"\",\n    number = \"\",\n    pages = \"189-195\",\n    doi = \"10.1109/IEMECONX.2019.8877082\"\n}\n\n",
    "abstract": "The software containing code smells indicates the violation of standard design and coding practices by developer during the development of the software system. Recent empirical studies observed that classes having code smells have higher probability of change proneness or fault proneness with respect to classes having no code smells [1]. The effort of removing bugs due to code smells increases exponentially if the smells are not identified during the earlier phases of software development. The code smell prediction using source code metrics can be used in starting phases of software development life cycle to reduce the maintenance and testing effort of software and also help in improving the quality of the software. The work in this paper empirically investigates and evaluates different classification techniques, feature selection techniques, and data sampling techniques to handle imbalance data in predicting 7 different types of code smell. The conclusion of this research is assessed over 629 application packages. The experimental finding confirms the estimating capability of different classifiers, feature selection, and data imbalance techniques for developing code smell prediction models. Our analysis also reveals that the models developed using one technique are superior than the models developed using other techniques."
}, {
    "py/object": "data.DataClassPaper",
    "Title": "Application of machine learning algorithms for code smell prediction using object-oriented software metrics",
    "year": 2020,
    "ML_Techniques": "DT, RF",
    "Category": "Quality assessment",
    "Sub_category": "Code smell detection",
    "Venue": "JSMS",
    "Link": "https://www.tandfonline.com/doi/abs/10.1080/09720510.2020.1799576",
    "bibtex": "article{Agnihotri2020_193,\n    author = \"Agnihotri, Mansi and Chug, Anuradha\",\n    title = \"Application of machine learning algorithms for code smell prediction using object-oriented software metrics\",\n    journal = \"Journal of Statistics and Management Systems\",\n    volume = \"23\",\n    number = \"7\",\n    pages = \"1159-1171\",\n    year = \"2020\",\n    publisher = \"Taylor \\& Francis\",\n    doi = \"10.1080/09720510.2020.1799576\",\n    URL = \"https://doi.org/10.1080/09720510.2020.1799576\",\n    eprint = \"https://doi.org/10.1080/09720510.2020.1799576\"\n}\n\n",
    "abstract": "Code smells are generally not considered as bugs; instead, they point out certain\nshortcomings in the software design or code. Identification of code smell is a necessary step\nfor improving the software quality and reducing the maintenance effort. In this study, we\nintroduce a bad smell prediction technique based on object- oriented software metrics that\nuse Decision Tree (DT) and Random Forest (RF) machine learning algorithm. An open-source\nproject, namely JHOTDRAW, was used as our dataset, for which values of object-oriented\nsoftware metrics were calculated. Two feature selection methods- Random Forest Importance\n(RFI) and Information Gain (IG) were applied to extract the most relevant attributes for the\nprediction of code smells, namely, Feature envy, Dispersed coupling, refused parent bequest,\nand God class. The random-search algorithm was used to tune the parameters of Random\nForest and Decision Tree. Results show that the best classification accuracy for Decision Tree\nwas obtained at 99.13% for refused parent bequest code smells. Results also show that after\nusing the Random Forest classifier, refused parent bequest smell was predicted with the best\naccuracy of 99.14%. Finally, in this research study, a set of code smell prediction rules were\nextracted using Decision Tree."
}, {
    "py/object": "data.DataClassPaper",
    "Title": "Applying Machine Learning in Technical Debt Management: Future Opportunities and Challenges",
    "year": 2020,
    "ML_Techniques": "",
    "Category": "Quality assessment",
    "Sub_category": "Technical debt identification",
    "Venue": "QICT",
    "Link": "https://link.springer.com/chapter/10.1007/978-3-030-58793-2_5",
    "bibtex": "InProceedings{Tsintzira2020_194,\n    author = \"Tsintzira, Angeliki-Agathi and Arvanitou, Elvira-Maria and Ampatzoglou, Apostolos and Chatzigeorgiou, Alexander\",\n    editor = \"Shepperd, Martin and Brito e Abreu, Fernando and Rodrigues da Silva, Alberto and P{\\'e}rez-Castillo, Ricardo\",\n    title = \"Applying Machine Learning in Technical Debt Management: Future Opportunities and Challenges\",\n    booktitle = \"Quality of Information and Communications Technology\",\n    year = \"2020\",\n    publisher = \"Springer International Publishing\",\n    address = \"Cham\",\n    pages = \"53--67\",\n    abstract = \"Technical Debt Management (TDM) is a fast-growing field that in the last years has attracted the attention of both academia and industry. TDM is a complex process, in the sense that it relies on multiple and heterogeneous data sources (e.g., source code, feature requests, bugs, developers' activity, etc.), which cannot be straightforwardly synthesized; leading the community to using mostly qualitative empirical methods. However, empirical studies that involve expert judgement are inherently biased, compared to automated or semi-automated approaches. To overcome this limitation, the broader (not TDM) software engineering community has started to employ machine learning (ML) technologies. Our goal is to investigate the opportunity of applying ML technologies for TDM, through a Systematic Literature Review (SLR) on the application of ML to software engineering problems (since ML applications on TDM are limited). Thus, we have performed a broader scope study, i.e., on machine learning for software engineering, and then synthesize the results so as to achieve our high-level goal (i.e., possible application of ML in TDM). Therefore, we have conducted a literature review, by browsing the research corpus published in five high-quality SE journals, with the goal of cataloging: (a) the software engineering practices in which ML is used; (b) the machine learning technologies that are used for solving them; and (c) the intersection of the two: developing a problem-solution mapping. The results are useful to both academics and industry, since the former can identify possible gaps, and interesting future research directions, whereas the latter can obtain benefits by adopting ML technologies.\",\n    isbn = \"978-3-030-58793-2\"\n}\n\n",
    "abstract": "Technical Debt Management (TDM) is a fast-growing field that in the last years has attracted the attention of both academia and industry. TDM is a complex process, in the sense that it relies on multiple and heterogeneous data sources (e.g., source code, feature requests, bugs, developers\u2019 activity, etc.), which cannot be straightforwardly synthesized; leading the community to using mostly qualitative empirical methods. However, empirical studies that involve expert judgement are inherently biased, compared to automated or semi-auto-mated approaches. To overcome this limitation, the broader (not TDM) software engineering community has started to employ machine learning (ML) technolo-gies. Our goal is to investigate the opportunity of applying ML technologies for TDM, through a Systematic Literature Review (SLR) on the application of ML to software engineering problems (since ML applications on TDM are limited). Thus, we have performed a broader scope study, i.e., on machine learning for software engineering, and then synthesize the results so as to achieve our high-level goal (i.e., possible application of ML in TDM). Therefore, we have con-ducted a literature review, by browsing the research corpus published in five high-quality SE journals, with the goal of cataloging: (a) the software engineering practices in which ML is used; (b) the machine learning technologies that are used for solving them; and (c) the intersection of the two: developing a problem-solution mapping. The results are useful to both academics and industry, since the former can identify possible gaps, and interesting future research directions, whereas the later can obtain benefits by adopting ML technologies."
}, {
    "py/object": "data.DataClassPaper",
    "Title": "Applying Machine Learning to Customized Smell Detection: A Multi-Project Study",
    "year": 2020,
    "ML_Techniques": "Ripper, RF, DT, OR, SVM, SMO, NB",
    "Category": "Quality assessment",
    "Sub_category": "Code smell detection",
    "Venue": "SBES",
    "Link": "https://www.researchgate.net/publication/345310750_Applying_Machine_Learning_to_Customized_Smell_Detection_A_Multi-Project_Study",
    "bibtex": "inproceedings{Oliveira2020_195,\n\tauthor = {Oliveira, Daniel and Assun\\c{c}\\~{a}o, Wesley K. G. and Souza, Leonardo and Oizumi, Willian and Garcia, Alessandro and Fonseca, Baldoino},\ntitle = {Applying Machine Learning to Customized Smell Detection: A Multi-Project Study},\nyear = {2020},\nisbn = {9781450387538},\npublisher = {Association for Computing Machinery},\naddress = {New York, NY, USA},\nurl = {https://doi.org/10.1145/3422392.3422427},\ndoi = {10.1145/3422392.3422427},\npages = {233\u2013242},\nnumpages = {10},\nkeywords = {code smell, software quality, code smell detection},\nlocation = {Natal, Brazil},\nseries = {SBES '20}\n}\n\n",
    "abstract": "Code smells are considered symptoms of poor implementation\nchoices, which may hamper the software maintainability. Hence,\ncode smells should be detected as early as possible to avoid software\nquality degradation. Unfortunately, detecting code smells is not a\ntrivial task. Some preliminary studies investigated and concluded\nthat machine learning (ML) techniques are a promising way to\nbetter support smell detection. However, these techniques are hard\nto be customized to promote an early and accurate detection of\nspecific smell types. Yet, ML techniques usually require numerous\ncode examples to be trained (composing a relevant dataset) in order\nto achieve satisfactory accuracy. Unfortunately, such a dependency\non a large validated dataset is impractical and leads to late detection\nof code smells. Thus, a prevailing challenge is the early customized\ndetection of code smells taking into account the typical limited\ntraining data. In this direction, this paper reports a study in which\nwe collected code smells, from ten active projects, that were actually\nrefactored by developers, differently from studies that rely on code\nsmells inferred by researchers. These smells were used for evaluating\nthe accuracy regarding early detection of code smells by using\nseven ML techniques. Once we take into account such smells that\nwere considered as important by developers, the ML techniques are\nable to customize the detection in order to focus on smells observed\nas relevant in the investigated systems. The results showed that\nall the analyzed techniques are sensitive to the type of smell and\nobtained good results for the majority of them, especially JRip and\nRandom Forest. We also observe that the ML techniques did not\nneed a high number of examples to reach their best accuracy results.\nThis finding implies that ML techniques can be successfully used\nfor early detection of smells without depending on the curation of\na large dataset."
}, {
    "py/object": "data.DataClassPaper",
    "Title": "Assessment of Code Smell for Predicting Class Change Proneness Using Machine Learning",
    "year": 2019,
    "ML_Techniques": "NB, MLP, LB, B, RF, DT",
    "Category": "Quality assessment",
    "Sub_category": "Code smell detection",
    "Venue": "IEEE Access",
    "Link": "https://ieeexplore.ieee.org/abstract/document/8667419",
    "bibtex": "ARTICLE{Pritam2019_196,\n    author = \"{Pritam}, N. and {Khari}, M. and {Hoang Son}, L. and {Kumar}, R. and {Jha}, S. and {Priyadarshini}, I. and {Abdel-Basset}, M. and {Viet Long}, H.\",\n    journal = \"IEEE Access\",\n    title = \"Assessment of Code Smell for Predicting Class Change Proneness Using Machine Learning\",\n    year = \"2019\",\n    volume = \"7\",\n    number = \"\",\n    pages = \"37414-37425\",\n    doi = \"10.1109/ACCESS.2019.2905133\"\n}\n\n",
    "abstract": "Assessment of code smell for predicting software change proneness is essential to ensure\nits signi cance in the area of software quality. While multiple studies have been conducted in this regard,\nthe number of systems studied and the methods used in this paper are quite different, thus, causing confusion\nfor understanding the best methodology. The objective of this paper is to approve the effect of code smell\non the change inclination of a speci c class in a product framework. This is the novelty and surplus of this\nwork against the others. Furthermore, this paper aims to validate code smell for predicting class change\nproneness to  nd an error in the prediction of change proneness using code smell. Six typical machine\nlearning algorithms (Naive Bayes Classi er, Multilayer Perceptron, LogitBoost, Bagging, Random Forest,\nand Decision Tree) have been used to predict change proneness using code smell from a set of 8200 Java\nclasses spanning 14 software systems. The experimental results suggest that code smell is indeed a powerful\npredictor of class change proneness with multilayer perceptron being the most effective technique. The\nsensitivity and speci city values for all the models are well over 70% with a few exceptions."
}, {
    "py/object": "data.DataClassPaper",
    "Title": "Bad Smell Detection Using Machine Learning Techniques: A Systematic Literature Review",
    "year": 2020,
    "ML_Techniques": "",
    "Category": "Quality assessment",
    "Sub_category": "Code smell detection",
    "Venue": "AJSE",
    "Link": "https://link.springer.com/article/10.1007/s13369-019-04311-w",
    "bibtex": "ARTICLE{Pritam2019_196,\n    author = \"{Pritam}, N. and {Khari}, M. and {Hoang Son}, L. and {Kumar}, R. and {Jha}, S. and {Priyadarshini}, I. and {Abdel-Basset}, M. and {Viet Long}, H.\",\n    journal = \"IEEE Access\",\n    title = \"Assessment of Code Smell for Predicting Class Change Proneness Using Machine Learning\",\n    year = \"2019\",\n    volume = \"7\",\n    number = \"\",\n    pages = \"37414-37425\",\n    doi = \"10.1109/ACCESS.2019.2905133\"\n}\n\n",
    "abstract": "Code smells are indicators of potential problems in software. They tend to have a negative impact on software quality. Several studies use machine learning techniques to detect bad smells. The objective of this study is to systematically review and analyze machine learning techniques used to detect code smells to provide interested research community with knowledge about the adopted techniques and practices for code smells detection. We use a systematic literature review approach to review studies that use machine learning techniques to detect code smells. Seventeen primary studies were identified. We found that 27 code smells were used in the identified studies; God Class and Long Method, Feature Envy, and Data Class are the most frequently detected code smells. In addition, we found that 16 machine learning algorithms were employed to detect code smells with acceptable prediction accuracy. Furthermore, we the results also indicate that support vector machine techniques were investigated the most. Moreover, we observed that J48 and Random Forest algorithms outperform the other algorithms. We also noticed that, in some cases, the use of boosting techniques on the models does not always enhance their performance. More studies are needed to consider the use of ensemble learning techniques, multiclassification, and feature selection technique for code smells detection. Thus, the application of machine learning algorithms to detect code smells in systems is still in its infancy and needs more research to facilitate the employment of machine learning algorithms in detecting code smells."
}, {
    "py/object": "data.DataClassPaper",
    "Title": "Bilateral Dependency Neural Networks for Cross-Language Algorithm Classification",
    "year": 2019,
    "ML_Techniques": "BiNN",
    "Category": "Quality assessment",
    "Sub_category": "Clone detection",
    "Venue": "SANER",
    "Link": "https://bdqnghi.github.io/files/SANER_2019_bilateral_dependency.pdf",
    "bibtex": "INPROCEEDINGS{Bui2019_200,\n    author = \"{Bui}, N. D. Q. and {Yu}, Y. and {Jiang}, L.\",\n    booktitle = \"2019 IEEE 26th International Conference on Software Analysis, Evolution and Reengineering (SANER)\",\n    title = \"Bilateral Dependency Neural Networks for Cross-Language Algorithm Classification\",\n    year = \"2019\",\n    volume = \"\",\n    number = \"\",\n    pages = \"422-433\",\n    doi = \"10.1109/SANER.2019.8667995\"\n}\n\n",
    "abstract": "Algorithm classification is to automatically identify\nthe classes of a program based on the algorithm(s) and/or data\nstructure(s) implemented in the program. It can be useful for\nvarious tasks, such as code reuse, code theft detection, and malware\ndetection. Code similarity metrics, on the basis of features\nextracted from syntax and semantics, have been used to classify\nprograms. Such features, however, often need manual selection\neffort and are specific to individual programming languages,\nlimiting the classifiers to programs in the same language.\nTo recognize the similarities and differences among algorithms\nimplemented in different languages, this paper describes a\nframework of Bilateral Neural Networks (Bi-NN) that builds a\nneural network on top of two underlying sub-networks, each of\nwhich encodes syntax and semantics of code in one language. A\nwhole Bi-NN can be trained with bilateral programs that implement\nthe same algorithms and/or data structures in different\nlanguages and then be applied to recognize algorithm classes\nacross languages.\nWe have instantiated the framework with several kinds of\ntoken-, tree- and graph-based neural networks that encode and\nlearn various kinds of information in code. We have applied\nthe instances of the framework to a code corpus collected from\nGitHub containing thousands of Java and C++ programs implementing\n50 different algorithms and data structures. Our evaluation\nresults show that the use of Bi-NN indeed produces promising\nalgorithm classification results both within one language and\nacross languages, and the encoding of dependencies from code\ninto the underlying neural networks helps improve algorithm\nclassification accuracy further. In particular, our custom-built\ndependency trees with tree-based convolutional neural networks\nachieve the highest classification accuracy among the different\ninstances of the framework that we have evaluated. Our study\npoints to a possible future research direction to tailor bilateral\nand multilateral neural networks that encode more relevant\nsemantics for code learning, mining and analysis tasks."
}, {
    "py/object": "data.DataClassPaper",
    "Title": "Classification model for code clones based on machine learning",
    "year": 2015,
    "ML_Techniques": "KM, COBWEB, EM",
    "Category": "Quality assessment",
    "Sub_category": "Clone detection",
    "Venue": "EMSE",
    "Link": "https://link.springer.com/article/10.1007/s10664-014-9316-x",
    "bibtex": "article{Yang2014_202,\n    author = \"Yang, Jiachen and Hotta, K. and Higo, Yoshiki and Igaki, H. and Kusumoto, S.\",\n    title = \"Classification model for code clones based on machine learning\",\n    journal = \"Empirical Software Engineering\",\n    year = \"2014\",\n    volume = \"20\",\n    pages = \"1095-1125\"\n}\n\n",
    "abstract": "Results from code clone detectors may contain plentiful useless code clones, but\njudging whether each code clone is useful varies from user to user based on a user\u2019s purpose\nfor the clone. In this research, we propose a classification model that applies machine learning\nto the judgments of each individual user regarding the code clones. To evaluate the proposed\nmodel, 32 participants completed an online survey to test its usability and accuracy. The result\nshowed several important observations on the characteristics of the true positives of code\nclones for the users. Our classification model showed more than 70% accuracy on average and\nmore than 90 % accuracy for some particular users and projects."
}, {
    "py/object": "data.DataClassPaper",
    "Title": "CloneCognition: machine learning based code clone validation tool",
    "year": 2019,
    "ML_Techniques": "ANN",
    "Category": "Quality assessment",
    "Sub_category": "Clone detection",
    "Venue": "FSE",
    "Link": "https://dl.acm.org/doi/10.1145/3338906.3341182",
    "bibtex": "article{Yang2014_202,\n    author = \"Yang, Jiachen and Hotta, K. and Higo, Yoshiki and Igaki, H. and Kusumoto, S.\",\n    title = \"Classification model for code clones based on machine learning\",\n    journal = \"Empirical Software Engineering\",\n    year = \"2014\",\n    volume = \"20\",\n    pages = \"1095-1125\"\n}\n\n",
    "abstract": "A code clone is a pair of similar code fragments, within or between\nsoftware systems. To detect each possible clone pair from\na software system while handling the complex code structures,\nthe clone detection tools undergo a lot of generalization of the\noriginal source codes. The generalization often results in returning\ncode fragments that are only coincidentally similar and not\nconsidered clones by users, and hence requires manual validation\nof the reported possible clones by users which is often both\ntime-consuming and challenging. In this paper, we propose a machine\nlearning based tool \u2018CloneCognition\u2019 (Open Source Codes:\nhttps://github.com/pseudoPixels/CloneCognition ; Video Demonstration:\nhttps://www.youtube.com/watch?v=KYQjmdr8rsw) to automate\nthe laborious manual validation process. The tool runs on\ntop of any code clone detection tools to facilitate the clone validation\nprocess. The tool shows promising clone classification performance\nwith an accuracy of up to 87.4%. The tool also exhibits significant\nimprovement in the results when compared with state-of-the-art\ntechniques for code clone validation."
}, {
    "py/object": "data.DataClassPaper",
    "Title": "Clonewise \u2013 Detecting Package-Level Clones Using Machine Learning",
    "year": 2013,
    "ML_Techniques": "NB, MLP, RF",
    "Category": "Quality assessment",
    "Sub_category": "Clone detection",
    "Venue": "SPCN",
    "Link": "https://link.springer.com/chapter/10.1007/978-3-319-04283-1_13",
    "bibtex": "article{Yang2014_202,\n    author = \"Yang, Jiachen and Hotta, K. and Higo, Yoshiki and Igaki, H. and Kusumoto, S.\",\n    title = \"Classification model for code clones based on machine learning\",\n    journal = \"Empirical Software Engineering\",\n    year = \"2014\",\n    volume = \"20\",\n    pages = \"1095-1125\"\n}\n\n",
    "abstract": "Developers sometimes maintain an internal copy of another software\nor fork development of an existing project. This practice can lead to software\nvulnerabilities when the embedded code is not kept up to date with upstream\nsources. We propose an automated solution to identify clones of packages\nwithout any prior knowledge of these relationships. We then correlate clones\nwith vulnerability information to identify outstanding security problems. This\napproach motivates software maintainers to avoid using cloned packages and\nlink against system wide libraries. We propose over 30 novel features that\nenable us to use to use pattern classification to accurately identify package-level\nclones. To our knowledge, we are the first to consider clone detection as a\nclassification problem. Our results show our system, Clonewise, compares well\nto manually tracked databases. Based on our work, over 30 unknown package\nclones and vulnerabilities have been identified and patched."
}, {
    "py/object": "data.DataClassPaper",
    "Title": "Code smell detection using multi-label classification approach",
    "year": 2020,
    "ML_Techniques": "BR, CC, LC",
    "Category": "Quality assessment",
    "Sub_category": "Code smell detection",
    "Venue": "SQJ",
    "Link": "https://link.springer.com/article/10.1007/s11219-020-09498-y",
    "bibtex": "article{Guggulothu2020_206,\n    author = \"Guggulothu, Thirupathi and Moiz, S. A.\",\n    title = \"Code smell detection using multi-label classification approach\",\n    journal = \"Software Quality Journal\",\n    year = \"2020\",\n    pages = \"1-24\"\n}\n\n",
    "abstract": "Code smells are characteristics of the software that indicates a code or design problem which\ncan make software hard to understand, evolve, and maintain. There are several code smell\ndetection tools proposed in the literature, but they produce different results. This is because\nsmells are informally defined or subjective in nature. Machine learning techniques help in\naddressing the issues of subjectivity, which can learn and distinguish the characteristics of\nsmelly and non-smelly source code elements (classes or methods). However, the existing\nmachine learning techniques can only detect a single type of smell in the code element that\ndoes not correspond to a real-world scenario as a single element can have multiple design\nproblems (smells). Further, the mechanisms proposed in the literature could not detect code\nsmells by considering the correlation (co-occurrence) among them. To address these shortcomings,\nwe propose and investigate the use of multi-label classification (MLC) methods to\ndetect whether the given code element is affected by multiple smells or not. In this proposal,\ntwo code smell datasets available in the literature are converted into a multi-label dataset\n(MLD). In the MLD, we found that there is a positive correlation between the two smells\n(long method and feature envy). In the classification phase, the two methods of MLC considered\nthe correlation among the smells and enhanced the performance (on average more\nthan 95% accuracy) for the 10-fold cross-validation with the ten iterations. The findings\nreported help the researchers and developers in prioritizing the critical code elements for\nrefactoring based on the number of code smells detected."
}, {
    "py/object": "data.DataClassPaper",
    "Title": "Code Smell Detection: Towards a Machine Learning-Based Approach",
    "year": 2013,
    "ML_Techniques": "DT, RF, NB, Ripper, SMO, SVM",
    "Category": "Quality assessment",
    "Sub_category": "Code smell detection",
    "Venue": "ICSME",
    "Link": "https://ieeexplore.ieee.org/document/6676916",
    "bibtex": "INPROCEEDINGS{Fontana2013_207,\n    author = \"{Fontana}, F. A. and {Zanoni}, M. and {Marino}, A. and {M\u00e4ntyl\u00e4}, M. V.\",\n    booktitle = \"2013 IEEE International Conference on Software Maintenance\",\n    title = \"Code Smell Detection: Towards a Machine Learning-Based Approach\",\n    year = \"2013\",\n    volume = \"\",\n    number = \"\",\n    pages = \"396-399\"\n}\n\n",
    "abstract": "Several code smells detection tools have been developed\nproviding different results, because smells can be subjectively\ninterpreted and hence detected in different ways. Usually\nthe detection techniques are based on the computation of different\nkinds of metrics, and other aspects related to the domain of the\nsystem under analysis, its size and other design features are not\ntaken into account. In this paper we propose an approach we are\nstudying based on machine learning techniques. We outline some\ncommon problems faced for smells detection and we describe the\ndifferent steps of our approach and the algorithms we use for\nthe classification."
}, {
    "py/object": "data.DataClassPaper",
    "Title": "Code Smell Prediction Employing Machine Learning Meets Emerging Java Language Constructs",
    "year": 2020,
    "ML_Techniques": "RF, NB, DT, Ripper",
    "Category": "Quality assessment",
    "Sub_category": "Code smell detection",
    "Venue": "Book",
    "Link": "https://link.springer.com/chapter/10.1007/978-3-030-34706-2_8",
    "bibtex": "Inbook{Grodzicka2020_208,\n    author = \"Grodzicka, Hanna and Ziobrowski, Arkadiusz and {\\L}akomiak, Zofia and Kawa, Micha{\\l} and Madeyski, Lech\",\n    editor = \"Poniszewska-Mara{\\'{n}}da, Aneta and Kryvinska, Natalia and Jarz{\\k{a}}bek, Stanis{\\l}aw and Madeyski, Lech\",\n    title = \"Code Smell Prediction Employing Machine Learning Meets Emerging Java Language Constructs\",\n    bookTitle = \"Data-Centric Business and Applications: Towards Software Development (Volume 4)\",\n    year = \"2020\",\n    publisher = \"Springer International Publishing\",\n    address = \"Cham\",\n    pages = \"137--167\",\n    abstract = \"Background: Defining code smell is not a trivial task. Their recognition tends to be highly subjective. Nevertheless some code smells detection tools have been proposed. Other recent approaches incline towards machine learning (ML) techniques to overcome disadvantages of using automatic detection tools. Objectives: We aim to develop a research infrastructure and reproduce the process of code smell prediction proposed by Arcelli Fontana et al. We investigate ML algorithms performance for samples including major modern Java language features. Those such as lambdas can shorten the code causing code smell presence not as obvious to detect and thus pose a challenge to both existing code smell detection tools and ML algorithms. Method: We extend the study with dataset consisting of 281 Java projects. For driving samples selection we define metrics considering lambdas and method reference, derived using custom JavaParser-based solution. Tagged samples with new constructions are used as an input for the utilized detection techniques. Results: Detection rules derived from the best performing algorithms like J48 and JRip incorporate newly introduced metrics. Conclusions: Presence of certain new Java language constructs may hide Long Method code smell or indicate a God Class. On the other hand, their absence or low number can suggest a Data Class.\",\n    isbn = \"978-3-030-34706-2\",\n    doi = \"10.1007/978-3-030-34706-2\\_8\",\n    url = \"https://doi.org/10.1007/978-3-030-34706-2\\_8\"\n}\n\n",
    "abstract": "Background: Defining code smell is not a trivial task. Their recognition tends to be highly\nsubjective. Nevertheless some code smells detection tools have been proposed. Other recent approaches incline\ntowards machine learning (ML) techniques to overcome disadvantages of using automatic detection tools.\nObjectives: We aim to develop a research infrastructure and reproduce the process of code smell prediction\nproposed by Arcelli Fontana et al. We investigate ML algorithms performance for samples including major\nmodern Java language features. Those such as lambdas can shorten the code causing code smell presence not\nas obvious to detect and thus pose a challenge to both existing code smell detection tools and ML algorithms.\nMethod: We extend the study with dataset consisting of 281 Java projects. For driving samples selection we\ndefine metrics considering lambdas and method reference, derived using custom JavaParser-based solution.\nTagged samples with new constructions are used as an input for the utilized detection techniques.\nResults: Detection rules derived from the best performing algorithms like J48 and JRip incorporate newly\nintroduced metrics.\nConclusions: Presence of certain new Java language constructs may hide Long Method code smell or indicate\na God Class. On the other hand, their absence or low number can suggest a Data Class"
}, {
    "py/object": "data.DataClassPaper",
    "Title": "Code smell severity classification using machine learning techniques",
    "year": 2017,
    "ML_Techniques": "SVM, SMO, NB, RF, Ripper, DT",
    "Category": "Quality assessment",
    "Sub_category": "Code smell detection",
    "Venue": "KBS",
    "Link": "https://www.sciencedirect.com/science/article/pii/S0950705117301880",
    "bibtex": "article{ArcelliFontana2017_209,\n    author = \"{Arcelli Fontana}, Francesca and Zanoni, Marco\",\n    title = \"Code smell severity classification using machine learning techniques\",\n    journal = \"Knowledge-Based Systems\",\n    volume = \"128\",\n    pages = \"43 - 58\",\n    year = \"2017\",\n    issn = \"0950-7051\",\n    doi = \"https://doi.org/10.1016/j.knosys.2017.04.014\",\n    url = \"http://www.sciencedirect.com/science/article/pii/S0950705117301880\",\n    keywords = \"Code smells detection, Machine learning, Code smell severity, Ordinal classification, Refactoring prioritization\"\n}\n\n",
    "abstract": "Several code smells detection tools have been developed providing different results, because smells can be subjectively interpreted and hence detected in different ways. Machine learning techniques have been used for different topics in software engineering, e.g., design pattern detection, code smell detection, bug prediction, recommending systems. In this paper, we focus our attention on the classification of code smell severity through the use of machine learning techniques in different experiments. The severity of code smells is an important factor to take into consideration when reporting code smell detection re- sults, since it allows the prioritization of refactoring efforts. In fact, code smells with high severity can be particularly large and complex, and create larger issues to the maintainability of software a system. In our experiments, we apply several machine learning models, spanning from multinomial classification to regression, plus a method to apply binary classifiers for ordinal classification. In fact, we model code smell severity as an ordinal variable. We take the baseline models from previous work, where we applied binary classification models for code smell detection with good results. We report and compare the per- formance of the models according to their accuracy and four different performance measures used for the evaluation of ordinal classification techniques. From our results, while the accuracy of the classification of severity is not high as in the binary classification of absence or presence of code smells, the ranking correlation of the actual and predicted severity for the best models reaches 0.88\u20130.96, measured through Spearman\u2019s \u03c1."
}, {
    "py/object": "data.DataClassPaper",
    "Title": "Comparing and experimenting machine learning techniques for code smell detection",
    "year": 2016,
    "ML_Techniques": "DT, Ripper, RF, NB, SMO, SVM",
    "Category": "Quality assessment",
    "Sub_category": "Code smell detection",
    "Venue": "EMSE",
    "Link": "https://link.springer.com/article/10.1007/s10664-015-9378-4",
    "bibtex": "article{Fontana2015_211,\n\ttitle={Comparing and experimenting machine learning techniques for code smell detection},\n\tauthor={F. Fontana and M. M{\\\"a}ntyl{\\\"a} and Marco Zanoni and Alessandro Marino},\n\tjournal={Empirical Software Engineering},\n\tyear={2015},\n\tvolume={21},\n\tpages={1143-1191}\n}\n\n",
    "abstract": "Several code smell detection tools have been developed providing different results,\nbecause smells can be subjectively interpreted, and hence detected, in different ways. In this\npaper, we perform the largest experiment of applying machine learning algorithms to code\nsmells to the best of our knowledge. We experiment 16 different machine-learning algorithms\non four code smells (Data Class, Large Class, Feature Envy, Long Method) and 74 software\nsystems, with 1986 manually validated code smell samples. We found that all algorithms\nachieved high performances in the cross-validation data set, yet the highest performances were\nobtained by J48 and Random Forest, while the worst performance were achieved by support\nvector machines. However, the lower prevalence of code smells, i.e., imbalanced data, in the\nentire data set caused varying performances that need to be addressed in the future studies. We\nconclude that the application of machine learning to the detection of these code smells can\nprovide high accuracy (>96 %), and only a hundred training examples are needed to reach at\nleast 95 % accuracy."
}, {
    "py/object": "data.DataClassPaper",
    "Title": "Comparing Heuristic and Machine Learning Approaches for Metric-Based Code Smell Detection",
    "year": 2019,
    "ML_Techniques": "DT, RF, NB, SVM, Ripper",
    "Category": "Quality assessment",
    "Sub_category": "Code smell detection",
    "Venue": "ICPC",
    "Link": "https://ieeexplore.ieee.org/document/8813271",
    "bibtex": "INPROCEEDINGS{Pecorelli2019_212,\n    author = \"{Pecorelli}, F. and {Palomba}, F. and {Di Nucci}, D. and {De Lucia}, A.\",\n    booktitle = \"2019 IEEE/ACM 27th International Conference on Program Comprehension (ICPC)\",\n    title = \"Comparing Heuristic and Machine Learning Approaches for Metric-Based Code Smell Detection\",\n    year = \"2019\",\n    volume = \"\",\n    number = \"\",\n    pages = \"93-104\"\n}\n\n",
    "abstract": "Code smells represent poor implementation choices\nperformed by developers when enhancing source code. Their\nnegative impact on source code maintainability and comprehensibility\nhas been widely shown in the past and several techniques\nto automatically detect them have been devised. Most of these\ntechniques are based on heuristics, namely they compute a set of\ncode metrics and combine them by creating detection rules; while\nthey have a reasonable accuracy, a recent trend is represented\nby the use of machine learning where code metrics are used as\npredictors of the smelliness of code artefacts. Despite the recent\nadvances in the field, there is still a noticeable lack of knowledge\nof whether machine learning can actually be more accurate than\ntraditional heuristic-based approaches. To fill this gap, in this\npaper we propose a large-scale study to empirically compare\nthe performance of heuristic-based and machine-learning-based\ntechniques for metric-based code smell detection. We consider\nfive code smell types and compare machine learning models with\nDECOR, a state-of-the-art heuristic-based approach. Key findings\nemphasize the need of further research aimed at improving the\neffectiveness of both machine learning and heuristic approaches\nfor code smell detection: while DECOR generally achieves better\nperformance than a machine learning baseline, its precision is\nstill too low to make it usable in practice."
}, {
    "py/object": "data.DataClassPaper",
    "Title": "Cross-Language Learning for Program Classification using Bilateral Tree-Based Convolutional Neural Networks",
    "year": 2018,
    "ML_Techniques": "",
    "Category": "Quality assessment",
    "Sub_category": "Clone detection",
    "Venue": "AAAI",
    "Link": "https://arxiv.org/abs/1710.06159v2",
    "bibtex": "inproceedings{Bui2018_214,\n    author = \"Bui, Nghi D. Q. and Jiang, Lingixao and Yu, Y.\",\n    title = \"Cross-Language Learning for Program Classification using Bilateral Tree-Based Convolutional Neural Networks\",\n    booktitle = \"AAAI Workshops\",\n    year = \"2018\"\n}\n\n",
    "abstract": "Towards the vision of translating code that implements an algorithm\nfrom one programming language into another, this\npaper proposes an approach for automated program classification\nusing bilateral tree-based convolutional neural networks\n(BiTBCNNs). It is layered on top of two tree-based\nconvolutional neural networks (TBCNNs), each of which recognizes\nthe algorithm of code written in an individual programming\nlanguage. The combination layer of the networks\nrecognizes the similarities and differences among code in different\nprogramming languages. The BiTBCNNs are trained\nusing the source code in different languages but known to\nimplement the same algorithms and/or functionalities. For\na preliminary evaluation, we use 3591 Java and 3534 C++\ncode snippets from 6 algorithms we crawled systematically\nfrom GitHub. We obtained over 90% accuracy in the crosslanguage\nbinary classification task to tell whether any given\ntwo code snippets implement a same algorithm. Also, for the\nalgorithm classification task, i.e., to predict which one of the\nsix algorithm labels is implemented by an arbitrary C++ code\nsnippet, we achieved over 80% precision."
}, {
    "py/object": "data.DataClassPaper",
    "Title": "Deep learning code fragments for code clone detection",
    "year": 2016,
    "ML_Techniques": "RNN, ReNN",
    "Category": "Quality assessment",
    "Sub_category": "Clone detection,,Clone detection,Clone detection,Clone detection,Clone detection,Clone detection,Clone detection,Clone detection,,Clone detection,Clone detection,Clone detection",
    "Venue": "ASE",
    "Link": "https://dl.acm.org/doi/10.1145/2970276.2970326",
    "bibtex": "inproceedings{Bui2018_214,\n    author = \"Bui, Nghi D. Q. and Jiang, Lingixao and Yu, Y.\",\n    title = \"Cross-Language Learning for Program Classification using Bilateral Tree-Based Convolutional Neural Networks\",\n    booktitle = \"AAAI Workshops\",\n    year = \"2018\"\n}\n\n",
    "abstract": "Code clone detection is an important problem for software\nmaintenance and evolution. Many approaches consider ei-\nther structure or identifiers, but none of the existing detec-\ntion techniques model both sources of information. These\ntechniques also depend on generic, handcrafted features to\nrepresent code fragments. We introduce learning-based de-\ntection techniques where everything for representing terms\nand fragments in source code is mined from the repository.\nOur code analysis supports a framework, which relies on\ndeep learning, for automatically linking patterns mined at\nthe lexical level with patterns mined at the syntactic level.\nWe evaluated our novel learning-based approach for code\nclone detection with respect to feasibility from the point\nof view of software maintainers. We sampled and manually\nevaluated 398 file- and 480 method-level pairs across eight\nreal-world Java systems; 93% of the file- and method-level\nsamples were evaluated to be true positives. Among the true\npositives, we found pairs mapping to all four clone types.We\ncompared our approach to a traditional structure-oriented\ntechnique and found that our learning-based approach de-\ntected clones that were either undetected or suboptimally\nreported by the prominent tool Deckard. Our results affirm\nthat our learning-based approach is suitable for clone detec-\ntion and a tenable technique for researchers."
}, {
    "py/object": "data.DataClassPaper",
    "Title": "DeepSim: deep learning code functional similarity",
    "year": 2018,
    "ML_Techniques": "DNN",
    "Category": "Quality assessment",
    "Sub_category": "Clone detection",
    "Venue": "FSE",
    "Link": "https://dl.acm.org/doi/10.1145/3236024.3236068",
    "bibtex": "inproceedings{Bui2018_214,\n    author = \"Bui, Nghi D. Q. and Jiang, Lingixao and Yu, Y.\",\n    title = \"Cross-Language Learning for Program Classification using Bilateral Tree-Based Convolutional Neural Networks\",\n    booktitle = \"AAAI Workshops\",\n    year = \"2018\"\n}\n\n",
    "abstract": "Measuring code similarity is fundamental for many software engineering\ntasks, e.g., code search, refactoring and reuse. However,\nmost existing techniques focus on code syntactical similarity only,\nwhile measuring code functional similarity remains a challenging\nproblem. In this paper, we propose a novel approach that encodes\ncode control flow and data flow into a semantic matrix in which\neach element is a high dimensional sparse binary feature vector,\nand we design a new deep learning model that measures code functional\nsimilarity based on this representation. By concatenating\nhidden representations learned from a code pair, this new model\ntransforms the problem of detecting functionally similar code to\nbinary classification, which can effectively learn patterns between\nfunctionally similar code with very different syntactics.\nWe have implemented our approach, DeepSim, for Java programs\nand evaluated its recall, precision and time performance on two\nlarge datasets of functionally similar code. The experimental results\nshow that DeepSim significantly outperforms existing state-of-theart\ntechniques, such as DECKARD, RtvNN, CDLH, and two baseline\ndeep neural networks models."
}, {
    "py/object": "data.DataClassPaper",
    "Title": "Design Flaws Prediction for Impact on Software Maintainability using Extreme Learning Machine",
    "year": 2020,
    "ML_Techniques": "ELM, LR, DT, PR, LOG",
    "Category": "Quality assessment",
    "Sub_category": "Code smell detection",
    "Venue": "JIC",
    "Link": "https://ieeexplore.ieee.org/document/9090717",
    "bibtex": "INPROCEEDINGS{Thongkum2020_217,\n    author = \"{Thongkum}, P. and {Mekruksavanich}, S.\",\n    booktitle = \"2020 Joint International Conference on Digital Arts, Media and Technology with ECTI Northern Section Conference on Electrical, Electronics, Computer and Telecommunications Engineering (ECTI DAMT NCON)\",\n    title = \"Design Flaws Prediction for Impact on Software Maintainability using Extreme Learning Machine\",\n    year = \"2020\",\n    volume = \"\",\n    number = \"\",\n    pages = \"79-82\",\n    doi = \"10.1109/ECTIDAMTNCON48261.2020.9090717\"\n}\n\n",
    "abstract": "The software that contains flaws in its design is\nan indication that the design and coding standards have been\nviolated by the developer during the software system\u2019s development.\nIt has been observed in recent empirical studies that\nclasses with flaws in the design flaws have a higher probability\nof change proneness or fault proneness when compared to\nclasses without flaws in the design. There is an exponential\nincrease in terms of the effort required to remove bugs due\nto design flaws in cases where the flaws are not detected in\nthe early stages of the development of the software. The use\nof source code metrics for the prediction of design flaws can\nbe implemented in the initial stages of the life cycle of the\nsoftware development for the reduction of the testing effort and\nthe maintenance of the software as well as the improvement of\nits quality. This empirical research study examines and assesses a\nvariety of techniques for classification, feature selection, and data\nsampling in order to deal with the imbalance data for prediction\nof several categories of design flaws. The assessment of more\nthan 20 application packages is the basis of the conclusions\nof this study. The results of the experiments indicate that the\nestimating capability of various classifiers, feature selection, and\ndata imbalance techniques for the development of prediction\nmodels for design flaws can be confirmed. In addition, it was\nalso revealed that the models that were developed through the\nuse of one particular technique were found to be superior to the\nmodels that were developed with the use of other techniques,\naccording to our analysis."
}, {
    "py/object": "data.DataClassPaper",
    "Title": "Detecting bad smells with machine learning algorithms: an empirical study",
    "year": 2020,
    "ML_Techniques": "NB, LR, DT, MLP, KNN, RF, GBM",
    "Category": "Quality assessment",
    "Sub_category": "Code smell detection",
    "Venue": "TechDebt",
    "Link": "https://dl.acm.org/doi/abs/10.1145/3387906.3388618",
    "bibtex": "INPROCEEDINGS{Thongkum2020_217,\n    author = \"{Thongkum}, P. and {Mekruksavanich}, S.\",\n    booktitle = \"2020 Joint International Conference on Digital Arts, Media and Technology with ECTI Northern Section Conference on Electrical, Electronics, Computer and Telecommunications Engineering (ECTI DAMT NCON)\",\n    title = \"Design Flaws Prediction for Impact on Software Maintainability using Extreme Learning Machine\",\n    year = \"2020\",\n    volume = \"\",\n    number = \"\",\n    pages = \"79-82\",\n    doi = \"10.1109/ECTIDAMTNCON48261.2020.9090717\"\n}\n\n",
    "abstract": "Bad smells are symptoms of bad design choices implemented on the source code. They are one of the key indicators of technical debts, specifically, design debt. To manage this kind of debt, it is important to be aware of bad smells and refactor them whenever possible. Therefore, several bad smell detection tools and techniques have been proposed over the years. These tools and techniques present different strategies to perform detections. More recently, machine learning algorithms have also been proposed to support bad smell detection. However, we lack empirical evidence on the accuracy and efficiency of these machine learning based techniques. In this paper, we present an evaluation of seven different machine learning algorithms on the task of detecting four types of bad smells. We also provide an analysis of the impact of software metrics for bad smell detection using a unified approach for interpreting the models' decisions. We found that with the right optimization, machine learning algorithms can achieve good performance (F1 score) for two bad smells: God Class (0.86) and Refused Parent Bequest (0.67). We also uncovered which metrics play fundamental roles for detecting each bad smell."
}, {
    "py/object": "data.DataClassPaper",
    "Title": "Detecting code smells using machine learning techniques: are we there yet?",
    "year": 2018,
    "ML_Techniques": "DT, Ripper, RF, NB, SMO, SVM",
    "Category": "Quality assessment",
    "Sub_category": "Code smell detection",
    "Venue": "SANER",
    "Link": "",
    "bibtex": "INPROCEEDINGS{Thongkum2020_217,\n    author = \"{Thongkum}, P. and {Mekruksavanich}, S.\",\n    booktitle = \"2020 Joint International Conference on Digital Arts, Media and Technology with ECTI Northern Section Conference on Electrical, Electronics, Computer and Telecommunications Engineering (ECTI DAMT NCON)\",\n    title = \"Design Flaws Prediction for Impact on Software Maintainability using Extreme Learning Machine\",\n    year = \"2020\",\n    volume = \"\",\n    number = \"\",\n    pages = \"79-82\",\n    doi = \"10.1109/ECTIDAMTNCON48261.2020.9090717\"\n}\n\n",
    "abstract": "Code smells are symptoms of poor design and implementation\nchoices weighing heavily on the quality of produced\nsource code. During the last decades several code smell detection\ntools have been proposed. However, the literature shows that\nthe results of these tools can be subjective and are intrinsically\ntied to the nature and approach of the detection. In a recent\nwork the use of Machine-Learning (ML) techniques for code\nsmell detection has been proposed, possibly solving the issue\nof tool subjectivity giving to a learner the ability to discern\nbetween smelly and non-smelly source code elements. While this\nwork opened a new perspective for code smell detection, it only\nconsidered the case where instances affected by a single type\nsmell are contained in each dataset used to train and test the\nmachine learners. In this work we replicate the study with a\ndifferent dataset configuration containing instances of more than\none type of smell. The results reveal that with this configuration\nthe machine learning techniques reveal critical limitations in the\nstate of the art which deserve further research."
}, {
    "py/object": "data.DataClassPaper",
    "Title": "Detection of Memory Leaks in C/C++ Code via Machine Learning",
    "year": 2017,
    "ML_Techniques": "DT",
    "Category": "Quality assessment",
    "Sub_category": "Quality assessment/prediction,Static or dynamic quality assessment,Quality assessment/prediction,Quality assessment/prediction,Static or dynamic quality assessment,Quality assessment/prediction,Static or dynamic quality assessment",
    "Venue": "ISSREW",
    "Link": "https://ieeexplore.ieee.org/abstract/document/8109292",
    "bibtex": "INPROCEEDINGS{Andrzejak2017_221,\n    author = \"{Andrzejak}, A. and {Eichler}, F. and {Ghanavati}, M.\",\n    booktitle = \"2017 IEEE International Symposium on Software Reliability Engineering Workshops (ISSREW)\",\n    title = \"Detection of Memory Leaks in C/C++ Code via Machine Learning\",\n    year = \"2017\",\n    volume = \"\",\n    number = \"\",\n    pages = \"252-258\",\n    doi = \"10.1109/ISSREW.2017.72\"\n}\n\n",
    "abstract": "Memory leaks are one of the primary causes of\nsoftware aging. Despite of recent countermeasures in C/C++ such\nas smart pointers, leak-related defects remain a troublesome issue\nin C/C++ code, especially in legacy applications.\nWe propose an approach for automatic detection of memory leaks\nin C/C++ programs based on characterizing memory allocation\nsites via the age distribution of the non-disposed memory chunks\nallocated by such a site (the so-called GenCount-technique introduced\nfor Java by Vladimir \u0160or). We instrument malloc and\nfree calls in C/C++ and collect for each allocation site data on\nthe number of allocated memory fragments, their lifetimes, and\nsizes. Based on this data we compute feature vectors and train\na machine learning classifier to differentiate between leaky and\ndefect-free allocation sites.\nOur evaluation uses applications from SPEC CPU2006 suite with\ninjected memory leaks resembling real leaks. The results show\nthat even out-of-the-box classification algorithms can achieve\nhigh accuracy, with precision and recall values of 0.93 and 0.88,\nrespectively."
}, {
    "py/object": "data.DataClassPaper",
    "Title": "Experience report: Evaluating the effectiveness of decision trees for detecting code smells",
    "year": 2015,
    "ML_Techniques": "DT",
    "Category": "Quality assessment",
    "Sub_category": "Code smell detection",
    "Venue": "ISSRE",
    "Link": "https://ieeexplore.ieee.org/abstract/document/7381819",
    "bibtex": "INPROCEEDINGS{Amorim2015_223,\n    author = \"{Amorim}, L. and {Costa}, E. and {Antunes}, N. and {Fonseca}, B. and {Ribeiro}, M.\",\n    booktitle = \"2015 IEEE 26th International Symposium on Software Reliability Engineering (ISSRE)\",\n    title = \"Experience report: Evaluating the effectiveness of decision trees for detecting code smells\",\n    year = \"2015\",\n    volume = \"\",\n    number = \"\",\n    pages = \"261-269\",\n    doi = \"10.1109/ISSRE.2015.7381819\"\n}\n\n",
    "abstract": "Developers continuously maintain software systems\nto adapt to new requirements and to fix bugs. Due to the complexity\nof maintenance tasks and the time-to-market, developers\nmake poor implementation choices, also known as code smells.\nStudies indicate that code smells hinder comprehensibility, and\npossibly increase change- and fault-proneness. Therefore, they\nmust be identified to enable the application of corrections. The\nchallenge is that the inaccurate definitions of code smells make\ndevelopers disagree whether a piece of code is a smell or not,\nconsequently, making difficult creation of a universal detection\nsolution able to recognize smells in different software projects.\nSeveral works have been proposed to identify code smells but\nthey still report inaccurate results and use techniques that do\nnot present to developers a comprehensive explanation how these\nresults have been obtained. In this experimental report we study\nthe effectiveness of the Decision Tree algorithm to recognize code\nsmells. For this, it was applied in a dataset containing 4 open\nsource projects and the results were compared with the manual\noracle, with existing detection approaches and with other machine\nlearning algorithms. The results showed that the approach was\nable to effectively learn rules for the detection of the code smells\nstudied. The results were even better when genetic algorithms\nare used to pre-select the metrics to use."
}, {
    "py/object": "data.DataClassPaper",
    "Title": "Functional code clone detection with syntax and semantics fusion learning",
    "year": 2020,
    "ML_Techniques": "DNN",
    "Category": "Quality assessment",
    "Sub_category": "Clone detection",
    "Venue": "ISSTA",
    "Link": "https://dl.acm.org/doi/10.1145/3395363.3397362",
    "bibtex": "INPROCEEDINGS{Amorim2015_223,\n    author = \"{Amorim}, L. and {Costa}, E. and {Antunes}, N. and {Fonseca}, B. and {Ribeiro}, M.\",\n    booktitle = \"2015 IEEE 26th International Symposium on Software Reliability Engineering (ISSRE)\",\n    title = \"Experience report: Evaluating the effectiveness of decision trees for detecting code smells\",\n    year = \"2015\",\n    volume = \"\",\n    number = \"\",\n    pages = \"261-269\",\n    doi = \"10.1109/ISSRE.2015.7381819\"\n}\n\n",
    "abstract": "Clone detection of source code is among the most fundamental\nsoftware engineering techniques. Despite intensive research in the\npast decade, existing techniques are still unsatisfactory in detecting\n\"functional\" code clones. In particular, existing techniques cannot\nefficiently extract syntax and semantics information from source\ncode. In this paper, we propose a novel joint code representation\nthat applies fusion embedding techniques to learn hidden syntactic\nand semantic features of source codes. Besides, we introduce a\nnew granularity for functional code clone detection. Our approach\nregards the connected methods with caller-callee relationships as a\nfunctionality and the method without any caller-callee relationship\nwith other methods represents a single functionality. Then we train\na supervised deep learning model to detect functional code clones.\nWe conduct evaluations on a large dataset of C++ programs and\nthe experimental results show that fusion learning can significantly\noutperform the state-of-the-art techniques in detecting functional\ncode clones."
}, {
    "py/object": "data.DataClassPaper",
    "Title": "Investigating Non-Usually Employed Features in the Identification of Architectural Smells: A Machine Learning-Based Approach",
    "year": 2020,
    "ML_Techniques": "NB, NN, KNN, B, AB, RF, SVM, DT",
    "Category": "Quality assessment",
    "Sub_category": "Code smell detection",
    "Venue": "BSSCAR",
    "Link": "https://dl.acm.org/doi/abs/10.1145/3425269.3425281",
    "bibtex": "INPROCEEDINGS{Amorim2015_223,\n    author = \"{Amorim}, L. and {Costa}, E. and {Antunes}, N. and {Fonseca}, B. and {Ribeiro}, M.\",\n    booktitle = \"2015 IEEE 26th International Symposium on Software Reliability Engineering (ISSRE)\",\n    title = \"Experience report: Evaluating the effectiveness of decision trees for detecting code smells\",\n    year = \"2015\",\n    volume = \"\",\n    number = \"\",\n    pages = \"261-269\",\n    doi = \"10.1109/ISSRE.2015.7381819\"\n}\n\n",
    "abstract": "Architectural smells (ASs) negatively affect the maintenance and evolution of software at the architectural level. Most of the current approaches for ASs identification rely on the same small and well-known set of usually employed metrics (UE-Ms) with fixed thresholds. Machine learning (ML) is a promising technique for smell identification as algorithms can learn from a rich set of metrics/features, covering several characteristics of the software and incorporating a certain degree of subjectivity. This has been explored by building datasets with a robust and rich set of features, including not only the UE-Ms but also other non-usually employed metrics (NUE-Ms). However, usually the UE-Ms determine the output of the algorithms, obfuscating other metrics that have the potential to improve the classification. This also leads to inflated and difficult to maintain datasets. In this paper, we investigate the accuracy of some ML algorithms employing only NUE-Ms. We scoped our study in the classification of two smells: God Component and Unstable Dependency. This investigation revealed a set of NUE-Ms that can be also used to identify these smells and the contribution of each one for the classification. Based on this information, software engineers can then build a final dataset just with the potential features. We also briefly present our tool, called InSet, that was used by academics and practitioners to identify smells in their systems. The feedback of them was used as the oracle to compare our tool to other approaches and good results were reached."
}, {
    "py/object": "data.DataClassPaper",
    "Title": "Keep it simple: Is deep learning good for linguistic smell detection?",
    "year": 2018,
    "ML_Techniques": "RF, SVM, DT, NB, CNN",
    "Category": "Quality assessment",
    "Sub_category": "Code smell detection",
    "Venue": "SANER",
    "Link": "https://ieeexplore.ieee.org/document/8330265",
    "bibtex": "INPROCEEDINGS{Fakhoury2018_232,\n    author = \"{Fakhoury}, S. and {Arnaoudova}, V. and {Noiseux}, C. and {Khomh}, F. and {Antoniol}, G.\",\n    booktitle = \"2018 IEEE 25th International Conference on Software Analysis, Evolution and Reengineering (SANER)\",\n    title = \"Keep it simple: Is deep learning good for linguistic smell detection?\",\n    year = \"2018\",\n    volume = \"\",\n    number = \"\",\n    pages = \"602-611\",\n    doi = \"10.1109/SANER.2018.8330265\"\n}\n\n",
    "abstract": "Deep neural networks is a popular technique that\nhas been applied successfully to domains such as image processing,\nsentiment analysis, speech recognition, and computational\nlinguistic. Deep neural networks are machine learning algorithms\nthat, in general, require a labeled set of positive and negative\nexamples that are used to tune hyper-parameters and adjust\nmodel coefficients to learn a prediction function. Recently, deep\nneural networks have also been successfully applied to certain\nsoftware engineering problem domains (e.g., bug prediction),\nhowever, results are shown to be outperformed by traditional\nmachine learning approaches in other domains (e.g., recovering\nlinks between entries in a discussion forum).\nIn this paper, we report our experience in building an automatic\nLinguistic Antipattern Detector (LAPD) using deep neural\nnetworks. We manually build and validate an oracle of around\n1,700 instances and create binary classification models using traditional\nmachine learning approaches and Convolutional Neural\nNetworks. Our experience is that, considering the size of the\noracle, the available hardware and software, as well as the theory\nto interpret results, deep neural networks are outperformed by\ntraditional machine learning algorithms in terms of all evaluation\nmetrics we used and resources (time and memory).\nTherefore, although deep learning is reported to produce results\ncomparable and even superior to human experts for certain\ncomplex tasks, it does not seem to be a good fit for simple classification\ntasks like smell detection. Researchers and practitioners\nshould be careful when selecting machine learning models for\nthe problem at hand."
}, {
    "py/object": "data.DataClassPaper",
    "Title": "Learning a classifier for false positive error reports emitted by static code analysis tools",
    "year": 2017,
    "ML_Techniques": "NB, LSTM",
    "Category": "Quality assessment",
    "Sub_category": "Quality assessment/prediction,Static or dynamic quality assessment,Quality assessment/prediction,Quality assessment/prediction,Static or dynamic quality assessment,Quality assessment/prediction,Static or dynamic quality assessment",
    "Venue": "MAPL",
    "Link": "https://dl.acm.org/doi/abs/10.1145/3088525.3088675",
    "bibtex": "INPROCEEDINGS{Fakhoury2018_232,\n    author = \"{Fakhoury}, S. and {Arnaoudova}, V. and {Noiseux}, C. and {Khomh}, F. and {Antoniol}, G.\",\n    booktitle = \"2018 IEEE 25th International Conference on Software Analysis, Evolution and Reengineering (SANER)\",\n    title = \"Keep it simple: Is deep learning good for linguistic smell detection?\",\n    year = \"2018\",\n    volume = \"\",\n    number = \"\",\n    pages = \"602-611\",\n    doi = \"10.1109/SANER.2018.8330265\"\n}\n\n",
    "abstract": "The large scale and high complexity of modern software systems\nmake perfectly precise static code analysis (SCA) infeasible. Therefore\nSCA tools often over-approximate, so not to miss any real\nproblems. This, however, comes at the expense of raising false\nalarms, which, in practice, reduces the usability of these tools.\nTo partially address this problem, we propose a novel learning\nprocess whose goal is to discover program structures that cause\na given SCA tool to emit false error reports, and then to use this\ninformation to predict whether a new error report is likely to be a\nfalse positive as well. To do this, we first preprocess code to isolate\nthe locations that are related to the error report. Then, we apply\nmachine learning techniques to the preprocessed code to discover\ncorrelations and to learn a classifier.\nWe evaluated this approach in an initial case study of a widelyused\nSCA tool for Java. Our results showed that for our dataset\nwe could accurately classify a large majority of false positive error\nreports. Moreover, we identified some common coding patterns that\nled to false positive errors. We believe that SCA developers may be\nable to redesign their methods to address these patterns and reduce\nfalse positive error reports."
}, {
    "py/object": "data.DataClassPaper",
    "Title": "Machine Learning Approach for Reliability Assessment of Open Source Software",
    "year": 2019,
    "ML_Techniques": "NB, DT, RF, SVM, ANN, PNN",
    "Category": "Quality assessment",
    "Sub_category": "Quality assessment/prediction,Static or dynamic quality assessment,Quality assessment/prediction,Quality assessment/prediction,Static or dynamic quality assessment,Quality assessment/prediction,Static or dynamic quality assessment",
    "Venue": "ICCSA",
    "Link": "https://link.springer.com/chapter/10.1007/978-3-030-24305-0_35",
    "bibtex": "InProceedings{Behera2019_235,\n    author = \"Behera, Ranjan Kumar and Rath, Santanu Kumar and Misra, Sanjay and Leon, Marcelo and Adewumi, Adewole\",\n    editor = \"Misra, Sanjay and Gervasi, Osvaldo and Murgante, Beniamino and Stankova, Elena and Korkhov, Vladimir and Torre, Carmelo and Rocha, Ana Maria A.C. and Taniar, David and Apduhan, Bernady O. and Tarantino, Eufemia\",\n    title = \"Machine Learning Approach for Reliability Assessment of Open Source Software\",\n    booktitle = \"Computational Science and Its Applications -- ICCSA 2019\",\n    year = \"2019\",\n    publisher = \"Springer International Publishing\",\n    address = \"Cham\",\n    pages = \"472--482\",\n    abstract = \"Some of the quality parameters for any successful open source software may be attributed to affordability, availability of source code, re-distributability, and modifiability etc. Quality of software can be further improvised subsequently by either users or associated developers by constantly monitoring some of the reliability aspects. Since multiple users are allowed to modify the code there is a potential threat for security, which might degrade the reliability of software. Bug tracking systems are often considered to monitor various software faults, detected mostly in open source software projects. Various authors have made research in this direction by applying different techniques in order to improve the reliability of open source software projects. In this work, an various machine learning models have been implemented to examine the reliability of the software. An extensive numerical illustration has also been presented for bug data recorded on bug tracking system. The effectiveness of machine learning models for estimating the level of faults associated with the systems has been verified by comparing it with similar approaches as available in the literature.\",\n    isbn = \"978-3-030-24305-0\"\n}\n\n",
    "abstract": "Some of the quality parameters for any successful open source\nsoftware may be attributed to a ordability, availability of source code,\nre-distributability, and modi ability etc. Quality of software can be fur-\nther improvised subsequently by either users or associated developers by\nconstantly monitoring some of the reliability aspects. Since multiple users\nare allowed to modify the code there is a potential threat for security,\nwhich might degrade the reliability of software. Bug tracking systems\nare often considered to monitor various software faults, detected mostly\nin open source software projects. Various authors have made research in\nthis direction by applying di erent techniques in order to improve the\nreliability of open source software projects. In this work, an various ma-\nchine learning models have been implemented to examine the reliability\nof the software. An extensive numerical illustration has also been pre-\nsented for bug data recorded on bug tracking system. The e ectiveness of\nmachine learning models for estimating the level of faults associated with\nthe systems has been veri ed by comparing it with similar approaches\nas available in the literature."
}, {
    "py/object": "data.DataClassPaper",
    "Title": "Machine learning techniques for code smell detection: A systematic literature review and meta-analysis",
    "year": 2019,
    "ML_Techniques": "",
    "Category": "Quality assessment",
    "Sub_category": "Code smell detection",
    "Venue": "IST",
    "Link": "",
    "bibtex": "article{Azeem2019_240,\n    author = \"Azeem, Muhammad Ilyas and Palomba, Fabio and Shi, Lin and Wang, Qing\",\n    title = \"Machine learning techniques for code smell detection: A systematic literature review and meta-analysis\",\n    journal = \"Information and Software Technology\",\n    volume = \"108\",\n    pages = \"115 - 138\",\n    year = \"2019\",\n    issn = \"0950-5849\",\n    doi = \"https://doi.org/10.1016/j.infsof.2018.12.009\",\n    url = \"http://www.sciencedirect.com/science/article/pii/S0950584918302623\",\n    keywords = \"Code smells, Machine learning, Systematic literature review\"\n}\n\n",
    "abstract": "Background : Code smells indicate suboptimal design or implementation choices in the source code that often lead it to be more change- and fault-prone. Researchers defined dozens of code smell detectors, which exploit different sources of information to support developers when diagnosing design flaws. Despite their good accuracy, previous work pointed out three important limitations that might preclude the use of code smell detectors in practice: (i) subjectiveness of developers with respect to code smells detected by such tools, (ii) scarce agreement between different detectors, and (iii) difficulties in finding good thresholds to be used for detection. To overcome these limitations, the use of machine learning techniques represents an ever increasing research area. Objective : While the research community carefully studied the methodologies applied by researchers when defin- ing heuristic-based code smell detectors, there is still a noticeable lack of knowledge on how machine learning approaches have been adopted for code smell detection and whether there are points of improvement to allow a better detection of code smells. Our goal is to provide an overview and discuss the usage of machine learning approaches in the field of code smells. Method : This paper presents a Systematic Literature Review (SLR) on Machine Learning Techniques for Code Smell Detection. Our work considers papers published between 2000 and 2017. Starting from an initial set of 2456 papers, we found that 15 of them actually adopted machine learning approaches. We studied them under four different perspectives: (i) code smells considered, (ii) setup of machine learning approaches, (iii) design of the evaluation strategies, and (iv) a meta-analysis on the performance achieved by the models proposed so far. Results : The analyses performed show that God Class, Long Method, Functional Decomposition , and Spaghetti Code have been heavily considered in the literature. Decision Trees and Support Vector Machines are the most commonly used machine learning algorithms for code smell detection. Models based on a large set of independent variables have performed well. JRip and Random Forest are the most effective classifiers in terms of perfor- mance. The analyses also reveal the existence of several open issues and challenges that the research community should focus on in the future. Conclusion : Based on our findings, we argue that there is still room for the improvement of machine learning techniques in the context of code smell detection. The open issues emerged in this study can represent the input for researchers interested in developing more powerful techniques."
}, {
    "py/object": "data.DataClassPaper",
    "Title": "Machine learning techniques for code smells detection: an empirical experiment on a highly imbalanced setup",
    "year": 2019,
    "ML_Techniques": "RF, NN, KNN, NB, DT, B",
    "Category": "Quality assessment",
    "Sub_category": "Code smell detection",
    "Venue": "SBSI",
    "Link": "https://dl.acm.org/doi/abs/10.1145/3330204.3330275",
    "bibtex": "article{Azeem2019_240,\n    author = \"Azeem, Muhammad Ilyas and Palomba, Fabio and Shi, Lin and Wang, Qing\",\n    title = \"Machine learning techniques for code smell detection: A systematic literature review and meta-analysis\",\n    journal = \"Information and Software Technology\",\n    volume = \"108\",\n    pages = \"115 - 138\",\n    year = \"2019\",\n    issn = \"0950-5849\",\n    doi = \"https://doi.org/10.1016/j.infsof.2018.12.009\",\n    url = \"http://www.sciencedirect.com/science/article/pii/S0950584918302623\",\n    keywords = \"Code smells, Machine learning, Systematic literature review\"\n}\n\n",
    "abstract": "NO Abs"
}, {
    "py/object": "data.DataClassPaper",
    "Title": "Machine-learning-guided selectively unsound static analysis",
    "year": 2017,
    "ML_Techniques": "SVM",
    "Category": "Quality assessment",
    "Sub_category": "Quality assessment/prediction,Static or dynamic quality assessment,Quality assessment/prediction,Quality assessment/prediction,Static or dynamic quality assessment,Quality assessment/prediction,Static or dynamic quality assessment",
    "Venue": "ICSE",
    "Link": "https://dl.acm.org/doi/10.1109/ICSE.2017.54",
    "bibtex": "article{Azeem2019_240,\n    author = \"Azeem, Muhammad Ilyas and Palomba, Fabio and Shi, Lin and Wang, Qing\",\n    title = \"Machine learning techniques for code smell detection: A systematic literature review and meta-analysis\",\n    journal = \"Information and Software Technology\",\n    volume = \"108\",\n    pages = \"115 - 138\",\n    year = \"2019\",\n    issn = \"0950-5849\",\n    doi = \"https://doi.org/10.1016/j.infsof.2018.12.009\",\n    url = \"http://www.sciencedirect.com/science/article/pii/S0950584918302623\",\n    keywords = \"Code smells, Machine learning, Systematic literature review\"\n}\n\n",
    "abstract": "We present a machine-learning-based technique for\nselectively applying unsoundness in static analysis. Existing bugfinding\nstatic analyzers are unsound in order to be precise and\nscalable in practice. However, they are uniformly unsound and\nhence at the risk of missing a large amount of real bugs. By being\nsound, we can improve the detectability of the analyzer but it\noften suffers from a large number of false alarms. Our approach\naims to strike a balance between these two approaches by\nselectively allowing unsoundness only when it is likely to reduce\nfalse alarms, while retaining true alarms. We use an anomalydetection\ntechnique to learn such harmless unsoundness. We\nimplemented our technique in two static analyzers for full C. One\nis for a taint analysis for detecting format-string vulnerabilities,\nand the other is for an interval analysis for buffer-overflow\ndetection. The experimental results show that our approach\nsignificantly improves the recall of the original unsound analysis\nwithout sacrificing the precision."
}, {
    "py/object": "data.DataClassPaper",
    "Title": "Measuring Software Reliability: A Trend Using Machine Learning Techniques",
    "year": 2015,
    "ML_Techniques": "SVR",
    "Category": "Quality assessment",
    "Sub_category": "Quality assessment/prediction,Static or dynamic quality assessment,Quality assessment/prediction,Quality assessment/prediction,Static or dynamic quality assessment,Quality assessment/prediction,Static or dynamic quality assessment",
    "Venue": "Book",
    "Link": "https://link.springer.com/chapter/10.1007/978-3-319-12883-2_28",
    "bibtex": "Inbook{Kumar2015_247,\n    author = \"Kumar, Nishikant and Banerjee, Soumya\",\n    editor = \"Zhu, Quanmin and Azar, Ahmad Taher\",\n    title = \"Measuring Software Reliability: A Trend Using Machine Learning Techniques\",\n    bookTitle = \"Complex System Modelling and Control Through Intelligent Soft Computations\",\n    year = \"2015\",\n    publisher = \"Springer International Publishing\",\n    address = \"Cham\",\n    pages = \"807--829\",\n    abstract = \"It has become inevitable for every software developer to understand, to follow that how and why software fails, and to express reliability in quantitative terms. This has led to a proliferation of software reliability models to estimate and predict reliability. The basic approach is to model past failure data to predict future behavior. Most of the models have three major components: assumptions, factors and a mathematical function, usually high order exponential or logarithmic used to relate factors to reliability. Software reliability models are used to forecast the curve of failure rate by statistical evidence available during testing phase. They also can indicate about the extra time required to carry out the test procedure in order to meet the specifications and deliver desired functionality with minimum number of defects. Therefore there are challenges whether, autonomous or machine learning techniques like other predictive methods could be able to forecast the reliability measures for a specific software application. This chapter contemplates reliability issue through a generic Machine Learning paradigm while referring the most common aspects of Support Vector Machine scenario. Couples of customized simulation and experimental results have been presented to support the proposed reliability measures and strategies.\",\n    isbn = \"978-3-319-12883-2\",\n    doi = \"10.1007/978-3-319-12883-2\\_28\",\n    url = \"https://doi.org/10.1007/978-3-319-12883-2\\_28\"\n}\n\n",
    "abstract": "It has become inevitable for every software developer to understand, to follow that how and why software fails, and to express reliability in quantitative terms. This has led to a proliferation of software reliability models to estimate and predict reliability. The basic approach is to model past failure data to predict future behavior. Most of the models have three major components: assumptions, factors and a mathematical function, usually high order exponential or logarithmic used to relate factors to reliability. Software reliability models are used to forecast the curve of failure rate by statistical evidence available during testing phase. They also can indicate about the extra time required to carry out the test procedure in order to meet the specifications and deliver desired functionality with minimum number of defects. Therefore there are challenges whether, autonomous or machine learning techniques like other predictive methods could be able to forecast the reliability measures for a specific software application. This chapter contemplates reliability issue through a generic Machine Learning paradigm while referring the most common aspects of Support Vector Machine scenario. Couples of customized simulation and experimental results have been presented to support the proposed reliability measures and strategies."
}, {
    "py/object": "data.DataClassPaper",
    "Title": "Mobile-Sandbox: combining static and dynamic analysis with machine-learning techniques",
    "year": 2015,
    "ML_Techniques": "SVM",
    "Category": "Vulnerability analysis",
    "Sub_category": "",
    "Venue": "IJIS",
    "Link": "https://link.springer.com/article/10.1007/s10207-014-0250-0#citeas",
    "bibtex": "article{Spreitzenbarth2014_248,\n    author = \"Spreitzenbarth, Michael and Schreck, Thomas and Echtler, F. and Arp, D. and Hoffmann, Johannes\",\n    title = \"Mobile-Sandbox: combining static and dynamic analysis with machine-learning techniques\",\n    journal = \"International Journal of Information Security\",\n    year = \"2014\",\n    volume = \"14\",\n    pages = \"141-153\"\n}\n\n",
    "abstract": "Smartphones in general and Android in particular are increasingly shifting into the focus of cyber criminals. For understanding the threat to security and privacy, it is important for security researchers to analyze malicious software written for these systems. The exploding number of Android malware calls for automation in the analysis. In this paper, we present Mobile-Sandbox, a system designed to automatically analyze Android applications in novel ways: First, it combines static and dynamic analysis, i.e., results of static analysis are used to guide dynamic analysis and extend coverage of executed code. Additionally, it uses specific techniques to log calls to native (i.e., \u201cnon-Java\u201d) APIs, and last but not least it combines these results with machine-learning techniques to cluster the analyzed samples into benign and malicious ones. We evaluated the system on more than 69,000 applications from Asian third-party mobile markets and found that about 21 % of them actually use native calls in their code."
}, {
    "py/object": "data.DataClassPaper",
    "Title": "On the role of data balancing for machine learning-based code smell detection",
    "year": 2019,
    "ML_Techniques": "CCS, OCC",
    "Category": "Quality assessment",
    "Sub_category": "Code smell detection",
    "Venue": "MALTeSQuE",
    "Link": "",
    "bibtex": "article{Spreitzenbarth2014_248,\n    author = \"Spreitzenbarth, Michael and Schreck, Thomas and Echtler, F. and Arp, D. and Hoffmann, Johannes\",\n    title = \"Mobile-Sandbox: combining static and dynamic analysis with machine-learning techniques\",\n    journal = \"International Journal of Information Security\",\n    year = \"2014\",\n    volume = \"14\",\n    pages = \"141-153\"\n}\n\n",
    "abstract": "Code smells can compromise software quality in the long term by\ninducing technical debt. For this reason, many approaches aimed\nat identifying these design flaws have been proposed in the last\ndecade. Most of them are based on heuristics in which a set of\nmetrics (e.g., code metrics, process metrics) is used to detect smelly\ncode components. However, these techniques suffer of subjective\ninterpretation, low agreement between detectors, and threshold\ndependability. To overcome these limitations, previouswork applied\nMachine Learning techniques that can learn from previous datasets\nwithout needing any threshold definition. However, more recent\nwork has shown that Machine Learning is not always suitable for\ncode smell detection due to the highly unbalanced nature of the\nproblem. In this study we investigate several approaches able to\nmitigate data unbalancing issues to understand their impact on MLbased\napproaches for code smell detection. Our findings highlight\na number of limitations and open issues with respect to the usage\nof data balancing in ML-based code smell detection."
}, {
    "py/object": "data.DataClassPaper",
    "Title": "On the Use of Machine Learning Techniques Towards the Design of Cloud Based Automatic Code Clone Validation Tools",
    "year": 2018,
    "ML_Techniques": "DT, RF, RT, NB, BN, LR, KS, ANN",
    "Category": "Quality assessment",
    "Sub_category": "Clone detection",
    "Venue": "SCAM",
    "Link": "https://ieeexplore.ieee.org/document/8530729",
    "bibtex": "INPROCEEDINGS{Mostaeen2018_251,\n    author = \"{Mostaeen}, G. and {Svajlenko}, J. and {Roy}, B. and {Roy}, C. K. and {Schneider}, K. A.\",\n    booktitle = \"2018 IEEE 18th International Working Conference on Source Code Analysis and Manipulation (SCAM)\",\n    title = \"[Research Paper] On the Use of Machine Learning Techniques Towards the Design of Cloud Based Automatic Code Clone Validation Tools\",\n    year = \"2018\",\n    volume = \"\",\n    number = \"\",\n    pages = \"155-164\",\n    doi = \"10.1109/SCAM.2018.00025\"\n}\n\n",
    "abstract": "A code clone is a pair of code fragments, within\nor between software systems that are similar. Since code clones\noften negatively impact the maintainability of a software system,\na great many numbers of code clone detection techniques and\ntools have been proposed and studied over the last decade. To\ndetect all possible similar source code patterns in general, the\nclone detection tools work on syntax level (such as texts, tokens,\nAST and so on) while lacking user-specific preferences. This often\nmeans the reported clones must be manually validated prior to\nany analysis in order to filter out the true positive clones from\ntask or user-specific considerations. This manual clone validation\neffort is very time-consuming and often error-prone, in particular\nfor large-scale clone detection. In this paper, we propose a\nmachine learning based approach for automating the validation\nprocess. In an experiment with clones detected by several clone\ndetectors in several different software systems, we found our\napproach has an accuracy of up to 87.4% when compared against\nthe manual validation by multiple expert judges. The proposed\nmethod shows promising results in several comparative studies\nwith the existing related approaches for automatic code clone\nvalidation. We also present our experimental results in terms of\ndifferent code clone detection tools, machine learning algorithms\nand open source software systems."
}, {
    "py/object": "data.DataClassPaper",
    "Title": "Predicting Code Smells and Analysis of Predictions: Using Machine Learning Techniques and Software Metrics",
    "year": 2020,
    "ML_Techniques": "RF, GBT, DT, SVM, MLP",
    "Category": "Quality assessment",
    "Sub_category": "Code smell detection",
    "Venue": "JCST",
    "Link": "https://link.springer.com/article/10.1007/s11390-020-0323-7",
    "bibtex": "article{Mhawish2020_252,\n    author = \"Mhawish, Mohammad Y. and Gupta, Manjari\",\n    title = \"Predicting Code Smells and Analysis of Predictions: Using Machine Learning Techniques and Software Metrics\",\n    journal = \"J. Comput. Sci. Technol.\",\n    year = \"2020\",\n    volume = \"35\",\n    pages = \"1428-1445\"\n}\n\n",
    "abstract": "Code smell detection is essential to improve software quality, enhancing software maintainability, and decrease\nthe risk of faults and failures in the software system. In this paper, we proposed a code smell prediction approach based on\nmachine learning techniques and software metrics. The local interpretable model-agnostic explanations (LIME) algorithm\nwas further used to explain the machine learning model\u2019s predictions and interpretability. The datasets obtained from\nFontana et al. were reformed and used to build binary-label and multi-label datasets. The results of 10-fold cross-validation\nshow that the performance of tree-based algorithms (mainly Random Forest) is higher compared with kernel-based and\nnetwork-based algorithms. The genetic algorithm based feature selection methods enhance the accuracy of these machine\nlearning algorithms by selecting the most relevant features in each dataset. Moreover, the parameter optimization techniques\nbased on the grid search algorithm significantly enhance the accuracy of all these algorithms. Finally, machine learning\ntechniques have high potential in predicting the code smells, which contribute to detect these smells and enhance the\nsoftware\u2019s quality."
}, {
    "py/object": "data.DataClassPaper",
    "Title": "Prediction of Web Service Anti-patterns Using Aggregate Software Metrics and Machine Learning Techniques",
    "year": 2020,
    "ML_Techniques": "LOG, DT, ANN, SVM, ELM, MVE, BTE",
    "Category": "Quality assessment",
    "Sub_category": "Code smell detection",
    "Venue": "ISEC",
    "Link": "https://dl.acm.org/doi/10.1145/3385032.3385042",
    "bibtex": "article{Mhawish2020_252,\n    author = \"Mhawish, Mohammad Y. and Gupta, Manjari\",\n    title = \"Predicting Code Smells and Analysis of Predictions: Using Machine Learning Techniques and Software Metrics\",\n    journal = \"J. Comput. Sci. Technol.\",\n    year = \"2020\",\n    volume = \"35\",\n    pages = \"1428-1445\"\n}\n\n",
    "abstract": "Service-Oriented Architecture(SOA) can be characterized as an approximately coupled engineering intended to meet the business needs of an association/organization. Service-Based Systems (SBSs) are inclined to continually change to enjoy new client necessities and adjust the execution settings, similar to some other huge and complex frameworks. These changes may lead to the evolution of designs/products with poor Quality of Service (QoS), resulting in the bad practiced solutions, commonly known as Anti-patterns. Anti-patterns makes the evolution and maintenance of the software systems hard and complex. Early identification of modules, classes, or source code regions where anti-patterns are more likely to occur can help in amending and maneuvering testing efforts leading to the improvement of software quality. In this work, we investigate the application of three sampling techniques, three feature selection techniques, and sixteen different classification techniques to develop the models for web service anti-pattern detection. We report the results of an empirical study by evaluating the approach proposed, on a data set of 226 Web Service Description Language(i.e., WSDL)files, a variety of five types of web-service anti-patterns. Experimental results demonstrated that SMOTE is the best performing data sampling techniques. The experimental results also reveal that the model developed by considering Uncorrelated Significant Predictors(SUCP) as the input obtained better performance compared to the model developed by other metrics. Experimental results also show that the Least Square Support Vector Machine with Linear(LSLIN) function has outperformed all other classifier techniques."
}, {
    "py/object": "data.DataClassPaper",
    "Title": "Ranking warnings from multiple source code static analyzers via ensemble learning",
    "year": 2019,
    "ML_Techniques": "AB",
    "Category": "Quality assessment",
    "Sub_category": "Quality assessment/prediction,Static or dynamic quality assessment,Quality assessment/prediction,Quality assessment/prediction,Static or dynamic quality assessment,Quality assessment/prediction,Static or dynamic quality assessment",
    "Venue": "OpenSym",
    "Link": "https://dl.acm.org/doi/10.1145/3306446.3340828",
    "bibtex": "article{Mhawish2020_252,\n    author = \"Mhawish, Mohammad Y. and Gupta, Manjari\",\n    title = \"Predicting Code Smells and Analysis of Predictions: Using Machine Learning Techniques and Software Metrics\",\n    journal = \"J. Comput. Sci. Technol.\",\n    year = \"2020\",\n    volume = \"35\",\n    pages = \"1428-1445\"\n}\n\n",
    "abstract": "While there is a wide variety of both open source and proprietary\nsource code static analyzers available in the market,\neach of them usually performs better in a small set of problems,\nmaking it hard to choose one single tool to rely on when\nexamining a program looking for bugs in the source code.\nCombining the analysis of different tools may reduce the number\nof false negatives, but yields a corresponding increase in\nthe absolute number of false positives (which is already high\nfor many tools). A possible solution, then, is to filter these\nresults to identify the issues least likely to be false positives. In\nthis study, we post-analyze the reports generated by three tools\non synthetic test cases provided by the US National Institute of\nStandards and Technology. In order to make our technique as\ngeneral as possible, we limit our data to the reports themselves,\nexcluding other information such as change histories or code\nmetrics. The features extracted from these reports are used to\ntrain a set of decision trees using AdaBoost to create a stronger\nclassifier, achieving 0.8 classification accuracy (the combined\nfalse positive rate from the used tools was 0.61). Finally, we\nuse this classifier to rank static analyzer alarms based on the\nprobability of a given alarm being an actual bug in the source\ncode."
}, {
    "py/object": "data.DataClassPaper",
    "Title": "Recognizing lines of code violating company-specific coding guidelines using machine learning",
    "year": 2020,
    "ML_Techniques": "CART, RF",
    "Category": "Quality assessment",
    "Sub_category": "Code smell detection",
    "Venue": "EMSE",
    "Link": "https://link.springer.com/article/10.1007/s10664-019-09769-8",
    "bibtex": "article{Ochodek2019_257,\n    author = \"Ochodek, Miroslaw and Hebig, Regina and Meding, Wilhelm and Frost, Gert and Staron, Miroslaw\",\n    title = \"Recognizing lines of code violating company-specific coding guidelines using machine learning\",\n    journal = \"Empirical Software Engineering\",\n    year = \"2019\",\n    volume = \"25\",\n    pages = \"220-265\"\n}\n\n",
    "abstract": "Software developers in big and medium-size companies are working with millions of lines\nof code in their codebases. Assuring the quality of this code has shifted from simple defect\nmanagement to proactive assurance of internal code quality. Although static code analysis\nand code reviews have been at the forefront of research and practice in this area, code\nreviews are still an effort-intensive and interpretation-prone activity. The aim of this research\nis to support code reviews by automatically recognizing company-specific code guidelines\nviolations in large-scale, industrial source code. In our action research project, we constructed\na machine-learning-based tool for code analysis where software developers and\narchitects in big and medium-sized companies can use a few examples of source code lines\nviolating code/design guidelines (up to 700 lines of code) to train decision-tree classifiers to\nfind similar violations in their codebases (up to 3 million lines of code). Our action research\nproject consisted of (i) understanding the challenges of two large software development\ncompanies, (ii) applying the machine-learning-based tool to detect violations of Sun\u2019s and\nGoogle\u2019s coding conventions in the code of three large open source projects implemented\nin Java, (iii) evaluating the tool on evolving industrial codebase, and (iv) finding the best\nlearning strategies to reduce the cost of training the classifiers. We were able to achieve\nthe average accuracy of over 99% and the average F-score of 0.80 for open source projects\nwhen using ca. 40K lines for training the tool.We obtained a similar average F-score of 0.78\nfor the industrial code but this time using only up to 700 lines of code as a training dataset.\nFinally, we observed the tool performed visibly better for the rules requiring to understand a\nsingle line of code or the context of a few lines (often allowing to reach the F-score of 0.90\nor higher). Based on these results, we could observe that this approach can provide modern\nsoftware development companies with the ability to use examples to teach an algorithm\nto recognize violations of code/design guidelines and thus increase the number of reviews\nconducted before the product release. This, in turn, leads to the increased quality of the final\nsoftware."
}, {
    "py/object": "data.DataClassPaper",
    "Title": "Risky Module Estimation in Safety-Critical Software",
    "year": 2009,
    "ML_Techniques": "SVM",
    "Category": "Quality assessment",
    "Sub_category": "Quality assessment/prediction,Static or dynamic quality assessment,Quality assessment/prediction,Quality assessment/prediction,Static or dynamic quality assessment,Quality assessment/prediction,Static or dynamic quality assessment",
    "Venue": "ACIS",
    "Link": "https://ieeexplore.ieee.org/document/5223201/keywords#keywords",
    "bibtex": "INPROCEEDINGS{Kim2009_259,\n    author = \"{Kim}, Y. and {Jeong}, C. and {Jeong}, A. and {Kim}, H. S.\",\n    booktitle = \"2009 Eighth IEEE/ACIS International Conference on Computer and Information Science\",\n    title = \"Risky Module Estimation in Safety-Critical Software\",\n    year = \"2009\",\n    volume = \"\",\n    number = \"\",\n    pages = \"967-970\",\n    doi = \"10.1109/ICIS.2009.83\"\n}\n\n",
    "abstract": "Software used in safety-critical system must have\nhigh dependability. Software testing and V&V (Verification\nand Validation) activities are very important for assuring high\nsoftware quality. If we can predict the risky modules in safetycritical\nsoftware, testing activities and regulation activities can\nbe applied to them more intensively. In this paper, we classify\nthe estimated risk classes which can be used for deep testing\nand V&V. We predict the risk class for each module using\nsupport vector machines. We can consider that the modules\nclassified to risk class 5 or 4 are more risky than others\nrelatively. For all classification error rates, we expect that the\nresults can be useful and practical for software testing, V&V,\nand activities for regulatory reviews. In the future works, to\nimprove the practicality, we will have to investigate other\nmachine learning algorithms and datasets."
}, {
    "py/object": "data.DataClassPaper",
    "Title": "Semantic Clone Detection Using Machine Learning",
    "year": 2016,
    "ML_Techniques": "SVM, LDA, KS, DT, NB, MLP, B, LB",
    "Category": "Quality assessment",
    "Sub_category": "Clone detection",
    "Venue": "ICMLA",
    "Link": "https://ieeexplore.ieee.org/abstract/document/7838289",
    "bibtex": "INPROCEEDINGS{Sheneamer2016_260,\n    author = \"{Sheneamer}, A. and {Kalita}, J.\",\n    booktitle = \"2016 15th IEEE International Conference on Machine Learning and Applications (ICMLA)\",\n    title = \"Semantic Clone Detection Using Machine Learning\",\n    year = \"2016\",\n    volume = \"\",\n    number = \"\",\n    pages = \"1024-1028\",\n    doi = \"10.1109/ICMLA.2016.0185\"\n}\n\n",
    "abstract": "If two fragments of source code are identical to\neach other, they are called code clones. Code clones introduce\ndifficulties in software maintenance and cause bug propagation.\nIn this paper, we present a machine learning framework to\nautomatically detect clones in software, which is able to detect\nTypes-3 and the most complicated kind of clones, Type-4 clones.\nPreviously used traditional features are often weak in detecting\nthe semantic clones The novel aspects of our approach are the\nextraction of features from abstract syntax trees (AST) and\nprogram dependency graphs (PDG), representation of a pair\nof code fragments as a vector and the use of classification\nalgorithms. The key benefit of this approach is that our approach\ncan find both syntactic and semantic clones extremely well. Our\nevaluation indicates that using our new AST and PDG features\nis a viable methodology, since they improve detecting clones on\nthe IJaDataset2.0."
}, {
    "py/object": "data.DataClassPaper",
    "Title": "SP-J48: a novel optimization and machine-learning-based approach for solving complex problems: special application in software engineering for detecting code smells",
    "year": 2020,
    "ML_Techniques": "DT",
    "Category": "Quality assessment",
    "Sub_category": "Code smell detection",
    "Venue": "NCA",
    "Link": "https://link.springer.com/article/10.1007/s00521-019-04175-z",
    "bibtex": "article{Kaur2019_264,\n    author = \"Kaur, Amandeep and Jain, Sushma and Goel, S.\",\n    title = \"SP-J48: a novel optimization and machine-learning-based approach for solving complex problems: special application in software engineering for detecting code smells\",\n    journal = \"Neural Computing and Applications\",\n    year = \"2019\",\n    volume = \"32\",\n    pages = \"7009-7027\"\n}\n\n",
    "abstract": "This paper presents a novel hybrid algorithm based on optimization and machine-learning approaches for solving real-life complex problems. The optimization algorithm is inspired from the searching and attacking behaviors of sandpipers, called as Sandpiper Optimization Algorithm (SPOA). These two behaviors are modeled and implemented computationally to emphasize intensification and diversification in the search space. A comparison of the proposed SPOA algorithm is performed with nine competing optimization algorithms over 23 benchmark test functions. The proposed SPOA is further hybridized with B-J48 pruned machine-learning approach for efficiently detecting the code smells from the data set. The results reveal that the proposed technique is able to solve challenging problems and outperforms the other well-known approaches."
}, {
    "py/object": "data.DataClassPaper",
    "Title": "Using Machine Learning and Information Retrieval Techniques to Improve Software Maintainability",
    "year": 2013,
    "ML_Techniques": "",
    "Category": "Quality assessment",
    "Sub_category": "Clone detection",
    "Venue": "TESESDK",
    "Link": "https://link.springer.com/chapter/10.1007/978-3-642-45260-4_9",
    "bibtex": "InProceedings{Corazza2013_267,\n    author = \"Corazza, Anna and Di Martino, Sergio and Maggio, Valerio and Moschitti, Alessandro and Passerini, Andrea and Scanniello, Giuseppe and Silvestri, Fabrizio\",\n    editor = \"Moschitti, Alessandro and Plank, Barbara\",\n    title = \"Using Machine Learning and Information Retrieval Techniques to Improve Software Maintainability\",\n    booktitle = \"Trustworthy Eternal Systems via Evolving Software, Data and Knowledge\",\n    year = \"2013\",\n    publisher = \"Springer Berlin Heidelberg\",\n    address = \"Berlin, Heidelberg\",\n    pages = \"117--134\",\n    abstract = \"In this paper, we investigate some ideas based on Machine Learning, Natural Language Processing, and Information Retrieval to outline possible research directions in the field of software architecture recovery and clone detection. In particular, after presenting an extensive related work, we illustrate two proposals for addressing these two issues, that represent hot topics in the field of Software Maintenance. Both proposals use Kernel Methods for exploiting structural representation of source code and to automate the detection of clones and the recovery of the actually implemented architecture in a subject software system.\",\n    isbn = \"978-3-642-45260-4\"\n}\n\n",
    "abstract": "In this paper, we investigate some ideas based on Machine Learning, Natural Language Processing, and Information Retrieval to outline possible research directions in the field of software architecture recovery and clone detection. In particular, after presenting an extensive related work, we illustrate two proposals for addressing these two issues, that represent hot topics in the field of Software Maintenance. Both proposals use Kernel Methods for exploiting structural representation of source code and to automate the detection of clones and the recovery of the actually implemented architecture in a subject software system."
}, {
    "py/object": "data.DataClassPaper",
    "Title": "Using Machine Learning Techniques to Classify and Predict Static Code Analysis Tool Warnings",
    "year": 2018,
    "ML_Techniques": "RF, SVM, KNN, Ripper",
    "Category": "Quality assessment",
    "Sub_category": "Quality assessment/prediction,Quality prediction,Quality assessment/prediction,Quality assessment/prediction,Quality prediction,Quality assessment/prediction,Quality prediction",
    "Venue": "AICCSA",
    "Link": "https://ieeexplore.ieee.org/abstract/document/8612819",
    "bibtex": "INPROCEEDINGS{Alikhashashneh2018_268,\n    author = \"{Alikhashashneh}, E. A. and {Raje}, R. R. and {Hill}, J. H.\",\n    booktitle = \"2018 IEEE/ACS 15th International Conference on Computer Systems and Applications (AICCSA)\",\n    title = \"Using Machine Learning Techniques to Classify and Predict Static Code Analysis Tool Warnings\",\n    year = \"2018\",\n    volume = \"\",\n    number = \"\",\n    pages = \"1-8\",\n    doi = \"10.1109/AICCSA.2018.8612819\"\n}\n\n",
    "abstract": "This paper discusses our work on using software\nengineering metrics (i.e., source code metrics) to classify an error\nmessage generated by a Static Code Analysis (SCA) tool as\na true-positive, false-positive, or false-negative. Specifically, we\ncompare the performance of Support Vector Machine (SVM),\nK-Nearest Neighbor (KNN), Random Forests, and Repeated\nIncremental Pruning to Produce Error Reduction (RIPPER) over\neight datasets. The performance of the techniques is assessed by\ncomputing the F-measure metric, which is defined as the weighted\nharmonic mean of the precision and recall of the predicted model.\nThe overall results of the study show that the F-measure value of\nthe predicted model, which is generated using Random Forests\ntechnique, ranges from 83% to 98%. Additionally, the Random\nForests technique outperforms the other techniques. Lastly, our\nresults indicate that the complexity and coupling metrics have the\nmost impact on whether a SCA tool with generate a false-positive\nwarning or not."
}, {
    "py/object": "data.DataClassPaper",
    "Title": "A New Word Embedding Approach to Evaluate Potential Fixes for Automated Program Repair",
    "year": 2018,
    "ML_Techniques": "Word2Vec",
    "Category": "Program synthesis",
    "Sub_category": "Program repair",
    "Venue": "IJCNN",
    "Link": "https://ieeexplore.ieee.org/abstract/document/8489079",
    "bibtex": "INPROCEEDINGS{Amorim2018_272,\n    author = \"{Amorim}, L. A. and {Freitas}, M. F. and {Dantas}, A. and {de Souza}, E. F. and {Camilo-Junior}, C. G. and {Martins}, W. S.\",\n    booktitle = \"2018 International Joint Conference on Neural Networks (IJCNN)\",\n    title = \"A New Word Embedding Approach to Evaluate Potential Fixes for Automated Program Repair\",\n    year = \"2018\",\n    volume = \"\",\n    number = \"\",\n    pages = \"1-8\",\n    doi = \"10.1109/IJCNN.2018.8489079\"\n}\n\n",
    "abstract": "Debugging is frequently a manual and costly task. Some work recently presented automated program repair methods aiming to reduce debugging time. Despite different approaches, the process of evaluating source code patches (potential fixes) is crucial for most of them, e.g., generate-and-validate systems. The evaluation is a complex task given that patches with different syntaxes might share the same semantics, behaving equally for typically limited specifications. Hence, many approaches fail to better explore the search space of patches, leading them to not reach the patch that fixes the bug. Some research points that a buggy code is more entropic, i.e., less natural than its fixed version. So, this work proposes applying Word2vec, a word embedding model, to improve the repair evaluation process based on the naturalness obtained from a corpus of known fixes. Word2vec captures co-occurrence relationships between words in a given context and then predicts the contextual words of a given word. This technique has been applied to deal with richer semantic relationships in a text. Word2vec evaluates patches according to distances of document vectors and a softmax output layer. We analyze the performance of our proposal with mutated patches created from correct source codes and we simulate potential fixes generated by automated program repair approaches. Thus, the main contribution of this paper is a new method to evaluate patches used in automated program repair methods. The results show that Word2vec-based metrics are capable of analyzing source code naturalness and be used to evaluate source code patches."
}, {
    "py/object": "data.DataClassPaper",
    "Title": "A Syntactic Neural Model for General-Purpose Code Generation",
    "year": 2017,
    "ML_Techniques": "EN-DE",
    "Category": "Program synthesis",
    "Sub_category": "",
    "Venue": "ACL",
    "Link": "https://arxiv.org/abs/1704.01696v1",
    "bibtex": "inproceedings{Yin2017_275,\n    author = \"Yin, Pengcheng and Neubig, Graham\",\n    title = \"A Syntactic Neural Model for General-Purpose Code Generation\",\n    booktitle = \"Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)\",\n    month = \"July\",\n    year = \"2017\",\n    address = \"Vancouver, Canada\",\n    publisher = \"Association for Computational Linguistics\",\n    url = \"https://www.aclweb.org/anthology/P17-1041\",\n    doi = \"10.18653/v1/P17-1041\",\n    pages = \"440--450\",\n    abstract = \"We consider the problem of parsing natural language descriptions into source code written in a general-purpose programming language like Python. Existing data-driven methods treat this problem as a language generation task without considering the underlying syntax of the target programming language. Informed by previous work in semantic parsing, in this paper we propose a novel neural architecture powered by a grammar model to explicitly capture the target syntax as prior knowledge. Experiments find this an effective way to scale up to generation of complex programs from natural language descriptions, achieving state-of-the-art results that well outperform previous code generation and semantic parsing approaches.\"\n}\n\n",
    "abstract": "We consider the problem of parsing natural language descriptions into source code written in a general-purpose programming language like Python. Existing data-driven methods treat this problem as a language generation task without considering the underlying syntax of the target programming language. Informed by previous work in semantic parsing, in this paper we propose a novel neural architecture powered by a grammar model to explicitly capture the target syntax as prior knowledge. Experiments find this an effective way to scale up to generation of complex programs from natural language descriptions, achieving state-of-the-art results that well outperform previous code generation and semantic parsing approaches."
}, {
    "py/object": "data.DataClassPaper",
    "Title": "Abstract Syntax Networks for Code Generation and Semantic Parsing",
    "year": 2017,
    "ML_Techniques": "EN-DE",
    "Category": "Program synthesis",
    "Sub_category": "",
    "Venue": "ACL",
    "Link": "https://arxiv.org/abs/1704.07535v1",
    "bibtex": "inproceedings{Rabinovich2017_276,\n    author = \"Rabinovich, Maxim and Stern, Mitchell and Klein, Dan\",\n    title = \"Abstract Syntax Networks for Code Generation and Semantic Parsing\",\n    booktitle = \"Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)\",\n    month = \"July\",\n    year = \"2017\",\n    address = \"Vancouver, Canada\",\n    publisher = \"Association for Computational Linguistics\",\n    url = \"https://www.aclweb.org/anthology/P17-1105\",\n    doi = \"10.18653/v1/P17-1105\",\n    pages = \"1139--1149\",\n    abstract = \"Tasks like code generation and semantic parsing require mapping unstructured (or partially structured) inputs to well-formed, executable outputs. We introduce abstract syntax networks, a modeling framework for these problems. The outputs are represented as abstract syntax trees (ASTs) and constructed by a decoder with a dynamically-determined modular structure paralleling the structure of the output tree. On the benchmark Hearthstone dataset for code generation, our model obtains 79.2 BLEU and 22.7{\\\\%} exact match accuracy, compared to previous state-of-the-art values of 67.1 and 6.1{\\\\%}. Furthermore, we perform competitively on the Atis, Jobs, and Geo semantic parsing datasets with no task-specific engineering.\"\n}\n\n",
    "abstract": "Tasks like code generation and semantic parsing require mapping unstructured (or partially structured) inputs to well-formed, executable outputs. We introduce abstract syntax networks, a modeling framework for these problems. The outputs are represented as abstract syntax trees (ASTs) and constructed by a decoder with a dynamically-determined modular structure paralleling the structure of the output tree. On the benchmark Hearthstone dataset for code generation, our model obtains 79.2 BLEU and 22.7% exact match accuracy, compared to previous state-of-the-art values of 67.1 and 6.1%. Furthermore, we perform competitively on the Atis, Jobs, and Geo semantic parsing datasets with no task-specific engineering."
}, {
    "py/object": "data.DataClassPaper",
    "Title": "Accelerating search-based program synthesis using learned probabilistic models",
    "year": 2018,
    "ML_Techniques": "",
    "Category": "Program synthesis",
    "Sub_category": "",
    "Venue": "PLDI",
    "Link": "https://dl.acm.org/doi/10.1145/3192366.3192410",
    "bibtex": "inproceedings{Rabinovich2017_276,\n    author = \"Rabinovich, Maxim and Stern, Mitchell and Klein, Dan\",\n    title = \"Abstract Syntax Networks for Code Generation and Semantic Parsing\",\n    booktitle = \"Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)\",\n    month = \"July\",\n    year = \"2017\",\n    address = \"Vancouver, Canada\",\n    publisher = \"Association for Computational Linguistics\",\n    url = \"https://www.aclweb.org/anthology/P17-1105\",\n    doi = \"10.18653/v1/P17-1105\",\n    pages = \"1139--1149\",\n    abstract = \"Tasks like code generation and semantic parsing require mapping unstructured (or partially structured) inputs to well-formed, executable outputs. We introduce abstract syntax networks, a modeling framework for these problems. The outputs are represented as abstract syntax trees (ASTs) and constructed by a decoder with a dynamically-determined modular structure paralleling the structure of the output tree. On the benchmark Hearthstone dataset for code generation, our model obtains 79.2 BLEU and 22.7{\\\\%} exact match accuracy, compared to previous state-of-the-art values of 67.1 and 6.1{\\\\%}. Furthermore, we perform competitively on the Atis, Jobs, and Geo semantic parsing datasets with no task-specific engineering.\"\n}\n\n",
    "abstract": "A key challenge in program synthesis concerns how to efficiently search for the desired program in the space of possible programs. We propose a general approach to accelerate search-based program synthesis by biasing the search towards likely programs. Our approach targets a standard formulation, syntax-guided synthesis (SyGuS), by extending the grammar of possible programs with a probabilistic model dictating the likelihood of each program. We develop a weighted search algorithm to efficiently enumerate programs in order of their likelihood. We also propose a method based on transfer learning that enables to effectively learn a powerful model, called probabilistic higher-order grammar, from known solutions in a domain. We have implemented our approach in a tool called Euphony and evaluate it on SyGuS benchmark problems from a variety of domains. We show that Euphony can learn good models using easily obtainable solutions, and achieves significant performance gains over existing general-purpose as well as domain-specific synthesizers."
}, {
    "py/object": "data.DataClassPaper",
    "Title": "An Empirical Study on Learning Bug-Fixing Patches in the Wild via Neural Machine Translation",
    "year": 2019,
    "ML_Techniques": "NMT",
    "Category": "Program synthesis",
    "Sub_category": "Program repair",
    "Venue": "TOSEM",
    "Link": "https://dl.acm.org/doi/10.1145/3340544",
    "bibtex": "article{Tufano2019_279,\n    author = \"Tufano, Michele and Watson, Cody and Bavota, Gabriele and Penta, Massimiliano Di and White, Martin and Poshyvanyk, Denys\",\n    title = \"An Empirical Study on Learning Bug-Fixing Patches in the Wild via Neural Machine Translation\",\n    year = \"2019\",\n    issue_date = \"October 2019\",\n    publisher = \"Association for Computing Machinery\",\n    address = \"New York, NY, USA\",\n    volume = \"28\",\n    number = \"4\",\n    issn = \"1049-331X\",\n    url = \"https://doi.org/10.1145/3340544\",\n    doi = \"10.1145/3340544\",\n    abstract = \"Millions of open source projects with numerous bug fixes are available in code repositories. This proliferation of software development histories can be leveraged to learn how to fix common programming bugs. To explore such a potential, we perform an empirical study to assess the feasibility of using Neural Machine Translation techniques for learning bug-fixing patches for real defects. First, we mine millions of bug-fixes from the change histories of projects hosted on GitHub in order to extract meaningful examples of such bug-fixes. Next, we abstract the buggy and corresponding fixed code, and use them to train an Encoder-Decoder model able to translate buggy code into its fixed version. In our empirical investigation, we found that such a model is able to fix thousands of unique buggy methods in the wild. Overall, this model is capable of predicting fixed patches generated by developers in 9--50\\% of the cases, depending on the number of candidate patches we allow it to generate. Also, the model is able to emulate a variety of different Abstract Syntax Tree operations and generate candidate patches in a split second.\",\n    journal = \"ACM Trans. Softw. Eng. Methodol.\",\n    month = \"September\",\n    articleno = \"19\",\n    numpages = \"29\",\n    keywords = \"Neural machine translation, bug-fixes\"\n}\n\n",
    "abstract": "Millions of open-source projects with numerous bug fixes are available in code repositories. This proliferation of software development histories can be leveraged to learn how to fix common programming bugs. To explore such a potential, we perform an empirical study to assess the feasibility of using Neural Machine Translation techniques for learning bug-fixing patches for real defects. First, we mine millions of bug-fixes from the change histories of projects hosted on GitHub, in order to extract meaningful examples of such bug-fixes. Next, we abstract the buggy and corresponding fixed code, and use them to train an Encoder-Decoder model able to translate buggy code into its fixed version. In our empirical investigation we found that such a model is able to fix thousands of unique buggy methods in the wild. Overall, this model is capable of predicting fixed patches generated by developers in 9-50% of the cases, depending on the number of candidate patches we allow it to generate. Also, the model is able to emulate a variety of different Abstract Syntax Tree operations and generate candidate patches in a split second."
}, {
    "py/object": "data.DataClassPaper",
    "Title": "Automated Large Program Repair based on Big Code",
    "year": 2018,
    "ML_Techniques": "",
    "Category": "Program synthesis",
    "Sub_category": "Program repair",
    "Venue": "SoICT",
    "Link": "https://dl.acm.org/doi/abs/10.1145/3287921.3287958",
    "bibtex": "article{Tufano2019_279,\n    author = \"Tufano, Michele and Watson, Cody and Bavota, Gabriele and Penta, Massimiliano Di and White, Martin and Poshyvanyk, Denys\",\n    title = \"An Empirical Study on Learning Bug-Fixing Patches in the Wild via Neural Machine Translation\",\n    year = \"2019\",\n    issue_date = \"October 2019\",\n    publisher = \"Association for Computing Machinery\",\n    address = \"New York, NY, USA\",\n    volume = \"28\",\n    number = \"4\",\n    issn = \"1049-331X\",\n    url = \"https://doi.org/10.1145/3340544\",\n    doi = \"10.1145/3340544\",\n    abstract = \"Millions of open source projects with numerous bug fixes are available in code repositories. This proliferation of software development histories can be leveraged to learn how to fix common programming bugs. To explore such a potential, we perform an empirical study to assess the feasibility of using Neural Machine Translation techniques for learning bug-fixing patches for real defects. First, we mine millions of bug-fixes from the change histories of projects hosted on GitHub in order to extract meaningful examples of such bug-fixes. Next, we abstract the buggy and corresponding fixed code, and use them to train an Encoder-Decoder model able to translate buggy code into its fixed version. In our empirical investigation, we found that such a model is able to fix thousands of unique buggy methods in the wild. Overall, this model is capable of predicting fixed patches generated by developers in 9--50\\% of the cases, depending on the number of candidate patches we allow it to generate. Also, the model is able to emulate a variety of different Abstract Syntax Tree operations and generate candidate patches in a split second.\",\n    journal = \"ACM Trans. Softw. Eng. Methodol.\",\n    month = \"September\",\n    articleno = \"19\",\n    numpages = \"29\",\n    keywords = \"Neural machine translation, bug-fixes\"\n}\n\n",
    "abstract": "The task of automatic program repair is to automatically localize and generate the correct patches for the bugs. A prominent approach is to produce a space of candidate patches, then find and validate candidates on test case sets. However, searching for the correct candidates is really challenging, since the search space is dominated by incorrect patches and its size is huge.\n\nThis paper presents several methods to improve the automated program repair system Prophet, called Prophet+. Our approach contributes three improvements over Prophet: 1) extract twelve relations of statements and blocks for Bi-gram model using Big code, 2) prune the search space, 3) develop an algorithm to re-rank candidate patches in the search space. The experimental results show that our proposed system enhances the performance of Prophet, recognized as the state-of-the-art system, significantly. Specifically, for the top 1, our system generates the correct patches for 17 over 69 bugs while the number achieved by Prophet is 15."
}, {
    "py/object": "data.DataClassPaper",
    "Title": "Automated program repair",
    "year": 2019,
    "ML_Techniques": "",
    "Category": "Program synthesis",
    "Sub_category": "Program repair",
    "Venue": "CACM",
    "Link": "https://dl.acm.org/doi/abs/10.1145/3318162",
    "bibtex": "article{Goues2019_281,\n    author = \"Goues, Claire Le and Pradel, Michael and Roychoudhury, Abhik\",\n    title = \"Automated Program Repair\",\n    year = \"2019\",\n    issue_date = \"December 2019\",\n    publisher = \"Association for Computing Machinery\",\n    address = \"New York, NY, USA\",\n    volume = \"62\",\n    number = \"12\",\n    issn = \"0001-0782\",\n    url = \"https://doi.org/10.1145/3318162\",\n    doi = \"10.1145/3318162\",\n    abstract = \"Automated program repair can relieve programmers from the burden of manually fixing the ever-increasing number of programming mistakes.\",\n    journal = \"Commun. ACM\",\n    month = \"November\",\n    pages = \"56\u201365\",\n    numpages = \"10\"\n}\n\n",
    "abstract": "Automated program repair can relieve programmers from the burden of manually fixing the ever-increasing number of programming mistakes."
}, {
    "py/object": "data.DataClassPaper",
    "Title": "Automated support for diagnosis and repair",
    "year": 2015,
    "ML_Techniques": "",
    "Category": "Program synthesis",
    "Sub_category": "Program repair",
    "Venue": "CACM",
    "Link": "https://dl.acm.org/doi/fullHtml/10.1145/2658986",
    "bibtex": "article{Goues2019_281,\n    author = \"Goues, Claire Le and Pradel, Michael and Roychoudhury, Abhik\",\n    title = \"Automated Program Repair\",\n    year = \"2019\",\n    issue_date = \"December 2019\",\n    publisher = \"Association for Computing Machinery\",\n    address = \"New York, NY, USA\",\n    volume = \"62\",\n    number = \"12\",\n    issn = \"0001-0782\",\n    url = \"https://doi.org/10.1145/3318162\",\n    doi = \"10.1145/3318162\",\n    abstract = \"Automated program repair can relieve programmers from the burden of manually fixing the ever-increasing number of programming mistakes.\",\n    journal = \"Commun. ACM\",\n    month = \"November\",\n    pages = \"56\u201365\",\n    numpages = \"10\"\n}\n\n",
    "abstract": "Model checking and logic-based learning together deliver automated support, especially in adaptive and autonomous systems."
}, {
    "py/object": "data.DataClassPaper",
    "Title": "Automatic B-model repair using model checking and machine learning",
    "year": 2019,
    "ML_Techniques": "ResNet, RF, CART ",
    "Category": "Program synthesis",
    "Sub_category": "Program repair",
    "Venue": "ASE",
    "Link": "https://link.springer.com/article/10.1007/s10515-019-00264-4",
    "bibtex": "article{Cai2019_284,\n    author = {Cai, Cheng-Hao and Sun, Jing and Dobbie, Gillian},\n    title = {Automatic B-model repair using model checking and machine learning},\n    year = {2019},\n    publisher = {Springer},\n    address = {},\n    volume = {26},\n    number = {3},\n    issn = {1573-7535},\n    doi = {10.1007/s10515-019-00264-4},\n    journal = {Automated Software Engineering},\n    month = jan,\n    pages = {},\n    numpages = {}\n}\n\n",
    "abstract": "The B-method, which provides automated verification for the design of software systems, still requires users to manually repair faulty models. This paper proposes B-repair, an approach that supports automated repair of faulty models written in the B formal specification language. After discovering a fault in a model using the B-method, B-repair is able to suggest possible repairs for the fault, estimate the quality of suggested repairs and use a suitable repair to revise the model. The suggestion of repairs is produced using the Isolation method, which suggests changing the pre-conditions of operations, and the Revision method, which suggests changing the post-conditions of operations. The estimation of repair quality makes use of machine learning techniques that can learn the features of state transitions. After estimating the quality of suggested repairs, the repairs are ranked, and a best repair is selected according to the result of ranking and is used to revise the model. This approach has been evaluated using a set of finite state machines seeded with faults and a case study. The evaluation has revealed that B-repair is able to repair a large number of faults, including invariant violations, assertion violations and deadlock states, and gain high accuracies of repair. Using the combination of model checking and machine learning-guided techniques, B-repair saves development time by finding and repairing faults automatically during design."
}, {
    "py/object": "data.DataClassPaper",
    "Title": "Automatic patch generation by learning correct code",
    "year": 2016,
    "ML_Techniques": "",
    "Category": "Program synthesis",
    "Sub_category": "Program repair",
    "Venue": "POPL",
    "Link": "https://dl.acm.org/doi/10.1145/2837614.2837617",
    "bibtex": "article{Cai2019_284,\n    author = {Cai, Cheng-Hao and Sun, Jing and Dobbie, Gillian},\n    title = {Automatic B-model repair using model checking and machine learning},\n    year = {2019},\n    publisher = {Springer},\n    address = {},\n    volume = {26},\n    number = {3},\n    issn = {1573-7535},\n    doi = {10.1007/s10515-019-00264-4},\n    journal = {Automated Software Engineering},\n    month = jan,\n    pages = {},\n    numpages = {}\n}\n\n",
    "abstract": "We present Prophet, a novel patch generation system that works with a set of successful human patches obtained from open- source software repositories to learn a probabilistic, application-independent model of correct code. It generates a space of candidate patches, uses the model to rank the candidate patches in order of likely correctness, and validates the ranked patches against a suite of test cases to find correct patches. Experimental results show that, on a benchmark set of 69 real-world defects drawn from eight open-source projects, Prophet significantly outperforms the previous state-of-the-art patch generation system."
}, {
    "py/object": "data.DataClassPaper",
    "Title": "CoCoNuT: combining context-aware neural translation models using ensemble for program repair",
    "year": 2020,
    "ML_Techniques": "NMT, CNN",
    "Category": "Program synthesis",
    "Sub_category": "Program repair",
    "Venue": "ISSTA",
    "Link": "https://dl.acm.org/doi/abs/10.1145/3395363.3397369",
    "bibtex": "article{Cai2019_284,\n    author = {Cai, Cheng-Hao and Sun, Jing and Dobbie, Gillian},\n    title = {Automatic B-model repair using model checking and machine learning},\n    year = {2019},\n    publisher = {Springer},\n    address = {},\n    volume = {26},\n    number = {3},\n    issn = {1573-7535},\n    doi = {10.1007/s10515-019-00264-4},\n    journal = {Automated Software Engineering},\n    month = jan,\n    pages = {},\n    numpages = {}\n}\n\n",
    "abstract": "Automated generate-and-validate (GV) program repair techniques (APR) typically rely on hard-coded rules, thus only fixing bugs following specific fix patterns. These rules require a significant amount of manual effort to discover and it is hard to adapt these rules to different programming languages.\n\nTo address these challenges, we propose a new G&V technique\u2014CoCoNuT, which uses ensemble learning on the combination of convolutional neural networks (CNNs) and a new context-aware neural machine translation (NMT) architecture to automatically fix bugs in multiple programming languages. To better represent the context of a bug, we introduce a new context-aware NMT architecture that represents the buggy source code and its surrounding context separately. CoCoNuT uses CNNs instead of recurrent neural networks (RNNs), since CNN layers can be stacked to extract hierarchical features and better model source code at different granularity levels (e.g., statements and functions). In addition, CoCoNuT takes advantage of the randomness in hyperparameter tuning to build multiple models that fix different bugs and combines these models using ensemble learning to fix more bugs.\n\nOur evaluation on six popular benchmarks for four programming languages (Java, C, Python, and JavaScript) shows that CoCoNuT correctly fixes (i.e., the first generated patch is semantically equivalent to the developer\u2019s patch) 509 bugs, including 309 bugs that are fixed by none of the 27 techniques with which we compare."
}, {
    "py/object": "data.DataClassPaper",
    "Title": "Code Naturalness to Assist Search Space Exploration in Search-Based Program Repair Methods",
    "year": 2019,
    "ML_Techniques": "Doc2vec, LSTM",
    "Category": "Program synthesis",
    "Sub_category": "Program repair",
    "Venue": "SSBSE",
    "Link": "https://link.springer.com/chapter/10.1007/978-3-030-27455-9_12",
    "bibtex": "InProceedings{Dantas2019_289,\n    author = \"Dantas, Altino and de Souza, Eduardo F. and Souza, Jerffeson and Camilo-Junior, Celso G.\",\n    editor = \"Nejati, Shiva and Gay, Gregory\",\n    title = \"Code Naturalness to Assist Search Space Exploration in Search-Based Program Repair Methods\",\n    booktitle = \"Search-Based Software Engineering\",\n    year = \"2019\",\n    publisher = \"Springer International Publishing\",\n    address = \"Cham\",\n    pages = \"164--170\",\n    abstract = \"Automated Program Repair (APR) is a research field that has recently gained attention due to its advances in proposing methods to fix buggy programs without human intervention. Search-Based Program Repair methods have difficulties to traverse the search space, mainly, because it is challenging and costly to evaluate each variant. Therefore, aiming to improve each program's variant evaluation through providing more information to the fitness function, we propose the combination of two techniques, Doc2vec and LSTM, to capture high-level differences among variants and to capture the dependence between source code statements in the fault localization region. The experiments performed with the IntroClass benchmark show that our approach captures differences between variants according to the level of changes they received, and the resulting information is useful to balance the search between the exploration and exploitation steps. Besides, the proposal might be promising to filter program variants that are adequate to the suspicious portion of the code.\",\n    isbn = \"978-3-030-27455-9\"\n}\n\n",
    "abstract": "Automated Program Repair (APR) is a research field that has recently gained attention due to its advances in proposing methods to fix buggy programs without human intervention. Search-Based Program Repair methods have difficulties to traverse the search space, mainly, because it is challenging and costly to evaluate each variant. Therefore, aiming to improve each program\u2019s variant evaluation through providing more information to the fitness function, we propose the combination of two techniques, Doc2vec and LSTM, to capture high-level differences among variants and to capture the dependence between source code statements in the fault localization region. The experiments performed with the IntroClass benchmark show that our approach captures differences between variants according to the level of changes they received, and the resulting information is useful to balance the search between the exploration and exploitation steps. Besides, the proposal might be promising to filter program variants that are adequate to the suspicious portion of the code."
}, {
    "py/object": "data.DataClassPaper",
    "Title": "CODIT: Code Editing with Tree-Based Neural Machine Translation",
    "year": 2020,
    "ML_Techniques": "NMT",
    "Category": "Program synthesis",
    "Sub_category": "Program translation",
    "Venue": "TSE",
    "Link": "https://arxiv.org/pdf/1810.00314.pdf",
    "bibtex": "InProceedings{Dantas2019_289,\n    author = \"Dantas, Altino and de Souza, Eduardo F. and Souza, Jerffeson and Camilo-Junior, Celso G.\",\n    editor = \"Nejati, Shiva and Gay, Gregory\",\n    title = \"Code Naturalness to Assist Search Space Exploration in Search-Based Program Repair Methods\",\n    booktitle = \"Search-Based Software Engineering\",\n    year = \"2019\",\n    publisher = \"Springer International Publishing\",\n    address = \"Cham\",\n    pages = \"164--170\",\n    abstract = \"Automated Program Repair (APR) is a research field that has recently gained attention due to its advances in proposing methods to fix buggy programs without human intervention. Search-Based Program Repair methods have difficulties to traverse the search space, mainly, because it is challenging and costly to evaluate each variant. Therefore, aiming to improve each program's variant evaluation through providing more information to the fitness function, we propose the combination of two techniques, Doc2vec and LSTM, to capture high-level differences among variants and to capture the dependence between source code statements in the fault localization region. The experiments performed with the IntroClass benchmark show that our approach captures differences between variants according to the level of changes they received, and the resulting information is useful to balance the search between the exploration and exploitation steps. Besides, the proposal might be promising to filter program variants that are adequate to the suspicious portion of the code.\",\n    isbn = \"978-3-030-27455-9\"\n}\n\n",
    "abstract": "The way developers edit day-to-day code tends to be repetitive, often using existing code elements. Many researchers have tried to automate repetitive code changes by learning from specific change templates which are applied to limited scope. The advancement of Neural Machine Translation (NMT) and the availability of vast open-source evolutionary data opens up the possibility of automatically learning those templates from the wild. However, unlike natural languages, for which NMT techniques were originally devised, source code and its changes have certain properties. For instance, compared to natural language, source code vocabulary can be significantly larger. Further, good changes in code do not break its syntactic structure. Thus, deploying state-of-the-art NMT models without adapting the methods to the source code domain yields sub-optimal results.\n\nTo this end, we propose a novel Tree based NMT system to model source code changes and learn code change patterns from the wild. We realize our model with a change suggestion engine: Codit and train the model with more than 30k real-world changes and evaluate it on 6k patches. Our evaluation shows the effectiveness of Codit in learning and suggesting patches. Codit also shows promise generating bug fix patches."
}, {
    "py/object": "data.DataClassPaper",
    "Title": "Common Statement Kind Changes to Inform Automatic Program Repair",
    "year": 2018,
    "ML_Techniques": "ARM",
    "Category": "Program synthesis",
    "Sub_category": "Program repair",
    "Venue": "MSR",
    "Link": "https://ieeexplore.ieee.org/abstract/document/8595190",
    "bibtex": "INPROCEEDINGS{Soto2018_292,\n    author = \"{Soto}, M. and {Le Goues}, C.\",\n    booktitle = \"2018 IEEE/ACM 15th International Conference on Mining Software Repositories (MSR)\",\n    title = \"Common Statement Kind Changes to Inform Automatic Program Repair\",\n    year = \"2018\",\n    volume = \"\",\n    number = \"\",\n    pages = \"102-105\",\n    doi = \"\"\n}\n\n",
    "abstract": "The search space for automatic program repair approaches is vast and the search for mechanisms to help restrict this search are increasing. We make a granular analysis based on statement kinds to find which statements are more likely to be modified than others when fixing an error. We construct a corpus for analysis by delimiting debugging regions in the provided dataset and recursively analyze the differences between the Simplified Syntax Trees associated with EditEvent's. We build a distribution of statement kinds with their corresponding likelihood of being modified and we validate the usage of this distribution to guide the statement selection. We then build association rules with different confidence thresholds to describe statement kinds commonly modified together for multi-edit patch creation. Finally we evaluate association rule coverage over a held out test set and find that when using a 95% confidence threshold we can create less and more accurate rules that fully cover 93.8% of the testing instances."
}, {
    "py/object": "data.DataClassPaper",
    "Title": "Compilation error repair: for the student programs, from the student programs",
    "year": 2018,
    "ML_Techniques": "RNN",
    "Category": "Program synthesis",
    "Sub_category": "Program repair",
    "Venue": "ICSE",
    "Link": "https://dl.acm.org/doi/abs/10.1145/3183377.3183383",
    "bibtex": "INPROCEEDINGS{Soto2018_292,\n    author = \"{Soto}, M. and {Le Goues}, C.\",\n    booktitle = \"2018 IEEE/ACM 15th International Conference on Mining Software Repositories (MSR)\",\n    title = \"Common Statement Kind Changes to Inform Automatic Program Repair\",\n    year = \"2018\",\n    volume = \"\",\n    number = \"\",\n    pages = \"102-105\",\n    doi = \"\"\n}\n\n",
    "abstract": "Compile-time errors pose a major learning hurdle for students of introductory programming courses. Compiler error messages, while accurate, are targeted at seasoned programmers, and seem cryptic to beginners. In this work, we address this problem of pedagogically-inspired program repair and report TRACER (Targeted RepAir of Compilation ERrors), a system for performing repairs on compilation errors, aimed at introductory programmers.\n\nTRACER invokes a novel combination of tools from programming language theory and deep learning and offers repairs that not only enable successful compilation, but repairs that are very close to those actually performed by students on similar errors. The ability to offer such targeted corrections, rather than just code that compiles, makes TRACER more relevant in offering real-time feedback to students in lab or tutorial sessions, as compared to existing works that merely offer a certain compilation success rate.\n\nIn an evaluation on 4500 erroneous C programs written by students of a freshman year programming course, TRACER recommends a repair exactly matching the one expected by the student for 68% of the cases, and in 79.27% of the cases, produces a compilable repair. On a further set of 6971 programs that require errors to be fixed on multiple lines, TRACER enjoyed a success rate of 44% compared to the 27% success rate offered by the state-of-the-art technique DeepFix."
}, {
    "py/object": "data.DataClassPaper",
    "Title": "Data-guided repair of selection statements",
    "year": 2014,
    "ML_Techniques": "SVM, DT",
    "Category": "Program synthesis",
    "Sub_category": "Program repair",
    "Venue": "ICSE",
    "Link": "https://dl.acm.org/doi/10.1145/2568225.2568303",
    "bibtex": "INPROCEEDINGS{Soto2018_292,\n    author = \"{Soto}, M. and {Le Goues}, C.\",\n    booktitle = \"2018 IEEE/ACM 15th International Conference on Mining Software Repositories (MSR)\",\n    title = \"Common Statement Kind Changes to Inform Automatic Program Repair\",\n    year = \"2018\",\n    volume = \"\",\n    number = \"\",\n    pages = \"102-105\",\n    doi = \"\"\n}\n\n",
    "abstract": "Database-centric programs form the backbone of many enterprise systems. Fixing defects in such programs takes much human effort due to the interplay between imperative code and database-centric logic. This paper presents a novel data-driven approach for automated fixing of bugs in the selection condition of database statements (e.g., WHERE clause of SELECT statements) \u2013 a common form of bugs in such programs. Our key observation is that in real-world data, there is information latent in the distribution of data that can be useful to repair selection conditions efficiently. Given a faulty database program and input data, only a part of which induces the defect, our novelty is in determining the correct behavior for the defect-inducing data by taking advantage of the information revealed by the rest of the data. We accomplish this by employing semi-supervised learning to predict the correct behavior for defect-inducing data and by patching up any inaccuracies in the prediction by a SAT-based combinatorial search. Next, we learn a compact decision tree for the correct behavior, including the correct behavior on the defect-inducing data. This tree suggests a plausible fix to the selection condition. We demonstrate the feasibility of our approach on seven realworld examples."
}, {
    "py/object": "data.DataClassPaper",
    "Title": "Deep Learning for Source Code Modeling and Generation: Models, Applications, and Challenges",
    "year": 2020,
    "ML_Techniques": "NMT",
    "Category": "Program synthesis",
    "Sub_category": ",Program translation",
    "Venue": "CSUR",
    "Link": "https://dl.acm.org/doi/10.1145/3383458",
    "bibtex": "article{Le2020_297,\n    author = \"Le, Triet H. M. and Chen, Hao and Babar, Muhammad Ali\",\n    title = \"Deep Learning for Source Code Modeling and Generation: Models, Applications, and Challenges\",\n    year = \"2020\",\n    issue_date = \"June 2020\",\n    publisher = \"Association for Computing Machinery\",\n    address = \"New York, NY, USA\",\n    volume = \"53\",\n    number = \"3\",\n    issn = \"0360-0300\",\n    url = \"https://doi.org/10.1145/3383458\",\n    doi = \"10.1145/3383458\",\n    journal = \"ACM Comput. Surv.\",\n    month = \"June\",\n    articleno = \"62\",\n    numpages = \"38\",\n    keywords = \"Deep learning, source code modeling, source code generation, big code\"\n}\n\n",
    "abstract": "Deep Learning (DL) techniques for Natural Language Processing have been evolving remarkably fast. Recently, the DL advances in language modeling, machine translation and paragraph understanding are so prominent that the potential of DL in Software Engineering cannot be overlooked, especially in the field of program learning. To facilitate further research and applications of DL in this field, we provide a comprehensive review to categorize and investigate existing DL methods for source code modeling and generation. To address the limitations of the traditional source code models, we formulate common program learning tasks under an encoder-decoder framework. After that, we introduce recent DL mechanisms suitable to solve such problems. Then, we present the state-of-the-art practices and discuss their challenges with some recommendations for practitioners and researchers as well."
}, {
    "py/object": "data.DataClassPaper",
    "Title": "Deep Reinforcement Learning for Syntactic Error Repair in Student Programs",
    "year": 2019,
    "ML_Techniques": "LSTM, A3C",
    "Category": "Program synthesis",
    "Sub_category": "Program repair",
    "Venue": "AAAI",
    "Link": "https://ojs.aaai.org//index.php/AAAI/article/view/3882",
    "bibtex": "article{Gupta2019_298,\n    author = \"Gupta, Rahul and Kanade, Aditya and Shevade, Shirish\",\n    year = \"2019\",\n    month = \"07\",\n    pages = \"930-937\",\n    title = \"Deep Reinforcement Learning for Syntactic Error Repair in Student Programs\",\n    volume = \"33\",\n    journal = \"Proceedings of the AAAI Conference on Artificial Intelligence\",\n    doi = \"10.1609/aaai.v33i01.3301930\"\n}\n\n",
    "abstract": "Novice programmers often struggle with the formal syntax of programming languages. In the traditional classroom setting, they can make progress with the help of real time feedback from their instructors which is often impossible to get in the massive open online course (MOOC) setting. Syntactic error repair techniques have huge potential to assist them at scale. Towards this, we design a novel programming language correction framework amenable to reinforcement learning. The framework allows an agent to mimic human actions for text navigation and editing. We demonstrate that the agent can be trained through self-exploration directly from the raw input, that is, program text itself, without either supervision or any prior knowledge of the formal syntax of the programming language. We evaluate our technique on a publicly available dataset containing 6975 erroneous C programs with typographic errors, written by students during an introductory programming course. Our technique fixes 1699 (24.4%) programs completely and 1310 (18.8%) program partially, outperforming DeepFix, a state-of-the-art syntactic error repair technique, which uses a fully supervised neural machine translation approach."
}, {
    "py/object": "data.DataClassPaper",
    "Title": "DeepCoder: Learning to Write Programs",
    "year": 2016,
    "ML_Techniques": "EN-DE",
    "Category": "Program synthesis",
    "Sub_category": "",
    "Venue": "CoRR",
    "Link": "https://arxiv.org/abs/1611.01989",
    "bibtex": "article{Balog2016_299,\n    author = \"Balog, Matej and Gaunt, Alexander L. and Brockschmidt, Marc and Nowozin, Sebastian and Tarlow, Daniel\",\n    title = \"DeepCoder: Learning to Write Programs\",\n    journal = \"CoRR\",\n    volume = \"abs/1611.01989\",\n    year = \"2016\",\n    url = \"http://arxiv.org/abs/1611.01989\",\n    archivePrefix = \"arXiv\",\n    eprint = \"1611.01989\",\n    timestamp = \"Mon, 13 Aug 2018 16:47:48 +0200\",\n    biburl = \"https://dblp.org/rec/journals/corr/BalogGBNT16.bib\",\n    bibsource = \"dblp computer science bibliography, https://dblp.org\"\n}\n\n",
    "abstract": "We develop a first line of attack for solving programming competition-style problems from input-output examples using deep learning. The approach is to train a neural network to predict properties of the program that generated the outputs from the inputs. We use the neural network's predictions to augment search techniques from the programming languages community, including enumerative search and an SMT-based solver. Empirically, we show that our approach leads to an order of magnitude speedup over the strong non-augmented baselines and a Recurrent Neural Network approach, and that we are able to solve problems of difficulty comparable to the simplest problems on programming competition websites."
}, {
    "py/object": "data.DataClassPaper",
    "Title": "DeepDelta: learning to repair compilation errors",
    "year": 2019,
    "ML_Techniques": "NMT",
    "Category": "Program synthesis",
    "Sub_category": "Program repair",
    "Venue": "FSE",
    "Link": "https://dl.acm.org/doi/10.1145/3338906.3340455",
    "bibtex": "article{Balog2016_299,\n    author = \"Balog, Matej and Gaunt, Alexander L. and Brockschmidt, Marc and Nowozin, Sebastian and Tarlow, Daniel\",\n    title = \"DeepCoder: Learning to Write Programs\",\n    journal = \"CoRR\",\n    volume = \"abs/1611.01989\",\n    year = \"2016\",\n    url = \"http://arxiv.org/abs/1611.01989\",\n    archivePrefix = \"arXiv\",\n    eprint = \"1611.01989\",\n    timestamp = \"Mon, 13 Aug 2018 16:47:48 +0200\",\n    biburl = \"https://dblp.org/rec/journals/corr/BalogGBNT16.bib\",\n    bibsource = \"dblp computer science bibliography, https://dblp.org\"\n}\n\n",
    "abstract": "Programmers spend a substantial amount of time manually repairing code that does not compile. We observe that the repairs for any particular error class typically follow a pattern and are highly mechanical. We propose a novel approach that automatically learns these patterns with a deep neural network and suggests program repairs for the most costly classes of build-time compilation failures. We describe how we collect all build errors and the human-authored, in-progress code changes that cause those failing builds to transition to successful builds at Google. We generate an AST diff from the textual code changes and transform it into a domain-specific language called Delta that encodes the change that must be made to make the code compile. We then feed the compiler diagnostic information (as source) and the Delta changes that resolved the diagnostic (as target) into a Neural Machine Translation network for training. For the two most prevalent and costly classes of Java compilation errors, namely missing symbols and mismatched method signatures, our system called DeepDelta, generates the correct repair changes for 19,314 out of 38,788 (50%) of unseen compilation errors. The correct changes are in the top three suggested fixes 86% of the time on average."
}, {
    "py/object": "data.DataClassPaper",
    "Title": "DeeperCoder: Code Generation Using Machine Learning",
    "year": 2020,
    "ML_Techniques": "NN",
    "Category": "Program synthesis",
    "Sub_category": "",
    "Venue": "CCWC",
    "Link": "https://ieeexplore.ieee.org/document/9031149",
    "bibtex": "article{Balog2016_299,\n    author = \"Balog, Matej and Gaunt, Alexander L. and Brockschmidt, Marc and Nowozin, Sebastian and Tarlow, Daniel\",\n    title = \"DeepCoder: Learning to Write Programs\",\n    journal = \"CoRR\",\n    volume = \"abs/1611.01989\",\n    year = \"2016\",\n    url = \"http://arxiv.org/abs/1611.01989\",\n    archivePrefix = \"arXiv\",\n    eprint = \"1611.01989\",\n    timestamp = \"Mon, 13 Aug 2018 16:47:48 +0200\",\n    biburl = \"https://dblp.org/rec/journals/corr/BalogGBNT16.bib\",\n    bibsource = \"dblp computer science bibliography, https://dblp.org\"\n}\n\n",
    "abstract": "In this paper, we present a program generation system based on input and output specification. The system is developed based on a programming-by-example technique used in program synthesis. The system can generate computer programs that satisfies user requirements based on inputs and outputs. We created a simple Domain Specific Language (DSL) which will be used in program synthesis. We trained our neural network with a large set of input space and store corresponding sample training programs. To get the final output which satisfies all the user specifications, we used inductive program synthesis and machine learning. We also experimented with different deep learning models to obtain the desired results with reduced number of steps and execution time. Finally, we show three layers of neural networks with LeakyReLU achieves the best performance when compared to other approaches."
}, {
    "py/object": "data.DataClassPaper",
    "Title": "DLFix: context-based code transformation learning for automated program repair",
    "year": 2020,
    "ML_Techniques": "RNN",
    "Category": "Program synthesis",
    "Sub_category": "Program repair",
    "Venue": "ICSE",
    "Link": "https://dl.acm.org/doi/abs/10.1145/3377811.3380345",
    "bibtex": "article{Balog2016_299,\n    author = \"Balog, Matej and Gaunt, Alexander L. and Brockschmidt, Marc and Nowozin, Sebastian and Tarlow, Daniel\",\n    title = \"DeepCoder: Learning to Write Programs\",\n    journal = \"CoRR\",\n    volume = \"abs/1611.01989\",\n    year = \"2016\",\n    url = \"http://arxiv.org/abs/1611.01989\",\n    archivePrefix = \"arXiv\",\n    eprint = \"1611.01989\",\n    timestamp = \"Mon, 13 Aug 2018 16:47:48 +0200\",\n    biburl = \"https://dblp.org/rec/journals/corr/BalogGBNT16.bib\",\n    bibsource = \"dblp computer science bibliography, https://dblp.org\"\n}\n\n",
    "abstract": "Automated Program Repair (APR) is very useful in helping developers in the process of software development and maintenance. Despite recent advances in deep learning (DL), the DL-based APR approaches still have limitations in learning bug-fixing code changes and the context of the surrounding source code of the bug-fixing code changes. These limitations lead to incorrect fixing locations or fixes. In this paper, we introduce DLFix, a two-tier DL model that treats APR as code transformation learning from the prior bug fixes and the surrounding code contexts of the fixes. The first layer is a tree-based RNN model that learns the contexts of bug fixes and its result is used as an additional weighting input for the second layer designed to learn the bug-fixing code transformations.\n\nWe conducted several experiments to evaluate DLFix in two benchmarks: Defect4j and Bugs.jar, and a newly built bug datasets with a total of +20K real-world bugs in eight projects. We compared DLFix against a total of 13 state-of-the-art pattern-based APR tools. Our results show that DLFix can auto-fix more bugs than 11 of them, and is comparable and complementary to the top two pattern-based APR tools in which there are 7 and 11 unique bugs that they cannot detect, respectively, but we can. Importantly, DLFix is fully automated and data-driven, and does not require hard-coding of bug-fixing patterns as in those tools. We compared DLFix against 4 state-of-the-art deep learning based APR models. DLFix is able to fix 2.5 times more bugs than the best performing baseline."
}, {
    "py/object": "data.DataClassPaper",
    "Title": "Dynamic Neural Program Embedding for Program Repair",
    "year": 2017,
    "ML_Techniques": "RNN",
    "Category": "Program synthesis",
    "Sub_category": "Program repair",
    "Venue": "ICLR",
    "Link": "https://arxiv.org/abs/1711.07163",
    "bibtex": "article{Wang2017_304,\n    author = \"Wang, Ke and Singh, Rishabh and Su, Zhendong\",\n    year = \"2017\",\n    month = \"11\",\n    pages = \"\",\n    title = \"Dynamic Neural Program Embedding for Program Repair\"\n}\n\n",
    "abstract": "Neural program embeddings have shown much promise recently for a variety of program analysis tasks, including program synthesis, program repair, fault localization, etc. However, most existing program embeddings are based on syntactic features of programs, such as raw token sequences or abstract syntax trees. Unlike images and text, a program has an unambiguous semantic meaning that can be difficult to capture by only considering its syntax (i.e. syntactically similar pro- grams can exhibit vastly different run-time behavior), which makes syntax-based program embeddings fundamentally limited. This paper proposes a novel semantic program embedding that is learned from program execution traces. Our key insight is that program states expressed as sequential tuples of live variable values not only captures program semantics more precisely, but also offer a more natural fit for Recurrent Neural Networks to model. We evaluate different syntactic and semantic program embeddings on predicting the types of errors that students make in their submissions to an introductory programming class and two exercises on the CodeHunt education platform. Evaluation results show that our new semantic program embedding significantly outperforms the syntactic program embeddings based on token sequences and abstract syntax trees. In addition, we augment a search-based program repair system with the predictions obtained from our se- mantic embedding, and show that search efficiency is also significantly improved."
}, {
    "py/object": "data.DataClassPaper",
    "Title": "Elixir: Effective object-oriented program repair",
    "year": 2017,
    "ML_Techniques": "LOG",
    "Category": "Program synthesis",
    "Sub_category": "Program repair",
    "Venue": "ASE",
    "Link": "https://ieeexplore.ieee.org/abstract/document/8115675",
    "bibtex": "INPROCEEDINGS{Saha2017_306,\n    author = \"{Saha}, R. K. and {Lyu}, Y. and {Yoshida}, H. and {Prasad}, M. R.\",\n    booktitle = \"2017 32nd IEEE/ACM International Conference on Automated Software Engineering (ASE)\",\n    title = \"Elixir: Effective object-oriented program repair\",\n    year = \"2017\",\n    volume = \"\",\n    number = \"\",\n    pages = \"648-659\",\n    doi = \"10.1109/ASE.2017.8115675\"\n}\n\n",
    "abstract": "This work is motivated by the pervasive use of method invocations in object-oriented (OO) programs, and indeed their prevalence in patches of OO-program bugs. We propose a generate-and-validate repair technique, called ELIXIR designed to be able to generate such patches. ELIXIR aggressively uses method calls, on par with local variables, fields, or constants, to construct more expressive repair-expressions, that go into synthesizing patches. The ensuing enlargement of the repair space, on account of the wider use of method calls, is effectively tackled by using a machine-learnt model to rank concrete repairs. The machine-learnt model relies on four features derived from the program context, i.e., the code surrounding the potential repair location, and the bug report. We implement ELIXIR and evaluate it on two datasets, the popular Defects4J dataset and a new dataset Bugs.jar created by us, and against 2 baseline versions of our technique, and 5 other techniques representing the state of the art in program repair. Our evaluation shows that ELIXIR is able to increase the number of correctly repaired bugs in Defects4J by 85% (from 14 to 26) and by 57% in Bugs.jar (from 14 to 22), while also significantly out-performing other state-of-the-art repair techniques including ACS, HD-Repair, NOPOL, PAR, and jGenProg."
}, {
    "py/object": "data.DataClassPaper",
    "Title": "Enabling Machine Learning on Resource Constrained Devices by Source Code Generation of the Learned Models",
    "year": 2018,
    "ML_Techniques": "NB, DT, MLP",
    "Category": "Program synthesis",
    "Sub_category": "",
    "Venue": "ICCS",
    "Link": "https://link.springer.com/chapter/10.1007/978-3-319-93701-4_54",
    "bibtex": "InProceedings{Szydlo2018_307,\n    author = \"Szydlo, Tomasz and Sendorek, Joanna and Brzoza-Woch, Robert\",\n    editor = \"Shi, Yong and Fu, Haohuan and Tian, Yingjie and Krzhizhanovskaya, Valeria V. and Lees, Michael Harold and Dongarra, Jack and Sloot, Peter M. A.\",\n    title = \"Enabling Machine Learning on Resource Constrained Devices by Source Code Generation of the Learned Models\",\n    booktitle = \"Computational Science -- ICCS 2018\",\n    year = \"2018\",\n    publisher = \"Springer International Publishing\",\n    address = \"Cham\",\n    pages = \"682--694\",\n    abstract = \"Due to the development of IoT solutions, we can observe the constantly growing number of these devices in almost every aspect of our lives. The machine learning may improve increase their intelligence and smartness. Unfortunately, the highly regarded programming libraries consume to much resources to be ported to the embedded processors. Thus, in the paper the concept of source code generation of machine learning models is presented as well as the generation algorithms for commonly used machine learning methods. The concept has been proven in the use cases.\",\n    isbn = \"978-3-319-93701-4\"\n}\n\n",
    "abstract": "Due to the development of IoT solutions, we can observe the constantly growing number of these devices in almost every aspect of our lives. The machine learning may improve increase their intelligence and smartness. Unfortunately, the highly regarded programming libraries consume to much resources to be ported to the embedded processors. Thus, in the paper the concept of source code generation of machine learning models is presented as well as the generation algorithms for commonly used machine learning methods. The concept has been proven in the use cases."
}, {
    "py/object": "data.DataClassPaper",
    "Title": "Evaluating Representation Learning of Code Changes for Predicting Patch Correctness in Program Repair",
    "year": 2020,
    "ML_Techniques": "BERT, LOG, NN",
    "Category": "Program synthesis",
    "Sub_category": "Program repair",
    "Venue": "ASE",
    "Link": "https://ieeexplore.ieee.org/abstract/document/9286101",
    "bibtex": "INPROCEEDINGS{Tian2020_309,\n    author = \"{Tian}, H. and {Liu}, K. and {Kabor\u00e9}, A. K. and {Koyuncu}, A. and {Li}, L. and {Klein}, J. and {Bissyand\u00e9}, T. F.\",\n    booktitle = \"2020 35th IEEE/ACM International Conference on Automated Software Engineering (ASE)\",\n    title = \"Evaluating Representation Learning of Code Changes for Predicting Patch Correctness in Program Repair\",\n    year = \"2020\",\n    volume = \"\",\n    number = \"\",\n    pages = \"981-992\",\n    doi = \"\"\n}\n\n",
    "abstract": "A large body of the literature of automated program repair develops approaches where patches are generated to be validated against an oracle (e.g., a test suite). Because such an oracle can be imperfect, the generated patches, although validated by the oracle, may actually be incorrect. While the state of the art explore research directions that require dynamic information or rely on manually-crafted heuristics, we study the benefit of learning code representations to learn deep features that may encode the properties of patch correctness. Our work mainly investigates different representation learning approaches for code changes to derive embeddings that are amenable to similarity computations. We report on findings based on embeddings produced by pre-trained and re-trained neural networks. Experimental results demonstrate the potential of embeddings to empower learning algorithms in reasoning about patch correctness: a machine learning predictor with BERT transformer-based embeddings associated with logistic regression yielded an AUC value of about 0.8 in predicting patch correctness on a deduplicated dataset of 1000 labeled patches. Our study shows that learned representations can lead to reasonable performance when comparing against the state-of-the-art, PATCH-SIM, which relies on dynamic information. These representations may further be complementary to features that were carefully (manually) engineered in the literature."
}, {
    "py/object": "data.DataClassPaper",
    "Title": "EXECUTION-GUIDED NEURAL PROGRAM SYNTHESIS",
    "year": 2019,
    "ML_Techniques": "EN-DE",
    "Category": "Program synthesis",
    "Sub_category": "",
    "Venue": "ICLR",
    "Link": "https://openreview.net/forum?id=H1gfOiAqYm",
    "bibtex": "INPROCEEDINGS{Tian2020_309,\n    author = \"{Tian}, H. and {Liu}, K. and {Kabor\u00e9}, A. K. and {Koyuncu}, A. and {Li}, L. and {Klein}, J. and {Bissyand\u00e9}, T. F.\",\n    booktitle = \"2020 35th IEEE/ACM International Conference on Automated Software Engineering (ASE)\",\n    title = \"Evaluating Representation Learning of Code Changes for Predicting Patch Correctness in Program Repair\",\n    year = \"2020\",\n    volume = \"\",\n    number = \"\",\n    pages = \"981-992\",\n    doi = \"\"\n}\n\n",
    "abstract": "Neural program synthesis from input-output examples has attracted an increasing interest from both the machine learning and the programming language community. Most existing neural program synthesis approaches employ an encoder-decoder architecture, which uses an encoder to compute the embedding of the given input-output examples, as well as a decoder to generate the program from the embedding following a given syntax. Although such approaches achieve a reasonable performance on simple tasks such as FlashFill, on more complex tasks such as Karel, the state-of-the-art approach can only achieve an accuracy of around 77%. We observe that the main drawback of existing approaches is that the semantic information is greatly under-utilized. In this work, we propose two simple yet principled techniques to better leverage the semantic information, which are execution-guided synthesis and synthesizer ensemble. These techniques are general enough to be combined with any existing encoder-decoder-style neural program synthesizer. Applying our techniques to the Karel dataset, we can boost the accuracy from around 77% to more than 90%."
}, {
    "py/object": "data.DataClassPaper",
    "Title": "Exploring Paraphrasing Techniques on Formal Language for Generating Semantics Preserving Source Code Transformations",
    "year": 2020,
    "ML_Techniques": "GAN",
    "Category": "Program synthesis",
    "Sub_category": ",Refactoring",
    "Venue": "ICSC",
    "Link": "https://ieeexplore.ieee.org/document/9031503",
    "bibtex": "INPROCEEDINGS{Stein2020_311,\n    author = \"{Stein}, A. J. and {Kapllani}, L. and {Mancoridis}, S. and {Greenstadt}, R.\",\n    booktitle = \"2020 IEEE 14th International Conference on Semantic Computing (ICSC)\",\n    title = \"Exploring Paraphrasing Techniques on Formal Language for Generating Semantics Preserving Source Code Transformations\",\n    year = \"2020\",\n    volume = \"\",\n    number = \"\",\n    pages = \"242-248\",\n    doi = \"10.1109/ICSC.2020.00051\"\n}\n\n",
    "abstract": "Automatically identifying and generating equivalent semantic content to a word, phrase, or sentence is an important part of natural language processing (NLP). The research done so far in paraphrases in NLP has been focused exclusively on textual data, but has significant potential if it is applied to formal languages like source code. In this paper, we present a novel technique for generating source code transformations via the use of paraphrases. We explore how to extract and validate source code paraphrases. The transformations can be used for stylometry tasks and processes like refactoring. A machine learning method of identifying valid transformations has the advantage of avoiding the generation of transformations by hand and is more likely to have more valid transformations. Our dataset is comprised by 27,300 C++ source code files, consisting of 273topics each with 10 parallel files. This generates approximately152,000 paraphrases. Of these paraphrases, 11% yield valid code transformations. We then train a random forest classifier that can identify valid transformations with 83% accuracy. In this paper we also discuss some of the observed relationships betweenlinked paraphrase transformations. We depict the relationshipsthat emerge between alternative equivalent code transformationsin a graph formalism"
}, {
    "py/object": "data.DataClassPaper",
    "Title": "Getafix: learning to fix bugs automatically",
    "year": 2019,
    "ML_Techniques": "HC",
    "Category": "Program synthesis",
    "Sub_category": "Program repair",
    "Venue": "OOPSLA",
    "Link": "https://dl.acm.org/doi/10.1145/3360585",
    "bibtex": "INPROCEEDINGS{Stein2020_311,\n    author = \"{Stein}, A. J. and {Kapllani}, L. and {Mancoridis}, S. and {Greenstadt}, R.\",\n    booktitle = \"2020 IEEE 14th International Conference on Semantic Computing (ICSC)\",\n    title = \"Exploring Paraphrasing Techniques on Formal Language for Generating Semantics Preserving Source Code Transformations\",\n    year = \"2020\",\n    volume = \"\",\n    number = \"\",\n    pages = \"242-248\",\n    doi = \"10.1109/ICSC.2020.00051\"\n}\n\n",
    "abstract": "Static analyzers help find bugs early by warning about recurring bug categories. While fixing these bugs still remains a mostly manual task in practice, we observe that fixes for a specific bug category often are repetitive. This paper addresses the problem of automatically fixing instances of common bugs by learning from past fixes. We present Getafix, an approach that produces human-like fixes while being fast enough to suggest fixes in time proportional to the amount of time needed to obtain static analysis results in the first place.\n\nGetafix is based on a novel hierarchical clustering algorithm that summarizes fix patterns into a hierarchy ranging from general to specific patterns. Instead of an expensive exploration of a potentially large space of candidate fixes, Getafix uses a simple yet effective ranking technique that uses the context of a code change to select the most appropriate fix for a given bug.\n\nOur evaluation applies Getafix to 1,268 bug fixes for six bug categories reported by popular static analyzers for Java, including null dereferences, incorrect API calls, and misuses of particular language constructs. The approach predicts exactly the human-written fix as the top-most suggestion between 12% and 91% of the time, depending on the bug category. The top-5 suggestions contain fixes for 526 of the 1,268 bugs. Moreover, we report on deploying the approach within Facebook, where it contributes to the reliability of software used by billions of people. To the best of our knowledge, Getafix is the first industrially-deployed automated bug-fixing tool that learns fix patterns from past, human-written fixes to produce human-like fixes."
}, {
    "py/object": "data.DataClassPaper",
    "Title": "Glass-Box Program Synthesis: A Machine Learning Approach",
    "year": 2017,
    "ML_Techniques": "LOG",
    "Category": "Program synthesis",
    "Sub_category": "",
    "Venue": "AAAI",
    "Link": "https://arxiv.org/abs/1709.08669v1",
    "bibtex": "inproceedings{Christakopoulou2018_313,\n    author = \"Christakopoulou, Konstantina and Kalai, A.\",\n    title = \"Glass-Box Program Synthesis: A Machine Learning Approach\",\n    booktitle = \"AAAI\",\n    year = \"2018\"\n}\n\n",
    "abstract": "Recently proposed models which learn to write computer programs from data use either input/output examples or rich execution traces. Instead, we argue that a novel alternative is to use a glass-box loss function, given as a program itself that can be directly inspected. Glass-box optimization covers a wide range of problems, from computing the greatest common divisor of two integers, to learning-to-learn problems.\nIn this paper, we present an intelligent search system which learns, given the partial program and the glass-box problem, the probabilities over the space of programs. We empirically demonstrate that our informed search procedure leads to significant improvements compared to brute-force program search, both in terms of accuracy and time. For our experiments we use rich context free grammars inspired by number theory, text processing, and algebra. Our results show that (i) performing 4 rounds of our framework typically solves about 70% of the target problems, (ii) our framework can improve itself even in domain agnostic scenarios, and (iii) it can solve problems that would be otherwise too slow to solve with brute-force search."
}, {
    "py/object": "data.DataClassPaper",
    "Title": "Harnessing Evolution for Multi-Hunk Program Repair",
    "year": 2019,
    "ML_Techniques": "",
    "Category": "Program synthesis",
    "Sub_category": "Program repair",
    "Venue": "ICSE",
    "Link": "https://ieeexplore.ieee.org/abstract/document/8812131",
    "bibtex": "INPROCEEDINGS{Saha2019_315,\n    author = \"{Saha}, S. and k. {Saha}, R. and r. {Prasad}, M.\",\n    booktitle = \"2019 IEEE/ACM 41st International Conference on Software Engineering (ICSE)\",\n    title = \"Harnessing Evolution for Multi-Hunk Program Repair\",\n    year = \"2019\",\n    volume = \"\",\n    number = \"\",\n    pages = \"13-24\",\n    doi = \"10.1109/ICSE.2019.00020\"\n}\n\n",
    "abstract": "Despite significant advances in automatic program repair (APR) techniques over the past decade, practical deployment remains an elusive goal. One of the important challenges in this regard is the general inability of current APR techniques to produce patches that require edits in multiple locations, i.e., multi-hunk patches. In this work, we present a novel APR technique that generalizes single-hunk repair techniques to include an important class of multi-hunk bugs, namely bugs that may require applying a substantially similar patch at a number of locations. We term such sets of repair locations as evolutionary siblings - similar looking code, instantiated in similar contexts, that are expected to undergo similar changes. At the heart of our proposed method is an analysis to accurately identify a set of evolutionary siblings, for a given bug. This analysis leverages three distinct sources of information, namely the test-suite spectrum, a novel code similarity analysis, and the revision history of the project. The discovered siblings are then simultaneously repaired in a similar fashion. We instantiate this technique in a tool called Hercules and demonstrate that it is able to correctly fix 46 bugs in the Defects4J dataset, the highest of any individual APR technique to date. This includes 15 multi-hunk bugs and overall 11 bugs which have not been fixed by any other technique so far."
}, {
    "py/object": "data.DataClassPaper",
    "Title": "How Different Is It Between Machine-Generated and Developer-Provided Patches? : An Empirical Study on the Correct Patches Generated by Automated Program Repair Techniques",
    "year": 2019,
    "ML_Techniques": "",
    "Category": "Program synthesis",
    "Sub_category": "Program repair",
    "Venue": "ESEM",
    "Link": "https://ieeexplore.ieee.org/abstract/document/8870172",
    "bibtex": "INPROCEEDINGS{Wang2019_316,\n    author = \"{Wang}, S. and {Wen}, M. and {Chen}, L. and {Yi}, X. and {Mao}, X.\",\n    booktitle = \"2019 ACM/IEEE International Symposium on Empirical Software Engineering and Measurement (ESEM)\",\n    title = \"How Different Is It Between Machine-Generated and Developer-Provided Patches? : An Empirical Study on the Correct Patches Generated by Automated Program Repair Techniques\",\n    year = \"2019\",\n    volume = \"\",\n    number = \"\",\n    pages = \"1-12\",\n    doi = \"10.1109/ESEM.2019.8870172\"\n}\n\n",
    "abstract": "Background: Over the years, Automated Program Repair (APR) has attracted much attention from both academia and industry since it can reduce the costs in fixing bugs. However, how to assess the patch correctness remains to be an open challenge. Two widely adopted ways to approach this challenge, including manually checking and validating using automated generated tests, are biased (i.e., suffering from subjectivity and low precision respectively). Aim: To address this concern, we propose to conduct an empirical study towards understanding the correct patches that are generated by existing state-of-the-art APR techniques, aiming at providing guidelines for future assessment of patches. Method: To this end, we first present a Literature Review (LR) on the reported correct patches generated by recent techniques on the Defects 4J benchmark and collect 177 correct patches after a process of sanity check. We investigate how these machine-generated correct patches achieve semantic equivalence, but syntactic difference compared with developer-provided ones, how these patches distribute in different projects and APR techniques, and how the characteristics of a bug affect the patches generated for it. Results: Our main findings include: 1) we do not need to fix bugs exactly like how developers do since we observe that 25.4% (45/177) of the correct patches generated by APR techniques are syntactically different from developer-provided ones; 2) the distribution of machine-generated correct patches diverges for the aspects of Defects 4J projects and APR techniques; and 3) APR techniques tend to generate patches that are different from those by developers for bugs with large patch sizes. Conclusion: Our study not only verifies the conclusions from previous studies but also highlights implications for future study towards assessing patch correctness."
}, {
    "py/object": "data.DataClassPaper",
    "Title": "Human-In-The-Loop Automatic Program Repair",
    "year": 2020,
    "ML_Techniques": "",
    "Category": "Program synthesis",
    "Sub_category": "Program repair",
    "Venue": "ICST",
    "Link": "https://arxiv.org/abs/1912.07758",
    "bibtex": "INPROCEEDINGS{B\u00f6hme2020_317,\n    author = \"{B\u00f6hme}, M. and {Geethal}, C. and {Pham}, V. -T.\",\n    booktitle = \"2020 IEEE 13th International Conference on Software Testing, Validation and Verification (ICST)\",\n    title = \"Human-In-The-Loop Automatic Program Repair\",\n    year = \"2020\",\n    volume = \"\",\n    number = \"\",\n    pages = \"274-285\",\n    doi = \"10.1109/ICST46399.2020.00036\"\n}\n\n",
    "abstract": "We introduce Learn2fix, the first human-in-the-loop, semi-automatic repair technique when no bug oracle--except for the user who is reporting the bug--is available. Our approach negotiates with the user the condition under which the bug is observed. Only when a budget of queries to the user is exhausted, it attempts to repair the bug. A query can be thought of as the following question: \"When executing this alternative test input, the program produces the following output; is the bug observed\"? Through systematic queries, Learn2fix trains an automatic bug oracle that becomes increasingly more accurate in predicting the user's response. Our key challenge is to maximize the oracle's accuracy in predicting which tests are bug-exposing given a small budget of queries. From the alternative tests that were labeled by the user, test-driven automatic repair produces the patch.\nOur experiments demonstrate that Learn2fix learns a sufficiently accurate automatic oracle with a reasonably low labeling effort (lt. 20 queries). Given Learn2fix's test suite, the GenProg test-driven repair tool produces a higher-quality patch (i.e., passing a larger proportion of validation tests) than using manual test suites provided with the repair benchmark."
}, {
    "py/object": "data.DataClassPaper",
    "Title": "Improving automated program repair using two-layer tree-based neural networks",
    "year": 2020,
    "ML_Techniques": "EN-DE, CNN",
    "Category": "Program synthesis",
    "Sub_category": "Program repair",
    "Venue": "ICSE",
    "Link": "https://dl.acm.org/doi/10.1145/3377812.3390896",
    "bibtex": "INPROCEEDINGS{B\u00f6hme2020_317,\n    author = \"{B\u00f6hme}, M. and {Geethal}, C. and {Pham}, V. -T.\",\n    booktitle = \"2020 IEEE 13th International Conference on Software Testing, Validation and Verification (ICST)\",\n    title = \"Human-In-The-Loop Automatic Program Repair\",\n    year = \"2020\",\n    volume = \"\",\n    number = \"\",\n    pages = \"274-285\",\n    doi = \"10.1109/ICST46399.2020.00036\"\n}\n\n",
    "abstract": "We present DLFix, a two-layer tree-based model learning bug-fixing code changes and their surrounding code context to improve Automated Program Repair (APR). The first layer learns the surrounding code context of a fix and uses it as weights for the second layer that is used to learn the bug-fixing code transformation. Our empirical results on Defect4J show that DLFix can fix 30 bugs and its results are comparable and complementary to the best performing pattern-based APR tools. Furthermore, DLFix can fix 2.5 times more bugs than the best performing deep learning baseline."
}, {
    "py/object": "data.DataClassPaper",
    "Title": "Improving performance of automatic program repair using learned heuristics",
    "year": 2017,
    "ML_Techniques": "RF",
    "Category": "Program synthesis",
    "Sub_category": "Program repair",
    "Venue": "FSE",
    "Link": "https://dl.acm.org/doi/abs/10.1145/3106237.3121281",
    "bibtex": "INPROCEEDINGS{B\u00f6hme2020_317,\n    author = \"{B\u00f6hme}, M. and {Geethal}, C. and {Pham}, V. -T.\",\n    booktitle = \"2020 IEEE 13th International Conference on Software Testing, Validation and Verification (ICST)\",\n    title = \"Human-In-The-Loop Automatic Program Repair\",\n    year = \"2020\",\n    volume = \"\",\n    number = \"\",\n    pages = \"274-285\",\n    doi = \"10.1109/ICST46399.2020.00036\"\n}\n\n",
    "abstract": "Automatic program repair offers the promise of significant reduction in debugging time, but still faces challenges in making the process efficient, accurate, and generalizable enough for practical application. Recent efforts such as Prophet demonstrate that machine learning can be used to develop heuristics about which patches are likely to be correct, reducing overfitting problems and improving speed of repair. SearchRepair takes a different approach to accuracy, using blocks of human-written code as patches to better constrain repairs and avoid overfitting. This project combines Prophet's learning techniques with SearchRepair's larger block size to create a method that is both fast and accurate, leading to higher-quality repairs. We propose a novel first-pass filter to substantially reduce the number of candidate patches in SearchRepair and demonstrate 85% reduction in runtime over standard SearchRepair on the IntroClass dataset."
}, {
    "py/object": "data.DataClassPaper",
    "Title": "IntelliCode compose: code generation using transformer",
    "year": 2020,
    "ML_Techniques": "GPT-C",
    "Category": "Program synthesis",
    "Sub_category": "",
    "Venue": "FSE",
    "Link": "https://dl.acm.org/doi/10.1145/3368089.3417058",
    "bibtex": "INPROCEEDINGS{B\u00f6hme2020_317,\n    author = \"{B\u00f6hme}, M. and {Geethal}, C. and {Pham}, V. -T.\",\n    booktitle = \"2020 IEEE 13th International Conference on Software Testing, Validation and Verification (ICST)\",\n    title = \"Human-In-The-Loop Automatic Program Repair\",\n    year = \"2020\",\n    volume = \"\",\n    number = \"\",\n    pages = \"274-285\",\n    doi = \"10.1109/ICST46399.2020.00036\"\n}\n\n",
    "abstract": "In software development through integrated development environments (IDEs), code completion is one of the most widely used features. Nevertheless, majority of integrated development environments only support completion of methods and APIs, or arguments.\n\nIn this paper, we introduce IntelliCode Compose \u2013 a general-purpose multilingual code completion tool which is capable of predicting sequences of code tokens of arbitrary types, generating up to entire lines of syntactically correct code. It leverages state-of-the-art generative transformer model trained on 1.2 billion lines of source code in Python, C#, JavaScript and TypeScript programming languages. IntelliCode Compose is deployed as a cloud-based web service. It makes use of client-side tree-based caching, efficient parallel implementation of the beam search decoder, and compute graph optimizations to meet edit-time completion suggestion requirements in the Visual Studio Code IDE and Azure Notebook.\n\nOur best model yields an average edit similarity of 86.7% and a perplexity of 1.82 for Python programming language."
}, {
    "py/object": "data.DataClassPaper",
    "Title": "Latent Attention For If-Then Program Synthesis",
    "year": 2016,
    "ML_Techniques": "Bi-LSTM",
    "Category": "Program synthesis",
    "Sub_category": "",
    "Venue": "NIPS",
    "Link": "https://arxiv.org/abs/1611.01867v1",
    "bibtex": "INPROCEEDINGS{B\u00f6hme2020_317,\n    author = \"{B\u00f6hme}, M. and {Geethal}, C. and {Pham}, V. -T.\",\n    booktitle = \"2020 IEEE 13th International Conference on Software Testing, Validation and Verification (ICST)\",\n    title = \"Human-In-The-Loop Automatic Program Repair\",\n    year = \"2020\",\n    volume = \"\",\n    number = \"\",\n    pages = \"274-285\",\n    doi = \"10.1109/ICST46399.2020.00036\"\n}\n\n",
    "abstract": "Automatic translation from natural language descriptions into programs is a longstanding challenging problem. In this work, we consider a simple yet important sub-problem: translation from textual descriptions to If-Then programs. We devise a novel neural network architecture for this task which we train end-to-end. Specifically, we introduce Latent Attention, which computes multiplicative weights for the words in the description in a two-stage process with the goal of better leveraging the natural language structures that indicate the relevant parts for predicting program elements. Our architecture reduces the error rate by 28.57% compared to prior art. We also propose a one-shot learning scenario of If-Then program synthesis and simulate it with our existing dataset. We demonstrate a variation on the training procedure for this scenario that outperforms the original procedure, significantly closing the gap to the model trained with all data."
}, {
    "py/object": "data.DataClassPaper",
    "Title": "Latent Predictor Networks for Code Generation",
    "year": 2016,
    "ML_Techniques": "",
    "Category": "Program synthesis",
    "Sub_category": "",
    "Venue": "ACL",
    "Link": "https://arxiv.org/abs/1603.06744",
    "bibtex": "inproceedings{Ling2016_324,\n    author = \"Ling, Wang and Blunsom, Phil and Grefenstette, Edward and Hermann, Karl Moritz and Ko{\\v{c}}isk{\\'y}, Tom{\\'a}{\\v{s}} and Wang, Fumin and Senior, Andrew\",\n    title = \"Latent Predictor Networks for Code Generation\",\n    booktitle = \"Proceedings of the 54th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)\",\n    month = \"August\",\n    year = \"2016\",\n    address = \"Berlin, Germany\",\n    publisher = \"Association for Computational Linguistics\",\n    url = \"https://www.aclweb.org/anthology/P16-1057\",\n    doi = \"10.18653/v1/P16-1057\",\n    pages = \"599--609\"\n}\n\n",
    "abstract": "Many language generation tasks require the production of text conditioned on both structured and unstructured inputs. We present a novel neural network architecture which generates an output sequence conditioned on an arbitrary number of input functions. Crucially, our approach allows both the choice of conditioning context and the granularity of generation, for example characters or tokens, to be marginalised, thus permitting scalable and effective training. Using this framework, we address the problem of generating programming code from a mixed natural language and structured specification. We create two new data sets for this paradigm derived from the collectible trading card games Magic the Gathering and Hearthstone. On these, and a third preexisting corpus, we demonstrate that marginalising multiple predictors allows our model to outperform strong benchmarks."
}, {
    "py/object": "data.DataClassPaper",
    "Title": "Learning to Generate Pseudo-Code from Source Code Using Statistical Machine Translation",
    "year": 2015,
    "ML_Techniques": "SMT",
    "Category": "Program synthesis",
    "Sub_category": "Program translation",
    "Venue": "ASE",
    "Link": "https://ieeexplore.ieee.org/abstract/document/7372045",
    "bibtex": "INPROCEEDINGS{Oda2015_325,\n    author = \"{Oda}, Y. and {Fudaba}, H. and {Neubig}, G. and {Hata}, H. and {Sakti}, S. and {Toda}, T. and {Nakamura}, S.\",\n    booktitle = \"2015 30th IEEE/ACM International Conference on Automated Software Engineering (ASE)\",\n    title = \"Learning to Generate Pseudo-Code from Source Code Using Statistical Machine Translation\",\n    year = \"2015\",\n    volume = \"\",\n    number = \"\",\n    pages = \"574-584\",\n    doi = \"10.1109/ASE.2015.36\"\n}\n\n",
    "abstract": "Pseudo-code written in natural language can aid the comprehension of source code in unfamiliar programming languages. However, the great majority of source code has no corresponding pseudo-code, because pseudo-code is redundant and laborious to create. If pseudo-code could be generated automatically and instantly from given source code, we could allow for on-demand production of pseudo-code without human effort. In this paper, we propose a method to automatically generate pseudo-code from source code, specifically adopting the statistical machine translation (SMT) framework. SMT, which was originally designed to translate between two natural languages, allows us to automatically learn the relationship between source code/pseudo-code pairs, making it possible to create a pseudo-code generator with less human effort. In experiments, we generated English or Japanese pseudo-code from Python statements using SMT, and find that the generated pseudo-code is largely accurate, and aids code understanding."
}, {
    "py/object": "data.DataClassPaper",
    "Title": "Learning to Represent Programs with Graphs",
    "year": 2017,
    "ML_Techniques": "GGNN",
    "Category": "Program synthesis",
    "Sub_category": "",
    "Venue": "ICLR",
    "Link": "https://arxiv.org/abs/1711.00740v1",
    "bibtex": "inproceedings{Allamanis2018_326,\n    author = \"Allamanis, Miltiadis and Brockschmidt, Marc and Khademi, Mahmoud\",\n    title = \"Learning to Represent Programs with Graphs\",\n    booktitle = \"International Conference on Learning Representations\",\n    year = \"2018\",\n    url = \"https://openreview.net/forum?id=BJOFETxR-\"\n}\n\n",
    "abstract": "Learning tasks on source code (i.e., formal languages) have been considered recently, but most work has tried to transfer natural language methods and does not capitalize on the unique opportunities offered by code's known syntax. For example, long-range dependencies induced by using the same variable or function in distant locations are often not considered. We propose to use graphs to represent both the syntactic and semantic structure of code and use graph-based deep learning methods to learn to reason over program structures.\nIn this work, we present how to construct graphs from source code and how to scale Gated Graph Neural Networks training to such large graphs. We evaluate our method on two tasks: VarNaming, in which a network attempts to predict the name of a variable given its usage, and VarMisuse, in which the network learns to reason about selecting the correct variable that should be used at a given program location. Our comparison to methods that use less structured program representations shows the advantages of modeling known structure, and suggests that our models learn to infer meaningful names and to solve the VarMisuse task in many cases. Additionally, our testing showed that VarMisuse identifies a number of bugs in mature open-source projects."
}, {
    "py/object": "data.DataClassPaper",
    "Title": "Learning to synthesize",
    "year": 2018,
    "ML_Techniques": "GBT",
    "Category": "Program synthesis",
    "Sub_category": "",
    "Venue": "GI",
    "Link": "https://dl.acm.org/doi/10.1145/3194810.3194816",
    "bibtex": "inproceedings{Allamanis2018_326,\n    author = \"Allamanis, Miltiadis and Brockschmidt, Marc and Khademi, Mahmoud\",\n    title = \"Learning to Represent Programs with Graphs\",\n    booktitle = \"International Conference on Learning Representations\",\n    year = \"2018\",\n    url = \"https://openreview.net/forum?id=BJOFETxR-\"\n}\n\n",
    "abstract": "In many scenarios we need to find the most likely program under a local context, where the local context can be an incomplete program, a partial specification, natural language description, etc. We call such problem program estimations. In this paper we propose an abstract framework, learning to synthesis, or L2S in short, to address this problem. L2S combines four tools to achieve this: rewriting rules are used to define the search space and search steps, constraint solving is used to prune off invalid candidates at each search step, machine learning is used to estimate conditional probabilities for the candidates at each search step, and search algorithms are used to find the best possible solution. The main goal of L2S is to lay out the design space to motivate the research on program estimation.\n\nWe have performed a preliminary evaluation by instantiating this framework for synthesizing conditions of an automated program repair (APR) system. The training data are from the project itself and related JDK packages. Compared to ACS, a state-of-the-art condition synthesis system for program repair, our approach could deal with a larger search space such that we fixed 4 additional bugs outside the search space of ACS, and relies only the source code of the current projects."
}, {
    "py/object": "data.DataClassPaper",
    "Title": "Machine Learning-Driven Automatic Program Transformation to Increase Performance in Heterogeneous Architectures",
    "year": 2017,
    "ML_Techniques": "RL",
    "Category": "Program synthesis",
    "Sub_category": "Refactoring",
    "Venue": "HPC",
    "Link": "https://link.springer.com/chapter/10.1007/978-3-319-56702-0_7",
    "bibtex": "InProceedings{Tamarit2017_328,\n    author = \"Tamarit, Salvador and Vigueras, Guillermo and Carro, Manuel and Mari{\\\\textasciitilde {n}}o, Julio\",\n    editor = {Niethammer, Christoph and Gracia, Jos{\\'e} and Hilbrich, Tobias and Kn{\\\"u}pfer, Andreas and Resch, Michael M. and Nagel, Wolfgang E.},\n    title = \"Machine Learning-Driven Automatic Program Transformation to Increase Performance in Heterogeneous Architectures\",\n    booktitle = \"Tools for High Performance Computing 2016\",\n    year = \"2017\",\n    publisher = \"Springer International Publishing\",\n    address = \"Cham\",\n    pages = \"115--140\",\n    abstract = \"We present a program transformation approach to convert procedural code into functionally equivalent code adapted to a given platform. Our framework is based on the application of guarded transformation rules that capture semantic conditions to ensure the soundness of their application. Our goal is to determine a sequence of rule applications which transform some initial code into final code which optimizes some non-functional properties. The code to be transformed is adorned with semantic annotations, either provided by the user or by external analysis tools. These annotations give information to decide whether applying a transformation rule is or is not sound. In general, there are several rules applicable at several program points and, besides, transformation sequences do not monotonically change the optimization function. Therefore, we face a search problem that grows exponentially with the length of the transformation sequence. In our experience with even small examples, that becomes impractical very quickly. In order to effectively deal with this issue, we have adopted a machine-learning approach using classification trees and reinforcement learning. It learns from successful transformation sequences and produces encodings of strategies which can provide long-term rewards for a given characteristic, avoiding local minima. We have evaluated the proposed technique in a series of benchmarks, adapting standard C code to GPU execution via OpenCL. We have found the automatically produced code to be as efficient as hand-written code generated by an expert human programmer.\",\n    isbn = \"978-3-319-56702-0\"\n}\n\n",
    "abstract": "We present a program transformation approach to convert procedural code into functionally equivalent code adapted to a given platform. Our framework is based on the application of guarded transformation rules that capture semantic conditions to ensure the soundness of their application. Our goal is to determine a sequence of rule applications which transform some initial code into final code which optimizes some non-functional properties. The code to be transformed is adorned with semantic annotations, either provided by the user or by external analysis tools. These annotations give information to decide whether applying a transformation rule is or is not sound. In general, there are several rules applicable at several program points and, besides, transformation sequences do not monotonically change the optimization function. Therefore, we face a search problem that grows exponentially with the length of the transformation sequence. In our experience with even small examples, that becomes impractical very quickly. In order to effectively deal with this issue, we have adopted a machine-learning approach using classification trees and reinforcement learning. It learns from successful transformation sequences and produces encodings of strategies which can provide long-term rewards for a given characteristic, avoiding local minima. We have evaluated the proposed technique in a series of benchmarks, adapting standard C code to GPU execution via OpenCL. We have found the automatically produced code to be as efficient as hand-written code generated by an expert human programmer."
}, {
    "py/object": "data.DataClassPaper",
    "Title": "MAKING NEURAL PROGRAMMING ARCHITECTURES GENERALIZE VIA RECURSION",
    "year": 2017,
    "ML_Techniques": "LSTM",
    "Category": "Program synthesis",
    "Sub_category": "",
    "Venue": "CoRR",
    "Link": "https://arxiv.org/abs/1704.06611v1",
    "bibtex": "InProceedings{Tamarit2017_328,\n    author = \"Tamarit, Salvador and Vigueras, Guillermo and Carro, Manuel and Mari{\\\\textasciitilde {n}}o, Julio\",\n    editor = {Niethammer, Christoph and Gracia, Jos{\\'e} and Hilbrich, Tobias and Kn{\\\"u}pfer, Andreas and Resch, Michael M. and Nagel, Wolfgang E.},\n    title = \"Machine Learning-Driven Automatic Program Transformation to Increase Performance in Heterogeneous Architectures\",\n    booktitle = \"Tools for High Performance Computing 2016\",\n    year = \"2017\",\n    publisher = \"Springer International Publishing\",\n    address = \"Cham\",\n    pages = \"115--140\",\n    abstract = \"We present a program transformation approach to convert procedural code into functionally equivalent code adapted to a given platform. Our framework is based on the application of guarded transformation rules that capture semantic conditions to ensure the soundness of their application. Our goal is to determine a sequence of rule applications which transform some initial code into final code which optimizes some non-functional properties. The code to be transformed is adorned with semantic annotations, either provided by the user or by external analysis tools. These annotations give information to decide whether applying a transformation rule is or is not sound. In general, there are several rules applicable at several program points and, besides, transformation sequences do not monotonically change the optimization function. Therefore, we face a search problem that grows exponentially with the length of the transformation sequence. In our experience with even small examples, that becomes impractical very quickly. In order to effectively deal with this issue, we have adopted a machine-learning approach using classification trees and reinforcement learning. It learns from successful transformation sequences and produces encodings of strategies which can provide long-term rewards for a given characteristic, avoiding local minima. We have evaluated the proposed technique in a series of benchmarks, adapting standard C code to GPU execution via OpenCL. We have found the automatically produced code to be as efficient as hand-written code generated by an expert human programmer.\",\n    isbn = \"978-3-319-56702-0\"\n}\n\n",
    "abstract": "Empirically, neural networks that attempt to learn programs from data have exhibited poor generalizability. Moreover, it has traditionally been difficult to reason about the behavior of these models beyond a certain level of input complexity. In order to address these issues, we propose augmenting neural architectures with a key abstraction: recursion. As an application, we implement recursion in the Neural Programmer-Interpreter framework on four tasks: grade-school addition, bubble sort, topological sort, and quicksort. We demonstrate superior generalizability and interpretability with small amounts of training data. Recursion divides the problem into smaller pieces and drastically reduces the domain of each neural network component, making it tractable to prove guarantees about the overall system's behavior. Our experience suggests that in order for neural architectures to robustly learn program semantics, it is necessary to incorporate a concept like recursion."
}, {
    "py/object": "data.DataClassPaper",
    "Title": "Neural Program Meta-Induction",
    "year": 2017,
    "ML_Techniques": "EN-DE",
    "Category": "Program synthesis",
    "Sub_category": "",
    "Venue": "NIPS",
    "Link": "https://arxiv.org/abs/1710.04157v1",
    "bibtex": "inproceedings{Devlin2017_332,\n    author = \"Devlin, Jacob and Bunel, Rudy and Singh, Rishabh and Hausknecht, Matthew and Kohli, Pushmeet\",\n    title = \"Neural Program Meta-Induction\",\n    year = \"2017\",\n    isbn = \"9781510860964\",\n    publisher = \"Curran Associates Inc.\",\n    address = \"Red Hook, NY, USA\",\n    abstract = \"Most recently proposed methods for Neural Program Induction work under the assumption of having a large set of input/output (I/O) examples for learning any underlying input-output mapping. This paper aims to address the problem of data and computation efficiency of program induction by leveraging information from related tasks. Specifically, we propose two approaches for cross-task knowledge transfer to improve program induction in limited-data scenarios. In our first proposal, portfolio adaptation, a set of induction models is pretrained on a set of related tasks, and the best model is adapted towards the new task using transfer learning. In our second approach, meta program induction, a k-shot learning approach is used to make a model generalize to new tasks without additional training. To test the efficacy of our methods, we constructed a new benchmark of programs written in the Karel programming language [17]. Using an extensive experimental evaluation on the Karel benchmark, we demonstrate that our proposals dramatically outperform the baseline induction method that does not use knowledge transfer. We also analyze the relative performance of the two approaches and study conditions in which they perform best. In particular, meta induction outperforms all existing approaches under extreme data sparsity (when a very small number of examples are available), i.e., fewer than ten. As the number of available I/O examples increase (i.e. a thousand or more), portfolio adapted program induction becomes the best approach. For intermediate data sizes, we demonstrate that the combined method of adapted meta program induction has the strongest performance.\",\n    booktitle = \"Proceedings of the 31st International Conference on Neural Information Processing Systems\",\n    pages = \"2077\u20132085\",\n    numpages = \"9\",\n    location = \"Long Beach, California, USA\",\n    series = \"NIPS'17\"\n}\n\n",
    "abstract": "Most recently proposed methods for Neural Program Induction work under the assumption of having a large set of input/output (I/O) examples for learning any underlying input-output mapping. This paper aims to address the problem of data and computation efficiency of program induction by leveraging information from related tasks. Specifically, we propose two approaches for cross-task knowledge transfer to improve program induction in limited-data scenarios. In our first proposal, portfolio adaptation, a set of induction models is pretrained on a set of related tasks, and the best model is adapted towards the new task using transfer learning. In our second approach, meta program induction, a k-shot learning approach is used to make a model generalize to new tasks without additional training. To test the efficacy of our methods, we constructed a new benchmark of programs written in the Karel programming language [17]. Using an extensive experimental evaluation on the Karel benchmark, we demonstrate that our proposals dramatically outperform the baseline induction method that does not use knowledge transfer. We also analyze the relative performance of the two approaches and study conditions in which they perform best. In particular, meta induction outperforms all existing approaches under extreme data sparsity (when a very small number of examples are available), i.e., fewer than ten. As the number of available I/O examples increase (i.e. a thousand or more), portfolio adapted program induction becomes the best approach. For intermediate data sizes, we demonstrate that the combined method of adapted meta program induction has the strongest performance."
}, {
    "py/object": "data.DataClassPaper",
    "Title": "Neural Program Repair by Jointly Learning to Localize and Repair",
    "year": 2019,
    "ML_Techniques": "LSTM",
    "Category": "Program synthesis",
    "Sub_category": "Program repair",
    "Venue": "ICLR",
    "Link": "https://arxiv.org/abs/1904.01720",
    "bibtex": "unknown{Vasic2019_333,\n    author = \"Vasic, Marko and Kanade, Aditya and Maniatis, Petros and Bieber, David and Singh, Rishabh\",\n    year = \"2019\",\n    month = \"04\",\n    pages = \"\",\n    title = \"Neural Program Repair by Jointly Learning to Localize and Repair\"\n}\n\n",
    "abstract": "Due to its potential to improve programmer productivity and software quality, automated program repair has been an active topic of research. Newer techniques harness neural networks to learn directly from examples of buggy programs and their fixes. In this work, we consider a recently identified class of bugs called variable-misuse bugs. The state-of-the-art solution for variable misuse enumerates potential fixes for all possible bug locations in a program, before selecting the best prediction. We show that it is beneficial to train a model that jointly and directly localizes and repairs variable-misuse bugs. We present multi-headed pointer networks for this purpose, with one head each for localization and repair. The experimental results show that the joint model significantly outperforms an enumerative solution that uses a pointer based model for repair alone."
}, {
    "py/object": "data.DataClassPaper",
    "Title": "Neural Programming by Example",
    "year": 2017,
    "ML_Techniques": "DNN",
    "Category": "Program synthesis",
    "Sub_category": "",
    "Venue": "CoRR",
    "Link": "https://arxiv.org/abs/1703.04990v1",
    "bibtex": "article{Shu2017_334,\n    author = \"Shu, Chengxun and Zhang, Hongyu\",\n    title = \"Neural Programming by Example\",\n    journal = \"CoRR\",\n    volume = \"abs/1703.04990\",\n    year = \"2017\",\n    url = \"http://arxiv.org/abs/1703.04990\",\n    archivePrefix = \"arXiv\",\n    eprint = \"1703.04990\",\n    timestamp = \"Sun, 06 Oct 2019 12:45:50 +0200\",\n    biburl = \"https://dblp.org/rec/journals/corr/ShuZ17.bib\",\n    bibsource = \"dblp computer science bibliography, https://dblp.org\"\n}\n\n",
    "abstract": "Programming by Example (PBE) targets at automatically inferring a computer program for accomplishing a certain task from sample input and output. In this paper, we propose a deep neural networks (DNN) based PBE model called Neural Programming by Example (NPBE), which can learn from input-output strings and induce programs that solve the string manipulation problems. Our NPBE model has four neural network based components: a string encoder, an input-output analyzer, a program generator, and a symbol selector. We demonstrate the effectiveness of NPBE by training it end-to-end to solve some common string manipulation problems in spreadsheet systems. The results show that our model can induce string manipulation programs effectively. Our work is one step towards teaching DNN to generate computer programs.\n"
}, {
    "py/object": "data.DataClassPaper",
    "Title": "Neural Sketch Learning for Conditional Program Generation",
    "year": 2017,
    "ML_Techniques": "GED",
    "Category": "Program synthesis",
    "Sub_category": "",
    "Venue": "ICLR",
    "Link": "https://arxiv.org/abs/1703.05698",
    "bibtex": "inproceedings{Murali2018_335,\n    author = \"Murali, Vijayaraghavan and Qi, Letao and Chaudhuri, S. and Jermaine, C.\",\n    title = \"Neural Sketch Learning for Conditional Program Generation\",\n    booktitle = \"ICLR\",\n    year = \"2018\"\n}\n\n",
    "abstract": "We study the problem of generating source code in a strongly typed, Java-like programming language, given a label (for example a set of API calls or types) carrying a small amount of information about the code that is desired. The generated programs are expected to respect a \"realistic\" relationship between programs and labels, as exemplified by a corpus of labeled programs available during training.\nTwo challenges in such conditional program generation are that the generated programs must satisfy a rich set of syntactic and semantic constraints, and that source code contains many low-level features that impede learning. We address these problems by training a neural generator not on code but on program sketches, or models of program syntax that abstract out names and operations that do not generalize across programs. During generation, we infer a posterior distribution over sketches, then concretize samples from this distribution into type-safe programs using combinatorial techniques. We implement our ideas in a system for generating API-heavy Java code, and show that it can often predict the entire body of a method given just a few API calls or data types that appear in the method."
}, {
    "py/object": "data.DataClassPaper",
    "Title": "Neural Symbolic Machines: Learning Semantic Parsers on Freebase with Weak Supervision (Short Version)",
    "year": 2016,
    "ML_Techniques": "EN-DE",
    "Category": "Program synthesis",
    "Sub_category": "",
    "Venue": "ACL",
    "Link": "https://arxiv.org/abs/1612.01197",
    "bibtex": "inproceedings{Murali2018_335,\n    author = \"Murali, Vijayaraghavan and Qi, Letao and Chaudhuri, S. and Jermaine, C.\",\n    title = \"Neural Sketch Learning for Conditional Program Generation\",\n    booktitle = \"ICLR\",\n    year = \"2018\"\n}\n\n",
    "abstract": "Extending the success of deep neural networks to natural language understanding and symbolic reasoning requires complex operations and external memory. Recent neural program induction approaches have attempted to address this problem, but are typically limited to differentiable memory, and consequently cannot scale beyond small synthetic tasks. In this work, we propose the Manager-Programmer-Computer framework, which integrates neural networks with non-differentiable memory to support abstract, scalable and precise operations through a friendly neural computer interface. Specifically, we introduce a Neural Symbolic Machine, which contains a sequence-to-sequence neural \"programmer\", and a non-differentiable \"computer\" that is a Lisp interpreter with code assist. To successfully apply REINFORCE for training, we augment it with approximate gold programs found by an iterative maximum likelihood training process. NSM is able to learn a semantic parser from weak supervision over a large knowledge base. It achieves new state-of-the-art performance on WebQuestionsSP, a challenging semantic parsing dataset, with weak supervision. Compared to previous approaches, NSM is end-to-end, therefore does not rely on feature engineering or domain specific knowledge."
}, {
    "py/object": "data.DataClassPaper",
    "Title": "Neuro-symbolic program corrector for introductory programming assignments",
    "year": 2018,
    "ML_Techniques": "RNN",
    "Category": "Program synthesis",
    "Sub_category": "Program repair",
    "Venue": "ICSE",
    "Link": "https://dl.acm.org/doi/10.1145/3180155.3180219",
    "bibtex": "inproceedings{Murali2018_335,\n    author = \"Murali, Vijayaraghavan and Qi, Letao and Chaudhuri, S. and Jermaine, C.\",\n    title = \"Neural Sketch Learning for Conditional Program Generation\",\n    booktitle = \"ICLR\",\n    year = \"2018\"\n}\n\n",
    "abstract": "Automatic correction of programs is a challenging problem with numerous real world applications in security, verification, and education. One application that is becoming increasingly important is the correction of student submissions in online courses for providing feedback. Most existing program repair techniques analyze Abstract Syntax Trees (ASTs) of programs, which are unfortunately unavailable for programs with syntax errors. In this paper, we propose a novel Neuro-symbolic approach that combines neural networks with constraint-based reasoning. Specifically, our method first uses a Recurrent Neural Network (RNN) to perform syntax repairs for the buggy programs; subsequently, the resulting syntactically-fixed programs are repaired using constraint-based techniques to ensure functional correctness. The RNNs are trained using a corpus of syntactically correct submissions for a given programming assignment, and are then queried to fix syntax errors in an incorrect programming submission by replacing or inserting the predicted tokens at the error location. We evaluate our technique on a dataset comprising of over 14,500 student submissions with syntax errors. Our method is able to repair syntax errors in 60% (8689) of submissions, and finds functionally correct repairs for 23.8% (3455) submissions."
}, {
    "py/object": "data.DataClassPaper",
    "Title": "Program Synthesis and Semantic Parsing with Learned Code Idioms",
    "year": 2019,
    "ML_Techniques": "EN-DE",
    "Category": "Program synthesis",
    "Sub_category": "",
    "Venue": "NeurIPS",
    "Link": "https://papers.nips.cc/paper/2019/file/cff34ad343b069ea6920464ad17d4bcf-Paper.pdf",
    "bibtex": "inproceedings{Murali2018_335,\n    author = \"Murali, Vijayaraghavan and Qi, Letao and Chaudhuri, S. and Jermaine, C.\",\n    title = \"Neural Sketch Learning for Conditional Program Generation\",\n    booktitle = \"ICLR\",\n    year = \"2018\"\n}\n\n",
    "abstract": "Program synthesis of general-purpose source code from natural language specifications is challenging due to the need to reason about high-level patterns in the target program and low-level implementation details at the same time. In this work, we present PATOIS, a system that allows a neural program synthesizer to explicitly interleave high-level and low-level reasoning at every generation step. It accomplishes this by automatically mining common code idioms from a given corpus, incorporating them into the underlying language for neural synthesis, and training a tree-based neural synthesizer to use these idioms during code generation. We evaluate PATOIS on two complex semantic parsing datasets and show that using learned code idioms improves the synthesizer's accuracy."
}, {
    "py/object": "data.DataClassPaper",
    "Title": "PROGRAM SYNTHESIS FOR CHARACTER LEVEL LANGUAGE MODELING",
    "year": 2017,
    "ML_Techniques": "LSTM",
    "Category": "Program synthesis",
    "Sub_category": "",
    "Venue": "ICLR",
    "Link": "https://files.sri.inf.ethz.ch/website/papers/charmodel-iclr2017.pdf",
    "bibtex": "inproceedings{Murali2018_335,\n    author = \"Murali, Vijayaraghavan and Qi, Letao and Chaudhuri, S. and Jermaine, C.\",\n    title = \"Neural Sketch Learning for Conditional Program Generation\",\n    booktitle = \"ICLR\",\n    year = \"2018\"\n}\n\n",
    "abstract": "We propose a statistical model applicable to character level language modeling and show that it is a good fit for both, program source code and English text. The model is parameterized by a program from a domain-specific language (DSL) that allows expressing non-trivial data dependencies. Learning is done in two phases: (i) we synthesize a program from the DSL, essentially learning a good representation for the data, and (ii) we learn parameters from the training data - the process is done via counting, as in simple language models such as n-gram.\n\nOur experiments show that the precision of our model is comparable to that of neural networks while sharing a number of advantages with n-gram models such as fast query time and the capability to quickly add and remove training data samples. Further, the model is parameterized by a program that can be manually inspected, understood and updated, addressing a major problem of neural networks."
}, {
    "py/object": "data.DataClassPaper",
    "Title": "Repairing Intricate Faults in Code Using Machine Learning and Path Exploration",
    "year": 2016,
    "ML_Techniques": "SVM, DT",
    "Category": "Program synthesis",
    "Sub_category": "Program repair",
    "Venue": "ICSME",
    "Link": "https://ieeexplore.ieee.org/abstract/document/7816493",
    "bibtex": "INPROCEEDINGS{Gopinath2016_348,\n    author = \"{Gopinath}, D. and {Wang}, K. and {Hua}, J. and {Khurshid}, S.\",\n    booktitle = \"2016 IEEE International Conference on Software Maintenance and Evolution (ICSME)\",\n    title = \"Repairing Intricate Faults in Code Using Machine Learning and Path Exploration\",\n    year = \"2016\",\n    volume = \"\",\n    number = \"\",\n    pages = \"453-457\",\n    doi = \"10.1109/ICSME.2016.75\"\n}\n\n",
    "abstract": "Debugging remains costly and tedious, especially for code that performs intricate operations that are conceptually complex to reason about. We present MLR, a novel approach for repairing faults in such operations, specifically in the context of complex data structures. Our focus is on faults in conditional statements. Our insight is that an integrated approach based on machine learning and systematic path exploration can provide effective repairs. MLR mines the data-spectra of the passing and failing executions of conditional branches to prune the search space for repair and generate patches that are likely valid beyond the existing test-suite. We apply MLR to repair faults in small but complex data structure subjects to demonstrate its efficacy. Experimental results show that MLR has the potential to repair this fault class more effectively than state-of-the-art repair tools."
}, {
    "py/object": "data.DataClassPaper",
    "Title": "SEQUENCER: Sequence-to-Sequence Learning for End-to-End Program Repair",
    "year": 2019,
    "ML_Techniques": "EN-DE",
    "Category": "Program synthesis",
    "Sub_category": "Program repair",
    "Venue": "TSE",
    "Link": "https://ieeexplore.ieee.org/abstract/document/8827954",
    "bibtex": "ARTICLE{Chen2019_350,\n    author = \"{Chen}, Z. and {Kommrusch}, S. J. and {Tufano}, M. and {Pouchet}, L. and {Poshyvanyk}, D. and {Monperrus}, M.\",\n    journal = \"IEEE Transactions on Software Engineering\",\n    title = \"SEQUENCER: Sequence-to-Sequence Learning for End-to-End Program Repair\",\n    year = \"2019\",\n    volume = \"\",\n    number = \"\",\n    pages = \"1-1\",\n    doi = \"10.1109/TSE.2019.2940179\"\n}\n\n",
    "abstract": "This paper presents a novel end-to-end approach to program repair based on sequence-to-sequence learning. We devise, implement, and evaluate a system, called SequenceR, for fixing bugs based on sequence-to-sequence learning on source code. This approach uses the copy mechanism to overcome the unlimited vocabulary problem that occurs with big code. Our system is data-driven; we train it on 35,578 samples, carefully curated from commits to open-source repositories. We evaluate it on 4,711 independent real bug fixes, as well on the Defects4J benchmark used in program repair research. SequenceR is able to perfectly predict the fixed line for 950/4711 testing samples, and find correct patches for 14 bugs in Defects4J. It captures a wide range of repair operators without any domain-specific top-down design."
}, {
    "py/object": "data.DataClassPaper",
    "Title": "Should fixing these failures be delegated to automated program repair?",
    "year": 2015,
    "ML_Techniques": "RF",
    "Category": "Program synthesis",
    "Sub_category": "Program repair",
    "Venue": "ISSRE",
    "Link": "https://ieeexplore.ieee.org/abstract/document/7381836",
    "bibtex": "INPROCEEDINGS{Le2015_352,\n    author = \"{Le}, X. D. and {Le}, T. B. and {Lo}, D.\",\n    booktitle = \"2015 IEEE 26th International Symposium on Software Reliability Engineering (ISSRE)\",\n    title = \"Should fixing these failures be delegated to automated program repair?\",\n    year = \"2015\",\n    volume = \"\",\n    number = \"\",\n    pages = \"427-437\",\n    doi = \"10.1109/ISSRE.2015.7381836\"\n}\n\n",
    "abstract": "Program repair constitutes one of the major components of software maintenance that usually incurs a significant cost in software production. Automated program repair is supposed to help in reducing the software maintenance cost by automatically fixing software defects. Despite the recent advances in automated software repair, it is still very costly to wait for repair tools to produce valid repairs of defects. This paper addresses the following question: \"Will an automated program repair technique find a repair for a defect within a reasonable time?\". To answer this question, we build an oracle that can predict whether fixing a failure should be delegated to an automated repair technique. If the repair technique is predicted to take too long to produce a repair, the bug fixing process should rather be assigned to a developer or other appropriate techniques available. Our oracle is built for genetic-programming-based automated program repair approaches, which have recently received considerable attention due to their capability to automatically fix real-world bugs. These approaches search for a valid repair over a large number of variants that are syntactically mutated from the original program. At an early stage of running a repair tool, we extract a number of features that are potentially related to the effectiveness of the tool. Leveraging advances in machine learning, we process the values of these features to learn a discriminative model that is able to predict whether continuing a genetic programming search will lead to a repair within a desired time limit. We perform experiments to evaluate the ability of our approach to predict the effectiveness of GenProg, a well-known genetic-programming-based automated program repair approach, in fixing 105 real bugs. Our experiments show that our approach can identify effective cases from ineffective ones (i.e., bugs for which GenProg cannot produce correct fixes after a long period of time) with a precision, recall, F-measure, and AUC of 72%, 74%, 73%, and 76% respectively."
}, {
    "py/object": "data.DataClassPaper",
    "Title": "SLDeep: Statement-level software defect prediction using deep-learning model on static code features",
    "year": 2020,
    "ML_Techniques": "LSTM",
    "Category": "Program synthesis",
    "Sub_category": "Program repair",
    "Venue": "ESA",
    "Link": "https://www.sciencedirect.com/science/article/abs/pii/S0957417419308735",
    "bibtex": "INPROCEEDINGS{Le2015_352,\n    author = \"{Le}, X. D. and {Le}, T. B. and {Lo}, D.\",\n    booktitle = \"2015 IEEE 26th International Symposium on Software Reliability Engineering (ISSRE)\",\n    title = \"Should fixing these failures be delegated to automated program repair?\",\n    year = \"2015\",\n    volume = \"\",\n    number = \"\",\n    pages = \"427-437\",\n    doi = \"10.1109/ISSRE.2015.7381836\"\n}\n\n",
    "abstract": "Software defect prediction (SDP) seeks to estimate fault-prone areas of the code to focus testing activities on more suspicious portions. Consequently, high-quality software is released with less time and effort. The current SDP techniques however work at coarse-grained units, such as a module or a class, putting some burden on the developers to locate the fault. To address this issue, we propose a new technique called as Statement-Level software defect prediction using Deep-learning model (SLDeep). The significance of SLDeep for intelligent and expert systems is that it demonstrates a novel use of deep-learning models to the solution of a practical problem faced by software developers. To reify our proposal, we defined a suite of 32 statement-level metrics, such as the number of binary and unary operators used in a statement. Then, we applied as learning model, long short-term memory (LSTM). We conducted experiments using 119,989 C/C++ programs within Code4Bench. The programs comprise 2,356,458 lines of code of which 292,064 lines are faulty. The benchmark comprises a diverse set of programs and versions, written by thousands of developers. Therefore, it tends to give a model that can be used for cross-project SDP. In the experiments, our trained model could successfully classify the unseen data (that is, fault-proneness of new statements) with average performance measures 0.979, 0.570, and 0.702 in terms of recall, precision, and accuracy, respectively. These experimental results suggest that SLDeep is effective for statement-level SDP. The impact of this work is twofold. Working at statement-level further alleviates developer's burden in pinpointing the fault locations. Second, cross-project feature of SLDeep helps defect prediction research become more industrially-viable."
}, {
    "py/object": "data.DataClassPaper",
    "Title": "Structured Generative Models of Natural Source Code",
    "year": 2014,
    "ML_Techniques": "GD",
    "Category": "Program synthesis",
    "Sub_category": "",
    "Venue": "ICML",
    "Link": "https://arxiv.org/abs/1401.0514",
    "bibtex": "inproceedings{Maddison2014_355,\n    author = \"Maddison, Chris J. and Tarlow, Daniel\",\n    title = \"Structured Generative Models of Natural Source Code\",\n    year = \"2014\",\n    publisher = \"JMLR.org\",\n    abstract = \"We study the problem of building generative models of natural source code (NSC); that is, source code written by humans and meant to be understood by humans. Our primary contribution is to describe new generative models that are tailored to NSC. The models are based on probabilistic context free grammars (PCFGs) and neuro-probabilistic language models (Mnih \\&amp; Teh, 2012), which are extended to incorporate additional source code-specific structure. These models can be efficiently trained on a corpus of source code and outperform a variety of less structured baselines in terms of predictive log likelihoods on held-out data.\",\n    booktitle = \"Proceedings of the 31st International Conference on International Conference on Machine Learning - Volume 32\",\n    pages = \"II\u2013649\u2013II\u2013657\",\n    numpages = \"9\",\n    location = \"Beijing, China\",\n    series = \"ICML'14\"\n}\n\n",
    "abstract": "We study the problem of building generative models of natural source code (NSC); that is, source code written by humans and meant to be understood by humans. Our primary contribution is to describe new generative models that are tailored to NSC. The models are based on probabilistic context free grammars (PCFGs) and neuro-probabilistic language models (Mnih & Teh, 2012), which are extended to incorporate additional source code-specific structure. These models can be efficiently trained on a corpus of source code and outperform a variety of less structured baselines in terms of predictive log likelihoods on held-out data."
}, {
    "py/object": "data.DataClassPaper",
    "Title": "Syntax and Sensibility:Using language models to detect and correctsyntax errors",
    "year": 2018,
    "ML_Techniques": "LSTM",
    "Category": "Program synthesis",
    "Sub_category": "Program repair",
    "Venue": "SANER",
    "Link": "https://softwareprocess.es/pubs/santos2018SANER-syntax.pdf",
    "bibtex": "inproceedings{Maddison2014_355,\n    author = \"Maddison, Chris J. and Tarlow, Daniel\",\n    title = \"Structured Generative Models of Natural Source Code\",\n    year = \"2014\",\n    publisher = \"JMLR.org\",\n    abstract = \"We study the problem of building generative models of natural source code (NSC); that is, source code written by humans and meant to be understood by humans. Our primary contribution is to describe new generative models that are tailored to NSC. The models are based on probabilistic context free grammars (PCFGs) and neuro-probabilistic language models (Mnih \\&amp; Teh, 2012), which are extended to incorporate additional source code-specific structure. These models can be efficiently trained on a corpus of source code and outperform a variety of less structured baselines in terms of predictive log likelihoods on held-out data.\",\n    booktitle = \"Proceedings of the 31st International Conference on International Conference on Machine Learning - Volume 32\",\n    pages = \"II\u2013649\u2013II\u2013657\",\n    numpages = \"9\",\n    location = \"Beijing, China\",\n    series = \"ICML'14\"\n}\n\n",
    "abstract": "Syntax errors are made by novice and experienced programmers alike; however, novice programmers lack the years of experience that help them quickly resolve these frustrating errors. Standard LR parsers are of little help, typically resolving syntax errors and their precise location poorly. We propose a methodology that locates where syntax errors occur, and suggests possible changes to the token stream that can fix the error identified. This methodology finds syntax errors by using language models trained on correct source code to find tokens that seem out of place. Fixes are synthesized by consulting the language models to determine what tokens are more likely at the estimated error location. We compare n-gram and LSTM (long short-term memory) language models for this task, each trained on a large corpus of Java code collected from GitHub. Unlike prior work, our methodology does not rely that the problem source code comes from the same domain as the training data. We evaluated against a repository of real student mistakes. Our tools are able to find a syntactically-valid fix within its top-2 suggestions, often producing the exact fix that the student used to resolve the error. The results show that this tool and methodology can locate and suggest corrections for syntax errors. Our methodology is of practical use to all programmers, but will be especially useful to novices frustrated with incomprehensible syntax errors"
}, {
    "py/object": "data.DataClassPaper",
    "Title": "Synthesizing Benchmarks for Predictive Modeling",
    "year": 2017,
    "ML_Techniques": "LSTM",
    "Category": "Program synthesis",
    "Sub_category": "",
    "Venue": "CGO",
    "Link": "https://ieeexplore.ieee.org/document/7863731",
    "bibtex": "inproceedings{Maddison2014_355,\n    author = \"Maddison, Chris J. and Tarlow, Daniel\",\n    title = \"Structured Generative Models of Natural Source Code\",\n    year = \"2014\",\n    publisher = \"JMLR.org\",\n    abstract = \"We study the problem of building generative models of natural source code (NSC); that is, source code written by humans and meant to be understood by humans. Our primary contribution is to describe new generative models that are tailored to NSC. The models are based on probabilistic context free grammars (PCFGs) and neuro-probabilistic language models (Mnih \\&amp; Teh, 2012), which are extended to incorporate additional source code-specific structure. These models can be efficiently trained on a corpus of source code and outperform a variety of less structured baselines in terms of predictive log likelihoods on held-out data.\",\n    booktitle = \"Proceedings of the 31st International Conference on International Conference on Machine Learning - Volume 32\",\n    pages = \"II\u2013649\u2013II\u2013657\",\n    numpages = \"9\",\n    location = \"Beijing, China\",\n    series = \"ICML'14\"\n}\n\n",
    "abstract": "Predictive modeling using machine learning is an effective method for building compiler heuristics, but there is a shortage of benchmarks. Typical machine learning experiments outside of the compilation field train over thousands or millions of examples. In machine learning for compilers, however, there are typically only a few dozen common benchmarks available. This limits the quality of learned models, as they have very sparse training data for what are often high-dimensional feature spaces. What is needed is a way to generate an unbounded number of training programs that finely cover the feature space. At the same time the generated programs must be similar to the types of programs that human developers actually write, otherwise the learning will target the wrong parts of the feature space. We mine open source repositories for program fragments and apply deep learning techniques to automatically construct models for how humans write programs. We sample these models to generate an unbounded number of runnable training programs. The quality of the programs is such that even human developers struggle to distinguish our generated programs from hand-written code. We use our generator for OpenCL programs, CLgen, to automatically synthesize thousands of programs and show that learning over these improves the performance of a state of the art predictive model by 1.27x. In addition, the fine covering of the feature space automatically exposes weaknesses in the feature design which are invisible with the sparse training examples from existing benchmark suites. Correcting these weaknesses further increases performance by 4.30x."
}, {
    "py/object": "data.DataClassPaper",
    "Title": "Synthetic Datasets for Neural Program Synthesis",
    "year": 2019,
    "ML_Techniques": "",
    "Category": "Program synthesis",
    "Sub_category": "",
    "Venue": "LR",
    "Link": "https://openreview.net/forum?id=ryeOSnAqYm",
    "bibtex": "inproceedings{Shin2019_362,\n    author = \"Shin, Richard and Kant, Neel and Gupta, Kavi and Bender, Chris and Trabucco, Brandon and Singh, Rishabh and Song, Dawn\",\n    title = \"Synthetic Datasets for Neural Program Synthesis\",\n    booktitle = \"International Conference on Learning Representations\",\n    year = \"2019\",\n    url = \"https://openreview.net/forum?id=ryeOSnAqYm\"\n}\n\n",
    "abstract": "The goal of program synthesis is to automatically generate programs in a particular language from corresponding specifications, e.g. input-output behavior. Many current approaches achieve impressive results after training on randomly generated I/O examples in limited domain-specific languages (DSLs), as with string transformations in RobustFill. However, we empirically discover that applying test input generation techniques for languages with control flow and rich input space causes deep networks to generalize poorly to certain data distributions; to correct this, we propose a new methodology for controlling and evaluating the bias of synthetic data distributions over both programs and specifications. We demonstrate, using the Karel DSL and a small Calculator DSL, that training deep networks on these distributions leads to improved cross-distribution generalization performance."
}, {
    "py/object": "data.DataClassPaper",
    "Title": "Towards Synthesizing Complex Programs from Input-Output Example",
    "year": 2017,
    "ML_Techniques": "LSTM",
    "Category": "Program synthesis",
    "Sub_category": "",
    "Venue": "ICLR",
    "Link": "https://arxiv.org/abs/1706.01284v3",
    "bibtex": "misc{Chen2018_365,\n    author = \"Chen, Xinyun and Liu, Chang and Song, Dawn\",\n    title = \"Towards Synthesizing Complex Programs from Input-Output Examples\",\n    year = \"2018\",\n    eprint = \"1706.01284\",\n    archivePrefix = \"arXiv\",\n    primaryClass = \"cs.LG\"\n}\n\n",
    "abstract": "In recent years, deep learning techniques have been developed to improve the performance of program synthesis from input-output examples. Albeit its significant progress, the programs that can be synthesized by state-of-the-art approaches are still simple in terms of their complexity. In this work, we move a significant step forward along this direction by proposing a new class of challenging tasks in the domain of program synthesis from input-output examples: learning a context-free parser from pairs of input programs and their parse trees. We show that this class of tasks are much more challenging than previously studied tasks, and the test accuracy of existing approaches is almost 0%.\nWe tackle the challenges by developing three novel techniques inspired by three novel observations, which reveal the key ingredients of using deep learning to synthesize a complex program. First, the use of a non-differentiable machine is the key to effectively restrict the search space. Thus our proposed approach learns a neural program operating a domain-specific non-differentiable machine. Second, recursion is the key to achieve generalizability. Thus, we bake-in the notion of recursion in the design of our non-differentiable machine. Third, reinforcement learning is the key to learn how to operate the non-differentiable machine, but it is also hard to train the model effectively with existing reinforcement learning algorithms from a cold boot. We develop a novel two-phase reinforcement learning-based search algorithm to overcome this issue. In our evaluation, we show that using our novel approach, neural parsing programs can be learned to achieve 100% test accuracy on test inputs that are 500x longer than the training samples."
}, {
    "py/object": "data.DataClassPaper",
    "Title": "Type error feedback via analytic program repair",
    "year": 2020,
    "ML_Techniques": "DNN, MLP",
    "Category": "Program synthesis",
    "Sub_category": "Program repair",
    "Venue": "PLDI",
    "Link": "https://dl.acm.org/doi/abs/10.1145/3385412.3386005",
    "bibtex": "misc{Chen2018_365,\n    author = \"Chen, Xinyun and Liu, Chang and Song, Dawn\",\n    title = \"Towards Synthesizing Complex Programs from Input-Output Examples\",\n    year = \"2018\",\n    eprint = \"1706.01284\",\n    archivePrefix = \"arXiv\",\n    primaryClass = \"cs.LG\"\n}\n\n",
    "abstract": "We introduce Analytic Program Repair, a data-driven strategy for providing feedback for type-errors via repairs for the erroneous program. Our strategy is based on insight that similar errors have similar repairs. Thus, we show how to use a training dataset of pairs of ill-typed programs and their fixed versions to: (1) learn a collection of candidate repair templates by abstracting and partitioning the edits made in the training set into a representative set of templates; (2) predict the appropriate template from a given error, by training multi-class classifiers on the repair templates used in the training set; (3) synthesize a concrete repair from the template by enumerating and ranking correct (e.g. well-typed) terms matching the predicted template. We have implemented our approach in Rite: a type error reporting tool for OCaml programs. We present an evaluation of the accuracy and efficiency of Rite on a corpus of 4,500 ill-typed Ocaml programs drawn from two instances of an introductory programming course, and a user-study of the quality of the generated error messages that shows the locations and final repair quality to be better than the state-of-the-art tool in a statistically-significant manner."
}, {
    "py/object": "data.DataClassPaper",
    "Title": "An Application of Latent Dirichlet Allocation to Analyzing Software Evolution",
    "year": 2008,
    "ML_Techniques": "unsupervised statistical topic models",
    "Category": "Program comprehension",
    "Sub_category": "Entity identification/recommendation",
    "Venue": "ICMLA",
    "Link": "https://ieeexplore.ieee.org/document/4725072",
    "bibtex": "INPROCEEDINGS{Linstead2008_371,\n    author = \"{Linstead}, E. and {Lopes}, C. and {Baldi}, P.\",\n    booktitle = \"2008 Seventh International Conference on Machine Learning and Applications\",\n    title = \"An Application of Latent Dirichlet Allocation to Analyzing Software Evolution\",\n    year = \"2008\",\n    volume = \"\",\n    number = \"\",\n    pages = \"813-818\",\n    doi = \"10.1109/ICMLA.2008.47\"\n}\n\n",
    "abstract": "We develop and apply unsupervised statistical topic models, in particular latent Dirichlet allocation, to identify functional components of source code and study their evolution over multiple project versions. We present results for two large, open source Java projects, Eclipse and Argo UML, which are well-known and well-studied within the software mining community. Our results demonstrate the effectiveness of probabilistic topic models in automatically summarizing the temporal dynamics of software concerns, with direct application to project management and program understanding. In addition to detecting the emergence of topics on the release timeline which represent integration points for key source code functionality, our techniques can also be used to pinpoint refactoring events in the underlying software design, as well as to identify general programming concepts whose prevalence is dependent only of the size of the code base to be analyzed. Complete results are available from our supplementary materials website at http://sourcerer.ics.uci.edu/icmla2008/software_evolution.html."
}, {
    "py/object": "data.DataClassPaper",
    "Title": "Automatic classification of software artifacts in open-source applications",
    "year": 2018,
    "ML_Techniques": "",
    "Category": "Program comprehension",
    "Sub_category": "Program classification",
    "Venue": "MSR",
    "Link": "https://dl.acm.org/doi/10.1145/3196398.3196446",
    "bibtex": "INPROCEEDINGS{Linstead2008_371,\n    author = \"{Linstead}, E. and {Lopes}, C. and {Baldi}, P.\",\n    booktitle = \"2008 Seventh International Conference on Machine Learning and Applications\",\n    title = \"An Application of Latent Dirichlet Allocation to Analyzing Software Evolution\",\n    year = \"2008\",\n    volume = \"\",\n    number = \"\",\n    pages = \"813-818\",\n    doi = \"10.1109/ICMLA.2008.47\"\n}\n\n",
    "abstract": "With the increasing popularity of open-source software development, there is a tremendous growth of software artifacts that provide insight into how people build software. Researchers are always looking for large-scale and representative software artifacts to produce systematic and unbiased validation of novel and existing techniques. For example, in the domain of software requirements traceability, researchers often use software applications with multiple types of artifacts, such as requirements, system elements, verifications, or tasks to develop and evaluate their traceability analysis techniques. However, the manual identification of rich software artifacts is very labor-intensive. In this work, we first conduct a large-scale study to identify which types of software artifacts are produced by a wide variety of open-source projects at different levels of granularity. Then we propose an automated approach based on Machine Learning techniques to identify various types of software artifacts. Through a set of experiments, we report and compare the performance of these algorithms when applied to software artifacts."
}, {
    "py/object": "data.DataClassPaper",
    "Title": "Change Prediction through Coding Rules Violations",
    "year": 2017,
    "ML_Techniques": "DT, RF, NB",
    "Category": "Program comprehension",
    "Sub_category": "Change analysis",
    "Venue": "EASE",
    "Link": "https://dl.acm.org/doi/10.1145/3084226.3084282",
    "bibtex": "inproceedings{Tollin2017_374,\n    author = \"Tollin, Irene and Fontana, Francesca Arcelli and Zanoni, Marco and Roveda, Riccardo\",\n    title = \"Change Prediction through Coding Rules Violations\",\n    year = \"2017\",\n    isbn = \"9781450348041\",\n    publisher = \"Association for Computing Machinery\",\n    address = \"New York, NY, USA\",\n    url = \"https://doi.org/10.1145/3084226.3084282\",\n    doi = \"10.1145/3084226.3084282\",\n    abstract = \"Static source code analysis is an increasingly important activity to manage software project quality, and is often found as a part of the development process. A widely adopted way of checking code quality is through the detection of violations to specific sets of rules addressing good programming practices. SonarQube is a platform able to detect these violations, called Issues. In this paper we described an empirical study performend on two industrial projects, where we used Issues extracted on different versions of the projects to predict changes in code through a set of machine learning models. We achieved good detection performances, especially when predicting changes in the next version. This result paves the way for future investigations of the interest in an industrial setting towards the prioritization of Issues management according to their impact on change-proneness.\",\n    booktitle = \"Proceedings of the 21st International Conference on Evaluation and Assessment in Software Engineering\",\n    pages = \"61\u201364\",\n    numpages = \"4\",\n    keywords = \"change prediction, machine learning, issues, software quality\",\n    location = \"Karlskrona, Sweden\",\n    series = \"EASE'17\"\n}\n\n",
    "abstract": "Static source code analysis is an increasingly important activity to manage software project quality, and is often found as a part of the development process. A widely adopted way of checking code quality is through the detection of violations to specific sets of rules addressing good programming practices. SonarQube is a platform able to detect these violations, called Issues. In this paper we described an empirical study performend on two industrial projects, where we used Issues extracted on different versions of the projects to predict changes in code through a set of machine learning models. We achieved good detection performances, especially when predicting changes in the next version. This result paves the way for future investigations of the interest in an industrial setting towards the prioritization of Issues management according to their impact on change-proneness."
}, {
    "py/object": "data.DataClassPaper",
    "Title": "Classifying Software Changes: Clean or Buggy?",
    "year": 2008,
    "ML_Techniques": "SVM",
    "Category": "Testing",
    "Sub_category": "",
    "Venue": "TSE",
    "Link": "https://ieeexplore.ieee.org/document/4408585",
    "bibtex": "ARTICLE{Kim2008_375,\n    author = \"{Kim}, S. and {Whitehead,}, E. J. and {Zhang}, Y.\",\n    journal = \"IEEE Transactions on Software Engineering\",\n    title = \"Classifying Software Changes: Clean or Buggy?\",\n    year = \"2008\",\n    volume = \"34\",\n    number = \"2\",\n    pages = \"181-196\",\n    doi = \"10.1109/TSE.2007.70773\"\n}\n\n",
    "abstract": "This paper introduces a new technique for predicting latent software bugs, called change classification. Change classification uses a machine learning classifier to determine whether a new software change is more similar to prior buggy changes or clean changes. In this manner, change classification predicts the existence of bugs in software changes. The classifier is trained using features (in the machine learning sense) extracted from the revision history of a software project stored in its software configuration management repository. The trained classifier can classify changes as buggy or clean, with a 78 percent accuracy and a 60 percent buggy change recall on average. Change classification has several desirable qualities: 1) The prediction granularity is small (a change to a single file), 2) predictions do not require semantic information about the source code, 3) the technique works for a broad array of project types and programming languages, and 4) predictions can be made immediately upon the completion of a change. Contributions of this paper include a description of the change classification approach, techniques for extracting features from the source code and change histories, a characterization of the performance of change classification across 12 open source projects, and an evaluation of the predictive power of different groups of features."
}, {
    "py/object": "data.DataClassPaper",
    "Title": "Code Authorship Attribution: Methods and Challenges",
    "year": 2019,
    "ML_Techniques": "",
    "Category": "Program comprehension",
    "Sub_category": "Entity identification/recommendation",
    "Venue": "CSUR",
    "Link": "https://dl.acm.org/doi/10.1145/3292577",
    "bibtex": "article{Kalgutkar2019_376,\n    author = \"Kalgutkar, Vaibhavi and Kaur, Ratinder and Gonzalez, Hugo and Stakhanova, Natalia and Matyukhina, Alina\",\n    title = \"Code Authorship Attribution: Methods and Challenges\",\n    year = \"2019\",\n    issue_date = \"February 2019\",\n    publisher = \"Association for Computing Machinery\",\n    address = \"New York, NY, USA\",\n    volume = \"52\",\n    number = \"1\",\n    issn = \"0360-0300\",\n    url = \"https://doi.org/10.1145/3292577\",\n    doi = \"10.1145/3292577\",\n    abstract = \"Code authorship attribution is the process of identifying the author of a given code. With increasing numbers of malware and advanced mutation techniques, the authors of malware are creating a large number of malware variants. To better deal with this problem, methods for examining the authorship of malicious code are necessary. Code authorship attribution techniques can thus be utilized to identify and categorize the authors of malware. This information can help predict the types of tools and techniques that the author of a specific malware uses, as well as the manner in which the malware spreads and evolves. In this article, we present the first comprehensive review of research on code authorship attribution. The article summarizes various methods of authorship attribution and highlights challenges in the field.\",\n    journal = \"ACM Comput. Surv.\",\n    month = \"February\",\n    articleno = \"3\",\n    numpages = \"36\",\n    keywords = \"Authorship analysis, programming style, malware attribution, software forensics\"\n}\n\n",
    "abstract": "Code authorship attribution is the process of identifying the author of a given code. With increasing numbers of malware and advanced mutation techniques, the authors of malware are creating a large number of malware variants. To better deal with this problem, methods for examining the authorship of malicious code are necessary. Code authorship attribution techniques can thus be utilized to identify and categorize the authors of malware. This information can help predict the types of tools and techniques that the author of a specific malware uses, as well as the manner in which the malware spreads and evolves. In this article, we present the first comprehensive review of research on code authorship attribution. The article summarizes various methods of authorship attribution and highlights challenges in the field."
}, {
    "py/object": "data.DataClassPaper",
    "Title": "CommtPst: Deep learning source code for commenting positions prediction",
    "year": 2020,
    "ML_Techniques": "",
    "Category": "Program comprehension",
    "Sub_category": "Entity identification/recommendation",
    "Venue": "JSS",
    "Link": "https://www.sciencedirect.com/science/article/abs/pii/S0164121220301758",
    "bibtex": "article{Huang2020_377,\n    author = \"Huang, Yuan and Hu, Xinyu and Jia, Nan and Chen, Xiangping and Zheng, Zibin and Luo, Xiapu\",\n    title = \"CommtPst: Deep learning source code for commenting positions prediction\",\n    journal = \"Journal of Systems and Software\",\n    volume = \"170\",\n    pages = \"110754\",\n    year = \"2020\",\n    issn = \"0164-1212\",\n    doi = \"https://doi.org/10.1016/j.jss.2020.110754\",\n    url = \"http://www.sciencedirect.com/science/article/pii/S0164121220301758\",\n    keywords = \"Comment position, LSTM, Code syntax, Code semantics, Comment generation\",\n    abstract = \"Existing techniques for automatic code commenting assume that the code snippet to be commented has been identified, thus requiring users to provide the code snippet in advance. A smarter commenting approach is desired to first self-determine where to comment in a given source code and then generate comments for the code snippets that need comments. To achieve the first step of this goal, we propose a novel method, CommtPst, to automatically find the appropriate commenting positions in the source code. Since commenting is closely related to the code syntax and semantics, we adopt neural language model (word embeddings) to capture the code semantic information, and analyze the abstract syntax trees to capture code syntactic information. Then, we employ LSTM (long short term memory) to model the long-term logical dependency of code statements over the fused semantic and syntactic information and learn the commenting patterns on the code sequence. We evaluated CommtPst using large data sets from dozens of open-source software systems in GitHub. The experimental results show that the precision, recall and F-Measure values achieved by CommtPst are 0.792, 0.602 and 0.684, respectively, which outperforms the traditional machine learning method with 11.4\\% improvement on F-measure.\"\n}\n\n",
    "abstract": "Existing techniques for automatic code commenting assume that the code snippet to be commented has been identified, thus requiring users to provide the code snippet in advance. A smarter commenting approach is desired to first self-determine where to comment in a given source code and then generate comments for the code snippets that need comments. To achieve the first step of this goal, we propose a novel method, CommtPst, to automatically find the appropriate commenting positions in the source code. Since commenting is closely related to the code syntax and semantics, we adopt neural language model (word embeddings) to capture the code semantic information, and analyze the abstract syntax trees to capture code syntactic information. Then, we employ LSTM (long short term memory) to model the long-term logical dependency of code statements over the fused semantic and syntactic information and learn the commenting patterns on the code sequence. We evaluated CommtPst using large data sets from dozens of open-source software systems in GitHub. The experimental results show that the precision, recall and F-Measure values achieved by CommtPst are 0.792, 0.602 and 0.684, respectively, which outperforms the traditional machine learning method with 11.4% improvement on F-measure."
}, {
    "py/object": "data.DataClassPaper",
    "Title": "Deep Learning Type Inference",
    "year": 2018,
    "ML_Techniques": "Bi-RNN",
    "Category": "Program comprehension",
    "Sub_category": "Entity identification/recommendation",
    "Venue": "FSE",
    "Link": "http://vhellendoorn.github.io/PDF/fse2018-j2t.pdf",
    "bibtex": "inproceedings{Hellendoorn2018_378,\n    author = \"Hellendoorn, Vincent J. and Bird, Christian and Barr, Earl T. and Allamanis, Miltiadis\",\n    title = \"Deep Learning Type Inference\",\n    year = \"2018\",\n    isbn = \"9781450355735\",\n    publisher = \"Association for Computing Machinery\",\n    address = \"New York, NY, USA\",\n    url = \"https://doi.org/10.1145/3236024.3236051\",\n    doi = \"10.1145/3236024.3236051\",\n    pages = \"152\u2013162\",\n    numpages = \"11\",\n    keywords = \"Deep Learning, Naturalness, Type Inference\",\n    location = \"Lake Buena Vista, FL, USA\",\n    series = \"ESEC/FSE 2018\"\n}\n\n",
    "abstract": "Dynamically typed languages such as JavaScript and Python are increasingly popular, yet static typing has not been totally eclipsed: Python now supports type annotations and languages like TypeScript offer a middle-ground for JavaScript: a strict superset of JavaScript, to which it transpiles, coupled with a type system that permits partially typed programs. However, static typing has a cost: adding annotations, reading the added syntax, and wrestling with the type system to fix type errors. Type inference can ease the transition to more statically typed code and unlock the benefits of richer compile-time information, but is limited in languages like JavaScript as it cannot soundly handle duck-typing or runtime evaluation via eval. We propose DeepTyper, a deep learning model that understands which types naturally occur in certain contexts and relations and can provide type suggestions, which can often be verified by the type checker, even if it could not infer the type initially. DeepTyper, leverages an automatically aligned corpus of tokens and types to accurately predict thousands of variable and function type annotations. Furthermore, we demonstrate that context is key in accurately assigning these types and introduce a technique to reduce overfitting on local cues while highlighting the need for further improvements. Finally, we show that our model can interact with a compiler to provide more than 4,000 additional type annotations with over 95% precision that could not be inferred without the aid of DeepTyper."
}, {
    "py/object": "data.DataClassPaper",
    "Title": "Detecting Design Patterns in Object-Oriented Program Source Code by Using Metrics and Machine Learning",
    "year": 2014,
    "ML_Techniques": "DNN",
    "Category": "Program comprehension",
    "Sub_category": "Entity identification/recommendation",
    "Venue": "JSEA",
    "Link": "https://www.scirp.org/html/2-9301797_51394.htm",
    "bibtex": "article{Uchiyama2014_379,\n    author = \"Uchiyama, S. and Kubo, A. and Washizaki, H. and Fukazawa, Y.\",\n    title = \"Detecting Design Patterns in Object-Oriented Program Source Code by Using Metrics and Machine Learning\",\n    journal = \"Journal of Software Engineering and Applications\",\n    year = \"2014\",\n    volume = \"07\",\n    pages = \"983-998\"\n}\n\n",
    "abstract": "Detecting well-known design patterns in object-oriented program source code can help maintainers understand the design of a program. Through the detection, the understandability, maintainability, and reusability of object-oriented programs can be improved. There are automated detection techniques; however, many existing techniques are based on static analysis and use strict conditions composed on class structure data. Hence, it is difficult for them to detect and distinguish design patterns in which the class structures are similar. Moreover, it is difficult for them to deal with diversity in design pattern applications. To solve these problems in existing techniques, we propose a design pattern detection technique using source code metrics and machine learning. Our technique judges candidates for the roles that compose design patterns by using machine learning and measurements of several metrics, and it detects design patterns by analyzing the relations between candidates. It suppresses false negatives and distinguishes patterns in which the class structures are similar. As a result of experimental evaluations with a set of programs, we confirmed that our technique is more accurate than two conventional techniques."
}, {
    "py/object": "data.DataClassPaper",
    "Title": "Embedding Java Classes with code2vec: Improvements from Variable Obfuscation",
    "year": 2020,
    "ML_Techniques": "Code2Vec",
    "Category": "Program comprehension",
    "Sub_category": "",
    "Venue": "MSR",
    "Link": "https://dl.acm.org/doi/10.1145/3379597.3387445",
    "bibtex": "article{Uchiyama2014_379,\n    author = \"Uchiyama, S. and Kubo, A. and Washizaki, H. and Fukazawa, Y.\",\n    title = \"Detecting Design Patterns in Object-Oriented Program Source Code by Using Metrics and Machine Learning\",\n    journal = \"Journal of Software Engineering and Applications\",\n    year = \"2014\",\n    volume = \"07\",\n    pages = \"983-998\"\n}\n\n",
    "abstract": "Automatic source code analysis in key areas of software engineering, such as code security, can benefit from Machine Learning (ML). However, many standard ML approaches require a numeric representation of data and cannot be applied directly to source code. Thus, to enable ML, we need to embed source code into numeric feature vectors while maintaining the semantics of the code as much as possible. code2vec is a recently released embedding approach that uses the proxy task of method name prediction to map Java methods to feature vectors. However, experimentation with code2vec shows that it learns to rely on variable names for prediction, causing it to be easily fooled by typos or adversarial attacks. Moreover, it is only able to embed individual Java methods and cannot embed an entire collection of methods such as those present in a typical Java class, making it difficult to perform predictions at the class level (e.g., for the identification of malicious Java classes). Both shortcomings are addressed in the research presented in this paper. We investigate the effect of obfuscating variable names during the training of a code2vec model to force it to rely on the structure of the code rather than specific names and consider a simple approach to creating class-level embeddings by aggregating sets of method embeddings. Our results, obtained on a challenging new collection of source-code classification problems, indicate that obfuscating variable names produces an embedding model that is both impervious to variable naming and more accurately reflects code semantics. The datasets, models, and code are shared for further ML research on source code."
}, {
    "py/object": "data.DataClassPaper",
    "Title": "Identifying Auto-Generated Code by Using Machine Learning Techniques",
    "year": 2016,
    "ML_Techniques": "DT, RF, NB, SVM",
    "Category": "Program comprehension",
    "Sub_category": "Program classification",
    "Venue": "IWESEP",
    "Link": "https://ieeexplore.ieee.org/document/7464547",
    "bibtex": "INPROCEEDINGS{Shimonaka2016_381,\n    author = \"{Shimonaka}, K. and {Sumi}, S. and {Higo}, Y. and {Kusumoto}, S.\",\n    booktitle = \"2016 7th International Workshop on Empirical Software Engineering in Practice (IWESEP)\",\n    title = \"Identifying Auto-Generated Code by Using Machine Learning Techniques\",\n    year = \"2016\",\n    volume = \"\",\n    number = \"\",\n    pages = \"18-23\",\n    doi = \"10.1109/IWESEP.2016.18\"\n}\n\n",
    "abstract": "Recently, many researchers have conducted mining source code repositories to retrieve useful information about software development. Source code repositories often include auto-generated code, and auto-generated code is usually removed in a preprocessing phase because the presence of auto-generated code is harmful to source code analysis. A usual way to remove auto-generated code is searching particular comments which exist among auto-generated code. However, we cannot identify auto-generated code automatically with such a way if comments have disappeared. In addition, it takes too much time to identify auto-generated code manually. Therefore, we propose a technique to identify auto-generated code automatically by using machine learning techniques. In our proposed technique, we can identify whether source code is auto-generated code or not by utilizing syntactic information of source code. In order to evaluate the proposed technique, we conducted experiments on source code generated by four kinds of code generators. As a result, we confirmed that the proposed technique was able to identify auto-generated code with high accuracy."
}, {
    "py/object": "data.DataClassPaper",
    "Title": "Identifying Supplementary Bug-fix Commits",
    "year": 2018,
    "ML_Techniques": "SVM",
    "Category": "Program comprehension",
    "Sub_category": "Program classification",
    "Venue": "COMPSAC",
    "Link": "https://ieeexplore.ieee.org/document/8377655",
    "bibtex": "INPROCEEDINGS{Ji2018_382,\n    author = \"{Ji}, T. and {Pan}, J. and {Chen}, L. and {Mao}, X.\",\n    booktitle = \"2018 IEEE 42nd Annual Computer Software and Applications Conference (COMPSAC)\",\n    title = \"Identifying Supplementary Bug-fix Commits\",\n    year = \"2018\",\n    volume = \"01\",\n    number = \"\",\n    pages = \"184-193\",\n    doi = \"10.1109/COMPSAC.2018.00031\"\n}\n\n",
    "abstract": "Real-world bugs and the bug-fix activities are essential in many fields such as bug prediction and automatic program repair. Identifying bug-fix commits from version histories has received much recent attention. Linking commits to bug reports and analyzing the commits individually are common practice. However, considering the one-to-many relationship between the bug report and the bug-fix commits, analyzing commits individually will miss the relevance between commits, since several commits might fix the same bug together. In addition, some supplementary bug-fix commits which supplement or correct the identified bug-fix commit may be neglected. For empirical studies on bug-fix commits, it is important to study all the relevant commits as a whole, otherwise we will fail to understand the complete real bug-fix activities. In this paper, we investigate the relevance between bug-fix commits that are linked to the same bug-fix pull request, and utilize machine learning techniques to determine supplementary bug-fix commits for an identified bug-fix commit. Experimental results show that there indeed exist supplementary bug-fix commits (i.e., 19.8% on average) that are neglected when analyzing commits individually. The performance of our tool SupBCFinder is much better than that of using a sliding window of one hour and that of analyzing the local change. Moreover, inspired by our learning-based approach and extracted features, we propose one effective heuristic as an alternative for the cases when there are not enough pull requests for training."
}, {
    "py/object": "data.DataClassPaper",
    "Title": "Large-Scale and Language-Oblivious Code Authorship Identification",
    "year": 2017,
    "ML_Techniques": "RNN",
    "Category": "Program comprehension",
    "Sub_category": "Entity identification/recommendation",
    "Venue": "CCS",
    "Link": "https://dl.acm.org/doi/10.1145/3243734.3243738",
    "bibtex": "inproceedings{Abuhamad2018_383,\n    author = \"Abuhamad, Mohammed and AbuHmed, Tamer and Mohaisen, Aziz and Nyang, DaeHun\",\n    title = \"Large-Scale and Language-Oblivious Code Authorship Identification\",\n    year = \"2018\",\n    isbn = \"9781450356930\",\n    publisher = \"Association for Computing Machinery\",\n    address = \"New York, NY, USA\",\n    url = \"https://doi.org/10.1145/3243734.3243738\",\n    doi = \"10.1145/3243734.3243738\",\n    abstract = \"Efficient extraction of code authorship attributes is key for successful identification. However, the extraction of such attributes is very challenging, due to various programming language specifics, the limited number of available code samples per author, and the average code lines per file, among others. To this end, this work proposes a Deep Learning-based Code Authorship Identification System (DL-CAIS) for code authorship attribution that facilitates large-scale, language-oblivious, and obfuscation-resilient code authorship identification. The deep learning architecture adopted in this work includes TF-IDF-based deep representation using multiple Recurrent Neural Network (RNN) layers and fully-connected layers dedicated to authorship attribution learning. The deep representation then feeds into a random forest classifier for scalability to de-anonymize the author. Comprehensive experiments are conducted to evaluate DL-CAIS over the entire Google Code Jam (GCJ) dataset across all years (from 2008 to 2016) and over real-world code samples from 1987 public repositories on GitHub. The results of our work show the high accuracy despite requiring a smaller number of files per author. Namely, we achieve an accuracy of 96\\% when experimenting with 1,600 authors for GCJ, and 94.38\\% for the real-world dataset for 745 C programmers. Our system also allows us to identify 8,903 authors, the largest-scale dataset used by far, with an accuracy of 92.3\\%. Moreover, our technique is resilient to language-specifics, and thus it can identify authors of four programming languages (e.g. C, C++, Java, and Python), and authors writing in mixed languages (e.g. Java/C++, Python/C++). Finally, our system is resistant to sophisticated obfuscation (e.g. using C Tigress) with an accuracy of 93.42\\% for a set of 120 authors.\",\n    booktitle = \"Proceedings of the 2018 ACM SIGSAC Conference on Computer and Communications Security\",\n    pages = \"101\u2013114\",\n    numpages = \"14\",\n    keywords = \"deep learning identification, software forensics, program features, code authorship identification\",\n    location = \"Toronto, Canada\",\n    series = \"CCS '18\"\n}\n\n",
    "abstract": "Efficient extraction of code authorship attributes is key for successful identification. However, the extraction of such attributes is very challenging, due to various programming language specifics, the limited number of available code samples per author, and the average code lines per file, among others. To this end, this work proposes a Deep Learning-based Code Authorship Identification System (DL-CAIS) for code authorship attribution that facilitates large-scale, language-oblivious, and obfuscation-resilient code authorship identification. The deep learning architecture adopted in this work includes TF-IDF-based deep representation using multiple Recurrent Neural Network (RNN) layers and fully-connected layers dedicated to authorship attribution learning. The deep representation then feeds into a random forest classifier for scalability to de-anonymize the author. Comprehensive experiments are conducted to evaluate DL-CAIS over the entire Google Code Jam (GCJ) dataset across all years (from 2008 to 2016) and over real-world code samples from 1987 public repositories on GitHub. The results of our work show the high accuracy despite requiring a smaller number of files per author. Namely, we achieve an accuracy of 96% when experimenting with 1,600 authors for GCJ, and 94.38% for the real-world dataset for 745 C programmers. Our system also allows us to identify 8,903 authors, the largest-scale dataset used by far, with an accuracy of 92.3%. Moreover, our technique is resilient to language-specifics, and thus it can identify authors of four programming languages (e.g. C, C++, Java, and Python), and authors writing in mixed languages (e.g. Java/C++, Python/C++). Finally, our system is resistant to sophisticated obfuscation (e.g. using C Tigress) with an accuracy of 93.42% for a set of 120 authors."
}, {
    "py/object": "data.DataClassPaper",
    "Title": "Machine learning based recommendation of method names: how far are we",
    "year": 2019,
    "ML_Techniques": "",
    "Category": "Program comprehension",
    "Sub_category": "Entity identification/recommendation",
    "Venue": "ASE",
    "Link": "https://dl.acm.org/doi/10.1109/ASE.2019.00062",
    "bibtex": "inproceedings{Abuhamad2018_383,\n    author = \"Abuhamad, Mohammed and AbuHmed, Tamer and Mohaisen, Aziz and Nyang, DaeHun\",\n    title = \"Large-Scale and Language-Oblivious Code Authorship Identification\",\n    year = \"2018\",\n    isbn = \"9781450356930\",\n    publisher = \"Association for Computing Machinery\",\n    address = \"New York, NY, USA\",\n    url = \"https://doi.org/10.1145/3243734.3243738\",\n    doi = \"10.1145/3243734.3243738\",\n    abstract = \"Efficient extraction of code authorship attributes is key for successful identification. However, the extraction of such attributes is very challenging, due to various programming language specifics, the limited number of available code samples per author, and the average code lines per file, among others. To this end, this work proposes a Deep Learning-based Code Authorship Identification System (DL-CAIS) for code authorship attribution that facilitates large-scale, language-oblivious, and obfuscation-resilient code authorship identification. The deep learning architecture adopted in this work includes TF-IDF-based deep representation using multiple Recurrent Neural Network (RNN) layers and fully-connected layers dedicated to authorship attribution learning. The deep representation then feeds into a random forest classifier for scalability to de-anonymize the author. Comprehensive experiments are conducted to evaluate DL-CAIS over the entire Google Code Jam (GCJ) dataset across all years (from 2008 to 2016) and over real-world code samples from 1987 public repositories on GitHub. The results of our work show the high accuracy despite requiring a smaller number of files per author. Namely, we achieve an accuracy of 96\\% when experimenting with 1,600 authors for GCJ, and 94.38\\% for the real-world dataset for 745 C programmers. Our system also allows us to identify 8,903 authors, the largest-scale dataset used by far, with an accuracy of 92.3\\%. Moreover, our technique is resilient to language-specifics, and thus it can identify authors of four programming languages (e.g. C, C++, Java, and Python), and authors writing in mixed languages (e.g. Java/C++, Python/C++). Finally, our system is resistant to sophisticated obfuscation (e.g. using C Tigress) with an accuracy of 93.42\\% for a set of 120 authors.\",\n    booktitle = \"Proceedings of the 2018 ACM SIGSAC Conference on Computer and Communications Security\",\n    pages = \"101\u2013114\",\n    numpages = \"14\",\n    keywords = \"deep learning identification, software forensics, program features, code authorship identification\",\n    location = \"Toronto, Canada\",\n    series = \"CCS '18\"\n}\n\n",
    "abstract": "High quality method names are critical for the readability and maintainability of programs. However, constructing concise and consistent method names is often challenging, especially for inexperienced developers. To this end, advanced machine learning techniques have been recently leveraged to recommend method names automatically for given method bodies/implementation. Recent large-scale evaluations also suggest that such approaches are accurate. However, little is known about where and why such approaches work or don't work. To figure out the state of the art as well as the rationale for the success/failure, in this paper we conduct an empirical study on the state-of-the-art approach code2vec. We assess code2vec on a new dataset with more realistic settings. Our evaluation results suggest that although switching to new dataset does not significantly influence the performance, more realistic settings do significantly reduce the performance of code2vec. Further analysis on the successfully recommended method names also reveals the following findings: 1) around half (48.3%) of the accepted recommendations are made on getter/setter methods; 2) a large portion (19.2%) of the successfully recommended method names could be copied from the given bodies. To further validate its usefulness, we ask developers to manually score the difficulty in naming methods they developed. Code2vec is then applied to such manually scored methods to evaluate how often it works in need. Our evaluation results suggest that code2vec rarely works when it is really needed. Finally, to intuitively reveal the state of the art and to investigate the possibility of designing simple and straightforward alternative approaches, we propose a heuristics based approach to recommending method names. Evaluation results on large-scale dataset suggest that this simple heuristics-based approach significantly outperforms the state-of-the-art machine learning based approach, improving precision and recall by 65.25% and 22.45%, respectively. The comparison suggests that machine learning based recommendation of method names may still have a long way to go."
}, {
    "py/object": "data.DataClassPaper",
    "Title": "Metadata recovery from obfuscated programs using machine learning",
    "year": 2016,
    "ML_Techniques": "",
    "Category": "Program comprehension",
    "Sub_category": "Entity identification/recommendation",
    "Venue": "SSPREW",
    "Link": "https://dl.acm.org/doi/10.1145/3015135.3015136",
    "bibtex": "inproceedings{Abuhamad2018_383,\n    author = \"Abuhamad, Mohammed and AbuHmed, Tamer and Mohaisen, Aziz and Nyang, DaeHun\",\n    title = \"Large-Scale and Language-Oblivious Code Authorship Identification\",\n    year = \"2018\",\n    isbn = \"9781450356930\",\n    publisher = \"Association for Computing Machinery\",\n    address = \"New York, NY, USA\",\n    url = \"https://doi.org/10.1145/3243734.3243738\",\n    doi = \"10.1145/3243734.3243738\",\n    abstract = \"Efficient extraction of code authorship attributes is key for successful identification. However, the extraction of such attributes is very challenging, due to various programming language specifics, the limited number of available code samples per author, and the average code lines per file, among others. To this end, this work proposes a Deep Learning-based Code Authorship Identification System (DL-CAIS) for code authorship attribution that facilitates large-scale, language-oblivious, and obfuscation-resilient code authorship identification. The deep learning architecture adopted in this work includes TF-IDF-based deep representation using multiple Recurrent Neural Network (RNN) layers and fully-connected layers dedicated to authorship attribution learning. The deep representation then feeds into a random forest classifier for scalability to de-anonymize the author. Comprehensive experiments are conducted to evaluate DL-CAIS over the entire Google Code Jam (GCJ) dataset across all years (from 2008 to 2016) and over real-world code samples from 1987 public repositories on GitHub. The results of our work show the high accuracy despite requiring a smaller number of files per author. Namely, we achieve an accuracy of 96\\% when experimenting with 1,600 authors for GCJ, and 94.38\\% for the real-world dataset for 745 C programmers. Our system also allows us to identify 8,903 authors, the largest-scale dataset used by far, with an accuracy of 92.3\\%. Moreover, our technique is resilient to language-specifics, and thus it can identify authors of four programming languages (e.g. C, C++, Java, and Python), and authors writing in mixed languages (e.g. Java/C++, Python/C++). Finally, our system is resistant to sophisticated obfuscation (e.g. using C Tigress) with an accuracy of 93.42\\% for a set of 120 authors.\",\n    booktitle = \"Proceedings of the 2018 ACM SIGSAC Conference on Computer and Communications Security\",\n    pages = \"101\u2013114\",\n    numpages = \"14\",\n    keywords = \"deep learning identification, software forensics, program features, code authorship identification\",\n    location = \"Toronto, Canada\",\n    series = \"CCS '18\"\n}\n\n",
    "abstract": "Obfuscation is a mechanism used to hinder reverse engineering of programs. To cope with the large number of obfuscated programs, especially malware, reverse engineers automate the process of deobfuscation i.e. extracting information from obfuscated programs. Deobfuscation techniques target specific obfuscation transformations, which requires reverse engineers to manually identify the transformations used by a program, in what is known as metadata recovery attack. In this paper, we present Oedipus, a Python framework that uses machine learning classifiers viz., decision trees and naive Bayes, to automate metadata recovery attacks against obfuscated programs. We evaluated Oedipus' performance using two datasets totaling 1960 unobfuscated C programs, which were used to generate 11.075 programs obfuscated using 30 configurations of 6 different obfuscation transformations. Our results empirically show the feasibility of using machine learning to implement the metadata recovery attacks with classification accuracies of 100% in some cases."
}, {
    "py/object": "data.DataClassPaper",
    "Title": "Method name suggestion with hierarchical attention networks",
    "year": 2019,
    "ML_Techniques": "",
    "Category": "Program comprehension",
    "Sub_category": "Entity identification/recommendation",
    "Venue": "PEPM",
    "Link": "https://dl.acm.org/doi/10.1145/3294032.3294079",
    "bibtex": "inproceedings{Abuhamad2018_383,\n    author = \"Abuhamad, Mohammed and AbuHmed, Tamer and Mohaisen, Aziz and Nyang, DaeHun\",\n    title = \"Large-Scale and Language-Oblivious Code Authorship Identification\",\n    year = \"2018\",\n    isbn = \"9781450356930\",\n    publisher = \"Association for Computing Machinery\",\n    address = \"New York, NY, USA\",\n    url = \"https://doi.org/10.1145/3243734.3243738\",\n    doi = \"10.1145/3243734.3243738\",\n    abstract = \"Efficient extraction of code authorship attributes is key for successful identification. However, the extraction of such attributes is very challenging, due to various programming language specifics, the limited number of available code samples per author, and the average code lines per file, among others. To this end, this work proposes a Deep Learning-based Code Authorship Identification System (DL-CAIS) for code authorship attribution that facilitates large-scale, language-oblivious, and obfuscation-resilient code authorship identification. The deep learning architecture adopted in this work includes TF-IDF-based deep representation using multiple Recurrent Neural Network (RNN) layers and fully-connected layers dedicated to authorship attribution learning. The deep representation then feeds into a random forest classifier for scalability to de-anonymize the author. Comprehensive experiments are conducted to evaluate DL-CAIS over the entire Google Code Jam (GCJ) dataset across all years (from 2008 to 2016) and over real-world code samples from 1987 public repositories on GitHub. The results of our work show the high accuracy despite requiring a smaller number of files per author. Namely, we achieve an accuracy of 96\\% when experimenting with 1,600 authors for GCJ, and 94.38\\% for the real-world dataset for 745 C programmers. Our system also allows us to identify 8,903 authors, the largest-scale dataset used by far, with an accuracy of 92.3\\%. Moreover, our technique is resilient to language-specifics, and thus it can identify authors of four programming languages (e.g. C, C++, Java, and Python), and authors writing in mixed languages (e.g. Java/C++, Python/C++). Finally, our system is resistant to sophisticated obfuscation (e.g. using C Tigress) with an accuracy of 93.42\\% for a set of 120 authors.\",\n    booktitle = \"Proceedings of the 2018 ACM SIGSAC Conference on Computer and Communications Security\",\n    pages = \"101\u2013114\",\n    numpages = \"14\",\n    keywords = \"deep learning identification, software forensics, program features, code authorship identification\",\n    location = \"Toronto, Canada\",\n    series = \"CCS '18\"\n}\n\n",
    "abstract": "Method Rename has been a widely used refactoring operation that improves program comprehension and maintenance. Descriptive method names that summarize functionalities of source code can facilitate program comprehension. Much research has been done to suggest method names through source code summarization. However, unlike natural language, a code snippet consists of basic blocks organized by complicated structures. In this work, we observe a hierarchical structure --- tokens form basic blocks and basic blocks form a code snippet. Based on this observation, we exploit a hierarchical attention network to learn the representation of methods. Specifically, we apply two-level attention mechanism to learn the importance of each token in a basic block and that of a basic block in a method respectively. We evaluated our approach on 10 open source repositories and compared it against three state-of-the-art approaches. The results on these open-source data show the superiority of our hierarchical attention networks in terms of effectiveness."
}, {
    "py/object": "data.DataClassPaper",
    "Title": "Mining software repositories for adaptive change commits using machine learning techniques",
    "year": 2019,
    "ML_Techniques": "",
    "Category": "Program comprehension",
    "Sub_category": "Program classification",
    "Venue": "IST",
    "Link": "https://www.sciencedirect.com/science/article/abs/pii/S0950584919300084",
    "bibtex": "article{Meqdadi2019_387,\n    author = \"Meqdadi, Omar and Alhindawi, Nouh and Alsakran, Jamal and Saifan, Ahmad and Migdadi, Hatim\",\n    title = \"Mining software repositories for adaptive change commits using machine learning techniques\",\n    journal = \"Information and Software Technology\",\n    volume = \"109\",\n    pages = \"80 - 91\",\n    year = \"2019\",\n    issn = \"0950-5849\",\n    doi = \"https://doi.org/10.1016/j.infsof.2019.01.008\",\n    url = \"http://www.sciencedirect.com/science/article/pii/S0950584919300084\",\n    keywords = \"Code change metrics, Adaptive maintenance, Commit types, Maintenance classification, Machine learning\",\n    abstract = \"Context Version Control Systems, such as Subversion, are standard repositories that preserve all of the maintenance changes undertaken to source code artifacts during the evolution of a software system. The documented data of the version history are organized as commits; however, these commits do not keep a tag that would identify the purpose of the relevant undertaken change of a commit, thus, there is rarely enough detail to clearly direct developers to the changes associated with a specific type of maintenance. Objective This work examines the version histories of an open source system to automatically classify version commits into one of two categories, namely adaptive commits and non-adaptive commits. Method We collected the commits from the version history of three open source systems, then we obtained eight different code change metrics related to, for example, the number of changed statements, methods, hunks, and files. Based on these change metrics, we built a machine learning approach to classify whether a commit was adaptive or not. Results It is observed that code change metrics can be indicative of adaptive maintenance activities. Also, the classification findings show that the machine learning classifier developed has approximately 75\\% prediction accuracy within labeled change histories. Conclusion The proposed method automates the process of examining the version history of a software system and identifies which commits to the system are related to an adaptive maintenance task. The evaluation of the method supports its applicability and efficiency. Although the evaluation of the proposed classifier on unlabeled change histories shows that it is not much better than the random guessing in terms of F-measure, we feel that our classifier would serve as a better basis for developing advanced classifiers that have predictive power of adaptive commits without the need of manual efforts.\"\n}\n\n",
    "abstract": "Context\nVersion Control Systems, such as Subversion, are standard repositories that preserve all of the maintenance changes undertaken to source code artifacts during the evolution of a software system. The documented data of the version history are organized as commits; however, these commits do not keep a tag that would identify the purpose of the relevant undertaken change of a commit, thus, there is rarely enough detail to clearly direct developers to the changes associated with a specific type of maintenance.\n\nObjective\nThis work examines the version histories of an open source system to automatically classify version commits into one of two categories, namely adaptive commits and non-adaptive commits.\n\nMethod\nWe collected the commits from the version history of three open source systems, then we obtained eight different code change metrics related to, for example, the number of changed statements, methods, hunks, and files. Based on these change metrics, we built a machine learning approach to classify whether a commit was adaptive or not.\n\nResults\nIt is observed that code change metrics can be indicative of adaptive maintenance activities. Also, the classification findings show that the machine learning classifier developed has approximately 75% prediction accuracy within labeled change histories.\n\nConclusion\nThe proposed method automates the process of examining the version history of a software system and identifies which commits to the system are related to an adaptive maintenance task. The evaluation of the method supports its applicability and efficiency. Although the evaluation of the proposed classifier on unlabeled change histories shows that it is not much better than the random guessing in terms of F-measure, we feel that our classifier would serve as a better basis for developing advanced classifiers that have predictive power of adaptive commits without the need of manual efforts."
}, {
    "py/object": "data.DataClassPaper",
    "Title": "Neural Code Comprehension: A Learnable Representation of Code Semantics",
    "year": 2018,
    "ML_Techniques": " inst2vec",
    "Category": "Program comprehension",
    "Sub_category": "",
    "Venue": "NIPS",
    "Link": "https://arxiv.org/abs/1806.07336",
    "bibtex": "inproceedings{Ben-Nun2018_388,\n    author = \"Ben-Nun, Tal and Jakobovits, Alice Shoshana and Hoefler, Torsten\",\n    title = \"Neural Code Comprehension: A Learnable Representation of Code Semantics\",\n    year = \"2018\",\n    publisher = \"Curran Associates Inc.\",\n    address = \"Red Hook, NY, USA\",\n    abstract = \"With the recent success of embeddings in natural language processing, research has been conducted into applying similar methods to code analysis. Most works attempt to process the code directly or use a syntactic tree representation, treating it like sentences written in a natural language. However, none of the existing methods are sufficient to comprehend program semantics robustly, due to structural features such as function calls, branching, and interchangeable order of statements. In this paper, we propose a novel processing technique to learn code semantics, and apply it to a variety of program analysis tasks. In particular, we stipulate that a robust distributional hypothesis of code applies to both human- and machine-generated programs. Following this hypothesis, we define an embedding space, inst2vec, based on an Intermediate Representation (IR) of the code that is independent of the source programming language. We provide a novel definition of contextual flow for this IR, leveraging both the underlying data- and control-flow of the program. We then analyze the embeddings qualitatively using analogies and clustering, and evaluate the learned representation on three different high-level tasks. We show that even without fine-tuning, a single RNN architecture and fixed inst2vec embeddings outperform specialized approaches for performance prediction (compute device mapping, optimal thread coarsening); and algorithm classification from raw code (104 classes), where we set a new state-of-the-art.\",\n    booktitle = \"Proceedings of the 32nd International Conference on Neural Information Processing Systems\",\n    pages = \"3589\u20133601\",\n    numpages = \"13\",\n    location = \"Montr\\'{e}al, Canada\",\n    series = \"NIPS'18\"\n}\n\n",
    "abstract": "With the recent success of embeddings in natural language processing, research has been conducted into applying similar methods to code analysis. Most works attempt to process the code directly or use a syntactic tree representation, treating it like sentences written in a natural language. However, none of the existing methods are sufficient to comprehend program semantics robustly, due to structural features such as function calls, branching, and interchangeable order of statements. In this paper, we propose a novel processing technique to learn code semantics, and apply it to a variety of program analysis tasks. In particular, we stipulate that a robust distributional hypothesis of code applies to both human- and machine-generated programs. Following this hypothesis, we define an embedding space, inst2vec, based on an Intermediate Representation (IR) of the code that is independent of the source programming language. We provide a novel definition of contextual flow for this IR, leveraging both the underlying data- and control-flow of the program. We then analyze the embeddings qualitatively using analogies and clustering, and evaluate the learned representation on three different high-level tasks. We show that even without fine-tuning, a single RNN architecture and fixed inst2vec embeddings outperform specialized approaches for performance prediction (compute device mapping, optimal thread coarsening); and algorithm classification from raw code (104 classes), where we set a new state-of-the-art."
}, {
    "py/object": "data.DataClassPaper",
    "Title": "NL2Type: Inferring JavaScript Function Types fromNatural Language Information",
    "year": 2019,
    "ML_Techniques": "RNN",
    "Category": "Program comprehension",
    "Sub_category": "Entity identification/recommendation",
    "Venue": "ICSE",
    "Link": "https://ieeexplore.ieee.org/document/8811893",
    "bibtex": "inproceedings{Ben-Nun2018_388,\n    author = \"Ben-Nun, Tal and Jakobovits, Alice Shoshana and Hoefler, Torsten\",\n    title = \"Neural Code Comprehension: A Learnable Representation of Code Semantics\",\n    year = \"2018\",\n    publisher = \"Curran Associates Inc.\",\n    address = \"Red Hook, NY, USA\",\n    abstract = \"With the recent success of embeddings in natural language processing, research has been conducted into applying similar methods to code analysis. Most works attempt to process the code directly or use a syntactic tree representation, treating it like sentences written in a natural language. However, none of the existing methods are sufficient to comprehend program semantics robustly, due to structural features such as function calls, branching, and interchangeable order of statements. In this paper, we propose a novel processing technique to learn code semantics, and apply it to a variety of program analysis tasks. In particular, we stipulate that a robust distributional hypothesis of code applies to both human- and machine-generated programs. Following this hypothesis, we define an embedding space, inst2vec, based on an Intermediate Representation (IR) of the code that is independent of the source programming language. We provide a novel definition of contextual flow for this IR, leveraging both the underlying data- and control-flow of the program. We then analyze the embeddings qualitatively using analogies and clustering, and evaluate the learned representation on three different high-level tasks. We show that even without fine-tuning, a single RNN architecture and fixed inst2vec embeddings outperform specialized approaches for performance prediction (compute device mapping, optimal thread coarsening); and algorithm classification from raw code (104 classes), where we set a new state-of-the-art.\",\n    booktitle = \"Proceedings of the 32nd International Conference on Neural Information Processing Systems\",\n    pages = \"3589\u20133601\",\n    numpages = \"13\",\n    location = \"Montr\\'{e}al, Canada\",\n    series = \"NIPS'18\"\n}\n\n",
    "abstract": "JavaScript is dynamically typed and hence lacks the type safety of statically typed languages, leading to suboptimal IDE support, difficult to understand APIs, and unexpected runtime behavior. Several gradual type systems have been proposed, e.g., Flow and TypeScript, but they rely on developers to annotate code with types. This paper presents NL2Type, a learning-based approach for predicting likely type signatures of JavaScript functions. The key idea is to exploit natural language information in source code, such as comments, function names, and parameter names, a rich source of knowledge that is typically ignored by type inference algorithms. We formulate the problem of predicting types as a classification problem and train a recurrent, LSTM-based neural model that, after learning from an annotated code base, predicts function types for unannotated code. We evaluate the approach with a corpus of 162,673 JavaScript files from real-world projects. NL2Type predicts types with a precision of 84.1% and a recall of 78.9% when considering only the top-most suggestion, and with a precision of 95.5% and a recall of 89.6% when considering the top-5 suggestions. The approach outperforms both JSNice, a state-of-the-art approach that analyzes implementations of functions instead of natural language information, and DeepTyper, a recent type prediction approach that is also based on deep learning. Beyond predicting types, NL2Type serves as a consistency checker for existing type annotations. We show that it discovers 39 inconsistencies that deserve developer attention (from a manual analysis of 50 warnings), most of which are due to incorrect type annotations."
}, {
    "py/object": "data.DataClassPaper",
    "Title": "On Learning Meaningful Code Changes Via Neural Machine Translation",
    "year": 2019,
    "ML_Techniques": "EN-DE",
    "Category": "Program comprehension",
    "Sub_category": "Change analysis",
    "Venue": "ICSE",
    "Link": "https://ieeexplore.ieee.org/abstract/document/8811910",
    "bibtex": "INPROCEEDINGS{Tufano2019_390,\n    author = \"{Tufano}, M. and {Pantiuchina}, J. and {Watson}, C. and {Bavota}, G. and {Poshyvanyk}, D.\",\n    booktitle = \"2019 IEEE/ACM 41st International Conference on Software Engineering (ICSE)\",\n    title = \"On Learning Meaningful Code Changes Via Neural Machine Translation\",\n    year = \"2019\",\n    volume = \"\",\n    number = \"\",\n    pages = \"25-36\",\n    doi = \"10.1109/ICSE.2019.00021\"\n}\n\n",
    "abstract": "Recent years have seen the rise of Deep Learning (DL) techniques applied to source code. Researchers have exploited DL to automate several development and maintenance tasks, such as writing commit messages, generating comments and detecting vulnerabilities among others. One of the long lasting dreams of applying DL to source code is the possibility to automate non-trivial coding activities. While some steps in this direction have been taken (e.g., learning how to fix bugs), there is still a glaring lack of empirical evidence on the types of code changes that can be learned and automatically applied by DL.\n\nOur goal is to make this first important step by quantitatively and qualitatively investigating the ability of a Neural Machine Translation (NMT) model to learn how to automatically apply code changes implemented by developers during pull requests. We train and experiment with the NMT model on a set of 236k pairs of code components before and after the implementation of the changes provided in the pull requests. We show that, when applied in a narrow enough context (i.e., small/medium-sized pairs of methods before/after the pull request changes), NMT can automatically replicate the changes implemented by developers during pull requests in up to 36% of the cases. Moreover, our qualitative analysis shows that the model is capable of learning and replicating a wide variety of meaningful code changes, especially refactorings and bug-fixing activities. Our results pave the way for novel research in the area of DL on code, such as the automatic learning and applications of refactoring."
}, {
    "py/object": "data.DataClassPaper",
    "Title": "On using machine learning to automatically classify software applications into domain categories",
    "year": 2014,
    "ML_Techniques": "",
    "Category": "Program comprehension",
    "Sub_category": "Program classification",
    "Venue": "EMSE",
    "Link": "",
    "bibtex": "article{V\\'asquez2012_391,\n    author = \"V{\\'a}squez, M. and McMillan, Collin and Poshyvanyk, D. and Grechanik, M.\",\n    title = \"On using machine learning to automatically classify software applications into domain categories\",\n    journal = \"Empirical Software Engineering\",\n    year = \"2012\",\n    volume = \"19\",\n    pages = \"582-618\"\n}\n\n",
    "abstract": "Software repositories hold applications that are often categorized to improve the effectiveness of various maintenance tasks. Properly categorized applications allow stakeholders to identify requirements related to their applications and predict maintenance problems in software projects. Manual categorization is expensive, tedious, and laborious --- this is why automatic categorization approaches are gaining widespread importance. Unfortunately, for different legal and organizational reasons, the applications' source code is often not available, thus making it difficult to automatically categorize these applications. In this paper, we propose a novel approach in which we use Application Programming Interface (API) calls from third-party libraries for automatic categorization of software applications that use these API calls. Our approach is general since it enables different categorization algorithms to be applied to repositories that contain both source code and bytecode of applications, since API calls can be extracted from both the source code and byte-code. We compare our approach to a state-of-the-art approach that uses machine learning algorithms for software categorization, and conduct experiments on two large Java repositories: an open-source repository containing 3,286 projects and a closed-source repository with 745 applications, where the source code was not available. Our contribution is twofold: we propose a new approach that makes it possible to categorize software projects without any source code using a small number of API calls as attributes, and furthermore we carried out a comprehensive empirical evaluation of automatic categorization approaches."
}, {
    "py/object": "data.DataClassPaper",
    "Title": "Suggesting Accurate Method and Class Names",
    "year": 2015,
    "ML_Techniques": "neural context model",
    "Category": "Program comprehension",
    "Sub_category": "Entity identification/recommendation",
    "Venue": "FSE",
    "Link": "http://homepages.inf.ed.ac.uk/csutton/publications/accurate-method-and-class.pdf",
    "bibtex": "inproceedings{Allamanis2015_392,\n    author = \"Allamanis, Miltiadis and Barr, Earl T. and Bird, Christian and Sutton, Charles\",\n    title = \"Suggesting Accurate Method and Class Names\",\n    year = \"2015\",\n    isbn = \"9781450336758\",\n    publisher = \"Association for Computing Machinery\",\n    address = \"New York, NY, USA\",\n    url = \"https://doi.org/10.1145/2786805.2786849\",\n    doi = \"10.1145/2786805.2786849\",\n    abstract = \"Descriptive names are a vital part of readable, and hence maintainable, code. Recent progress on automatically suggesting names for local variables tantalizes with the prospect of replicating that success with method and class names. However, suggesting names for methods and classes is much more difficult. This is because good method and class names need to be functionally descriptive, but suggesting such names requires that the model goes beyond local context. We introduce a neural probabilistic language model for source code that is specifically designed for the method naming problem. Our model learns which names are semantically similar by assigning them to locations, called embeddings, in a high-dimensional continuous space, in such a way that names with similar embeddings tend to be used in similar contexts. These embeddings seem to contain semantic information about tokens, even though they are learned only from statistical co-occurrences of tokens. Furthermore, we introduce a variant of our model that is, to our knowledge, the first that can propose neologisms, names that have not appeared in the training corpus. We obtain state of the art results on the method, class, and even the simpler variable naming tasks. More broadly, the continuous embeddings that are learned by our model have the potential for wide application within software engineering.\",\n    booktitle = \"Proceedings of the 2015 10th Joint Meeting on Foundations of Software Engineering\",\n    pages = \"38\u201349\",\n    numpages = \"12\",\n    keywords = \"Coding conventions, naturalness of software\",\n    location = \"Bergamo, Italy\",\n    series = \"ESEC/FSE 2015\"\n}\n\n",
    "abstract": "Descriptive names are a vital part of readable, and hence maintainable, code. Recent progress on automatically suggesting names for local variables tantalizes with the prospect of replicating that success with method and class names. However, suggesting names for methods and classes is much more difficult. This is because good method and class names need to be functionally descriptive, but suggesting such names requires that the model goes beyond local context. We introduce a neural probabilistic language model for source code that is specifically designed for the method naming problem. Our model learns which names are semantically similar by assigning them to locations, called embeddings, in a high-dimensional continuous space, in such a way that names with similar embeddings tend to be used in similar contexts. These embeddings seem to contain semantic information about tokens, even though they are learned only from statistical co-occurrences of tokens. Furthermore, we introduce a variant of our model that is, to our knowledge, the first that can propose neologisms, names that have not appeared in the training corpus. We obtain state of the art results on the method, class, and even the simpler variable naming tasks. More broadly, the continuous embeddings that are learned by our model have the potential for wide application within software engineering."
}, {
    "py/object": "data.DataClassPaper",
    "Title": "Towards a universal code formatter through machine learning",
    "year": 2016,
    "ML_Techniques": "",
    "Category": "Program comprehension",
    "Sub_category": "",
    "Venue": "SLE",
    "Link": "https://dl.acm.org/doi/abs/10.1145/2997364.2997383",
    "bibtex": "inproceedings{Allamanis2015_392,\n    author = \"Allamanis, Miltiadis and Barr, Earl T. and Bird, Christian and Sutton, Charles\",\n    title = \"Suggesting Accurate Method and Class Names\",\n    year = \"2015\",\n    isbn = \"9781450336758\",\n    publisher = \"Association for Computing Machinery\",\n    address = \"New York, NY, USA\",\n    url = \"https://doi.org/10.1145/2786805.2786849\",\n    doi = \"10.1145/2786805.2786849\",\n    abstract = \"Descriptive names are a vital part of readable, and hence maintainable, code. Recent progress on automatically suggesting names for local variables tantalizes with the prospect of replicating that success with method and class names. However, suggesting names for methods and classes is much more difficult. This is because good method and class names need to be functionally descriptive, but suggesting such names requires that the model goes beyond local context. We introduce a neural probabilistic language model for source code that is specifically designed for the method naming problem. Our model learns which names are semantically similar by assigning them to locations, called embeddings, in a high-dimensional continuous space, in such a way that names with similar embeddings tend to be used in similar contexts. These embeddings seem to contain semantic information about tokens, even though they are learned only from statistical co-occurrences of tokens. Furthermore, we introduce a variant of our model that is, to our knowledge, the first that can propose neologisms, names that have not appeared in the training corpus. We obtain state of the art results on the method, class, and even the simpler variable naming tasks. More broadly, the continuous embeddings that are learned by our model have the potential for wide application within software engineering.\",\n    booktitle = \"Proceedings of the 2015 10th Joint Meeting on Foundations of Software Engineering\",\n    pages = \"38\u201349\",\n    numpages = \"12\",\n    keywords = \"Coding conventions, naturalness of software\",\n    location = \"Bergamo, Italy\",\n    series = \"ESEC/FSE 2015\"\n}\n\n",
    "abstract": "There are many declarative frameworks that allow us to implement code formatters relatively easily for any specific language, but constructing them is cumbersome. The first problem is that \u201ceverybody\u201d wants to format their code differently, leading to either many formatter variants or a ridiculous number of configuration options. Second, the size of each implementation scales with a language\u2019s grammar size, leading to hundreds of rules.\n\nIn this paper, we solve the formatter construction problem using a novel approach, one that automatically derives formatters for any given language without intervention from a language expert. We introduce a code formatter called CodeBuff that uses machine learning to abstract formatting rules from a representative corpus, using a carefully designed feature set. Our experiments on Java, SQL, and ANTLR grammars show that CodeBuff is efficient, has excellent accuracy, and is grammar invariant for a given language. It also generalizes to a 4th language tested during manuscript preparation."
}, {
    "py/object": "data.DataClassPaper",
    "Title": "What's the code?: automatic classification of source code archives",
    "year": 2002,
    "ML_Techniques": "",
    "Category": "Program comprehension",
    "Sub_category": "Program classification",
    "Venue": "KDD",
    "Link": "https://dl.acm.org/doi/10.1145/775047.775141",
    "bibtex": "inproceedings{Allamanis2015_392,\n    author = \"Allamanis, Miltiadis and Barr, Earl T. and Bird, Christian and Sutton, Charles\",\n    title = \"Suggesting Accurate Method and Class Names\",\n    year = \"2015\",\n    isbn = \"9781450336758\",\n    publisher = \"Association for Computing Machinery\",\n    address = \"New York, NY, USA\",\n    url = \"https://doi.org/10.1145/2786805.2786849\",\n    doi = \"10.1145/2786805.2786849\",\n    abstract = \"Descriptive names are a vital part of readable, and hence maintainable, code. Recent progress on automatically suggesting names for local variables tantalizes with the prospect of replicating that success with method and class names. However, suggesting names for methods and classes is much more difficult. This is because good method and class names need to be functionally descriptive, but suggesting such names requires that the model goes beyond local context. We introduce a neural probabilistic language model for source code that is specifically designed for the method naming problem. Our model learns which names are semantically similar by assigning them to locations, called embeddings, in a high-dimensional continuous space, in such a way that names with similar embeddings tend to be used in similar contexts. These embeddings seem to contain semantic information about tokens, even though they are learned only from statistical co-occurrences of tokens. Furthermore, we introduce a variant of our model that is, to our knowledge, the first that can propose neologisms, names that have not appeared in the training corpus. We obtain state of the art results on the method, class, and even the simpler variable naming tasks. More broadly, the continuous embeddings that are learned by our model have the potential for wide application within software engineering.\",\n    booktitle = \"Proceedings of the 2015 10th Joint Meeting on Foundations of Software Engineering\",\n    pages = \"38\u201349\",\n    numpages = \"12\",\n    keywords = \"Coding conventions, naturalness of software\",\n    location = \"Bergamo, Italy\",\n    series = \"ESEC/FSE 2015\"\n}\n\n",
    "abstract": "There are various source code archives on the World Wide Web. These archives are usually organized by application categories and programming languages. However, manually organizing source code repositories is not a trivial task since they grow rapidly and are very large (on the order of terabytes). We demonstrate machine learning methods for automatic classification of archived source code into eleven application topics and ten programming languages. For topical classification, we concentrate on C and C++ programs from the Ibiblio and the Sourceforge archives. Support vector machine (SVM) classifiers are trained on examples of a given programming language or programs in a specified category. We show that source code can be accurately and automatically classified into topical categories and can be identified to be in a specific programming language class."
}, {
    "py/object": "data.DataClassPaper",
    "Title": "Can AI Close the Design-Code Abstraction Gap?",
    "year": 2019,
    "ML_Techniques": "",
    "Category": "General",
    "Sub_category": "",
    "Venue": "ASEW",
    "Link": "https://ieeexplore.ieee.org/document/8967435",
    "bibtex": "INPROCEEDINGS{Ivers2019_395,\n    author = \"{Ivers}, J. and {Ozkaya}, I. and {Nord}, R. L.\",\n    booktitle = \"2019 34th IEEE/ACM International Conference on Automated Software Engineering Workshop (ASEW)\",\n    title = \"Can AI Close the Design-Code Abstraction Gap?\",\n    year = \"2019\",\n    volume = \"\",\n    number = \"\",\n    pages = \"122-125\",\n    doi = \"10.1109/ASEW.2019.00041\"\n}\n\n",
    "abstract": "Aligning the design of a system with its\nimplementation improves product quality and simplifies product\nevolution. While developers are empowered with AI/ML\naugmented tools and techniques that increasingly assist them in\nimplementation tasks, the abstraction gap between code and\ndesign limits automation for design tasks. In this position paper,\nwe argue that the software engineering community can take\nadvantage of the experiences built with AI/ML techniques to\nadvance automation in design analysis. We summarize research\nchallenges and describe two efforts that apply machine learning to\ncodebases to extract design constructs and detect deviation from\nintended designs and to use search-based refactoring to make\ndesign improvements for extracting functionality."
}, {
    "py/object": "data.DataClassPaper",
    "Title": "How does Machine Learning Change Software Development Practices?",
    "year": 2019,
    "ML_Techniques": "",
    "Category": "General",
    "Sub_category": "",
    "Venue": "TSE",
    "Link": "https://ieeexplore.ieee.org/abstract/document/8812912",
    "bibtex": "ARTICLE{Wan2019_396,\n    author = \"{Wan}, Z. and {Xia}, X. and {Lo}, D. and {Murphy}, G. C.\",\n    journal = \"IEEE Transactions on Software Engineering\",\n    title = \"How does Machine Learning Change Software Development Practices?\",\n    year = \"2019\",\n    volume = \"\",\n    number = \"\",\n    pages = \"1-1\",\n    doi = \"10.1109/TSE.2019.2937083\"\n}\n\n",
    "abstract": "Adding an ability for a system to learn inherently adds\nuncertainty into the system. Given the rising popularity of incorporating\nmachine learning into systems, we wondered how the addition alters\nsoftware development practices. We performed a mixture of qualitative\nand quantitative studies with 14 interviewees and 342 survey\nrespondents from 26 countries across four continents to elicit significant\ndifferences between the development of machine learning systems and\nthe development of non-machine-learning systems. Our study uncovers\nsignificant differences in various aspects of software engineering (e.g.,\nrequirements, design, testing, and process) and work characteristics\n(e.g., skill variety, problem solving and task identity). Based on our\nfindings, we highlight future research directions and provide recommendations\nfor practitioners."
}, {
    "py/object": "data.DataClassPaper",
    "Title": "Machine Learning and Software Engineering",
    "year": 2003,
    "ML_Techniques": "",
    "Category": "General",
    "Sub_category": "",
    "Venue": "SQJ",
    "Link": "https://link.springer.com/article/10.1023/A:1023760326768",
    "bibtex": "INPROCEEDINGS{Abubakar2020_230,\n    author = \"{Abubakar}, H. and {Obaidat}, M. S. and {Gupta}, A. and {Bhattacharya}, P. and {Tanwar}, S.\",\n    booktitle = \"2020 International Conference on Communications, Computing, Cybersecurity, and Informatics (CCCI)\",\n    title = \"Interplay of Machine Learning and Software Engineering for Quality Estimations\",\n    year = \"2020\",\n    volume = \"\",\n    number = \"\",\n    pages = \"1-6\",\n    doi = \"10.1109/CCCI49893.2020.9256507\"\n}\n\n",
    "abstract": "Machine learning deals with the issue of how to build programs that improve their performance\nat some task through experience. Machine learning algorithms have proven to be of great practical value in\na variety of application domains. They are particularly useful for (a) poorly understood problem domains\nwhere little knowledge exists for the humans to develop effective algorithms; (b) domains where there are\nlarge databases containing valuable implicit regularities to be discovered; or (c) domains where programs\nmust adapt to changing conditions. Not surprisingly, the field of software engineering turns out to be a fertile\nground where many software development and maintenance tasks could be formulated as learning problems\nand approached in terms of learning algorithms. This paper deals with the subject of applying machine\nlearning in software engineering. In the paper, we first provide the characteristics and applicability of some\nfrequently utilized machine learning algorithms. We then summarize and analyze the existing work and discuss\nsome general issues in this niche area. Finally we offer some guidelines on applying machine learning\nmethods to software engineering tasks and use some software development and maintenance tasks as examples\nto show how they can be formulated as learning problems and approached in terms of learning algorithms."
}, {
    "py/object": "data.DataClassPaper",
    "Title": "A manually-curated dataset of fixes to vulnerabilities of open-source software",
    "year": 2019,
    "ML_Techniques": "",
    "Category": "Dataset mining",
    "Sub_category": "",
    "Venue": "MSR",
    "Link": "https://dl.acm.org/doi/10.1109/MSR.2019.00064",
    "bibtex": "INPROCEEDINGS{Abubakar2020_230,\n    author = \"{Abubakar}, H. and {Obaidat}, M. S. and {Gupta}, A. and {Bhattacharya}, P. and {Tanwar}, S.\",\n    booktitle = \"2020 International Conference on Communications, Computing, Cybersecurity, and Informatics (CCCI)\",\n    title = \"Interplay of Machine Learning and Software Engineering for Quality Estimations\",\n    year = \"2020\",\n    volume = \"\",\n    number = \"\",\n    pages = \"1-6\",\n    doi = \"10.1109/CCCI49893.2020.9256507\"\n}\n\n",
    "abstract": "Advancing our understanding of software vulnerabilities, automating their identification, the analysis of their impact, and\nultimately their mitigation is necessary to enable the development of software that is more secure.\nWhile operating a vulnerability assessment tool that we developed and that is currently used by hundreds of development units\nat SAP, we manually collected and curated a dataset of vulnerabilities of open-source software and the commits fixing them.\nThe data was obtained both from the National Vulnerability Database (NVD) and from project-specific Web resources that we\nmonitor on a continuous basis.\nFrom that data, we extracted a dataset that maps 624 publicly disclosed vulnerabilities affecting 205 distinct open-source Java\nprojects, used in SAP products or internal tools, onto the 1282 commits that fix them. Out of 624 vulnerabilities, 29 do not\nhave a CVE identifier at all and 46, which do have a CVE identifier assigned by a numbering authority, are not available in\nthe NVD yet.\nThe dataset is released under an open-source license, together with supporting scripts that allow researchers to automatically\nretrieve the actual content of the commits from the corresponding repositories and to augment the attributes available for each\ninstance. Also, these scripts allow to complement the dataset with additional instances that are not security fixes (which is\nuseful, for example, in machine learning applications).\nOur dataset has been successfully used to train classifiers that could automatically identify security-relevant commits in code\nrepositories. The release of this dataset and the supporting code as open-source will allow future research to be based on\ndata of industrial relevance; also, it represents a concrete step towards making the maintenance of this dataset a shared effort\ninvolving open-source communities, academia, and the industry."
}, {
    "py/object": "data.DataClassPaper",
    "Title": "Learning to mine aligned code and natural language pairs from stack overflow",
    "year": 2018,
    "ML_Techniques": "LOG",
    "Category": "Dataset mining",
    "Sub_category": "",
    "Venue": "MSR",
    "Link": "https://dl.acm.org/doi/10.1145/3196398.3196408",
    "bibtex": "INPROCEEDINGS{Abubakar2020_230,\n    author = \"{Abubakar}, H. and {Obaidat}, M. S. and {Gupta}, A. and {Bhattacharya}, P. and {Tanwar}, S.\",\n    booktitle = \"2020 International Conference on Communications, Computing, Cybersecurity, and Informatics (CCCI)\",\n    title = \"Interplay of Machine Learning and Software Engineering for Quality Estimations\",\n    year = \"2020\",\n    volume = \"\",\n    number = \"\",\n    pages = \"1-6\",\n    doi = \"10.1109/CCCI49893.2020.9256507\"\n}\n\n",
    "abstract": "For tasks like code synthesis from natural language, code retrieval,\nand code summarization, data-driven models have shown great\npromise. However, creating these models require parallel data between\nnatural language (NL) and code with fine-grained alignments.\nStack Overflow (SO) is a promising source to create such a data\nset: the questions are diverse and most of them have corresponding\nanswers with high quality code snippets. However, existing\nheuristic methods (e.g., pairing the title of a post with the code in\nthe accepted answer) are limited both in their coverage and the\ncorrectness of the NL-code pairs obtained. In this paper, we propose\na novel method to mine high-quality aligned data from SO\nusing two sets of features: hand-crafted features considering the\nstructure of the extracted snippets, and correspondence features\nobtained by training a probabilistic model to capture the correlation\nbetween NL and code using neural networks. These features are\nfed into a classifier that determines the quality of mined NL-code\npairs. Experiments using Python and Java as test beds show that\nthe proposed method greatly expands coverage and accuracy over\nexisting mining methods, even when using only a small number\nof labeled examples. Further, we find that reasonable results are\nachieved even when training the classifier on one language and\ntesting on another, showing promise for scaling NL-code mining to\na wide variety of programming languages beyond those for which\nwe are able to annotate data."
}, {
    "py/object": "data.DataClassPaper",
    "Title": "A Convolutional Attention Network for Extreme Summarization of Source Code",
    "year": 2016,
    "ML_Techniques": "GRU, CNN",
    "Category": "Code summarization",
    "Sub_category": "",
    "Venue": "ICML",
    "Link": "https://arxiv.org/abs/1602.03001",
    "bibtex": "misc{Allamanis2016_403,\n    author = \"Allamanis, Miltiadis and Peng, Hao and Sutton, Charles\",\n    title = \"A Convolutional Attention Network for Extreme Summarization of Source Code\",\n    year = \"2016\",\n    eprint = \"1602.03001\",\n    archivePrefix = \"arXiv\",\n    primaryClass = \"cs.LG\"\n}\n\n",
    "abstract": "Attention mechanisms in neural networks have\nproved useful for problems in which the input\nand output do not have fixed dimension. Often\nthere exist features that are locally translation invariant\nand would be valuable for directing the\nmodel\u2019s attention, but previous attentional architectures\nare not constructed to learn such features\nspecifically. We introduce an attentional neural\nnetwork that employs convolution on the input tokens\nto detect local time-invariant and long-range\ntopical attention features in a context-dependent\nway. We apply this architecture to the problem\nof extreme summarization of source code snippets\ninto short, descriptive function name-like\nsummaries. Using those features, the model sequentially\ngenerates a summary bymarginalizing\nover two attention mechanisms: one that predicts\nthe next summary token based on the attention\nweights of the input tokens and another that is\nable to copy a code token as-is directly into the\nsummary. We demonstrate our convolutional attention\nneural network\u2019s performance on 10 popular\nJava projects showing that it achieves better\nperformance compared to previous attentional\nmechanisms."
}, {
    "py/object": "data.DataClassPaper",
    "Title": "A Human Study of Comprehension and Code Summarization",
    "year": 2020,
    "ML_Techniques": "GRU",
    "Category": "Code summarization",
    "Sub_category": ",code comprehension ",
    "Venue": "ICPC",
    "Link": "https://dl.acm.org/doi/abs/10.1145/3387904.3389258",
    "bibtex": "inproceedings{Stapleton2020_404,\n    author = \"Stapleton, Sean and Gambhir, Yashmeet and LeClair, Alexander and Eberhart, Zachary and Weimer, Westley and Leach, Kevin and Huang, Yu\",\n    title = \"A Human Study of Comprehension and Code Summarization\",\n    year = \"2020\",\n    isbn = \"9781450379588\",\n    publisher = \"Association for Computing Machinery\",\n    address = \"New York, NY, USA\",\n    url = \"https://doi.org/10.1145/3387904.3389258\",\n    doi = \"10.1145/3387904.3389258\",\n    abstract = \"Software developers spend a great deal of time reading and understanding code that is poorly-documented, written by other developers, or developed using differing styles. During the past decade, researchers have investigated techniques for automatically documenting code to improve comprehensibility. In particular, recent advances in deep learning have led to sophisticated summary generation techniques that convert functions or methods to simple English strings that succinctly describe that code's behavior. However, automatic summarization techniques are assessed using internal metrics such as BLEU scores, which measure natural language properties in translational models, or ROUGE scores, which measure overlap with human-written text. Unfortunately, these metrics do not necessarily capture how machine-generated code summaries actually affect human comprehension or developer productivity.We conducted a human study involving both university students and professional developers (n = 45). Participants reviewed Java methods and summaries and answered established program comprehension questions. In addition, participants completed coding tasks given summaries as specifications. Critically, the experiment controlled the source of the summaries: for a given method, some participants were shown human-written text and some were shown machine-generated text.We found that participants performed significantly better (p = 0.029) using human-written summaries versus machine-generated summaries. However, we found no evidence to support that participants perceive human- and machine-generated summaries to have different qualities. In addition, participants' performance showed no correlation with the BLEU and ROUGE scores often used to assess the quality of machine-generated summaries. These results suggest a need for revised metrics to assess and guide automatic summarization techniques.\",\n    booktitle = \"Proceedings of the 28th International Conference on Program Comprehension\",\n    pages = \"2\u201313\",\n    numpages = \"12\",\n    location = \"Seoul, Republic of Korea\",\n    series = \"ICPC '20\"\n}\n\n",
    "abstract": "Software developers spend a great deal of time reading and understanding\ncode that is poorly-documented, written by other developers,\nor developed using differing styles. During the past decade,\nresearchers have investigated techniques for automatically documenting\ncode to improve comprehensibility. In particular, recent\nadvances in deep learning have led to sophisticated summary generation\ntechniques that convert functions or methods to simple English\nstrings that succinctly describe that code\u2019s behavior. However,\nautomatic summarization techniques are assessed using internal\nmetrics such as BLEU scores, which measure natural language properties\nin translational models, or ROUGE scores, which measure\noverlap with human-written text. Unfortunately, these metrics do\nnot necessarily capture how machine-generated code summaries\nactually affect human comprehension or developer productivity.\nWe conducted a human study involving both university students\nand professional developers (n = 45). Participants reviewed Java\nmethods and summaries and answered established program comprehension\nquestions. In addition, participants completed coding\ntasks given summaries as specifications. Critically, the experiment\ncontrolled the source of the summaries: for a given method, some\nparticipants were shown human-written text and some were shown\nmachine-generated text.\nWe found that participants performed significantly better (p =\n0.029) using human-written summaries versus machine-generated\nsummaries. However, we found no evidence to support that participants\nperceive human- and machine-generated summaries to have\ndifferent qualities. In addition, participants\u2019 performance showed\nno correlation with the BLEU and ROUGE scores often used to\nassess the quality of machine-generated summaries. These results\nsuggest a need for revised metrics to assess and guide automatic\nsummarization techniques."
}, {
    "py/object": "data.DataClassPaper",
    "Title": "A machine learning based automatic folding of dynamically typed languages",
    "year": 2019,
    "ML_Techniques": "GB, RF",
    "Category": "Code summarization",
    "Sub_category": "",
    "Venue": "MaLTeSQuE",
    "Link": "https://dl.acm.org/doi/10.1145/3340482.3342746",
    "bibtex": "inproceedings{Stapleton2020_404,\n    author = \"Stapleton, Sean and Gambhir, Yashmeet and LeClair, Alexander and Eberhart, Zachary and Weimer, Westley and Leach, Kevin and Huang, Yu\",\n    title = \"A Human Study of Comprehension and Code Summarization\",\n    year = \"2020\",\n    isbn = \"9781450379588\",\n    publisher = \"Association for Computing Machinery\",\n    address = \"New York, NY, USA\",\n    url = \"https://doi.org/10.1145/3387904.3389258\",\n    doi = \"10.1145/3387904.3389258\",\n    abstract = \"Software developers spend a great deal of time reading and understanding code that is poorly-documented, written by other developers, or developed using differing styles. During the past decade, researchers have investigated techniques for automatically documenting code to improve comprehensibility. In particular, recent advances in deep learning have led to sophisticated summary generation techniques that convert functions or methods to simple English strings that succinctly describe that code's behavior. However, automatic summarization techniques are assessed using internal metrics such as BLEU scores, which measure natural language properties in translational models, or ROUGE scores, which measure overlap with human-written text. Unfortunately, these metrics do not necessarily capture how machine-generated code summaries actually affect human comprehension or developer productivity.We conducted a human study involving both university students and professional developers (n = 45). Participants reviewed Java methods and summaries and answered established program comprehension questions. In addition, participants completed coding tasks given summaries as specifications. Critically, the experiment controlled the source of the summaries: for a given method, some participants were shown human-written text and some were shown machine-generated text.We found that participants performed significantly better (p = 0.029) using human-written summaries versus machine-generated summaries. However, we found no evidence to support that participants perceive human- and machine-generated summaries to have different qualities. In addition, participants' performance showed no correlation with the BLEU and ROUGE scores often used to assess the quality of machine-generated summaries. These results suggest a need for revised metrics to assess and guide automatic summarization techniques.\",\n    booktitle = \"Proceedings of the 28th International Conference on Program Comprehension\",\n    pages = \"2\u201313\",\n    numpages = \"12\",\n    location = \"Seoul, Republic of Korea\",\n    series = \"ICPC '20\"\n}\n\n",
    "abstract": "The popularity of dynamically typed languages has been growing\nstrongly lately. Elegant syntax of such languages like javascript,\npython, PHP and ruby pays back when it comes to finding bugs\nin large codebases. The analysis is hindered by specific capabilities\nof dynamically typed languages, such as defining methods\ndynamically and evaluating string expressions. For finding bugs\nor investigating unfamiliar classes and libraries in modern IDEs\nand text editors features for folding unimportant code blocks are\nimplemented. In this work, data on user foldings from real projects\nwere collected and two classifiers were trained on their basis. The\ninput to the classifier is a set of parameters describing the structure\nand syntax of the code block. These classifiers were subsequently\nused to identify unimportant code fragments. The implemented\napproach was tested on JavaScript and Python programs and compared\nwith the best existing algorithm for automatic code folding."
}, {
    "py/object": "data.DataClassPaper",
    "Title": "A Neural Framework for Retrieval and Summarization of Source Code",
    "year": 2018,
    "ML_Techniques": "GRU",
    "Category": "Code summarization",
    "Sub_category": "",
    "Venue": "ASE",
    "Link": "https://ieeexplore.ieee.org/abstract/document/9000013",
    "bibtex": "INPROCEEDINGS{Chen2018_406,\n    author = \"{Chen}, Q. and {Zhou}, M.\",\n    booktitle = \"2018 33rd IEEE/ACM International Conference on Automated Software Engineering (ASE)\",\n    title = \"A Neural Framework for Retrieval and Summarization of Source Code\",\n    year = \"2018\",\n    volume = \"\",\n    number = \"\",\n    pages = \"826-831\",\n    doi = \"10.1145/3238147.3240471\"\n}\n\n",
    "abstract": "Code retrieval and summarization are two tasks often employed by\nsoftware developers to reuse code that spreads over online repositories.\nIn this paper, we present a neural framework that allows\nbidirectional mapping between source code and natural language\nto improve these two tasks. Our framework, BVAE, is designed\nto have two Variational AutoEncoders (VAEs) to model bimodal\ndata: C-VAE for source code and L-VAE for natural language. Both\nVAEs are trained jointly to reconstruct their input as much as possible\nwith regularization that captures the closeness between the\nlatent variables of code and description. BVAE could learn semantic\nvector representations for both code and description and generate\ncompletely new descriptions for arbitrary code snippets.We design\ntwo instance models of BVAE for retrieval and summarization tasks\nrespectively and evaluate their performance on a benchmark which\ninvolves two programming languages: C# and SQL. Experiments\ndemonstrate BVAE\u2019s potential on the two tasks."
}, {
    "py/object": "data.DataClassPaper",
    "Title": "A neural model for generating natural language summaries of program subroutines",
    "year": 2019,
    "ML_Techniques": "GRU",
    "Category": "Code summarization",
    "Sub_category": "",
    "Venue": "ICSE",
    "Link": "https://dl.acm.org/doi/10.1109/ICSE.2019.00087",
    "bibtex": "INPROCEEDINGS{Chen2018_406,\n    author = \"{Chen}, Q. and {Zhou}, M.\",\n    booktitle = \"2018 33rd IEEE/ACM International Conference on Automated Software Engineering (ASE)\",\n    title = \"A Neural Framework for Retrieval and Summarization of Source Code\",\n    year = \"2018\",\n    volume = \"\",\n    number = \"\",\n    pages = \"826-831\",\n    doi = \"10.1145/3238147.3240471\"\n}\n\n",
    "abstract": "Source code summarization \u2013 creating natural language\ndescriptions of source code behavior \u2013 is a rapidly-growing\nresearch topic with applications to automatic documentation\ngeneration, program comprehension, and software maintenance.\nTraditional techniques relied on heuristics and templates built\nmanually by human experts. Recently, data-driven approaches\nbased on neural machine translation have largely overtaken\ntemplate-based systems. But nearly all of these techniques rely\nalmost entirely on programs having good internal documentation;\nwithout clear identifier names, the models fail to create good\nsummaries. In this paper, we present a neural model that\ncombines words from code with code structure from an AST.\nUnlike previous approaches, our model processes each data\nsource as a separate input, which allows the model to learn code\nstructure independent of the text in code. This process helps\nour approach provide coherent summaries in many cases even\nwhen zero internal documentation is provided. We evaluate our\ntechnique with a dataset we created from 2.1m Java methods. We\nfind improvement over two baseline techniques from SE literature\nand one from NLP literature."
}, {
    "py/object": "data.DataClassPaper",
    "Title": "A Neural-Network based Code Summarization Approach by Using Source Code and its Call Dependencies",
    "year": 2019,
    "ML_Techniques": "EN-DE",
    "Category": "Code summarization",
    "Sub_category": "",
    "Venue": "Internetware",
    "Link": "https://dl.acm.org/doi/abs/10.1145/3361242.3362774",
    "bibtex": "INPROCEEDINGS{Chen2018_406,\n    author = \"{Chen}, Q. and {Zhou}, M.\",\n    booktitle = \"2018 33rd IEEE/ACM International Conference on Automated Software Engineering (ASE)\",\n    title = \"A Neural Framework for Retrieval and Summarization of Source Code\",\n    year = \"2018\",\n    volume = \"\",\n    number = \"\",\n    pages = \"826-831\",\n    doi = \"10.1145/3238147.3240471\"\n}\n\n",
    "abstract": "Code summarization aims at generating natural language\nabstraction for source code, and it can be of great help\nfor program comprehension and software maintenance. The\ncurrent code summarization approaches have made progress\nwith neural-network. However, most of these methods focus\non learning the semantic and syntax of source code snippets,\nignoring the dependency of codes. In this paper, we propose\na novel method based on neural-network model using the\nknowledge of the call dependency between source code and its\nrelated codes. We extract call dependencies from the source\ncode, transform it as a token sequence of method names, and\nleverage the Seq2Seq model for code summarization using the\ncombination of source code and call dependency information.\nAbout 100,000 code data is collected from 1,000 open source\nJava proejects on github for experiment. The large-scale code\nexperiment shows that by considering not only the code itself\nbut also the codes it called, the code summarization model\ncan be improved with the BLEU score to 33.08."
}, {
    "py/object": "data.DataClassPaper",
    "Title": "A Transformer-based Approach for Source Code Summarization",
    "year": 2020,
    "ML_Techniques": "TF",
    "Category": "Code summarization",
    "Sub_category": "",
    "Venue": "ACL",
    "Link": "https://arxiv.org/abs/2005.00653",
    "bibtex": "inproceedings{Ahmad2020_410,\n    author = \"Ahmad, Wasi and Chakraborty, Saikat and Ray, Baishakhi and Chang, Kai-Wei\",\n    title = \"A Transformer-based Approach for Source Code Summarization\",\n    booktitle = \"Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics\",\n    month = \"July\",\n    year = \"2020\",\n    address = \"Online\",\n    publisher = \"Association for Computational Linguistics\",\n    url = \"https://www.aclweb.org/anthology/2020.acl-main.449\",\n    doi = \"10.18653/v1/2020.acl-main.449\",\n    pages = \"4998--5007\",\n    abstract = \"Generating a readable summary that describes the functionality of a program is known as source code summarization. In this task, learning code representation by modeling the pairwise relationship between code tokens to capture their long-range dependencies is crucial. To learn code representation for summarization, we explore the Transformer model that uses a self-attention mechanism and has shown to be effective in capturing long-range dependencies. In this work, we show that despite the approach is simple, it outperforms the state-of-the-art techniques by a significant margin. We perform extensive analysis and ablation studies that reveal several important findings, e.g., the absolute encoding of source code tokens{'} position hinders, while relative encoding significantly improves the summarization performance. We have made our code publicly available to facilitate future research.\"\n}\n\n",
    "abstract": "Generating a readable summary that describes\nthe functionality of a program is known as\nsource code summarization. In this task,\nlearning code representation by modeling the\npairwise relationship between code tokens to\ncapture their long-range dependencies is crucial.\nTo learn code representation for summarization,\nwe explore the Transformer model\nthat uses a self-attention mechanism and has\nshown to be effective in capturing long-range\ndependencies. In this work, we show that despite\nthe approach is simple, it outperforms\nthe state-of-the-art techniques by a significant\nmargin. We perform extensive analysis and\nablation studies that reveal several important\nfindings, e.g., the absolute encoding of source\ncode tokens\u2019 position hinders, while relative\nencoding significantly improves the summarization\nperformance. We have made our code\npublicly available1 to facilitate future research."
}, {
    "py/object": "data.DataClassPaper",
    "Title": "AUSUM: approach for unsupervised bug report summarization",
    "year": 2012,
    "ML_Techniques": "MMR, GRASSHOPER, DR",
    "Category": "Code summarization",
    "Sub_category": "",
    "Venue": "FSE",
    "Link": "https://dl.acm.org/doi/abs/10.1145/2393596.2393607",
    "bibtex": "inproceedings{Ahmad2020_410,\n    author = \"Ahmad, Wasi and Chakraborty, Saikat and Ray, Baishakhi and Chang, Kai-Wei\",\n    title = \"A Transformer-based Approach for Source Code Summarization\",\n    booktitle = \"Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics\",\n    month = \"July\",\n    year = \"2020\",\n    address = \"Online\",\n    publisher = \"Association for Computational Linguistics\",\n    url = \"https://www.aclweb.org/anthology/2020.acl-main.449\",\n    doi = \"10.18653/v1/2020.acl-main.449\",\n    pages = \"4998--5007\",\n    abstract = \"Generating a readable summary that describes the functionality of a program is known as source code summarization. In this task, learning code representation by modeling the pairwise relationship between code tokens to capture their long-range dependencies is crucial. To learn code representation for summarization, we explore the Transformer model that uses a self-attention mechanism and has shown to be effective in capturing long-range dependencies. In this work, we show that despite the approach is simple, it outperforms the state-of-the-art techniques by a significant margin. We perform extensive analysis and ablation studies that reveal several important findings, e.g., the absolute encoding of source code tokens{'} position hinders, while relative encoding significantly improves the summarization performance. We have made our code publicly available to facilitate future research.\"\n}\n\n",
    "abstract": "In most software projects, resolved bugs are archived for future\nreference. These bug reports contain valuable information on the\nreported problem, investigation and resolution. When bug triaging,\ndevelopers look for how similar problems were resolved in the\npast. Search over bug repository gives the developer a set of recommended\nbugs to look into. However, the developer still needs\nto manually peruse the contents of the recommended bugs which\nmight vary in size from a couple of lines to thousands. Automatic\nsummarization of bug reports is one way to reduce the amount of\ndata a developer might need to go through. Prior work has presented\nlearning based approaches for bug summarization. These\napproaches have the disadvantage of requiring large training set and\nbeing biased towards the data on which the model was learnt. In\nfact, maximum efficacy was reported when the model was trained\nand tested on bug reports from the same project. In this paper, we\npresent the results of applying four unsupervised summarization\ntechniques for bug summarization. Industrial bug reports typically\ncontain a large amount of noise\u2014email dump, chat transcripts,\ncore-dump\u2014useless sentences from the perspective of summarization.\nThese derail the unsupervised approaches, which are optimized\nto work on more well-formed documents. We present an\napproach for noise reduction, which helps to improve the precision\nof summarization over the base technique (4% to 24% across\nsubjects and base techniques). Importantly, by applying noise reduction,\ntwo of the unsupervised techniques became scalable for\nlarge sized bug reports."
}, {
    "py/object": "data.DataClassPaper",
    "Title": "Automatic Source Code Summarization with Extended Tree-LSTM",
    "year": 2019,
    "ML_Techniques": "LSTM",
    "Category": "Code summarization",
    "Sub_category": "",
    "Venue": "IJCNN",
    "Link": "https://ieeexplore.ieee.org/abstract/document/8851751",
    "bibtex": "INPROCEEDINGS{Shido2019_415,\n    author = \"{Shido}, Y. and {Kobayashi}, Y. and {Yamamoto}, A. and {Miyamoto}, A. and {Matsumura}, T.\",\n    booktitle = \"2019 International Joint Conference on Neural Networks (IJCNN)\",\n    title = \"Automatic Source Code Summarization with Extended Tree-LSTM\",\n    year = \"2019\",\n    volume = \"\",\n    number = \"\",\n    pages = \"1-8\",\n    doi = \"10.1109/IJCNN.2019.8851751\"\n}\n\n",
    "abstract": "Neural machine translation models are used to automatically generate a document from given source code\nsince this can be regarded as a machine translation task. Source code summarization is one of the components for\nautomatic document generation, which generates a summary in natural language from given source code. This\nsuggests that techniques used in neural machine translation, such as Long Short-Term Memory (LSTM), can be\nused for source code summarization. However, there is a considerable di erence between source code and natural\nlanguage: Source code is essentially structured, having loops and conditional branching, etc. Therefore, there is\nsome obstacle to apply known machine translation models to source code.\nAbstract syntax trees (ASTs) capture these structural properties and play an important role in recent machine\nlearning studies on source code. Tree-LSTM is proposed as a generalization of LSTMs for tree-structured data.\nHowever, there is a critical issue when applying it to ASTs: It cannot handle a tree that contains nodes having\nan arbitrary number of children and their order simultaneously, which ASTs generally have such nodes. To\naddress this issue, we propose an extension of Tree-LSTM, which we call Multi-way Tree-LSTM and apply it for\nsource code summarization. As a result of computational experiments, our proposal achieved better results when\ncompared with several state-of-the-art techniques."
}, {
    "py/object": "data.DataClassPaper",
    "Title": "Automatically generating commit messages from diffs using neural machine translation",
    "year": 2017,
    "ML_Techniques": "EN-DE, LSTM, GRU",
    "Category": "Code summarization",
    "Sub_category": "",
    "Venue": "ASE",
    "Link": "https://ieeexplore.ieee.org/document/8115626",
    "bibtex": "INPROCEEDINGS{Jiang2017_416,\n    author = \"{Jiang}, S. and {Armaly}, A. and {McMillan}, C.\",\n    booktitle = \"2017 32nd IEEE/ACM International Conference on Automated Software Engineering (ASE)\",\n    title = \"Automatically generating commit messages from diffs using neural machine translation\",\n    year = \"2017\",\n    volume = \"\",\n    number = \"\",\n    pages = \"135-146\",\n    doi = \"10.1109/ASE.2017.8115626\"\n}\n\n",
    "abstract": "Commit messages are a valuable resource in comprehension\nof software evolution, since they provide a record of\nchanges such as feature additions and bug repairs. Unfortunately,\nprogrammers often neglect to write good commit messages.\nDifferent techniques have been proposed to help programmers\nby automatically writing these messages. These techniques are\neffective at describing what changed, but are often verbose and\nlack context for understanding the rationale behind a change. In\ncontrast, humans write messages that are short and summarize\nthe high level rationale. In this paper, we adapt Neural Machine\nTranslation (NMT) to automatically \u201ctranslate\u201d diffs into commit\nmessages. We trained an NMT algorithm using a corpus of diffs\nand human-written commit messages from the top 1k Github\nprojects. We designed a filter to help ensure that we only trained\nthe algorithm on higher-quality commit messages. Our evaluation\nuncovered a pattern in which the messages we generate tend to\nbe either very high or very low quality. Therefore, we created a\nquality-assurance filter to detect cases in which we are unable to\nproduce good messages, and return a warning instead."
}, {
    "py/object": "data.DataClassPaper",
    "Title": "CoaCor: Code Annotation for Code Retrieval with Reinforcement Learning",
    "year": 2019,
    "ML_Techniques": "LSTM",
    "Category": "Code summarization",
    "Sub_category": "",
    "Venue": "WWW ",
    "Link": "https://dl.acm.org/doi/abs/10.1145/3308558.3313632",
    "bibtex": "inproceedings{Yao2019_418,\n    author = \"Yao, Ziyu and Peddamail, Jayavardhan Reddy and Sun, Huan\",\n    title = \"CoaCor: Code Annotation for Code Retrieval with Reinforcement Learning\",\n    year = \"2019\",\n    isbn = \"9781450366748\",\n    publisher = \"Association for Computing Machinery\",\n    address = \"New York, NY, USA\",\n    url = \"https://doi.org/10.1145/3308558.3313632\",\n    doi = \"10.1145/3308558.3313632\",\n    abstract = \"To accelerate software development, much research has been performed to help people understand and reuse the huge amount of available code resources. Two important tasks have been widely studied: code retrieval, which aims to retrieve code snippets relevant to a given natural language query from a code base, and code annotation, where the goal is to annotate a code snippet with a natural language description. Despite their advancement in recent years, the two tasks are mostly explored separately. In this work, we investigate a novel perspective of Code annotation for Code retrieval (hence called \u201cCoaCor\u201d), where a code annotation model is trained to generate a natural language annotation that can represent the semantic meaning of a given code snippet and can be leveraged by a code retrieval model to better distinguish relevant code snippets from others. To this end, we propose an effective framework based on reinforcement learning, which explicitly encourages the code annotation model to generate annotations that can be used for the retrieval task. Through extensive experiments, we show that code annotations generated by our framework are much more detailed and more useful for code retrieval, and they can further improve the performance of existing code retrieval models significantly.1\",\n    booktitle = \"The World Wide Web Conference\",\n    pages = \"2203\u20132214\",\n    numpages = \"12\",\n    keywords = \"Code Retrieval, Reinforcement Learning, Code Annotation\",\n    location = \"San Francisco, CA, USA\",\n    series = \"WWW '19\"\n}\n\n",
    "abstract": "To accelerate software development, much research has been performed\nto help people understand and reuse the huge amount of\navailable code resources. Two important tasks have been widely\nstudied: code retrieval, which aims to retrieve code snippets relevant\nto a given natural language query from a code base, and code\nannotation, where the goal is to annotate a code snippet with a\nnatural language description. Despite their advancement in recent\nyears, the two tasks are mostly explored separately. In this work, we\ninvestigate a novel perspective of Code annotation for Code retrieval\n(hence called \u201cCoaCor\u201d), where a code annotation model is trained\nto generate a natural language annotation that can represent the\nsemantic meaning of a given code snippet and can be leveraged by\na code retrieval model to better distinguish relevant code snippets\nfrom others. To this end, we propose an effective framework based\non reinforcement learning, which explicitly encourages the code\nannotation model to generate annotations that can be used for the\nretrieval task. Through extensive experiments, we show that code\nannotations generated by our framework are much more detailed\nand more useful for code retrieval, and they can further improve\nthe performance of existing code retrieval models significantly."
}, {
    "py/object": "data.DataClassPaper",
    "Title": "Code fragment summarization",
    "year": 2013,
    "ML_Techniques": "NB, SVM",
    "Category": "Code summarization",
    "Sub_category": "",
    "Venue": "FSE",
    "Link": "https://dl.acm.org/doi/abs/10.1145/2491411.2494587",
    "bibtex": "inproceedings{Yao2019_418,\n    author = \"Yao, Ziyu and Peddamail, Jayavardhan Reddy and Sun, Huan\",\n    title = \"CoaCor: Code Annotation for Code Retrieval with Reinforcement Learning\",\n    year = \"2019\",\n    isbn = \"9781450366748\",\n    publisher = \"Association for Computing Machinery\",\n    address = \"New York, NY, USA\",\n    url = \"https://doi.org/10.1145/3308558.3313632\",\n    doi = \"10.1145/3308558.3313632\",\n    abstract = \"To accelerate software development, much research has been performed to help people understand and reuse the huge amount of available code resources. Two important tasks have been widely studied: code retrieval, which aims to retrieve code snippets relevant to a given natural language query from a code base, and code annotation, where the goal is to annotate a code snippet with a natural language description. Despite their advancement in recent years, the two tasks are mostly explored separately. In this work, we investigate a novel perspective of Code annotation for Code retrieval (hence called \u201cCoaCor\u201d), where a code annotation model is trained to generate a natural language annotation that can represent the semantic meaning of a given code snippet and can be leveraged by a code retrieval model to better distinguish relevant code snippets from others. To this end, we propose an effective framework based on reinforcement learning, which explicitly encourages the code annotation model to generate annotations that can be used for the retrieval task. Through extensive experiments, we show that code annotations generated by our framework are much more detailed and more useful for code retrieval, and they can further improve the performance of existing code retrieval models significantly.1\",\n    booktitle = \"The World Wide Web Conference\",\n    pages = \"2203\u20132214\",\n    numpages = \"12\",\n    keywords = \"Code Retrieval, Reinforcement Learning, Code Annotation\",\n    location = \"San Francisco, CA, USA\",\n    series = \"WWW '19\"\n}\n\n",
    "abstract": "Current research in software engineering has mostly focused\non the retrieval accuracy aspect but little on the presentation\naspect of code examples, e.g., how code examples are\npresented in a result page. We investigate the feasibility\nof summarizing code examples for better presenting a code\nexample. Our algorithm based on machine learning could\napproximate summaries in an oracle manually generated by\nhumans with a precision of 0.71. This result is promising\nas summaries with this level of precision achieved the same\nlevel of agreement as human annotators with each other."
}, {
    "py/object": "data.DataClassPaper",
    "Title": "Code Summarization with Abstract Syntax Tree",
    "year": 2019,
    "ML_Techniques": "EN-DE, LSTM, GRU",
    "Category": "Code summarization",
    "Sub_category": "",
    "Venue": "NIPS",
    "Link": "https://link.springer.com/chapter/10.1007/978-3-030-36802-9_69",
    "bibtex": "InProceedings{Chen2019_420,\n    author = \"Chen, Qiuyuan and Hu, Han and Liu, Zhaoyi\",\n    editor = \"Gedeon, Tom and Wong, Kok Wai and Lee, Minho\",\n    title = \"Code Summarization with Abstract Syntax Tree\",\n    booktitle = \"Neural Information Processing\",\n    year = \"2019\",\n    publisher = \"Springer International Publishing\",\n    address = \"Cham\",\n    pages = \"652--660\",\n    abstract = \"Code summarization, which provides a high-level description of the function implemented by code, plays a vital role in software maintenance and code retrieval. Traditional approaches focus on retrieving similar code snippets to generate summaries, and recently researchers pay increasing attention to leverage deep learning approaches, especially the encoder-decoder framework. Approaches based on encoder-decoder suffer from two drawbacks: (a) Lack of summarization in functionality level; (b) Code snippets are always too long (more than ten words), regular encoders perform poorly. In this paper, we propose a novel code representation with the help of Abstract Syntax Trees, which could describe the functionality of code snippets and shortens the length of inputs. Based on our proposed code representation, we develop Generative Task, which aims to generate summary sentences of code snippets. Experiments on large-scale real-world industrial Java projects indicate that our approaches are effective and outperform the state-of-the-art approaches in code summarization.\",\n    isbn = \"978-3-030-36802-9\"\n}\n\n",
    "abstract": "Code summarization, which provides a high-level description\nof the function implemented by code, plays a vital role in software maintenance\nand code retrieval. Traditional approaches focus on retrieving\nsimilar code snippets to generate summaries, and recently researchers\npay increasing attention to leverage deep learning approaches, especially\nthe encoder-decoder framework. Approaches based on encoder-decoder\nsuffer from two drawbacks: (a) Lack of summarization in functionality\nlevel; (b) Code snippets are always too long (more than ten words), regular\nencoders perform poorly. In this paper, we propose a novel code representation\nwith the help of Abstract Syntax Trees, which could describe\nthe functionality of code snippets and shortens the length of inputs.\nBased on our proposed code representation, we develop Generative Task,\nwhich aims to generate summary sentences of code snippets. Experiments\non large-scale real-world industrial Java projects indicate that our\napproaches are effective and outperform the state-of-the-art approaches\nin code summarization."
}, {
    "py/object": "data.DataClassPaper",
    "Title": "Deep Code Comment Generation",
    "year": 2018,
    "ML_Techniques": "EN-DE, LSTM, GRU",
    "Category": "Code summarization",
    "Sub_category": "",
    "Venue": "ICPC",
    "Link": "https://ieeexplore.ieee.org/abstract/document/8973050",
    "bibtex": "INPROCEEDINGS{Hu2018_421,\n    author = \"{Hu}, X. and {Li}, G. and {Xia}, X. and {Lo}, D. and {Jin}, Z.\",\n    booktitle = \"2018 IEEE/ACM 26th International Conference on Program Comprehension (ICPC)\",\n    title = \"Deep Code Comment Generation\",\n    year = \"2018\",\n    volume = \"\",\n    number = \"\",\n    pages = \"200-20010\",\n    doi = \"\"\n}\n\n",
    "abstract": "During software maintenance, code comments help developers\ncomprehend programs and reduce additional time spent on reading\nand navigating source code. Unfortunately, these comments are\noften mismatched, missing or outdated in the software projects.\nDevelopers have to infer the functionality from the source code.\nThis paper proposes a new approach named DeepCom to automatically\ngenerate code comments for Java methods. The generated\ncomments aim to help developers understand the functionality\nof Java methods. DeepCom applies Natural Language Processing\n(NLP) techniques to learn from a large code corpus and generates\ncomments from learned features. We use a deep neural network\nthat analyzes structural information of Java methods for better\ncomments generation. We conduct experiments on a large-scale\nJava corpus built from 9,714 open source projects from GitHub. We\nevaluate the experimental results on a machine translation metric.\nExperimental results demonstrate that our method DeepCom\noutperforms the state-of-the-art by a substantial margin."
}, {
    "py/object": "data.DataClassPaper",
    "Title": "Deep code comment generation with hybrid lexical and syntactical information",
    "year": 2020,
    "ML_Techniques": "EN-DE, LSTM, GRU",
    "Category": "Code summarization",
    "Sub_category": "",
    "Venue": "EMSE",
    "Link": "https://link.springer.com/article/10.1007/s10664-019-09730-9",
    "bibtex": "INPROCEEDINGS{Hu2018_421,\n    author = \"{Hu}, X. and {Li}, G. and {Xia}, X. and {Lo}, D. and {Jin}, Z.\",\n    booktitle = \"2018 IEEE/ACM 26th International Conference on Program Comprehension (ICPC)\",\n    title = \"Deep Code Comment Generation\",\n    year = \"2018\",\n    volume = \"\",\n    number = \"\",\n    pages = \"200-20010\",\n    doi = \"\"\n}\n\n",
    "abstract": "During software maintenance, developers spend a lot of time understanding the source\ncode. Existing studies show that code comments help developers comprehend programs\nand reduce additional time spent on reading and navigating source code. Unfortunately,\nthese comments are often mismatched, missing or outdated in software projects. Developers\nhave to infer the functionality from the source code. This paper proposes a new approach\nnamed Hybrid-DeepCom to automatically generate code comments for the functional units\nof Java language, namely, Java methods. The generated comments aim to help developers\nunderstand the functionality of Java methods. Hybrid-DeepCom applies Natural Language\nProcessing (NLP) techniques to learn from a large code corpus and generates comments\nfrom learned features. It formulates the comment generation task as the machine translation\nproblem. Hybrid-DeepCom exploits a deep neural network that combines the lexical\nand structure information of Java methods for better comments generation. We conduct\nexperiments on a large-scale Java corpus built from 9,714 open source projects on GitHub.\nWe evaluate the experimental results on both machine translation metrics and information\nretrieval metrics. Experimental results demonstrate that our method Hybrid-DeepCom outperforms\nthe state-of-the-art by a substantial margin. In addition, we evaluate the influence\nof out-of-vocabulary tokens on comment generation. The results show that reducing the\nout-of-vocabulary tokens improves the accuracy effectively."
}, {
    "py/object": "data.DataClassPaper",
    "Title": "Fret: Functional Reinforced Transformer With BERT for Code Summarization",
    "year": 2020,
    "ML_Techniques": "LSTM, EN-DE",
    "Category": "Code summarization",
    "Sub_category": "",
    "Venue": "IEEE Access",
    "Link": "https://ieeexplore.ieee.org/abstract/document/9146834/keywords#keywords",
    "bibtex": "ARTICLE{Wang2020_424,\n    author = \"{Wang}, R. and {Zhang}, H. and {Lu}, G. and {Lyu}, L. and {Lyu}, C.\",\n    journal = \"IEEE Access\",\n    title = \"Fret: Functional Reinforced Transformer With BERT for Code Summarization\",\n    year = \"2020\",\n    volume = \"8\",\n    number = \"\",\n    pages = \"135591-135604\",\n    doi = \"10.1109/ACCESS.2020.3011744\"\n}\n\n",
    "abstract": "Code summarization has long been viewed as a challenge in software engineering because of\nthe difficulties of understanding source code and generating natural language. Some mainstream methods\ncombine abstract syntax trees with language models to capture the structural information of the source\ncode and generate relatively satisfactory comments. However, these methods are still deficient in code\nunderstanding and limited by the long dependency problem. In this paper, we propose a novel model\ncalled Fret, which stands for Functional REinforced Transformer with BERT. The model provides a\nnew way to generate code comments by learning code functionalities and deepening code understanding\nwhile alleviating the problem of long dependency. For this purpose, a novel reinforcer is proposed for\nlearning the functional contents of code so that more accurate summaries to describe the code functionalities\ncan be generated. In addition, a more efficient algorithm is newly designed to capture the source code\nstructure. The experimental results show that the effectiveness of our model is remarkable. Fret significantly\noutperforms all the state-of-the-art methods we examine. It pushes the BLEU-4 score to 24.32 for Java code\nsummarization (14.23% absolute improvement) and the ROUGE-L score to 40.12 for Python. An ablation\ntest is also conducted to further explore the impact of each component of our method."
}, {
    "py/object": "data.DataClassPaper",
    "Title": "Improved Code Summarization via a Graph Neural Network",
    "year": 2020,
    "ML_Techniques": "LSTM, GRU, EN-DE, GNN",
    "Category": "Code summarization",
    "Sub_category": "",
    "Venue": "ICPC",
    "Link": "https://arxiv.org/abs/2004.02843",
    "bibtex": "inproceedings{LeClair2020_426,\n    author = \"LeClair, Alexander and Haque, Sakib and Wu, Lingfei and McMillan, Collin\",\n    title = \"Improved Code Summarization via a Graph Neural Network\",\n    year = \"2020\",\n    isbn = \"9781450379588\",\n    publisher = \"Association for Computing Machinery\",\n    address = \"New York, NY, USA\",\n    url = \"https://doi.org/10.1145/3387904.3389268\",\n    doi = \"10.1145/3387904.3389268\",\n    abstract = \"Automatic source code summarization is the task of generating natural language descriptions for source code. Automatic code summarization is a rapidly expanding research area, especially as the community has taken greater advantage of advances in neural network and AI technologies. In general, source code summarization techniques use the source code as input and outputs a natural language description. Yet a strong consensus is developing that using structural information as input leads to improved performance. The first approaches to use structural information flattened the AST into a sequence. Recently, more complex approaches based on random AST paths or graph neural networks have improved on the models using flattened ASTs. However, the literature still does not describe the using a graph neural network together with source code sequence as separate inputs to a model. Therefore, in this paper, we present an approach that uses a graph-based neural architecture that better matches the default structure of the AST to generate these summaries. We evaluate our technique using a data set of 2.1 million Java method-comment pairs and show improvement over four baseline techniques, two from the software engineering literature, and two from machine learning literature.\",\n    booktitle = \"Proceedings of the 28th International Conference on Program Comprehension\",\n    pages = \"184\u2013195\",\n    numpages = \"12\",\n    keywords = \"artificial intelligence, neural networks, deep learning, Automatic documentation\",\n    location = \"Seoul, Republic of Korea\",\n    series = \"ICPC '20\"\n}\n\n",
    "abstract": "Automatic source code summarization is the task of generating\nnatural language descriptions for source code. Automatic code\nsummarization is a rapidly expanding research area, especially as\nthe community has taken greater advantage of advances in neural\nnetwork and AI technologies. In general, source code summarization\ntechniques use the source code as input and outputs a natural\nlanguage description. Yet a strong consensus is developing that using\nstructural information as input leads to improved performance.\n\u008ce \u0080rst approaches to use structural information \u0083a\u008aened the\nAST into a sequence. Recently, more complex approaches based\non random AST paths or graph neural networks have improved\non the models using \u0083a\u008aened ASTs. However, the literature still\ndoes not describe the using a graph neural network together with\nsource code sequence as separate inputs to a model. \u008cerefore, in\nthis paper, we present an approach that uses a graph-based neural\narchitecture that be\u008aer matches the default structure of the AST\nto generate these summaries. We evaluate our technique using a\ndata set of 2.1 million Java method-comment pairs and show improvement\nover four baseline techniques, two from the so\u0089ware\nengineering literature, and two from machine learning literature."
}, {
    "py/object": "data.DataClassPaper",
    "Title": "Improving automatic source code summarization via deep reinforcement learning",
    "year": 2018,
    "ML_Techniques": "LSTM,  GNN",
    "Category": "Code summarization",
    "Sub_category": "",
    "Venue": "ASE",
    "Link": "https://dl.acm.org/doi/abs/10.1145/3238147.3238206",
    "bibtex": "inproceedings{LeClair2020_426,\n    author = \"LeClair, Alexander and Haque, Sakib and Wu, Lingfei and McMillan, Collin\",\n    title = \"Improved Code Summarization via a Graph Neural Network\",\n    year = \"2020\",\n    isbn = \"9781450379588\",\n    publisher = \"Association for Computing Machinery\",\n    address = \"New York, NY, USA\",\n    url = \"https://doi.org/10.1145/3387904.3389268\",\n    doi = \"10.1145/3387904.3389268\",\n    abstract = \"Automatic source code summarization is the task of generating natural language descriptions for source code. Automatic code summarization is a rapidly expanding research area, especially as the community has taken greater advantage of advances in neural network and AI technologies. In general, source code summarization techniques use the source code as input and outputs a natural language description. Yet a strong consensus is developing that using structural information as input leads to improved performance. The first approaches to use structural information flattened the AST into a sequence. Recently, more complex approaches based on random AST paths or graph neural networks have improved on the models using flattened ASTs. However, the literature still does not describe the using a graph neural network together with source code sequence as separate inputs to a model. Therefore, in this paper, we present an approach that uses a graph-based neural architecture that better matches the default structure of the AST to generate these summaries. We evaluate our technique using a data set of 2.1 million Java method-comment pairs and show improvement over four baseline techniques, two from the software engineering literature, and two from machine learning literature.\",\n    booktitle = \"Proceedings of the 28th International Conference on Program Comprehension\",\n    pages = \"184\u2013195\",\n    numpages = \"12\",\n    keywords = \"artificial intelligence, neural networks, deep learning, Automatic documentation\",\n    location = \"Seoul, Republic of Korea\",\n    series = \"ICPC '20\"\n}\n\n",
    "abstract": "Code summarization provides a high level natural\nlanguage description of the function performed by code, as it\ncan benefit the software maintenance, code categorization and\nretrieval. To the best of our knowledge, most state-of-the-art\napproaches follow an encoder-decoder framework which encodes\nthe code into a hidden space and then decode it into natural\nlanguage space, suffering from two major drawbacks: a) Their\nencoders only consider the sequential content of code, ignoring\nthe tree structure which is also critical for the task of code\nsummarization; b) Their decoders are typically trained to predict\nthe next word by maximizing the likelihood of next groundtruth\nword with previous ground-truth word given. However, it\nis expected to generate the entire sequence from scratch at test\ntime. This discrepancy can cause an exposure bias issue, making\nthe learnt decoder suboptimal. In this paper, we incorporate an\nabstract syntax tree structure as well as sequential content of\ncode snippets into a deep reinforcement learning framework (i.e.,\nactor-critic network). The actor network provides the confidence\nof predicting the next word according to current state. On the\nother hand, the critic network evaluates the reward value of all\npossible extensions of the current state and can provide global\nguidance for explorations. We employ an advantage reward composed\nof BLEU metric to train both networks. Comprehensive\nexperiments on a real-world dataset show the effectiveness of\nour proposed model when compared with some state-of-the-art\nmethods."
}, {
    "py/object": "data.DataClassPaper",
    "Title": "Leveraging Code Generation to Improve Code Retrieval and Summarization via Dual Learning",
    "year": 2020,
    "ML_Techniques": "Bi-LSTM",
    "Category": "Code summarization",
    "Sub_category": "",
    "Venue": "WWW ",
    "Link": "https://dl.acm.org/doi/abs/10.1145/3366423.3380295",
    "bibtex": "inproceedings{Ye2020_428,\n    author = \"Ye, Wei and Xie, Rui and Zhang, Jinglei and Hu, Tianxiang and Wang, Xiaoyin and Zhang, Shikun\",\n    title = \"Leveraging Code Generation to Improve Code Retrieval and Summarization via Dual Learning\",\n    year = \"2020\",\n    isbn = \"9781450370233\",\n    publisher = \"Association for Computing Machinery\",\n    address = \"New York, NY, USA\",\n    url = \"https://doi.org/10.1145/3366423.3380295\",\n    doi = \"10.1145/3366423.3380295\",\n    abstract = \"Code summarization generates brief natural language description given a source code snippet, while code retrieval fetches relevant source code given a natural language query. Since both tasks aim to model the association between natural language and programming language, recent studies have combined these two tasks to improve their performance. However, researchers have yet been able to effectively leverage the intrinsic connection between the two tasks as they train these tasks in a separate or pipeline manner, which means their performance can not be well balanced. In this paper, we propose a novel end-to-end model for the two tasks by introducing an additional code generation task. More specifically, we explicitly exploit the probabilistic correlation between code summarization and code generation with dual learning, and utilize the two encoders for code summarization and code generation to train the code retrieval task via multi-task learning. We have carried out extensive experiments on an existing dataset of SQL and Python, and results show that our model can significantly improve the results of the code retrieval task over the-state-of-art models, as well as achieve competitive performance in terms of BLEU score for the code summarization task.\",\n    booktitle = \"Proceedings of The Web Conference 2020\",\n    pages = \"2309\u20132319\",\n    numpages = \"11\",\n    keywords = \"code retrieval, code summarization, code generation, dual learning\",\n    location = \"Taipei, Taiwan\",\n    series = \"WWW '20\"\n}\n\n",
    "abstract": "Code summarization generates brief natural language description\ngiven a source code snippet, while code retrieval fetches relevant\nsource code given a natural language query. Since both tasks aim\nto model the association between natural language and programming\nlanguage, recent studies have combined these two tasks to\nimprove their performance. However, researchers have yet been\nable to effectively leverage the intrinsic connection between the\ntwo tasks as they train these tasks in a separate or pipeline manner,\nwhich means their performance can not be well balanced. In this\npaper, we propose a novel end-to-end model for the two tasks by\nintroducing an additional code generation task. More specifically,\nwe explicitly exploit the probabilistic correlation between code\nsummarization and code generation with dual learning, and utilize\nthe two encoders for code summarization and code generation to\ntrain the code retrieval task via multi-task learning. We have carried\nout extensive experiments on an existing dataset of SQL and\nPython, and results show that our model can significantly improve\nthe results of the code retrieval task over the-state-of-art models,\nas well as achieve competitive performance in terms of BLEU score\nfor the code summarization task."
}, {
    "py/object": "data.DataClassPaper",
    "Title": "Neural-machine-translation-based commit message generation: how far are we?",
    "year": 2018,
    "ML_Techniques": "KNN",
    "Category": "Code summarization",
    "Sub_category": "",
    "Venue": "ASE",
    "Link": "https://dl.acm.org/doi/10.1145/3238147.3238190",
    "bibtex": "inproceedings{Ye2020_428,\n    author = \"Ye, Wei and Xie, Rui and Zhang, Jinglei and Hu, Tianxiang and Wang, Xiaoyin and Zhang, Shikun\",\n    title = \"Leveraging Code Generation to Improve Code Retrieval and Summarization via Dual Learning\",\n    year = \"2020\",\n    isbn = \"9781450370233\",\n    publisher = \"Association for Computing Machinery\",\n    address = \"New York, NY, USA\",\n    url = \"https://doi.org/10.1145/3366423.3380295\",\n    doi = \"10.1145/3366423.3380295\",\n    abstract = \"Code summarization generates brief natural language description given a source code snippet, while code retrieval fetches relevant source code given a natural language query. Since both tasks aim to model the association between natural language and programming language, recent studies have combined these two tasks to improve their performance. However, researchers have yet been able to effectively leverage the intrinsic connection between the two tasks as they train these tasks in a separate or pipeline manner, which means their performance can not be well balanced. In this paper, we propose a novel end-to-end model for the two tasks by introducing an additional code generation task. More specifically, we explicitly exploit the probabilistic correlation between code summarization and code generation with dual learning, and utilize the two encoders for code summarization and code generation to train the code retrieval task via multi-task learning. We have carried out extensive experiments on an existing dataset of SQL and Python, and results show that our model can significantly improve the results of the code retrieval task over the-state-of-art models, as well as achieve competitive performance in terms of BLEU score for the code summarization task.\",\n    booktitle = \"Proceedings of The Web Conference 2020\",\n    pages = \"2309\u20132319\",\n    numpages = \"11\",\n    keywords = \"code retrieval, code summarization, code generation, dual learning\",\n    location = \"Taipei, Taiwan\",\n    series = \"WWW '20\"\n}\n\n",
    "abstract": "Commit messages can be regarded as the documentation of software\nchanges. These messages describe the content and purposes\nof changes, hence are useful for program comprehension and software\nmaintenance. However, due to the lack of time and direct\nmotivation, commit messages sometimes are neglected by developers.\nTo address this problem, Jiang et al. proposed an approach (we\nrefer to it as NMT), which leverages a neural machine translation\nalgorithm to automatically generate short commit messages from\ncode. The reported performance of their approach is promising,\nhowever, they did not explore why their approach performs well.\nThus, in this paper, we first perform an in-depth analysis of their\nexperimental results. We find that (1) Most of the test diffs from\nwhich NMT can generate high-quality messages are similar to one\nor more training diffs at the token level. (2) About 16% of the\ncommit messages in Jiang et al.\u2019s dataset are noisy due to being\nautomatically generated or due to them describing repetitive trivial\nchanges. (3) The performance of NMT declines by a large amount\nafter removing such noisy commit messages. In addition, NMT is\ncomplicated and time-consuming. Inspired by our first finding, we\nproposed a simpler and faster approach, named NNGen (Nearest\nNeighbor Generator), to generate concise commit messages using\nthe nearest neighbor algorithm. Our experimental results show\nthat NNGen is over 2,600 times faster than NMT, and outperforms\nNMT in terms of BLEU (an accuracy measure that is widely used\nto evaluate machine translation systems) by 21%. Finally, we also\ndiscuss some observations for the road ahead for automated commit\nmessage generation to inspire other researchers."
}, {
    "py/object": "data.DataClassPaper",
    "Title": "Reinforcement-Learning-Guided Source Code Summarization via Hierarchical Attention",
    "year": 2020,
    "ML_Techniques": "HAN, EN-DE",
    "Category": "Code summarization",
    "Sub_category": "",
    "Venue": "TSE",
    "Link": "https://ieeexplore.ieee.org/abstract/document/9031440",
    "bibtex": "ARTICLE{Wang2020_434,\n    author = \"{Wang}, W. and {Zhang}, Y. and {Sui}, Y. and {Wan}, Y. and {Zhao}, Z. and {Wu}, J. and {Yu}, P. and {Xu}, G.\",\n    journal = \"IEEE Transactions on Software Engineering\",\n    title = \"Reinforcement-Learning-Guided Source Code Summarization via Hierarchical Attention\",\n    year = \"2020\",\n    volume = \"\",\n    number = \"\",\n    pages = \"1-1\",\n    doi = \"10.1109/TSE.2020.2979701\"\n}\n\n",
    "abstract": "Code summarization (aka comment generation) provides a high-level natural language description of the function performed by code, which can benefit the software maintenance, code categorization and retrieval. To the best of our knowledge, the state-of-the-art approaches follow an encoder-decoder framework which encodes source code into a hidden space and later decodes it into a natural language space. Such approaches suffer from the following drawbacks: (a) they are mainly input by representing code as a sequence of tokens while ignoring code hierarchy; (b) most of the encoders only input simple features (e.g., tokens) while ignoring the features that can help capture the correlations between comments and code; (c) the decoders are typically trained to predict subsequent words by maximizing the likelihood of subsequent ground truth words, while in real world, they are excepted to generate the entire word sequence from scratch. As a result, such drawbacks lead to inferior and inconsistent comment generation accuracy. To address the above limitations, this paper presents a new code summarization approach using hierarchical attention network by incorporating multiple code features, including type-augmented abstract syntax trees and program control flows. Such features, along with plain code sequences, are injected into a deep reinforcement learning (DRL) framework (e.g., actor-critic network) for comment generation. Our approach assigns weights (pays \u201cattention\u201d) to tokens and statements when constructing the code representation to reflect the hierarchical code structure under different contexts regarding code features (e.g., control flows and abstract syntax trees). Our reinforcement learning mechanism further strengthens the prediction results through the actor network and the critic network, where the actor network provides the confidence of predicting subsequent words based on the current state, and the critic network computes the reward values of all the possible extensions of the current state to provide global guidance for explorations. Eventually, we employ an advantage reward to train both networks and conduct a set of experiments on a real-world dataset. The experimental results demonstrate that our approach outperforms the baselines by around 22% to 45% in BLEU-1 and outperforms the state-of-the-art approaches by around 5% to 60% in terms of S-BLEU and C-BLEU."
}, {
    "py/object": "data.DataClassPaper",
    "Title": "Retrieval-based neural source code summarization",
    "year": 2020,
    "ML_Techniques": "LSTM, EN-DE",
    "Category": "Code summarization",
    "Sub_category": "",
    "Venue": "ICSE",
    "Link": "https://dl.acm.org/doi/10.1145/3377811.3380383",
    "bibtex": "ARTICLE{Wang2020_434,\n    author = \"{Wang}, W. and {Zhang}, Y. and {Sui}, Y. and {Wan}, Y. and {Zhao}, Z. and {Wu}, J. and {Yu}, P. and {Xu}, G.\",\n    journal = \"IEEE Transactions on Software Engineering\",\n    title = \"Reinforcement-Learning-Guided Source Code Summarization via Hierarchical Attention\",\n    year = \"2020\",\n    volume = \"\",\n    number = \"\",\n    pages = \"1-1\",\n    doi = \"10.1109/TSE.2020.2979701\"\n}\n\n",
    "abstract": "Source code summarization aims to automatically generate concise\nsummaries of source code in natural language texts, in order to help\ndevelopers better understand and maintain source code. Traditional\nwork generates a source code summary by utilizing information\nretrieval techniques, which select terms from original source code\nor adapt summaries of similar code snippets. Recent studies adopt\nNeural Machine Translation techniques and generate summaries\nfrom code snippets using encoder-decoder neural networks. The\nneural-based approaches prefer the high-frequency words in the\ncorpus and have trouble with the low-frequency ones. In this paper,\nwe propose a retrieval-based neural source code summarization\napproach where we enhance the neural model with the most similar\ncode snippets retrieved from the training set. Our approach\ncan take advantages of both neural and retrieval-based techniques.\nSpecifically, we first train an attentional encoder-decoder model\nbased on the code snippets and the summaries in the training set;\nSecond, given one input code snippet for testing, we retrieve its\ntwo most similar code snippets in the training set from the aspects\nof syntax and semantics, respectively; Third, we encode the input\nand two retrieved code snippets, and predict the summary by fusing\nthem during decoding. We conduct extensive experiments to\nevaluate our approach and the experimental results show that our\nproposed approach can improve the state-of-the-art methods."
}, {
    "py/object": "data.DataClassPaper",
    "Title": "Source code fragment summarization with small-scale crowdsourcing based features",
    "year": 2016,
    "ML_Techniques": "SVM, NB",
    "Category": "Code summarization",
    "Sub_category": "",
    "Venue": "FCS",
    "Link": "https://link.springer.com/article/10.1007/s11704-015-4409-2",
    "bibtex": "article{Nazar2015_437,\n    author = \"Nazar, N. and Jiang, He and Gao, Guojun and Zhang, Tao and Li, Xiaochen and Ren, Zhilei\",\n    title = \"Source code fragment summarization with small-scale crowdsourcing based features\",\n    journal = \"Frontiers of Computer Science\",\n    year = \"2015\",\n    volume = \"10\",\n    pages = \"504-517\"\n}\n\n",
    "abstract": "Recent studies have applied different approaches\nfor summarizing software artifacts, and yet very few efforts\nhave been made in summarizing the source code fragments\navailable on web. This paper investigates the feasibility of\ngenerating code fragment summaries by using supervised\nlearning algorithms.We hire a crowd of ten individuals from\nthe same work place to extract source code features on a corpus\nof 127 code fragments retrieved from Eclipse and Net-\nBeans Official frequently asked questions (FAQs). Human annotators\nsuggest summary lines. Our machine learning algorithms\nproduce better results with the precision of 82% and\nperformstatistically better than existing code fragment classifiers.\nEvaluation of algorithms on several statistical measures\nendorses our result. This result is promising when employing\nmechanisms such as data-driven crowd enlistment improve\nthe efficacy of existing code fragment classifiers."
}, {
    "py/object": "data.DataClassPaper",
    "Title": "Source Code Summarization Using Attention-Based Keyword Memory Networks",
    "year": 2020,
    "ML_Techniques": "LSTM, CNN",
    "Category": "Code summarization",
    "Sub_category": "",
    "Venue": "BigComp",
    "Link": "https://ieeexplore.ieee.org/abstract/document/9070483",
    "bibtex": "INPROCEEDINGS{Choi2020_438,\n    author = \"{Choi}, Y. and {Kim}, S. and {Lee}, J.\",\n    booktitle = \"2020 IEEE International Conference on Big Data and Smart Computing (BigComp)\",\n    title = \"Source Code Summarization Using Attention-Based Keyword Memory Networks\",\n    year = \"2020\",\n    volume = \"\",\n    number = \"\",\n    pages = \"564-570\",\n    doi = \"10.1109/BigComp48618.2020.00011\"\n}\n\n",
    "abstract": "Recently, deep learning techniques have been developed\nfor source code summarization. Most existing studies have simply\nadopted natural language processing techniques, because source\ncode summarization can be considered as machine translation\ntasks from source code into descriptions. However, source code\nand its description are very different, not only in the languages of\nwriting, but also in the purpose of writing. There is a large\nsemantic gap between source codes in programming languages\nand their descriptions in natural languages. To respond to the\nsemantic gap, we propose a two-phase model that consists of a\nkeyword predictor and a description generator. The keyword\npredictor captures the natural language keywords semantically\nassociated with the source code, and the generator generates a\ndescription by referring to the natural language keywords\nprovided by the predictor. Using such keywords as scaffolding, we\ncan effectively reduce the semantic gap and generate more\naccurate descriptions of source codes. To evaluate the proposed\nmethod, we use datasets collected from GitHub and\nStackOverflow. We perform various experiments with these\ndatasets. Our methods show outstanding performance compared\nwith baselines that include state-of-the-art methods, which\nconcludes that keyword prediction is very helpful to the\ngeneration of accurate descriptions."
}, {
    "py/object": "data.DataClassPaper",
    "Title": "Summarizing Software Artifacts: A Literature Review",
    "year": 2016,
    "ML_Techniques": "",
    "Category": "Code summarization",
    "Sub_category": "",
    "Venue": "JCST",
    "Link": "https://link.springer.com/article/10.1007/s11390-016-1671-1",
    "bibtex": "article{Nazar2016_439,\n    author = \"Nazar, N. and Hu, Y. and Jiang, He\",\n    title = \"Summarizing Software Artifacts: A Literature Review\",\n    journal = \"Journal of Computer Science and Technology\",\n    year = \"2016\",\n    volume = \"31\",\n    pages = \"883-909\"\n}\n\n",
    "abstract": "This paper presents a literature review in the field of summarizing software artifacts, focusing on bug reports,\nsource code, mailing lists and developer discussions artifacts. From Jan. 2010 to Apr. 2016, numerous summarization\ntechniques, approaches, and tools have been proposed to satisfy the ongoing demand of improving software performance\nand quality and facilitating developers in understanding the problems at hand. Since aforementioned artifacts contain both\nstructured and unstructured data at the same time, researchers have applied different machine learning and data mining\ntechniques to generate summaries. Therefore, this paper first intends to provide a general perspective on the state of the art,\ndescribing the type of artifacts, approaches for summarization, as well as the common portions of experimental procedures\nshared among these artifacts. Moreover, we discuss the applications of summarization, i.e., what tasks at hand have been\nachieved through summarization. Next, this paper presents tools that are generated for summarization tasks or employed\nduring summarization tasks. In addition, we present different summarization evaluation methods employed in selected\nstudies as well as other important factors that are used for the evaluation of generated summaries such as adequacy and\nquality. Moreover, we briefly present modern communication channels and complementarities with commonalities among\ndifferent software artifacts. Finally, some thoughts about the challenges applicable to the existing studies in general as well\nas future research directions are also discussed. The survey of existing studies will allow future researchers to have a wide\nand useful background knowledge on the main and important aspects of this research field."
}, {
    "py/object": "data.DataClassPaper",
    "Title": "Summarizing Source Code using a Neural Attention Model",
    "year": 2016,
    "ML_Techniques": "LSTM",
    "Category": "Code summarization",
    "Sub_category": "",
    "Venue": "ACL",
    "Link": "https://www.aclweb.org/anthology/P16-1195/",
    "bibtex": "inproceedings{Iyer2016_440,\n    author = \"Iyer, Srinivasan and Konstas, Ioannis and Cheung, Alvin and Zettlemoyer, Luke\",\n    title = \"Summarizing Source Code using a Neural Attention Model\",\n    booktitle = \"Proceedings of the 54th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)\",\n    month = \"August\",\n    year = \"2016\",\n    address = \"Berlin, Germany\",\n    publisher = \"Association for Computational Linguistics\",\n    url = \"https://www.aclweb.org/anthology/P16-1195\",\n    doi = \"10.18653/v1/P16-1195\",\n    pages = \"2073--2083\"\n}\n\n",
    "abstract": "High quality source code is often paired\nwith high level summaries of the computation\nit performs, for example in code\ndocumentation or in descriptions posted\nin online forums. Such summaries are\nextremely useful for applications such as\ncode search but are expensive to manually\nauthor, hence only done for a small fraction\nof all code that is produced. In this\npaper, we present the first completely datadriven\napproach for generating high level\nsummaries of source code. Our model,\nCODE-NN , uses Long Short Term Memory\n(LSTM) networks with attention to\nproduce sentences that describe C# code\nsnippets and SQL queries. CODE-NN\nis trained on a new corpus that is automatically\ncollected from StackOverflow,\nwhich we release. Experiments demonstrate\nstrong performance on two tasks:\n(1) code summarization, where we establish\nthe first end-to-end learning results\nand outperform strong baselines, and (2)\ncode retrieval, where our learned model\nimproves the state of the art on a recently\nintroduced C# benchmark by a large margin."
}, {
    "py/object": "data.DataClassPaper",
    "Title": "Generating Question Titles for Stack Overflow from Mined Code Snippets",
    "year": 2020,
    "ML_Techniques": "Bi-LSTM, EN-DE",
    "Category": "Code summarization",
    "Sub_category": "",
    "Venue": "TOSEM",
    "Link": "https://dl.acm.org/doi/10.1145/3401026",
    "bibtex": "article{Gao2020_441,\n    author = \"Gao, Zhipeng and Xia, Xin and Grundy, John and Lo, David and Li, Yuan-Fang\",\n    title = \"Generating Question Titles for Stack Overflow from Mined Code Snippets\",\n    year = \"2020\",\n    issue_date = \"October 2020\",\n    publisher = \"Association for Computing Machinery\",\n    address = \"New York, NY, USA\",\n    volume = \"29\",\n    number = \"4\",\n    issn = \"1049-331X\",\n    url = \"https://doi.org/10.1145/3401026\",\n    doi = \"10.1145/3401026\",\n    abstract = \"Stack Overflow has been heavily used by software developers as a popular way to seek programming-related information from peers via the internet. The Stack Overflow community recommends users to provide the related code snippet when they are creating a question to help others better understand it and offer their help. Previous studies have shown that a significant number of these questions are of low-quality and not attractive to other potential experts in Stack Overflow. These poorly asked questions are less likely to receive useful answers and hinder the overall knowledge generation and sharing process. Considering one of the reasons for introducing low-quality questions in SO is that many developers may not be able to clarify and summarize the key problems behind their presented code snippets due to their lack of knowledge and terminology related to the problem, and/or their poor writing skills, in this study we propose an approach to assist developers in writing high-quality questions by automatically generating question titles for a code snippet using a deep sequence-to-sequence learning approach. Our approach is fully data-driven and uses an attention mechanism to perform better content selection, a copy mechanism to handle the rare-words problem and a coverage mechanism to eliminate word repetition problem. We evaluate our approach on Stack Overflow datasets over a variety of programming languages (e.g., Python, Java, Javascript, C\\# and SQL) and our experimental results show that our approach significantly outperforms several state-of-the-art baselines in both automatic and human evaluation. We have released our code and datasets to facilitate other researchers to verify their ideas and inspire the follow up work.\",\n    journal = \"ACM Trans. Softw. Eng. Methodol.\",\n    month = \"September\",\n    articleno = \"26\",\n    numpages = \"37\",\n    keywords = \"question quality, question generation, sequence-to-sequence, Stack overflow\"\n}\n\n",
    "abstract": "Stack Overflow has been heavily used by software developers as a popular way to seek programming-related\ninformation from peers via the internet. The Stack Overflow community recommends users to provide the\nrelated code snippet when they are creating a question to help others better understand it and offer their help.\nPrevious studies have shown that a significant number of these questions are of low-quality and not attractive\nto other potential experts in Stack Overflow. These poorly asked questions are less likely to receive useful\nanswers and hinder the overall knowledge generation and sharing process. Considering one of the reasons for\nintroducing low-quality questions in SO is that many developers may not be able to clarify and summarize the\nkey problems behind their presented code snippets due to their lack of knowledge and terminology related to\nthe problem, and/or their poor writing skills, in this study we propose an approach to assist developers in\nwriting high-quality questions by automatically generating question titles for a code snippet using a deep\nsequence-to-sequence learning approach. Our approach is fully data-driven and uses an attention mechanism\nto perform better content selection, a copy mechanism to handle the rare-words problem and a coverage\nmechanism to eliminate word repetition problem. We evaluate our approach on Stack Overflow datasets over\na variety of programming languages (e.g., Python, Java, Javascript, C# and SQL) and our experimental results\nshow that our approach significantly outperforms several state-of-the-art baselines in both automatic and\nhuman evaluation. We have released our code and datasets to facilitate other researchers to verify their ideas\nand inspire the follow up work."
}, {
    "py/object": "data.DataClassPaper",
    "Title": "Improving Code Search with Co-Attentive Representation Learning",
    "year": 2020,
    "ML_Techniques": "CNN",
    "Category": "Code Search",
    "Sub_category": "",
    "Venue": "ICPC",
    "Link": "https://dl.acm.org/doi/10.1145/3387904.3389269",
    "bibtex": "inproceedings{Shuai2020_442,\n    author = \"Shuai, Jianhang and Xu, Ling and Liu, Chao and Yan, Meng and Xia, Xin and Lei, Yan\",\n    title = \"Improving Code Search with Co-Attentive Representation Learning\",\n    year = \"2020\",\n    isbn = \"9781450379588\",\n    publisher = \"Association for Computing Machinery\",\n    address = \"New York, NY, USA\",\n    url = \"https://doi.org/10.1145/3387904.3389269\",\n    doi = \"10.1145/3387904.3389269\",\n    abstract = \"Searching and reusing existing code from a large-scale codebase, e.g, GitHub, can help developers complete a programming task efficiently. Recently, Gu et al. proposed a deep learning-based model (i.e., DeepCS), which significantly outperformed prior models. The DeepCS embedded codebase and natural language queries into vectors by two LSTM (long and short-term memory) models separately, and returned developers the code with higher similarity to a code search query. However, such embedding method learned two isolated representations for code and query but ignored their internal semantic correlations. As a result, the learned isolated representations of code and query may limit the effectiveness of code search.To address the aforementioned issue, we propose a co-attentive representation learning model, i.e., Co-Attentive Representation Learning Code Search-CNN (CARLCS-CNN). CARLCS-CNN learns interdependent representations for the embedded code and query with a co-attention mechanism. Generally, such mechanism learns a correlation matrix between embedded code and query, and co-attends their semantic relationship via row/column-wise max-pooling. In this way, the semantic correlation between code and query can directly affect their individual representations. We evaluate the effectiveness of CARLCS-CNN on Gu et al.'s dataset with 10k queries. Experimental results show that the proposed CARLCS-CNN model significantly outperforms DeepCS by 26.72\\% in terms of MRR (mean reciprocal rank). Additionally, CARLCS-CNN is five times faster than DeepCS in model training and four times in testing.\",\n    booktitle = \"Proceedings of the 28th International Conference on Program Comprehension\",\n    pages = \"196\u2013207\",\n    numpages = \"12\",\n    keywords = \"co-attention mechanism, representation learning, code search\",\n    location = \"Seoul, Republic of Korea\",\n    series = \"ICPC '20\"\n}\n\n",
    "abstract": "Searching and reusing existing code from a large-scale codebase,\ne.g, GitHub, can help developers complete a programming task efficiently.\nRecently, Gu et al. proposed a deep learning-based model\n(i.e., DeepCS), which significantly outperformed prior models. The\nDeepCS embedded codebase and natural language queries into\nvectors by two LSTM (long and short-term memory) models separately,\nand returned developers the code with higher similarity\nto a code search query. However, such embedding method learned\ntwo isolated representations for code and query but ignored their\ninternal semantic correlations. As a result, the learned isolated representations\nof code and query may limit the effectiveness of code\nsearch.\nTo address the aforementioned issue, we propose a co-attentive\nrepresentation learning model, i.e., Co-Attentive Representation\nLearning Code Search-CNN (CARLCS-CNN). CARLCS-CNN learns\ninterdependent representations for the embedded code and query\nwith a co-attention mechanism. Generally, such mechanism learns\na correlation matrix between embedded code and query, and coattends\ntheir semantic relationship via row/column-wise max-pooling.\nIn this way, the semantic correlation between code and query can\ndirectly affect their individual representations. We evaluate the effectiveness\nof CARLCS-CNN on Gu et al.\u2019s dataset with 10k queries.\nExperimental results show that the proposed CARLCS-CNN model\nsignificantly outperforms DeepCS by 26.72% in terms of MRR (mean\nreciprocal rank). Additionally, CARLCS-CNN is five times faster\nthan DeepCS in model training and four times in testing."
}, {
    "py/object": "data.DataClassPaper",
    "Title": "Multi-modal attention network learning for semantic source code retrieval",
    "year": 2019,
    "ML_Techniques": "LSTM, GGNN",
    "Category": "Code Search",
    "Sub_category": "",
    "Venue": "ASE",
    "Link": "https://dl.acm.org/doi/10.1109/ASE.2019.00012",
    "bibtex": "inproceedings{Shuai2020_442,\n    author = \"Shuai, Jianhang and Xu, Ling and Liu, Chao and Yan, Meng and Xia, Xin and Lei, Yan\",\n    title = \"Improving Code Search with Co-Attentive Representation Learning\",\n    year = \"2020\",\n    isbn = \"9781450379588\",\n    publisher = \"Association for Computing Machinery\",\n    address = \"New York, NY, USA\",\n    url = \"https://doi.org/10.1145/3387904.3389269\",\n    doi = \"10.1145/3387904.3389269\",\n    abstract = \"Searching and reusing existing code from a large-scale codebase, e.g, GitHub, can help developers complete a programming task efficiently. Recently, Gu et al. proposed a deep learning-based model (i.e., DeepCS), which significantly outperformed prior models. The DeepCS embedded codebase and natural language queries into vectors by two LSTM (long and short-term memory) models separately, and returned developers the code with higher similarity to a code search query. However, such embedding method learned two isolated representations for code and query but ignored their internal semantic correlations. As a result, the learned isolated representations of code and query may limit the effectiveness of code search.To address the aforementioned issue, we propose a co-attentive representation learning model, i.e., Co-Attentive Representation Learning Code Search-CNN (CARLCS-CNN). CARLCS-CNN learns interdependent representations for the embedded code and query with a co-attention mechanism. Generally, such mechanism learns a correlation matrix between embedded code and query, and co-attends their semantic relationship via row/column-wise max-pooling. In this way, the semantic correlation between code and query can directly affect their individual representations. We evaluate the effectiveness of CARLCS-CNN on Gu et al.'s dataset with 10k queries. Experimental results show that the proposed CARLCS-CNN model significantly outperforms DeepCS by 26.72\\% in terms of MRR (mean reciprocal rank). Additionally, CARLCS-CNN is five times faster than DeepCS in model training and four times in testing.\",\n    booktitle = \"Proceedings of the 28th International Conference on Program Comprehension\",\n    pages = \"196\u2013207\",\n    numpages = \"12\",\n    keywords = \"co-attention mechanism, representation learning, code search\",\n    location = \"Seoul, Republic of Korea\",\n    series = \"ICPC '20\"\n}\n\n",
    "abstract": "Code retrieval techniques and tools have been playing\na key role in facilitating software developers to retrieve\nexisting code fragments from available open-source repositories\ngiven a user query (e.g., a short natural language text describing\nthe functionality for retrieving a particular code snippet). Despite\nthe existing efforts in improving the effectiveness of code retrieval,\nthere are still two main issues hindering them from being used\nto accurately retrieve satisfiable code fragments from largescale\nrepositories when answering complicated queries. First, the\nexisting approaches only consider shallow features of source code\nsuch as method names and code tokens, but ignoring structured\nfeatures such as abstract syntax trees (ASTs) and control-flow\ngraphs (CFGs) of source code, which contains rich and welldefined\nsemantics of source code. Second, although the deep\nlearning-based approach performs well on the representation of\nsource code, it lacks the explainability, making it hard to interpret\nthe retrieval results and almost impossible to understand which\nfeatures of source code contribute more to the final results.\nTo tackle the two aforementioned issues, this paper proposes\nMMAN, a novel Multi-Modal Attention Network for semantic\nsource code retrieval. A comprehensive multi-modal representation\nis developed for representing unstructured and structured\nfeatures of source code, with one LSTM for the sequential tokens\nof code, a Tree-LSTM for the AST of code and a GGNN (Gated\nGraph Neural Network) for the CFG of code. Furthermore, a\nmulti-modal attention fusion layer is applied to assign weights to\ndifferent parts of each modality of source code and then integrate\nthem into a single hybrid representation. Comprehensive experiments\nand analysis on a large-scale real-world dataset show that\nour proposed model can accurately retrieve code snippets and\noutperforms the state-of-the-art methods."
}, {
    "py/object": "data.DataClassPaper",
    "Title": "Retrieval on source code: a neural code search",
    "year": 2018,
    "ML_Techniques": "DNN",
    "Category": "Code Search",
    "Sub_category": "",
    "Venue": "MAPL",
    "Link": "https://dl.acm.org/doi/10.1145/3211346.3211353",
    "bibtex": "inproceedings{Shuai2020_442,\n    author = \"Shuai, Jianhang and Xu, Ling and Liu, Chao and Yan, Meng and Xia, Xin and Lei, Yan\",\n    title = \"Improving Code Search with Co-Attentive Representation Learning\",\n    year = \"2020\",\n    isbn = \"9781450379588\",\n    publisher = \"Association for Computing Machinery\",\n    address = \"New York, NY, USA\",\n    url = \"https://doi.org/10.1145/3387904.3389269\",\n    doi = \"10.1145/3387904.3389269\",\n    abstract = \"Searching and reusing existing code from a large-scale codebase, e.g, GitHub, can help developers complete a programming task efficiently. Recently, Gu et al. proposed a deep learning-based model (i.e., DeepCS), which significantly outperformed prior models. The DeepCS embedded codebase and natural language queries into vectors by two LSTM (long and short-term memory) models separately, and returned developers the code with higher similarity to a code search query. However, such embedding method learned two isolated representations for code and query but ignored their internal semantic correlations. As a result, the learned isolated representations of code and query may limit the effectiveness of code search.To address the aforementioned issue, we propose a co-attentive representation learning model, i.e., Co-Attentive Representation Learning Code Search-CNN (CARLCS-CNN). CARLCS-CNN learns interdependent representations for the embedded code and query with a co-attention mechanism. Generally, such mechanism learns a correlation matrix between embedded code and query, and co-attends their semantic relationship via row/column-wise max-pooling. In this way, the semantic correlation between code and query can directly affect their individual representations. We evaluate the effectiveness of CARLCS-CNN on Gu et al.'s dataset with 10k queries. Experimental results show that the proposed CARLCS-CNN model significantly outperforms DeepCS by 26.72\\% in terms of MRR (mean reciprocal rank). Additionally, CARLCS-CNN is five times faster than DeepCS in model training and four times in testing.\",\n    booktitle = \"Proceedings of the 28th International Conference on Program Comprehension\",\n    pages = \"196\u2013207\",\n    numpages = \"12\",\n    keywords = \"co-attention mechanism, representation learning, code search\",\n    location = \"Seoul, Republic of Korea\",\n    series = \"ICPC '20\"\n}\n\n",
    "abstract": "Searching over large code corpora can be a powerful productivity\ntool for both beginner and experienced developers\nbecause it helps them quickly find examples of code related\nto their intent. Code search becomes even more attractive\nif developers could express their intent in natural language,\nsimilar to the interaction that Stack Overflow supports.\nIn this paper, we investigate the use of natural language\nprocessing and information retrieval techniques to carry\nout natural language search directly over source code, i.e.\nwithout having a curated Q&A forum such as Stack Overflow\nat hand.\nOur experiments using a benchmark suite derived from\nStack Overflow and GitHub repositories show promising\nresults. We find that while a basic word\u2013embedding based\nsearch procedure works acceptably, better results can be\nobtained by adding a layer of supervision, as well as by a\ncustomized ranking strategy."
}, {
    "py/object": "data.DataClassPaper",
    "Title": "A Survey on Source Code Review Using Machine Learning",
    "year": 2018,
    "ML_Techniques": "CNN",
    "Category": "Code review",
    "Sub_category": "",
    "Venue": "ICISE",
    "Link": "https://ieeexplore.ieee.org/abstract/document/8614720",
    "bibtex": "INPROCEEDINGS{Xiaomeng2018_445,\n    author = \"{Xiaomeng}, W. and {Tao}, Z. and {Wei}, X. and {Changyu}, H.\",\n    booktitle = \"2018 3rd International Conference on Information Systems Engineering (ICISE)\",\n    title = \"A Survey on Source Code Review Using Machine Learning\",\n    year = \"2018\",\n    volume = \"\",\n    number = \"\",\n    pages = \"56-60\",\n    doi = \"10.1109/ICISE.2018.00018\"\n}\n\n",
    "abstract": "Source code review constrains software system security\nsufficiently. Scalability and precision are of importance for\nthe deployment of code review tools. However, traditional tools\ncan only detect some security flaws automatically with high\nfalse positive and false negative by tedious reviewing largescale\nsource code. Various flaws and vulnerabilities show specific\ncharacteristic in source code. Machine learning systems\nfounded feature matrixes of source code as input, including\nvariables, functions and files, generating ad-hoc label by distinguish\nor generation methodologies to review source code\nautomatically and intelligently. Source code, whatever the programming\nlanguage, is text information in nature. Both secure\nand vulnerable feature can be curved from source code. Fortunately,\na variety of machine learning approaches have been\ndeveloped to learn and detect flaws and vulnerabilities in intelligent\nsource code security review. Combination of code semantic\nand syntactic feature contribute to the optimation of\nfalse positive and false negative during source code review. In\nthis paper, we give the review of literature related to intelligent\nsource code security review using machine learning methods. It\nillustrate the primary evidence of approaching ML in source\ncode security review. We believe machine learning and its\nbranches will become out-standing in source code review."
}, {
    "py/object": "data.DataClassPaper",
    "Title": "Code review analysis of software system using machine learning techniques",
    "year": 2017,
    "ML_Techniques": "",
    "Category": "Code review",
    "Sub_category": "",
    "Venue": "ISCO",
    "Link": "https://ieeexplore.ieee.org/abstract/document/7855962",
    "bibtex": "INPROCEEDINGS{Lal2017_446,\n    author = \"{Lal}, H. and {Pahwa}, G.\",\n    booktitle = \"2017 11th International Conference on Intelligent Systems and Control (ISCO)\",\n    title = \"Code review analysis of software system using machine learning techniques\",\n    year = \"2017\",\n    volume = \"\",\n    number = \"\",\n    pages = \"8-13\",\n    doi = \"10.1109/ISCO.2017.7855962\"\n}\n\n",
    "abstract": "Code review is systematic examination of a software system's source code. It is intended to find mistakes overlooked in the initial development phase, improving the overall quality of software and reducing the risk of bugs among other benefits. Reviews are done in various forms such as pair programming, informal walk-through, and formal inspections. Code review has been found to accelerate and streamline the process of software development like very few other practices in software development can. In this paper we propose a machine learning approach for the code reviews in a software system. This would help in faster and a cleaner reviews of the checked in code. The proposed approach is evaluated for feasibility on an open source system eclipse. [1], [2], [3]."
}, {
    "py/object": "data.DataClassPaper",
    "Title": "Detecting Defects with an Interactive Code Review Tool Based on Visualisation and Machine Learning",
    "year": 2009,
    "ML_Techniques": "KNN",
    "Category": "Code review",
    "Sub_category": "",
    "Venue": "SEKE",
    "Link": "https://www.diva-portal.org/smash/record.jsf?pid=diva2%3A835773&dswid=-7493",
    "bibtex": "inproceedings{Axelsson2009_447,\n    author = \"Axelsson, S. and Baca, D. and Feldt, Robert and Sidlauskas, Darius and Kacan, Denis\",\n    title = \"Detecting Defects with an Interactive Code Review Tool Based on Visualisation and Machine Learning\",\n    booktitle = \"SEKE\",\n    year = \"2009\"\n}\n\n",
    "abstract": "Code review is often suggested as a means of improving\ncode quality. Since humans are poor at repetitive tasks,\nsome form of tool support is valuable. To that end we developed\na prototype tool to illustrate the novel idea of applying\nmachine learning (based on Normalised Compression\nDistance) to the problem of static analysis of source\ncode. Since this tool learns by example, it is trivially programmer\nadaptable. As machine learning algorithms are\nnotoriously difficult to understand operationally (they are\nopaque) we applied information visualisation to the results\nof the learner. In order to validate the approach we applied\nthe prototype to source code from the open-source project\nSamba and from an industrial, telecom software system.\nOur results showed that the tool did indeed correctly find\nand classify problematic sections of code based on training\nexamples."
}, {
    "py/object": "data.DataClassPaper",
    "Title": "A deep neural network language model with contexts for source code",
    "year": 2018,
    "ML_Techniques": "DNN",
    "Category": "Code representation",
    "Sub_category": "",
    "Venue": "SANER",
    "Link": "https://ieeexplore.ieee.org/document/8330220",
    "bibtex": "INPROCEEDINGS{Nguyen2018_448,\n    author = \"{Nguyen}, A. T. and {Nguyen}, T. D. and {Phan}, H. D. and {Nguyen}, T. N.\",\n    booktitle = \"2018 IEEE 25th International Conference on Software Analysis, Evolution and Reengineering (SANER)\",\n    title = \"A deep neural network language model with contexts for source code\",\n    year = \"2018\",\n    volume = \"\",\n    number = \"\",\n    pages = \"323-334\",\n    doi = \"10.1109/SANER.2018.8330220\"\n}\n\n",
    "abstract": "Statistical language models (LMs) have been applied\nin several software engineering applications. However, they have\nissues in dealing with ambiguities in the names of program and\nAPI elements (classes and method calls). In this paper, inspired by\nthe success of Deep Neural Network (DNN) in natural language\nprocessing, we present Dnn4C, a DNN language model that\ncomplements the local context of lexical code elements with both\nsyntactic and type contexts. We designed a context-incorporating\nmethod to use with syntactic and type annotations for source code\nin order to learn to distinguish the lexical tokens in different\nsyntactic and type contexts. Our empirical evaluation on code\ncompletion for real-world projects shows that Dnn4C relatively\nimproves 11.6%, 16.3%, 27.1%, and 44.7% top-1 accuracy over\nthe state-of-the-art language models for source code used with the\nsame features: RNN LM, DNN LM, SLAMC, and n-gram LM,\nrespectively. For another application, we showed that Dnn4C\nhelps improve accuracy over n-gram LM in migrating source\ncode from Java to C# with a machine translation model."
}, {
    "py/object": "data.DataClassPaper",
    "Title": "A General Path-Based Representation for Predicting Program Properties",
    "year": 2018,
    "ML_Techniques": "",
    "Category": "Code representation",
    "Sub_category": "",
    "Venue": "PLDI",
    "Link": "https://arxiv.org/abs/1803.09544",
    "bibtex": "article{Alon2018_449,\n    author = \"Alon, Uri and Zilberstein, Meital and Levy, Omer and Yahav, Eran\",\n    title = \"A General Path-Based Representation for Predicting Program Properties\",\n    year = \"2018\",\n    issue_date = \"April 2018\",\n    publisher = \"Association for Computing Machinery\",\n    address = \"New York, NY, USA\",\n    volume = \"53\",\n    number = \"4\",\n    issn = \"0362-1340\",\n    url = \"https://doi.org/10.1145/3296979.3192412\",\n    doi = \"10.1145/3296979.3192412\",\n    abstract = \"Predicting program properties such as names or expression types has a wide range of applications. It can ease the task of programming, and increase programmer productivity. A major challenge when learning from programs is how to represent programs in a way that facilitates effective learning. We present a general path-based representation for learning from programs. Our representation is purely syntactic and extracted automatically. The main idea is to represent a program using paths in its abstract syntax tree (AST). This allows a learning model to leverage the structured nature of code rather than treating it as a flat sequence of tokens. We show that this representation is general and can: (i) cover different prediction tasks, (ii) drive different learning algorithms (for both generative and discriminative models), and (iii) work across different programming languages. We evaluate our approach on the tasks of predicting variable names, method names, and full types. We use our representation to drive both CRF-based and word2vec-based learning, for programs of four languages: JavaScript, Java, Python and C\\#. Our evaluation shows that our approach obtains better results than task-specific handcrafted representations across different tasks and programming languages.\",\n    journal = \"SIGPLAN Not.\",\n    month = \"June\",\n    pages = \"404\u2013419\",\n    numpages = \"16\",\n    keywords = \"Machine Learning, Learning Representations, Big Code, Programming Languages\"\n}\n\n",
    "abstract": "Predicting program properties such as names or expression\ntypes has a wide range of applications. It can ease the task\nof programming, and increase programmer productivity. A\nmajor challenge when learning from programs is how to represent\nprograms in a way that facilitates effective learning.\nWe present a general path-based representation for learning\nfrom programs. Our representation is purely syntactic\nand extracted automatically. The main idea is to represent a\nprogram using paths in its abstract syntax tree (AST). This\nallows a learning model to leverage the structured nature of\ncode rather than treating it as a flat sequence of tokens.\nWe show that this representation is general and can: (i) cover\ndifferent prediction tasks, (ii) drive different learning algorithms\n(for both generative and discriminative models), and\n(iii) work across different programming languages.\nWe evaluate our approach on the tasks of predicting variable\nnames, method names, and full types. We use our representation\nto drive both CRF-based and word2vec-based learning,\nfor programs of four languages: JavaScript, Java, Python\nand C#. Our evaluation shows that our approach obtains better\nresults than task-specific handcrafted representations across\ndifferent tasks and programming languages."
}, {
    "py/object": "data.DataClassPaper",
    "Title": "A multi-task representation learning approach for source code",
    "year": 2020,
    "ML_Techniques": "BERT, EN-DE",
    "Category": "Code representation",
    "Sub_category": "",
    "Venue": "RL+SE&PL",
    "Link": "https://dl.acm.org/doi/10.1145/3416506.3423575",
    "bibtex": "article{Alon2018_449,\n    author = \"Alon, Uri and Zilberstein, Meital and Levy, Omer and Yahav, Eran\",\n    title = \"A General Path-Based Representation for Predicting Program Properties\",\n    year = \"2018\",\n    issue_date = \"April 2018\",\n    publisher = \"Association for Computing Machinery\",\n    address = \"New York, NY, USA\",\n    volume = \"53\",\n    number = \"4\",\n    issn = \"0362-1340\",\n    url = \"https://doi.org/10.1145/3296979.3192412\",\n    doi = \"10.1145/3296979.3192412\",\n    abstract = \"Predicting program properties such as names or expression types has a wide range of applications. It can ease the task of programming, and increase programmer productivity. A major challenge when learning from programs is how to represent programs in a way that facilitates effective learning. We present a general path-based representation for learning from programs. Our representation is purely syntactic and extracted automatically. The main idea is to represent a program using paths in its abstract syntax tree (AST). This allows a learning model to leverage the structured nature of code rather than treating it as a flat sequence of tokens. We show that this representation is general and can: (i) cover different prediction tasks, (ii) drive different learning algorithms (for both generative and discriminative models), and (iii) work across different programming languages. We evaluate our approach on the tasks of predicting variable names, method names, and full types. We use our representation to drive both CRF-based and word2vec-based learning, for programs of four languages: JavaScript, Java, Python and C\\#. Our evaluation shows that our approach obtains better results than task-specific handcrafted representations across different tasks and programming languages.\",\n    journal = \"SIGPLAN Not.\",\n    month = \"June\",\n    pages = \"404\u2013419\",\n    numpages = \"16\",\n    keywords = \"Machine Learning, Learning Representations, Big Code, Programming Languages\"\n}\n\n",
    "abstract": "Representation learning has shown impressive results for a multitude\nof tasks in software engineering. However, most researches\nstill focus on a single problem. As a result, the learned representations\ncannot be applied to other problems and lack generalizability\nand interpretability. In this paper, we propose a Multi-task learning\napproach for representation learning across multiple downstream\ntasks of software engineering. From the perspective of generalization,\nwe build a shared sequence encoder with a pretrained BERT\nfor the token sequence and a structure encoder with a Tree-LSTM\nfor the abstract syntax tree of code. From the perspective of interpretability,\nwe integrate attention mechanism to focus on different\nrepresentations and set learnable parameters to adjust the relationship\nbetween tasks. We also present the early results of our model.\nThe learning process analysis shows our model has a significant\nimprovement over strong baselines."
}, {
    "py/object": "data.DataClassPaper",
    "Title": "A Novel Neural Source Code Representation based on Abstract Syntax Tree",
    "year": 2019,
    "ML_Techniques": "Bi-GRU",
    "Category": "Code representation",
    "Sub_category": "",
    "Venue": "ICSE",
    "Link": "http://xuwang.tech/paper/astnn_icse2019.pdf",
    "bibtex": "article{Alon2018_449,\n    author = \"Alon, Uri and Zilberstein, Meital and Levy, Omer and Yahav, Eran\",\n    title = \"A General Path-Based Representation for Predicting Program Properties\",\n    year = \"2018\",\n    issue_date = \"April 2018\",\n    publisher = \"Association for Computing Machinery\",\n    address = \"New York, NY, USA\",\n    volume = \"53\",\n    number = \"4\",\n    issn = \"0362-1340\",\n    url = \"https://doi.org/10.1145/3296979.3192412\",\n    doi = \"10.1145/3296979.3192412\",\n    abstract = \"Predicting program properties such as names or expression types has a wide range of applications. It can ease the task of programming, and increase programmer productivity. A major challenge when learning from programs is how to represent programs in a way that facilitates effective learning. We present a general path-based representation for learning from programs. Our representation is purely syntactic and extracted automatically. The main idea is to represent a program using paths in its abstract syntax tree (AST). This allows a learning model to leverage the structured nature of code rather than treating it as a flat sequence of tokens. We show that this representation is general and can: (i) cover different prediction tasks, (ii) drive different learning algorithms (for both generative and discriminative models), and (iii) work across different programming languages. We evaluate our approach on the tasks of predicting variable names, method names, and full types. We use our representation to drive both CRF-based and word2vec-based learning, for programs of four languages: JavaScript, Java, Python and C\\#. Our evaluation shows that our approach obtains better results than task-specific handcrafted representations across different tasks and programming languages.\",\n    journal = \"SIGPLAN Not.\",\n    month = \"June\",\n    pages = \"404\u2013419\",\n    numpages = \"16\",\n    keywords = \"Machine Learning, Learning Representations, Big Code, Programming Languages\"\n}\n\n",
    "abstract": "Exploiting machine learning techniques for analyzing\nprograms has attracted much attention. One key problem\nis how to represent code fragments well for follow-up analysis.\nTraditional information retrieval based methods often treat\nprograms as natural language texts, which could miss important\nsemantic information of source code. Recently, state-of-the-art\nstudies demonstrate that abstract syntax tree (AST) based neural\nmodels can better represent source code. However, the sizes of\nASTs are usually large and the existing models are prone to\nthe long-term dependency problem. In this paper, we propose\na novel AST-based Neural Network (ASTNN) for source code\nrepresentation. Unlike existing models that work on entire ASTs,\nASTNN splits each large AST into a sequence of small statement\ntrees, and encodes the statement trees to vectors by capturing\nthe lexical and syntactical knowledge of statements. Based on the\nsequence of statement vectors, a bidirectional RNN model is used\nto leverage the naturalness of statements and finally produce the\nvector representation of a code fragment. We have applied our\nneural network based source code representation method to two\ncommon program comprehension tasks: source code classification\nand code clone detection. Experimental results on the two tasks\nindicate that our model is superior to state-of-the-art approaches"
}, {
    "py/object": "data.DataClassPaper",
    "Title": "A Survey of Machine Learning for Big Code and Naturalness",
    "year": 2018,
    "ML_Techniques": "",
    "Category": "Code representation",
    "Sub_category": "",
    "Venue": "CSUR",
    "Link": "https://arxiv.org/abs/1709.06182v1",
    "bibtex": "article{Allamanis2018_452,\n    author = \"Allamanis, Miltiadis and Barr, Earl T. and Devanbu, Premkumar and Sutton, Charles\",\n    title = \"A Survey of Machine Learning for Big Code and Naturalness\",\n    year = \"2018\",\n    issue_date = \"September 2018\",\n    publisher = \"Association for Computing Machinery\",\n    address = \"New York, NY, USA\",\n    volume = \"51\",\n    number = \"4\",\n    issn = \"0360-0300\",\n    url = \"https://doi.org/10.1145/3212695\",\n    doi = \"10.1145/3212695\",\n    abstract = \"Research at the intersection of machine learning, programming languages, and software engineering has recently taken important steps in proposing learnable probabilistic models of source code that exploit the abundance of patterns of code. In this article, we survey this work. We contrast programming languages against natural languages and discuss how these similarities and differences drive the design of probabilistic models. We present a taxonomy based on the underlying design principles of each model and use it to navigate the literature. Then, we review how researchers have adapted these models to application areas and discuss cross-cutting and application-specific challenges and opportunities.\",\n    journal = \"ACM Comput. Surv.\",\n    month = \"July\",\n    articleno = \"81\",\n    numpages = \"37\",\n    keywords = \"software engineering tools, Big code, code naturalness, machine learning\"\n}\n\n",
    "abstract": "Research at the intersection of machine learning, programming languages, and software engineering has\nrecently taken important steps in proposing learnable probabilistic models of source code that exploit the\nabundance of patterns of code. In this article, we survey this work. We contrast programming languages\nagainst natural languages and discuss how these similarities and differences drive the design of probabilistic\nmodels.We present a taxonomy based on the underlying design principles of eachmodel and use it to navigate\nthe literature. Then, we review how researchers have adapted these models to application areas and discuss\ncross-cutting and application-specific challenges and opportunities."
}, {
    "py/object": "data.DataClassPaper",
    "Title": "Applying Code Vectors for Presenting Software Features in Machine Learning",
    "year": 2018,
    "ML_Techniques": "SVM",
    "Category": "Code representation",
    "Sub_category": "",
    "Venue": "COMPSAC",
    "Link": "https://ieeexplore.ieee.org/document/8377753",
    "bibtex": "INPROCEEDINGS{Lim2018_453,\n    author = \"{Lim}, H.\",\n    booktitle = \"2018 IEEE 42nd Annual Computer Software and Applications Conference (COMPSAC)\",\n    title = \"Applying Code Vectors for Presenting Software Features in Machine Learning\",\n    year = \"2018\",\n    volume = \"01\",\n    number = \"\",\n    pages = \"803-804\",\n    doi = \"10.1109/COMPSAC.2018.00128\"\n}\n\n",
    "abstract": "Machine learning is a statistical approach to give\nmachines the ability to learn with data, without being explicitly\nprogrammed. This approach is widely used in various areas with\ncomplex problems, such as image recognition, speech recognition,\nregression, classification, and prediction. The most important\nfactor is how to express the characteristics of the data being\nanalyzed. In this paper, we present code vectors as training data\nfor presenting software features in software analysis, and give\navailability results for applying code vectors in machine learning\napproach for analyzing software through experiments with Java\napplications."
}, {
    "py/object": "data.DataClassPaper",
    "Title": "Applying probabilistic models to C++ code on an industrial scale",
    "year": 2020,
    "ML_Techniques": "",
    "Category": "Code representation",
    "Sub_category": "",
    "Venue": "ICSEW",
    "Link": "https://dl.acm.org/doi/10.1145/3387940.3391477",
    "bibtex": "INPROCEEDINGS{Lim2018_453,\n    author = \"{Lim}, H.\",\n    booktitle = \"2018 IEEE 42nd Annual Computer Software and Applications Conference (COMPSAC)\",\n    title = \"Applying Code Vectors for Presenting Software Features in Machine Learning\",\n    year = \"2018\",\n    volume = \"01\",\n    number = \"\",\n    pages = \"803-804\",\n    doi = \"10.1109/COMPSAC.2018.00128\"\n}\n\n",
    "abstract": "Machine learning approaches are widely applied to different re\nsearch\ntasks of software engineering, but C/C++ code presents a\nchallenge for these approaches because of its complex build system.\nHowever, C and C++ languages still remain two of the most popular\nprogramming languages, especially in industrial software, where\na big amount of legacy code is still used. This fact prevents the\napplication of recent advances in probabilistic modeling of source\ncode to the C/C++ domain.\nWe demonstrate that it is possible to at least partially overcome\nthese difficulties by the use of a simple token-based representation\nof C/C++ code that can be used as a possible replacement for more\nprecise representations. Enriched token representation is verifie\nat a large scale to ensure that its precision is good enough to learn\nrules from.\nWe consider two different tasks as an application of this represen\ntation:\ncoding style detection and API usage anomaly detection.We\napply simple probabilistic models to these tasks and demonstrate\nthat even complex coding style rules and API usage patterns can\nbe detected by the means of this representation.\nThis paper provides a vision of how different research ML-based\nmethods for software engineering could be applied to the domain of\nC/C++ languages and show how they can be applied to the source\ncode of a large software company like Samsung."
}, {
    "py/object": "data.DataClassPaper",
    "Title": "Are Deep Neural Networks the Best Choice for Modeling Source Code",
    "year": 2017,
    "ML_Techniques": "",
    "Category": "Code representation",
    "Sub_category": "",
    "Venue": "FSE",
    "Link": "https://web.cs.ucdavis.edu/~devanbu/isDLgood.pdf",
    "bibtex": "inproceedings{Hellendoorn2017_455,\n    author = \"Hellendoorn, Vincent J. and Devanbu, Premkumar\",\n    title = \"Are Deep Neural Networks the Best Choice for Modeling Source Code?\",\n    year = \"2017\",\n    isbn = \"9781450351058\",\n    publisher = \"Association for Computing Machinery\",\n    address = \"New York, NY, USA\",\n    url = \"https://doi.org/10.1145/3106237.3106290\",\n    doi = \"10.1145/3106237.3106290\",\n    booktitle = \"Proceedings of the 2017 11th Joint Meeting on Foundations of Software Engineering\",\n    pages = \"763\u2013773\",\n    numpages = \"11\",\n    keywords = \"software tools, naturalness, language models\",\n    location = \"Paderborn, Germany\",\n    series = \"ESEC/FSE 2017\"\n}\n\n",
    "abstract": "Current statistical language modeling techniques, including deeplearning\nbased models, have proven to be quite effective for source\ncode. We argue here that the special properties of source code can\nbe exploited for further improvements. In this work, we enhance\nestablished language modeling approaches to handle the special\nchallenges of modeling source code, such as: frequent changes,\nlarger, changing vocabularies, deeply nested scopes, etc.We present\na fast, nested language modeling toolkit specifically designed for\nsoftware, with the ability to add & remove text, and mix & swap out\nmany models. Specifically, we improve upon prior cache-modeling\nwork and present a model with a much more expansive, multi-level\nnotion of locality that we show to be well-suited for modeling\nsoftware. We present results on varying corpora in comparison\nwith traditional N-gram, as well as RNN, and LSTM deep-learning\nlanguage models, and release all our source code for public use.\nOur evaluations suggest that carefully adapting N-gram models for\nsource code can yield performance that"
}, {
    "py/object": "data.DataClassPaper",
    "Title": "Big code != big vocabulary: open-vocabulary models for source code",
    "year": 2020,
    "ML_Techniques": "RNN GRU",
    "Category": "Code representation",
    "Sub_category": "",
    "Venue": "ICSE",
    "Link": "https://dl.acm.org/doi/10.1145/3377811.3380342",
    "bibtex": "inproceedings{Hellendoorn2017_455,\n    author = \"Hellendoorn, Vincent J. and Devanbu, Premkumar\",\n    title = \"Are Deep Neural Networks the Best Choice for Modeling Source Code?\",\n    year = \"2017\",\n    isbn = \"9781450351058\",\n    publisher = \"Association for Computing Machinery\",\n    address = \"New York, NY, USA\",\n    url = \"https://doi.org/10.1145/3106237.3106290\",\n    doi = \"10.1145/3106237.3106290\",\n    booktitle = \"Proceedings of the 2017 11th Joint Meeting on Foundations of Software Engineering\",\n    pages = \"763\u2013773\",\n    numpages = \"11\",\n    keywords = \"software tools, naturalness, language models\",\n    location = \"Paderborn, Germany\",\n    series = \"ESEC/FSE 2017\"\n}\n\n",
    "abstract": "Statistical language modeling techniques have successfully been\napplied to large source code corpora, yielding a variety of new\nsoftware development tools, such as tools for code suggestion, improving\nreadability, and API migration. A major issue with these\ntechniques is that code introduces new vocabulary at a far higher\nrate than natural language, as new identifier names proliferate.\nBoth large vocabularies and out-of-vocabulary issues severely affect\nNeural Language Models (NLMs) of source code, degrading\ntheir performance and rendering them unable to scale.\nIn this paper, we address this issue by: 1) studying how various\nmodelling choices impact the resulting vocabulary on a large-scale\ncorpus of 13,362 projects; 2) presenting an open vocabulary source\ncode NLM that can scale to such a corpus, 100 times larger than in\nprevious work; and 3) showing that such models outperform the\nstate of the art on three distinct code corpora (Java, C, Python). To\nour knowledge, these are the largest NLMs for code that have been\nreported."
}, {
    "py/object": "data.DataClassPaper",
    "Title": "Bimodal modelling of source code and natural language",
    "year": 2015,
    "ML_Techniques": "",
    "Category": "Code representation",
    "Sub_category": "",
    "Venue": "ICML",
    "Link": "https://dl.acm.org/doi/10.5555/3045118.3045344",
    "bibtex": "inproceedings{Hellendoorn2017_455,\n    author = \"Hellendoorn, Vincent J. and Devanbu, Premkumar\",\n    title = \"Are Deep Neural Networks the Best Choice for Modeling Source Code?\",\n    year = \"2017\",\n    isbn = \"9781450351058\",\n    publisher = \"Association for Computing Machinery\",\n    address = \"New York, NY, USA\",\n    url = \"https://doi.org/10.1145/3106237.3106290\",\n    doi = \"10.1145/3106237.3106290\",\n    booktitle = \"Proceedings of the 2017 11th Joint Meeting on Foundations of Software Engineering\",\n    pages = \"763\u2013773\",\n    numpages = \"11\",\n    keywords = \"software tools, naturalness, language models\",\n    location = \"Paderborn, Germany\",\n    series = \"ESEC/FSE 2017\"\n}\n\n",
    "abstract": "We consider the problem of building probabilistic\nmodels that jointly model short natural language\nutterances and source code snippets. The aim is to\nbring together recent work on statistical modelling\nof source code and work on bimodal models of\nimages and natural language. The resulting models\nare useful for a variety of tasks that involve\nnatural language and source code. We demonstrate\ntheir performance on two retrieval tasks:\nretrieving source code snippets given a natural language\nquery, and retrieving natural language descriptions\ngiven a source code query (i.e., source\ncode captioning). Experiments show there to be\npromise in this direction, and that modelling the\nstructure of source code improves performance."
}, {
    "py/object": "data.DataClassPaper",
    "Title": "Building Implicit Vector Representations of Individual Coding Style",
    "year": 2020,
    "ML_Techniques": "",
    "Category": "Code representation",
    "Sub_category": "",
    "Venue": "ICSEW",
    "Link": "https://dl.acm.org/doi/10.1145/3387940.3391494",
    "bibtex": "inproceedings{Kovalenko2020_458,\n    author = \"Kovalenko, Vladimir and Bogomolov, Egor and Bryksin, Timofey and Bacchelli, Alberto\",\n    title = \"Building Implicit Vector Representations of Individual Coding Style\",\n    year = \"2020\",\n    isbn = \"9781450379632\",\n    publisher = \"Association for Computing Machinery\",\n    address = \"New York, NY, USA\",\n    url = \"https://doi.org/10.1145/3387940.3391494\",\n    doi = \"10.1145/3387940.3391494\",\n    abstract = \"We propose a new approach to building vector representations of individual developers by capturing their individual contribution style, or coding style. Such representations can find use in the next generation of software development team collaboration tools, for example by enabling the tools to track knowledge transfer in teams. The key idea of our approach is to avoid using explicitly defined metrics of coding style and instead build the representations through training a model for authorship recognition and extracting the representations of individual developers from the trained model. By empirically evaluating the output of our approach, we find that implicitly built individual representations reflect some properties of team structure: developers who report learning from each other are represented closer to each other.\",\n    booktitle = \"Proceedings of the IEEE/ACM 42nd International Conference on Software Engineering Workshops\",\n    pages = \"117\u2013124\",\n    numpages = \"8\",\n    location = \"Seoul, Republic of Korea\",\n    series = \"ICSEW'20\"\n}\n\n",
    "abstract": "With the goal of facilitating team collaboration, we propose a new approach to building vector representations of individual developers by capturing their individual contribution style, or coding style. Such representations can find use in the next generation of software development team collaboration tools, for example by enabling the tools to track knowledge transfer in teams. The key idea of our approach is to avoid using explicitly defined metrics of coding style and instead build the representations through training a model for authorship recognition and extracting the representations of individual developers from the trained model. By empirically evaluating the output of our approach, we find that implicitly built individual representations reflect some properties of team structure: developers who report learning from each other are represented closer to each other."
}, {
    "py/object": "data.DataClassPaper",
    "Title": "Can Latent Topics in Source Code Predict Missing Architectural Tactics?",
    "year": 2017,
    "ML_Techniques": "RF, LOG, NN, LDA",
    "Category": "Code completion",
    "Sub_category": "",
    "Venue": "ICSE",
    "Link": "https://ieeexplore.ieee.org/document/7985646",
    "bibtex": "INPROCEEDINGS{Gopalakrishnan2017_459,\n    author = \"{Gopalakrishnan}, R. and {Sharma}, P. and {Mirakhorli}, M. and {Galster}, M.\",\n    booktitle = \"2017 IEEE/ACM 39th International Conference on Software Engineering (ICSE)\",\n    title = \"Can Latent Topics in Source Code Predict Missing Architectural Tactics?\",\n    year = \"2017\",\n    volume = \"\",\n    number = \"\",\n    pages = \"15-26\",\n    doi = \"10.1109/ICSE.2017.10\"\n}\n\n",
    "abstract": "Architectural tactics such as heartbeat, resource pooling, and scheduling provide solutions to satisfy reliability, security, performance, and other critical characteristics of a software system. Current design practices advocate rigorous up-front analysis of the systems quality concerns to identify tactics and where in the code they should be used. In this paper, we explore a bottom-up approach to recommend architectural tactics based on latent topics discovered in the source code of projects. We present a recommender system developed by building predictor models which capture relationships between topical concepts in source code and the use of specific architectural tactics in that code. Based on an extensive analysis of over 116,000 open source systems, we identify significant correlations between latent topics in source code and the usage of architectural tactics. We use this information to construct a predictor for generating tactic recommendations. Our approach is validated through a series of experiments which demonstrate the ability to generate package-level tactic recommendations. We provide further validation via two large-scale studies of Apache Hive and Hadoop to illustrate that our recommender system predicts tactics that are actually implemented by developers in later releases."
}, {
    "py/object": "data.DataClassPaper",
    "Title": "Capturing source code semantics via tree-based convolution over API-enhanced AST",
    "year": 2019,
    "ML_Techniques": "CNN",
    "Category": "Code representation",
    "Sub_category": "",
    "Venue": "CF",
    "Link": "https://dl.acm.org/doi/10.1145/3310273.3321560",
    "bibtex": "INPROCEEDINGS{Gopalakrishnan2017_459,\n    author = \"{Gopalakrishnan}, R. and {Sharma}, P. and {Mirakhorli}, M. and {Galster}, M.\",\n    booktitle = \"2017 IEEE/ACM 39th International Conference on Software Engineering (ICSE)\",\n    title = \"Can Latent Topics in Source Code Predict Missing Architectural Tactics?\",\n    year = \"2017\",\n    volume = \"\",\n    number = \"\",\n    pages = \"15-26\",\n    doi = \"10.1109/ICSE.2017.10\"\n}\n\n",
    "abstract": "When deep learning meets big code, a key question is how to efficiently\nlearn a distributed representation for source code that\ncan capture its semantics effectively. We propose to use tree-based\nconvolution over API-enhanced AST. To demonstrate the effectiveness\nof our approach, we apply it to detect semantic clones\u2014\ncode fragments with similar semantics but dissimilar syntax. Experiment\nresults show that our approach outperforms an existing\nstate-of-the-art approach that uses tree-based LSTM, with an increase\nof 0.39 and 0.12 in F1-score on OJClone and BigCloneBench\nrespectively. We further propose architectures that incorporate our\napproach for code search and code summarization."
}, {
    "py/object": "data.DataClassPaper",
    "Title": "CC2Vec: distributed representations of code changes",
    "year": 2020,
    "ML_Techniques": "HAN, EN-DE",
    "Category": "Code representation",
    "Sub_category": "",
    "Venue": "ICSE",
    "Link": "https://dl.acm.org/doi/10.1145/3377811.3380361",
    "bibtex": "INPROCEEDINGS{Gopalakrishnan2017_459,\n    author = \"{Gopalakrishnan}, R. and {Sharma}, P. and {Mirakhorli}, M. and {Galster}, M.\",\n    booktitle = \"2017 IEEE/ACM 39th International Conference on Software Engineering (ICSE)\",\n    title = \"Can Latent Topics in Source Code Predict Missing Architectural Tactics?\",\n    year = \"2017\",\n    volume = \"\",\n    number = \"\",\n    pages = \"15-26\",\n    doi = \"10.1109/ICSE.2017.10\"\n}\n\n",
    "abstract": "Existing work on software patches often use features specific to a\nsingle task. These works often rely on manually identified features,\nand human effort is required to identify these features for each\ntask. In this work, we propose CC2Vec, a neural network model\nthat learns a representation of code changes guided by their accompanying\nlog messages, which represent the semantic intent of\nthe code changes. CC2Vec models the hierarchical structure of a\ncode change with the help of the attention mechanism and uses\nmultiple comparison functions to identify the differences between\nthe removed and added code.\nTo evaluate if CC2Vec can produce a distributed representation\nof code changes that is general and useful for multiple tasks on\nsoftware patches, we use the vectors produced by CC2Vec for three\ntasks: log message generation, bug fixing patch identification, and\njust-in-time defect prediction. In all tasks, the models using CC2Vec\noutperform the state-of-the-art techniques."
}, {
    "py/object": "data.DataClassPaper",
    "Title": "Code vectors: understanding programs through embedded abstracted symbolic traces",
    "year": 2018,
    "ML_Techniques": "Glove",
    "Category": "Code representation",
    "Sub_category": "",
    "Venue": "FSE",
    "Link": "https://dl.acm.org/doi/10.1145/3236024.3236085",
    "bibtex": "INPROCEEDINGS{Gopalakrishnan2017_459,\n    author = \"{Gopalakrishnan}, R. and {Sharma}, P. and {Mirakhorli}, M. and {Galster}, M.\",\n    booktitle = \"2017 IEEE/ACM 39th International Conference on Software Engineering (ICSE)\",\n    title = \"Can Latent Topics in Source Code Predict Missing Architectural Tactics?\",\n    year = \"2017\",\n    volume = \"\",\n    number = \"\",\n    pages = \"15-26\",\n    doi = \"10.1109/ICSE.2017.10\"\n}\n\n",
    "abstract": "With the rise of machine learning, there is a great deal of interest in\ntreating programs as data to be fed to learning algorithms. However,\nprograms do not start off in a form that is immediately amenable\nto most off-the-shelf learning techniques. Instead, it is necessary to\ntransform the program to a suitable representation before a learning\ntechnique can be applied.\nIn this paper, we use abstractions of traces obtained from symbolic\nexecution of a program as a representation for learning word\nembeddings. We trained a variety of word embeddings under hundreds\nof parameterizations, and evaluated each learned embedding\non a suite of different tasks. In our evaluation, we obtain 93% top-1\naccuracy on a benchmark consisting of over 19,000 API-usage analogies\nextracted from the Linux kernel. In addition, we show that\nembeddings learned from (mainly) semantic abstractions provide\nnearly triple the accuracy of those learned from (mainly) syntactic\nabstractions."
}, {
    "py/object": "data.DataClassPaper",
    "Title": "code2seq: Generating Sequences from Structured Representations of Code",
    "year": 2019,
    "ML_Techniques": "EN-DE, LSTM",
    "Category": "Code representation",
    "Sub_category": "",
    "Venue": "ICLR",
    "Link": "https://arxiv.org/abs/1808.01400",
    "bibtex": "misc{Alon2019_463,\n    author = \"Alon, Uri and Brody, Shaked and Levy, Omer and Yahav, Eran\",\n    title = \"code2seq: Generating Sequences from Structured Representations of Code\",\n    year = \"2019\",\n    eprint = \"1808.01400\",\n    archivePrefix = \"arXiv\",\n    primaryClass = \"cs.LG\"\n}\n\n",
    "abstract": "The ability to generate natural language sequences from source code snippets has\na variety of applications such as code summarization, documentation, and retrieval.\nSequence-to-sequence (seq2seq) models, adopted from neural machine\ntranslation (NMT), have achieved state-of-the-art performance on these tasks by\ntreating source code as a sequence of tokens. We present CODE2SEQ: an alternative\napproach that leverages the syntactic structure of programming languages\nto better encode source code. Our model represents a code snippet as\nthe set of compositional paths in its abstract syntax tree (AST) and uses attention\nto select the relevant paths while decoding. We demonstrate the effectiveness\nof our approach for two tasks, two programming languages, and four\ndatasets of up to 16M examples. Our model significantly outperforms previous\nmodels that were specifically designed for programming languages, as well\nas state-of-the-art NMT models. An online demo of our model is available at\nhttp://code2seq.org. Our code, data and trained models are available at\nhttp://github.com/tech-srl/code2seq."
}, {
    "py/object": "data.DataClassPaper",
    "Title": "code2vec: Learning Distributed Representations of Code",
    "year": 2019,
    "ML_Techniques": "Code2Vec",
    "Category": "Code representation",
    "Sub_category": "",
    "Venue": "POPL",
    "Link": "https://arxiv.org/abs/1803.09473v2",
    "bibtex": "misc{Alon2019_463,\n    author = \"Alon, Uri and Brody, Shaked and Levy, Omer and Yahav, Eran\",\n    title = \"code2seq: Generating Sequences from Structured Representations of Code\",\n    year = \"2019\",\n    eprint = \"1808.01400\",\n    archivePrefix = \"arXiv\",\n    primaryClass = \"cs.LG\"\n}\n\n",
    "abstract": "We present a neural model for representing snippets of code as continuous distributed vectors. The main idea\nis to represent code as a collection of paths in its abstract syntax tree, and aggregate these paths, in a smart and\nscalable way, into a single fixed-length code vector, which can be used to predict semantic properties of the\nsnippet.\nWe demonstrate the effectiveness of our approach by using it to predict a method\u2019s name from the vector\nrepresentation of its body. We evaluate our approach by training a model on a dataset of 14M methods. We show\nthat code vectors trained on this dataset can predict method names from files that were completely unobserved\nduring training. Furthermore, we show that our model learns useful method name vectors that capture semantic\nsimilarities, combinations, and analogies.\nComparing previous techniques over the same data set, our approach obtains a relative improvement of over\n75%, being the first to successfully predict method names based on a large, cross-project, corpus."
}, {
    "py/object": "data.DataClassPaper",
    "Title": "Compiler-based graph representations for deep learning models of code",
    "year": 2020,
    "ML_Techniques": "GNN",
    "Category": "Code representation",
    "Sub_category": "",
    "Venue": "CC",
    "Link": "https://dl.acm.org/doi/10.1145/3377555.3377894",
    "bibtex": "misc{Alon2019_463,\n    author = \"Alon, Uri and Brody, Shaked and Levy, Omer and Yahav, Eran\",\n    title = \"code2seq: Generating Sequences from Structured Representations of Code\",\n    year = \"2019\",\n    eprint = \"1808.01400\",\n    archivePrefix = \"arXiv\",\n    primaryClass = \"cs.LG\"\n}\n\n",
    "abstract": "In natural language processing, novel methods in deep learning,\nlike recurrent neural networks (RNNs) on sequences of\nwords, have been very successful. In contrast to natural languages,\nprogramming languages usually have a well-defined\nstructure. With this structure compilers can reason about\nprograms, using graphs such as abstract syntax trees (ASTs)\nor control-data flow graphs (CDFGs). In this paper, we argue\nthat we should use these graph structures instead of\nsequences for learning compiler optimization tasks. To this\nend, we use graph neural networks (GNNs) for learning predictive\ncompiler tasks on two representations based on ASTs\nand CDFGs. Experiments show that this improves upon the\nstate-of-the-art in the task of heterogeneous OpenCL mapping,\nwhile providing orders of magnitude faster inference\ntimes, crucial for compiler optimizations. When testing on\nbenchmark suites not included for training, our AST-based\nmodel significantly outperforms the state-of-the-art by over\n12 percentage points in terms of accuracy. It is the only one\nto perform clearly better than a random mapping. On the\ntask of predicting thread coarsening factors, we show that\nall of the methods fail to produce an overall speedup."
}, {
    "py/object": "data.DataClassPaper",
    "Title": "Convolutional Neural Networks over Tree Structures for Programming Language Processing",
    "year": 2016,
    "ML_Techniques": "CNN",
    "Category": "Code representation",
    "Sub_category": "",
    "Venue": "AAAI",
    "Link": "https://arxiv.org/abs/1409.5718",
    "bibtex": "inproceedings{Mou2016_466,\n    author = \"Mou, Lili and Li, Ge and Zhang, Lu and Wang, Tao and Jin, Zhi\",\n    title = \"Convolutional Neural Networks over Tree Structures for Programming Language Processing\",\n    year = \"2016\",\n    publisher = \"AAAI Press\",\n    abstract = \"Programming language processing (similar to natural language processing) is a hot research topic in the field of software engineering; it has also aroused growing interest in the artificial intelligence community. However, different from a natural language sentence, a program contains rich, explicit, and complicated structural information. Hence, traditional NLP models may be inappropriate for programs. In this paper, we propose a novel tree-based convolutional neural network (TBCNN) for programming language processing, in which a convolution kernel is designed over programs' abstract syntax trees to capture structural information. TBCNN is a generic architecture for programming language processing; our experiments show its effectiveness in two different program analysis tasks: classifying programs according to functionality, and detecting code snippets of certain patterns. TBCNN outperforms baseline methods, including several neural models for NLP.\",\n    booktitle = \"Proceedings of the Thirtieth AAAI Conference on Artificial Intelligence\",\n    pages = \"1287\u20131293\",\n    numpages = \"7\",\n    location = \"Phoenix, Arizona\",\n    series = \"AAAI'16\"\n}\n\n",
    "abstract": "Programming language processing (similar to natural\nlanguage processing) is a hot research topic in the field\nof software engineering; it has also aroused growing interest\nin the artificial intelligence community. However,\ndifferent from a natural language sentence, a program\ncontains rich, explicit, and complicated structural information.\nHence, traditional NLP models may be inappropriate\nfor programs. In this paper, we propose a novel\ntree-based convolutional neural network (TBCNN) for\nprogramming language processing, in which a convolution\nkernel is designed over programs\u2019 abstract syntax\ntrees to capture structural information. TBCNN is\na generic architecture for programming language processing;\nour experiments show its effectiveness in two\ndifferent program analysis tasks: classifying programs\naccording to functionality, and detecting code snippets\nof certain patterns. TBCNN outperforms baseline methods,\nincluding several neural models for NLP."
}, {
    "py/object": "data.DataClassPaper",
    "Title": "Deep learning similarities from different representations of source code",
    "year": 2018,
    "ML_Techniques": "RNN",
    "Category": "Code representation",
    "Sub_category": "",
    "Venue": "MSR",
    "Link": "https://dl.acm.org/doi/10.1145/3196398.3196431",
    "bibtex": "inproceedings{Mou2016_466,\n    author = \"Mou, Lili and Li, Ge and Zhang, Lu and Wang, Tao and Jin, Zhi\",\n    title = \"Convolutional Neural Networks over Tree Structures for Programming Language Processing\",\n    year = \"2016\",\n    publisher = \"AAAI Press\",\n    abstract = \"Programming language processing (similar to natural language processing) is a hot research topic in the field of software engineering; it has also aroused growing interest in the artificial intelligence community. However, different from a natural language sentence, a program contains rich, explicit, and complicated structural information. Hence, traditional NLP models may be inappropriate for programs. In this paper, we propose a novel tree-based convolutional neural network (TBCNN) for programming language processing, in which a convolution kernel is designed over programs' abstract syntax trees to capture structural information. TBCNN is a generic architecture for programming language processing; our experiments show its effectiveness in two different program analysis tasks: classifying programs according to functionality, and detecting code snippets of certain patterns. TBCNN outperforms baseline methods, including several neural models for NLP.\",\n    booktitle = \"Proceedings of the Thirtieth AAAI Conference on Artificial Intelligence\",\n    pages = \"1287\u20131293\",\n    numpages = \"7\",\n    location = \"Phoenix, Arizona\",\n    series = \"AAAI'16\"\n}\n\n",
    "abstract": "Assessing the similarity between code components plays a pivotal\nrole in a number of Software Engineering (SE) tasks, such as clone\ndetection, impact analysis, refactoring, etc. Code similarity is generally\nmeasured by relying on manually defined or hand-crafted\nfeatures, e.g., by analyzing the overlap among identifiers or comparing\nthe Abstract Syntax Trees of two code components. These\nfeatures represent a best guess at what SE researchers can utilize to\nexploit and reliably assess code similarity for a given task. Recent\nwork has shown, when using a stream of identifiers to represent\nthe code, that Deep Learning (DL) can effectively replace manual\nfeature engineering for the task of clone detection. However, source\ncode can be represented at different levels of abstraction: identifiers,\nAbstract Syntax Trees, Control Flow Graphs, and Bytecode.\nWe conjecture that each code representation can provide a different,\nyet orthogonal view of the same code fragment, thus, enabling a\nmore reliable detection of similarities in code. In this paper, we\ndemonstrate how SE tasks can benefit from a DL-based approach,\nwhich can aut"
}, {
    "py/object": "data.DataClassPaper",
    "Title": "Feature Maps: A Comprehensible Software Representation for Design Pattern Detection",
    "year": 2019,
    "ML_Techniques": "CNN, RF",
    "Category": "Code representation",
    "Sub_category": "",
    "Venue": "SANER",
    "Link": "https://ieeexplore.ieee.org/document/8667978",
    "bibtex": "INPROCEEDINGS{Thaller2019_468,\n    author = \"{Thaller}, H. and {Linsbauer}, L. and {Egyed}, A.\",\n    booktitle = \"2019 IEEE 26th International Conference on Software Analysis, Evolution and Reengineering (SANER)\",\n    title = \"Feature Maps: A Comprehensible Software Representation for Design Pattern Detection\",\n    year = \"2019\",\n    volume = \"\",\n    number = \"\",\n    pages = \"207-217\",\n    doi = \"10.1109/SANER.2019.8667978\"\n}\n\n",
    "abstract": "Design patterns are elegant and well-tested solutions\nto recurrent software development problems. They are the result\nof software developers dealing with problems that frequently\noccur, solving them in the same or a slightly adapted way. A pattern\u2019s\nsemantics provide the intent, motivation, and applicability,\ndescribing what it does, why it is needed, and where it is useful.\nConsequently, design patterns encode a well of information. Developers\nweave this information into their systems whenever they\nuse design patterns to solve problems. This work presents Feature\nMaps, a flexible human- and machine-comprehensible software\nrepresentation based on micro-structures. Our algorithm, the\nFeature-Role Normalization, presses the high-dimensional, inhomogeneous\nvector space of micro-structures into a feature map.\nWe apply these concepts to the problem of detecting instances of\ndesign patterns in source code. We evaluate our methodology on\nfour design patterns, a wide range of balanced and imbalanced\nlabeled training data, and compare classical machine learning\n(Random Forests) with modern deep learning approaches\n(Convolutional Neural Networks). Feature maps yield robust\nclassifiers even under challenging settings of strongly imbalanced\ndata distributions without sacrificing human comprehensibility.\nResults suggest that feature maps are an excellent addition in\nthe software analysis toolbox that can reveal useful information\nhidden in the source code."
}, {
    "py/object": "data.DataClassPaper",
    "Title": "Flow2Vec: value-flow-based precise code embedding",
    "year": 2020,
    "ML_Techniques": "Code2Vec, EN-DE",
    "Category": "Code representation",
    "Sub_category": "",
    "Venue": "OOPSLA",
    "Link": " https://dl.acm.org/doi/10.1145/3428301",
    "bibtex": "INPROCEEDINGS{Thaller2019_468,\n    author = \"{Thaller}, H. and {Linsbauer}, L. and {Egyed}, A.\",\n    booktitle = \"2019 IEEE 26th International Conference on Software Analysis, Evolution and Reengineering (SANER)\",\n    title = \"Feature Maps: A Comprehensible Software Representation for Design Pattern Detection\",\n    year = \"2019\",\n    volume = \"\",\n    number = \"\",\n    pages = \"207-217\",\n    doi = \"10.1109/SANER.2019.8667978\"\n}\n\n",
    "abstract": "Code embedding, as an emerging paradigm for source code analysis, has attracted much attention over the past\nfew years. It aims to represent code semantics through distributed vector representations, which can be used to\nsupport a variety of program analysis tasks (e.g., code summarization and semantic labeling). However, existing\ncode embedding approaches are intraprocedural, alias-unaware and ignoring the asymmetric transitivity\nof directed graphs abstracted from source code, thus they are still ineffective in preserving the structural\ninformation of code.\nThis paper presents Flow2Vec, a new code embedding approach that precisely preserves interprocedural\nprogram dependence (a.k.a value-flows). By approximating the high-order proximity, i.e., the asymmetric\ntransitivity of value-flows, Flow2Vec embeds control-flows and alias-aware data-flows of a program in a\nlow-dimensional vector space. Our value-flow embedding is formulated as matrix multiplication to preserve\ncontext-sensitive transitivity through CFL reachability by filtering out infeasible value-flow paths.\nWe have evaluated Flow2Vec using 32 popular open-source projects. Results from our experiments show\nthat Flow2Vec successfully boosts the performance of two recent code embedding approaches code2vec and\ncode2seq for two client applications, i.e., code classification and code summarization. For code classification,\nFlow2Vec improves code2vec with an average increase of 21.2%, 20.1% and 20.7% in precision, recall and F1,\nrespectively. For code summarization, Flow2Vec outperforms code2seq by an average of 13.2%, 18.8% and\n16.0% in precision, recall and F1, respectively."
}, {
    "py/object": "data.DataClassPaper",
    "Title": "From Programs to Interpretable Deep Models and Back",
    "year": 2018,
    "ML_Techniques": "",
    "Category": "Code representation",
    "Sub_category": "",
    "Venue": "CAV",
    "Link": "https://link.springer.com/content/pdf/10.1007%2F978-3-319-96145-3_2.pdf",
    "bibtex": "InProceedings{Yahav2018_470,\n    author = \"Yahav, Eran\",\n    editor = \"Chockler, Hana and Weissenbacher, Georg\",\n    title = \"From Programs to Interpretable Deep Models and Back\",\n    booktitle = \"Computer Aided Verification\",\n    year = \"2018\",\n    publisher = \"Springer International Publishing\",\n    address = \"Cham\",\n    pages = \"27--37\",\n    abstract = \"We demonstrate how deep learning over programs is used to provide (preliminary) augmented programmer intelligence. In the first part, we show how to tackle tasks like code completion, code summarization, and captioning. We describe a general path-based representation of source code that can be used across programming languages and learning tasks, and discuss how this representation enables different learning algorithms. In the second part, we describe techniques for extracting interpretable representations from deep models, shedding light on what has actually been learned in various tasks.\",\n    isbn = \"978-3-319-96145-3\"\n}\n\n",
    "abstract": "We demonstrate how deep learning over programs is used to\nprovide (preliminary) augmented programmer intelligence. In the first\npart, we show how to tackle tasks like code completion, code summarization,\nand captioning. We describe a general path-based representation of\nsource code that can be used across programming languages and learning\ntasks, and discuss how this representation enables different learning\nalgorithms. In the second part, we describe techniques for extracting\ninterpretable representations from deep models, shedding light on what\nhas actually been learned in various tasks."
}, {
    "py/object": "data.DataClassPaper",
    "Title": "GENERATIVE CODE MODELING WITH GRAPHS",
    "year": 2019,
    "ML_Techniques": "GNN",
    "Category": "Code representation",
    "Sub_category": "",
    "Venue": "ICLR",
    "Link": "https://openreview.net/forum?id=Bke4KsA5FX",
    "bibtex": "InProceedings{Yahav2018_470,\n    author = \"Yahav, Eran\",\n    editor = \"Chockler, Hana and Weissenbacher, Georg\",\n    title = \"From Programs to Interpretable Deep Models and Back\",\n    booktitle = \"Computer Aided Verification\",\n    year = \"2018\",\n    publisher = \"Springer International Publishing\",\n    address = \"Cham\",\n    pages = \"27--37\",\n    abstract = \"We demonstrate how deep learning over programs is used to provide (preliminary) augmented programmer intelligence. In the first part, we show how to tackle tasks like code completion, code summarization, and captioning. We describe a general path-based representation of source code that can be used across programming languages and learning tasks, and discuss how this representation enables different learning algorithms. In the second part, we describe techniques for extracting interpretable representations from deep models, shedding light on what has actually been learned in various tasks.\",\n    isbn = \"978-3-319-96145-3\"\n}\n\n",
    "abstract": "Generative models for source code are an interesting structured prediction problem,\nrequiring to reason about both hard syntactic and semantic constraints as well as\nabout natural, likely programs. We present a novel model for this problem that\nuses a graph to represent the intermediate state of the generated output. Our model\ngenerates code by interleaving grammar-driven expansion steps with graph augmentation\nand neural message passing steps. An experimental evaluation shows\nthat our new model can generate semantically meaningful expressions, outperforming\na range of strong baselines."
}, {
    "py/object": "data.DataClassPaper",
    "Title": "Learning Programs: A Hierarchical Bayesian Approach",
    "year": 2010,
    "ML_Techniques": "",
    "Category": "Code representation",
    "Sub_category": "",
    "Venue": "ICML",
    "Link": "https://www.semanticscholar.org/paper/Learning-Programs%3A-A-Hierarchical-Bayesian-Approach-Liang-Jordan/c26770f29afafe22f2a507506e3f43c413f6a619",
    "bibtex": "inproceedings{Liang2010_472,\n    author = \"Liang, Percy and Jordan, Michael I. and Klein, D.\",\n    title = \"Learning Programs: A Hierarchical Bayesian Approach\",\n    booktitle = \"ICML\",\n    year = \"2010\"\n}\n\n",
    "abstract": "We are interested in learning programs for\nmultiple related tasks given only a few training\nexamples per task. Since the program\nfor a single task is underdetermined by its\ndata, we introduce a nonparametric hierarchical\nBayesian prior over programs which\nshares statistical strength across multiple\ntasks. The key challenge is to parametrize\nthis multi-task sharing. For this, we introduce\na new representation of programs\nbased on combinatory logic and provide an\nMCMC algorithm that can perform safe program\ntransformations on this representation\nto reveal shared inter-program substructures."
}, {
    "py/object": "data.DataClassPaper",
    "Title": "Learning semantic program embeddings with graph interval neural network",
    "year": 2020,
    "ML_Techniques": "GINN",
    "Category": "Code representation",
    "Sub_category": "",
    "Venue": "OOPSLA",
    "Link": "https://dl.acm.org/doi/10.1145/3428205",
    "bibtex": "inproceedings{Liang2010_472,\n    author = \"Liang, Percy and Jordan, Michael I. and Klein, D.\",\n    title = \"Learning Programs: A Hierarchical Bayesian Approach\",\n    booktitle = \"ICML\",\n    year = \"2010\"\n}\n\n",
    "abstract": "Learning distributed representations of source code has been a challenging task for machine learning models.\nEarlier works treated programs as text so that natural language methods can be readily applied. Unfortunately,\nsuch approaches do not capitalize on the rich structural information possessed by source code. Of late, Graph\nNeural Network (GNN) was proposed to learn embeddings of programs from their graph representations.\nDue to the homogeneous (i.e. do not take advantage of the program-speci\u0080c graph characteristics) and\nexpensive (i.e. require heavy information exchange among nodes in the graph) message-passing procedure,\nGNN can su\u0082er from precision issues, especially when dealing with programs rendered into large graphs.\nIn this paper, we present a new graph neural architecture, called Graph Interval Neural Network (GINN),\nto tackle the weaknesses of the existing GNN. Unlike the standard GNN, GINN generalizes from a curated\ngraph representation obtained through an abstraction method designed to aid models to learn. In particular,\nGINN focuses exclusively on intervals (generally manifested in looping construct) for mining the feature\nrepresentation of a program, furthermore, GINN operates on a hierarchy of intervals for scaling the learning\nto large graphs.\nWe evaluate GINN for two popular downstream applications: variable misuse prediction and method name\nprediction. Results show in both cases GINN outperforms the state-of-the-art models by a comfortable margin.\nWe have also created a neural bug detector based on GINN to catch null pointer deference bugs in Java code.\nWhile learning from the same 9,000 methods extracted from 64 projects, GINN-based bug detector signi\u0080cantly\noutperforms GNN-based bug detector on 13 unseen test projects. Next, we deploy our trained GINN-based\nbug detector and Facebook Infer, arguably the state-of-the-art static analysis tool, to scan the codebase of 20\nhighly starred projects on GitHub. \u008crough our manual inspection, we con\u0080rm 38 bugs out of 102 warnings\nraised by GINN-based bug detector compared to 34 bugs out of 129 warnings for Facebook Infer. We have\nreported 38 bugs GINN caught to developers, among which 11 have been \u0080xed and 12 have been con\u0080rmed\n(\u0080x pending). GINN has shown to be a general, powerful deep neural network for learning precise, semantic\nprogram embeddings."
}, {
    "py/object": "data.DataClassPaper",
    "Title": "Mining Source Code Repositories at Massive Scale using Language Modeling",
    "year": 2013,
    "ML_Techniques": "",
    "Category": "Code representation",
    "Sub_category": "",
    "Venue": "MSR",
    "Link": "http://homepages.inf.ed.ac.uk/csutton/publications/msr2013.pdf",
    "bibtex": "inproceedings{Liang2010_472,\n    author = \"Liang, Percy and Jordan, Michael I. and Klein, D.\",\n    title = \"Learning Programs: A Hierarchical Bayesian Approach\",\n    booktitle = \"ICML\",\n    year = \"2010\"\n}\n\n",
    "abstract": "The tens of thousands of high-quality open source\nsoftware projects on the Internet raise the exciting possibility\nof studying software development by finding patterns across\ntruly large source code repositories. This could enable new tools\nfor developing code, encouraging reuse, and navigating large\nprojects. In this paper, we build the first giga-token probabilistic\nlanguage model of source code, based on 352 million lines of\nJava. This is 100 times the scale of the pioneering work by\nHindle et al. The giga-token model is significantly better at the\ncode suggestion task than previous models. More broadly, our\napproach provides a new \u201clens\u201d for analyzing software projects,\nenabling new complexity metrics based on statistical analysis\nof large corpora. We call these metrics data-driven complexity\nmetrics. We propose new metrics that measure the complexity of\na code module and the topical centrality of a module to a software\nproject. In particular, it is possible to distinguish reusable utility\nclasses from classes that are part of a program\u2019s core logic based\nsolely on general information theoretic criteria."
}, {
    "py/object": "data.DataClassPaper",
    "Title": "Modular Tree Network for Source Code Representation Learning",
    "year": 2020,
    "ML_Techniques": "MTN, RNN",
    "Category": "Code representation",
    "Sub_category": "",
    "Venue": "TOSEM",
    "Link": "https://dl.acm.org/doi/abs/10.1145/3409331",
    "bibtex": "article{Wang2020_475,\n    author = \"Wang, Wenhan and Li, Ge and Shen, Sijie and Xia, Xin and Jin, Zhi\",\n    title = \"Modular Tree Network for Source Code Representation Learning\",\n    year = \"2020\",\n    issue_date = \"October 2020\",\n    publisher = \"Association for Computing Machinery\",\n    address = \"New York, NY, USA\",\n    volume = \"29\",\n    number = \"4\",\n    issn = \"1049-331X\",\n    url = \"https://doi.org/10.1145/3409331\",\n    doi = \"10.1145/3409331\",\n    journal = \"ACM Trans. Softw. Eng. Methodol.\",\n    month = \"September\",\n    articleno = \"31\",\n    numpages = \"23\",\n    keywords = \"Deep learning, code clone detection, neural networks, program classification\"\n}\n\n",
    "abstract": "Learning representation for source code is a foundation of many program analysis tasks. In recent years,\nneural networks have already shown success in this area, but most existing models did not make full use of\nthe unique structural information of programs. Although abstract syntax tree (AST)-based neural models can\nhandle the tree structure in the source code, they cannot capture the richness of different types of substructure\nin programs. In this article, we propose a modular tree network that dynamically composes different\nneural network units into tree structures based on the input AST. Different from previous tree-structural\nneural network models, a modular tree network can capture the semantic differences between types of AST\nsubstructures. We evaluate our model on two tasks: program classification and code clone detection. Our\nmodel achieves the best performance compared with state-of-the-art approaches in both tasks, showing the\nadvantage of leveraging more elaborate structure information of the source code."
}, {
    "py/object": "data.DataClassPaper",
    "Title": "Open Vocabulary Learning on Source Code with a Graph-Structured Cache",
    "year": 2019,
    "ML_Techniques": "GNN",
    "Category": "Code representation",
    "Sub_category": "",
    "Venue": "ICML",
    "Link": "http://proceedings.mlr.press/v97/cvitkovic19b.html",
    "bibtex": "InProceedings{Cvitkovic2019_476,\n    author = \"Cvitkovic, Milan and Singh, Badal and Anandkumar, Animashree\",\n    editor = \"Chaudhuri, Kamalika and Salakhutdinov, Ruslan\",\n    title = \"Open Vocabulary Learning on Source Code with a Graph-Structured Cache\",\n    pages = \"1475--1485\",\n    year = \"2019\",\n    volume = \"97\",\n    series = \"Proceedings of Machine Learning Research\",\n    address = \"Long Beach, California, USA\",\n    month = \"09--15 Jun\",\n    publisher = \"PMLR\",\n    pdf = \"http://proceedings.mlr.press/v97/cvitkovic19b/cvitkovic19b.pdf\",\n    url = \"http://proceedings.mlr.press/v97/cvitkovic19b.html\"\n}\n\n",
    "abstract": "Machine learning models that take computer program\nsource code as input typically use Natural\nLanguage Processing (NLP) techniques. However,\na major challenge is that code is written\nusing an open, rapidly changing vocabulary due\nto, e.g., the coinage of new variable and method\nnames. Reasoning over such a vocabulary is not\nsomething for which most NLP methods are designed.\nWe introduce a Graph\u2013Structured Cache\nto address this problem; this cache contains a\nnode for each new word the model encounters\nwith edges connecting each word to its occurrences\nin the code. We find that combining\nthis graph\u2013structured cache strategy with recent\nGraph\u2013Neural\u2013Network\u2013based models for supervised\nlearning on code improves the models\u2019 performance\non a code completion task and a variable\nnaming task \u2014 with over 100% relative improvement\non the latter \u2014 at the cost of a moderate\nincrease in computation time."
}, {
    "py/object": "data.DataClassPaper",
    "Title": "RobustFill: Neural Program Learning under Noisy I/O",
    "year": 2017,
    "ML_Techniques": "RNN",
    "Category": "Program synthesis",
    "Sub_category": "",
    "Venue": "ICML",
    "Link": "https://arxiv.org/abs/1703.07469v1",
    "bibtex": "inproceedings{Devlin2017_480,\n    author = \"Devlin, Jacob and Uesato, Jonathan and Bhupatiraju, Surya and Singh, Rishabh and Mohamed, Abdel-rahman and Kohli, Pushmeet\",\n    title = \"RobustFill: Neural Program Learning under Noisy I/O\",\n    year = \"2017\",\n    publisher = \"JMLR.org\",\n    abstract = \"The problem of automatically generating a computer program from some specification has been studied since the early days of AI. Recently, two competing approaches for automatic program learning have received significant attention: (1) neural program synthesis, where a neural network is conditioned on input/output (I/O) examples and learns to generate a program, and (2) neural program induction, where a neural network generates new outputs directly using a latent program representation. Here, for the first time, we directly compare both approaches on a large-scale, real-world learning task and we additionally contrast to rule-based program synthesis, which uses hand-crafted semantics to guide the program generation. Our neural models use a modified attention RNN to allow encoding of variable-sized sets of I/O pairs, which achieve 92\\% accuracy on a real-world test set, compared to the 34\\% accuracy of the previous best neural synthesis approach. The synthesis model also outperforms a comparable induction model on this task, but we more importantly demonstrate that the strength of each approach is highly dependent on the evaluation metric and end-user application. Finally, we show that we can train our neural models to remain very robust to the type of noise expected in real-world data (e.g., typos), while a highly-engineered rule-based system fails entirely.\",\n    booktitle = \"Proceedings of the 34th International Conference on Machine Learning - Volume 70\",\n    pages = \"990\u2013998\",\n    numpages = \"9\",\n    location = \"Sydney, NSW, Australia\",\n    series = \"ICML'17\"\n}\n\n",
    "abstract": "The problem of automatically generating a computer program from some specification has been studied since the early days of AI. Recently, two competing approaches for automatic program learning have received significant attention: (1) neural program synthesis, where a neural network is conditioned on input/output (I/O) examples and learns to generate a program, and (2) neural program induction, where a neural network generates new outputs directly using a latent program representation.\nHere, for the first time, we directly compare both approaches on a large-scale, real-world learning task. We additionally contrast to rule-based program synthesis, which uses hand-crafted semantics to guide the program generation. Our neural models use a modified attention RNN to allow encoding of variable-sized sets of I/O pairs. Our best synthesis model achieves 92% accuracy on a real-world test set, compared to the 34% accuracy of the previous best neural synthesis approach. The synthesis model also outperforms a comparable induction model on this task, but we more importantly demonstrate that the strength of each approach is highly dependent on the evaluation metric and end-user application. Finally, we show that we can train our neural models to remain very robust to the type of noise expected in real-world data (e.g., typos), while a highly-engineered rule-based system fails entirely."
}, {
    "py/object": "data.DataClassPaper",
    "Title": "Towards demystifying dimensions of source code embeddings",
    "year": 2020,
    "ML_Techniques": "Code2Vec",
    "Category": "Code representation",
    "Sub_category": "",
    "Venue": "RL+SE&PL",
    "Link": "https://dl.acm.org/doi/10.1145/3416506.3423580",
    "bibtex": "inproceedings{Devlin2017_480,\n    author = \"Devlin, Jacob and Uesato, Jonathan and Bhupatiraju, Surya and Singh, Rishabh and Mohamed, Abdel-rahman and Kohli, Pushmeet\",\n    title = \"RobustFill: Neural Program Learning under Noisy I/O\",\n    year = \"2017\",\n    publisher = \"JMLR.org\",\n    abstract = \"The problem of automatically generating a computer program from some specification has been studied since the early days of AI. Recently, two competing approaches for automatic program learning have received significant attention: (1) neural program synthesis, where a neural network is conditioned on input/output (I/O) examples and learns to generate a program, and (2) neural program induction, where a neural network generates new outputs directly using a latent program representation. Here, for the first time, we directly compare both approaches on a large-scale, real-world learning task and we additionally contrast to rule-based program synthesis, which uses hand-crafted semantics to guide the program generation. Our neural models use a modified attention RNN to allow encoding of variable-sized sets of I/O pairs, which achieve 92\\% accuracy on a real-world test set, compared to the 34\\% accuracy of the previous best neural synthesis approach. The synthesis model also outperforms a comparable induction model on this task, but we more importantly demonstrate that the strength of each approach is highly dependent on the evaluation metric and end-user application. Finally, we show that we can train our neural models to remain very robust to the type of noise expected in real-world data (e.g., typos), while a highly-engineered rule-based system fails entirely.\",\n    booktitle = \"Proceedings of the 34th International Conference on Machine Learning - Volume 70\",\n    pages = \"990\u2013998\",\n    numpages = \"9\",\n    location = \"Sydney, NSW, Australia\",\n    series = \"ICML'17\"\n}\n\n",
    "abstract": "Source code representations are key in applying machine learning\ntechniques for processing and analyzing programs. A popular approach\nin representing source code is neural source code embedding\nthat represents programs with high-dimensional vectors computed\nby training deep neural networks on a large volume of programs.\nAlthough successful, there is li\u008ale known about the contents of\nthese vectors and their characteristics.\nIn this paper, we present our preliminary results towards be\u008aer\nunderstanding the contents of code2vec neural source code embeddings.\nIn particular, in a small case study, we use the embeddings\nto create binary SVM classi\u0080ers and we compare their performance\nwith handcra\u0089ed features. Our results suggest that the handcra\u0089ed\nfeatures can perform very close to highly-dimensional code2vec\nembeddings, and the information gains are more evenly distributed\nin the code2vec embeddings compared to handcra\u0089ed features. We\nalso \u0080nd that code2vec is more resilient to the removal of dimensions\nwith low information gains than handcra\u0089ed features. We\nhope our results serve a stepping stone toward principled analysis\nand evaluation of these code representations."
}, {
    "py/object": "data.DataClassPaper",
    "Title": "user2code2vec: Embeddings for Profiling Students Based on Distributional Representations of Source Code",
    "year": 2019,
    "ML_Techniques": "",
    "Category": "Code representation",
    "Sub_category": "",
    "Venue": "LAK",
    "Link": "https://dl.acm.org/doi/10.1145/3303772.3303813",
    "bibtex": "inproceedings{Devlin2017_480,\n    author = \"Devlin, Jacob and Uesato, Jonathan and Bhupatiraju, Surya and Singh, Rishabh and Mohamed, Abdel-rahman and Kohli, Pushmeet\",\n    title = \"RobustFill: Neural Program Learning under Noisy I/O\",\n    year = \"2017\",\n    publisher = \"JMLR.org\",\n    abstract = \"The problem of automatically generating a computer program from some specification has been studied since the early days of AI. Recently, two competing approaches for automatic program learning have received significant attention: (1) neural program synthesis, where a neural network is conditioned on input/output (I/O) examples and learns to generate a program, and (2) neural program induction, where a neural network generates new outputs directly using a latent program representation. Here, for the first time, we directly compare both approaches on a large-scale, real-world learning task and we additionally contrast to rule-based program synthesis, which uses hand-crafted semantics to guide the program generation. Our neural models use a modified attention RNN to allow encoding of variable-sized sets of I/O pairs, which achieve 92\\% accuracy on a real-world test set, compared to the 34\\% accuracy of the previous best neural synthesis approach. The synthesis model also outperforms a comparable induction model on this task, but we more importantly demonstrate that the strength of each approach is highly dependent on the evaluation metric and end-user application. Finally, we show that we can train our neural models to remain very robust to the type of noise expected in real-world data (e.g., typos), while a highly-engineered rule-based system fails entirely.\",\n    booktitle = \"Proceedings of the 34th International Conference on Machine Learning - Volume 70\",\n    pages = \"990\u2013998\",\n    numpages = \"9\",\n    location = \"Sydney, NSW, Australia\",\n    series = \"ICML'17\"\n}\n\n",
    "abstract": "In this work, we propose a new methodology to profile individual\nstudents of computer science based on their programming design\nusing a technique called embeddings. We investigate different approaches\nto analyze user source code submissions in the Python\nlanguage. We compare the performances of different source code\nvectorization techniques to predict the correctness of a code submission.\nIn addition, we propose a new mechanism to represent\nstudents based on their code submissions for a given set of laboratory\ntasks on a particular course. This way, we can make deeper\nrecommendations for programming solutions and pathways to support\nstudent learning and progression in computer programming\nmodules effectively at a Higher Education Institution. Recent work\nusing Deep Learning tends to work better when more and more\ndata is provided. However, in Learning Analytics, the number of\nstudents in a course is an unavoidable limit. Thus we cannot simply\ngenerate more data as is done in other domains such as FinTech\nor Social Network Analysis. Our findings indicate there is a need\nto learn and develop better mechanisms to extract and learn effective\ndata features from students so as to analyze the students\u2019\nprogression and performance effectively."
}, {
    "py/object": "data.DataClassPaper",
    "Title": "A Neural Network Based Intelligent Support Model for Program Code Completion",
    "year": 2020,
    "ML_Techniques": "LSTM",
    "Category": "Code completion",
    "Sub_category": "",
    "Venue": "SP",
    "Link": "https://www.hindawi.com/journals/sp/2020/7426461/",
    "bibtex": "article{Rahman2020_484,\n    author = \"Rahman, M. and Watanobe, Yutaka and Nakamura, K.\",\n    title = \"A Neural Network Based Intelligent Support Model for Program Code Completion\",\n    journal = \"Sci. Program.\",\n    year = \"2020\",\n    volume = \"2020\",\n    doi = \"10.1155/2020/7426461\",\n    pages = \"7426461:1-7426461:18\"\n}\n\n",
    "abstract": "In recent years, millions of source codes are generated in different languages on a daily basis all over the world. A deep neural network-based intelligent support model for source code completion would be a great advantage in software engineering and programming education fields. Vast numbers of syntax, logical, and other critical errors that cannot be detected by normal compilers continue to exist in source codes, and the development of an intelligent evaluation methodology that does not rely on manual compilation has become essential. Even experienced programmers often find it necessary to analyze an entire program in order to find a single error and are thus being forced to waste valuable time debugging their source codes. With this point in mind, we proposed an intelligent model that is based on long short-term memory (LSTM) and combined it with an attention mechanism for source code completion. Thus, the proposed model can detect source code errors with locations and then predict the correct words. In addition, the proposed model can classify the source codes as to whether they are erroneous or not. We trained our proposed model using the source code and then evaluated the performance. All of the data used in our experiments were extracted from Aizu Online Judge (AOJ) system. The experimental results obtained show that the accuracy in terms of error detection and prediction of our proposed model approximately is 62% and source code classification accuracy is approximately 96% which outperformed a standard LSTM and other state-of-the-art models. Moreover, in comparison to state-of-the-art models, our proposed model achieved an interesting level of success in terms of error detection, prediction, and classification when applied to long source code sequences. Overall, these experimental results indicate the usefulness of our proposed model in software engineering and programming education arena."
}, {
    "py/object": "data.DataClassPaper",
    "Title": "A Self-Attentional Neural Architecture for Code Completion with Multi-Task Learning",
    "year": 2020,
    "ML_Techniques": "MTN, RNN",
    "Category": "Code completion",
    "Sub_category": "",
    "Venue": "ICPC",
    "Link": "https://dl.acm.org/doi/abs/10.1145/3387904.3389261",
    "bibtex": "inproceedings{Liu2020_485,\n    author = \"Liu, Fang and Li, Ge and Wei, Bolin and Xia, Xin and Fu, Zhiyi and Jin, Zhi\",\n    title = \"A Self-Attentional Neural Architecture for Code Completion with Multi-Task Learning\",\n    year = \"2020\",\n    isbn = \"9781450379588\",\n    publisher = \"Association for Computing Machinery\",\n    address = \"New York, NY, USA\",\n    url = \"https://doi.org/10.1145/3387904.3389261\",\n    doi = \"10.1145/3387904.3389261\",\n    abstract = \"Code completion, one of the most useful features in the Integrated Development Environments (IDEs), can accelerate software development by suggesting the libraries, APIs, and method names in real-time. Recent studies have shown that statistical language models can improve the performance of code completion tools through learning from large-scale software repositories. However, these models suffer from three major drawbacks: a) The hierarchical structural information of the programs is not fully utilized in the program's representation; b) In programs, the semantic relationships can be very long. Existing recurrent neural networks based language models are not sufficient to model the long-term dependency. c) Existing approaches perform a specific task in one model, which leads to the underuse of the information from related tasks. To address these challenges, in this paper, we propose a self-attentional neural architecture for code completion with multi-task learning. To utilize the hierarchical structural information of the programs, we present a novel method that considers the path from the predicting node to the root node. To capture the long-term dependency in the input programs, we adopt a self-attentional architecture based network as the base language model. To enable the knowledge sharing between related tasks, we creatively propose a Multi-Task Learning (MTL) framework to learn two related tasks in code completion jointly. Experiments on three real-world datasets demonstrate the effectiveness of our model when compared with state-of-the-art methods.\",\n    booktitle = \"Proceedings of the 28th International Conference on Program Comprehension\",\n    pages = \"37\u201347\",\n    numpages = \"11\",\n    keywords = \"Self-attention, Multi-task learning, Hierarchical structure, Code completion\",\n    location = \"Seoul, Republic of Korea\",\n    series = \"ICPC '20\"\n}\n\n",
    "abstract": "Code completion, one of the most useful features in the Integrated Development Environments (IDEs), can accelerate software development by suggesting the libraries, APIs, and method names in real-time. Recent studies have shown that statistical language models can improve the performance of code completion tools through learning from large-scale software repositories. However, these models suffer from three major drawbacks: a) The hierarchical structural information of the programs is not fully utilized in the program's representation; b) In programs, the semantic relationships can be very long. Existing recurrent neural networks based language models are not sufficient to model the long-term dependency. c) Existing approaches perform a specific task in one model, which leads to the underuse of the information from related tasks. To address these challenges, in this paper, we propose a self-attentional neural architecture for code completion with multi-task learning. To utilize the hierarchical structural information of the programs, we present a novel method that considers the path from the predicting node to the root node. To capture the long-term dependency in the input programs, we adopt a self-attentional architecture based network as the base language model. To enable the knowledge sharing between related tasks, we creatively propose a Multi-Task Learning (MTL) framework to learn two related tasks in code completion jointly. Experiments on three real-world datasets demonstrate the effectiveness of our model when compared with state-of-the-art methods."
}, {
    "py/object": "data.DataClassPaper",
    "Title": "Code Completion for Programming Education based on Recurrent Neural Network",
    "year": 2019,
    "ML_Techniques": "LSTM",
    "Category": "Code completion",
    "Sub_category": "",
    "Venue": "IWCIA",
    "Link": "https://ieeexplore.ieee.org/document/8955090",
    "bibtex": "INPROCEEDINGS{Terada2019_487,\n    author = \"{Terada}, K. and {Watanobe}, Y.\",\n    booktitle = \"2019 IEEE 11th International Workshop on Computational Intelligence and Applications (IWCIA)\",\n    title = \"Code Completion for Programming Education based on Recurrent Neural Network\",\n    year = \"2019\",\n    volume = \"\",\n    number = \"\",\n    pages = \"109-114\",\n    doi = \"10.1109/IWCIA47330.2019.8955090\"\n}\n\n",
    "abstract": "In solving programming problems, it is difficult for beginners to create program code from scratch. One way to navigate this difficulty is to provide a function of automatic code completion. In this work, we propose a method to predict the next word following a given incomplete program that has two key constituents, prediction of within-vocabulary words and prediction of identifiers. In terms of predicting within-vocabulary words, a neural language model based on a Long Short-Term Memory (LSTM) network is proposed. Regarding the prediction of identifiers, a model based on a pointer network is proposed. Additionally, a model for switching between these two models is proposed. For evaluation of the proposed method, source code accumulated in an online judge system is used. The results of the experiment demonstrate that the proposed method can predict both the next within-vocabulary word and the next identifier to a high degree of accuracy."
}, {
    "py/object": "data.DataClassPaper",
    "Title": "Code Completion from Abbreviated Input",
    "year": 2009,
    "ML_Techniques": "HMM",
    "Category": "Code completion",
    "Sub_category": "",
    "Venue": "ASE",
    "Link": "https://ieeexplore.ieee.org/abstract/document/5431761",
    "bibtex": "INPROCEEDINGS{Han2009_488,\n    author = \"{Han}, S. and {Wallace}, D. R. and {Miller}, R. C.\",\n    booktitle = \"2009 IEEE/ACM International Conference on Automated Software Engineering\",\n    title = \"Code Completion from Abbreviated Input\",\n    year = \"2009\",\n    volume = \"\",\n    number = \"\",\n    pages = \"332-343\",\n    doi = \"10.1109/ASE.2009.64\"\n}\n\n",
    "abstract": "Abbreviation Completion is a novel technique to improve the efficiency of code-writing by supporting code completion of multiple keywords based on non-predefined abbreviated input - a different approach from conventional code completion that finds one keyword at a time based on an exact character match. Abbreviated input is expanded into keywords by a Hidden Markov Model learned from a corpus of existing code. The technique does not require the user to memorize abbreviations and provides incremental feedback of the most likely completions. This paper presents the algorithm for abbreviation completion, integrated with a new user interface for multiple-keyword completion. We tested the system by sampling 3000 code lines from open source projects and found that more than 98% of the code lines could be resolved from acronym-like abbreviations. A user study found 30% reduction in time usage and 41% reduction of keystrokes over conventional code completion."
}, {
    "py/object": "data.DataClassPaper",
    "Title": "Code completion of multiple keywords from abbreviated input",
    "year": 2011,
    "ML_Techniques": "HMM",
    "Category": "Code completion",
    "Sub_category": "",
    "Venue": "ASE",
    "Link": "https://link.springer.com/article/10.1007%2Fs10515-011-0083-2",
    "bibtex": "INPROCEEDINGS{Han2009_488,\n    author = \"{Han}, S. and {Wallace}, D. R. and {Miller}, R. C.\",\n    booktitle = \"2009 IEEE/ACM International Conference on Automated Software Engineering\",\n    title = \"Code Completion from Abbreviated Input\",\n    year = \"2009\",\n    volume = \"\",\n    number = \"\",\n    pages = \"332-343\",\n    doi = \"10.1109/ASE.2009.64\"\n}\n\n",
    "abstract": "Abbreviation Completion is a novel technique to improve the efficiency of code-writing by supporting code completion of multiple keywords based on non-predefined abbreviated input--a different approach from conventional code completion that finds one keyword at a time based on an exact character match. Abbreviated input consisting of abbreviated keywords and non-alphanumeric characters between each abbreviated keyword (e.g. pb st nm) is expanded into a full expression (e.g. public String name) by a Hidden Markov Model learned from a corpus of existing code and abbreviation examples. The technique does not require the user to memorize abbreviations and provides incremental feedback of the most likely completions.\n\nIn addition to code completion by disabbreviation of multiple keywords, abbreviation completion supports prediction of the next keywords and non-alphanumeric characters of a code completion candidate, a technique called code completion by extrapolation. The system finds the most likely next keywords and non-alphanumeric characters using an n-gram model of programming language. This enables a code completion scenario in which a user first types a short abbreviated expression to complete the beginning part of a desired full expression and then uses the extrapolation feature to complete the remaining part without further typing.\n\nThis paper presents the algorithm for abbreviation completion, integrated with a new user interface for multiple-keyword code completion. We tested the system by sampling 4919 code lines from open source projects and found that more than 99% of the code lines could be resolved from acronym-like abbreviations. The system could also extrapolate code completion candidates to complete the next one or two keywords with the accuracy of 96% and 82%, respectively. A user study of code completion by disabbreviation found 30% reduction in time usage and 41% reduction of keystrokes over conventional code completion."
}, {
    "py/object": "data.DataClassPaper",
    "Title": "Code Completion with Neural Attention and Pointer Networks",
    "year": 2018,
    "ML_Techniques": "RNN",
    "Category": "Code completion",
    "Sub_category": "",
    "Venue": "IJCAI",
    "Link": "https://dl.acm.org/doi/10.5555/3304222.3304348",
    "bibtex": "inproceedings{Li2018_491,\n    author = \"Li, Jian and Wang, Yue and Lyu, Michael R. and King, Irwin\",\n    title = \"Code Completion with Neural Attention and Pointer Networks\",\n    year = \"2018\",\n    isbn = \"9780999241127\",\n    publisher = \"AAAI Press\",\n    abstract = \"Intelligent code completion has become an essential research task to accelerate modern software development. To facilitate effective code completion for dynamically-typed programming languages, we apply neural language models by learning from large codebases, and develop a tailored attention mechanism for code completion. However, standard neural language models even with attention mechanism cannot correctly predict the out-of-vocabulary (OoV) words that restrict the code completion performance. In this paper, inspired by the prevalence of locally repeated terms in program source code, and the recently proposed pointer copy mechanism, we propose a pointer mixture network for better predicting OoV words in code completion. Based on the context, the pointer mixture network learns to either generate a within-vocabulary word through an RNN component, or regenerate an OoV word from local context through a pointer component. Experiments on two benchmarked datasets demonstrate the effectiveness of our attention mechanism and pointer mixture network on the code completion task.\",\n    booktitle = \"Proceedings of the 27th International Joint Conference on Artificial Intelligence\",\n    pages = \"4159\u201325\",\n    numpages = \"7\",\n    location = \"Stockholm, Sweden\",\n    series = \"IJCAI'18\"\n}\n\n",
    "abstract": "Intelligent code completion has become an essential research task to accelerate modern software development. To facilitate effective code completion for dynamically-typed programming languages, we apply neural language models by learning from large codebases, and develop a tailored attention mechanism for code completion. However, standard neural language models even with attention mechanism cannot correctly predict the out-of-vocabulary (OoV) words that restrict the code completion performance. In this paper, inspired by the prevalence of locally repeated terms in program source code, and the recently proposed pointer copy mechanism, we propose a pointer mixture network for better predicting OoV words in code completion. Based on the context, the pointer mixture network learns to either generate a within-vocabulary word through an RNN component, or regenerate an OoV word from local context through a pointer component. Experiments on two benchmarked datasets demonstrate the effectiveness of our attention mechanism and pointer mixture network on the code completion task."
}, {
    "py/object": "data.DataClassPaper",
    "Title": "CodeGRU: Context-aware deep learning with gated recurrent unit for source code modeling",
    "year": 2020,
    "ML_Techniques": "GRU",
    "Category": "Code completion",
    "Sub_category": "",
    "Venue": "IST",
    "Link": "https://www.sciencedirect.com/science/article/abs/pii/S0950584920300616",
    "bibtex": "article{Hussain2020_492,\n    author = \"Hussain, Yasir and Huang, Zhiqiu and Zhou, Yu and Wang, Senzhang\",\n    title = \"CodeGRU: Context-aware deep learning with gated recurrent unit for source code modeling\",\n    journal = \"Information and Software Technology\",\n    volume = \"125\",\n    pages = \"106309\",\n    year = \"2020\",\n    issn = \"0950-5849\",\n    doi = \"https://doi.org/10.1016/j.infsof.2020.106309\",\n    url = \"http://www.sciencedirect.com/science/article/pii/S0950584920300616\",\n    keywords = \"Machine learning, Deep learning, Software language models, Source code suggestion, Source code completion\",\n    abstract = \"Context: Recently deep learning based Natural Language Processing (NLP) models have shown great potential in the modeling of source code. However, a major limitation of these approaches is that they take source code as simple tokens of text and ignore its contextual, syntactical and structural dependencies. Objective: In this work, we present CodeGRU, a gated recurrent unit based source code language model that is capable of capturing source code\u2019s contextual, syntactical and structural dependencies. Method: We introduce a novel approach which can capture the source code context by leveraging the source code token types. Further, we adopt a novel approach which can learn variable size context by taking into account source code\u2019s syntax, and structural information. Results: We evaluate CodeGRU with real-world data set and it shows that CodeGRU outperforms the state-of-the-art language models and help reduce the vocabulary size up to 24.93\\%. Unlike previous works, we tested CodeGRU with an independent test set which suggests that our methodology does not requisite the source code comes from the same domain as training data while providing suggestions. We further evaluate CodeGRU with two software engineering applications: source code suggestion, and source code completion. Conclusion: Our experiment confirms that the source code\u2019s contextual information can be vital and can help improve the software language models. The extensive evaluation of CodeGRU shows that it outperforms the state-of-the-art models. The results further suggest that the proposed approach can help reduce the vocabulary size and is of practical use for software developers.\"\n}\n\n",
    "abstract": "Recently deep learning based Natural Language Processing (NLP) models have shown great potential in the modeling of source code. However, a major limitation of these approaches is that they take source code as simple tokens of text and ignore its contextual, syntactical and structural dependencies. In this work, we present CodeGRU, a gated recurrent unit based source code language model that is capable of capturing source code's contextual, syntactical and structural dependencies. We introduce a novel approach which can capture the source code context by leveraging the source code token types. Further, we adopt a novel approach which can learn variable size context by taking into account source code's syntax, and structural information. We evaluate CodeGRU with real-world data set and it shows that CodeGRU outperforms the state-of-the-art language models and help reduce the vocabulary size up to 24.93\\%. Unlike previous works, we tested CodeGRU with an independent test set which suggests that our methodology does not requisite the source code comes from the same domain as training data while providing suggestions. We further evaluate CodeGRU with two software engineering applications: source code suggestion, and source code completion. Our experiment confirms that the source code's contextual information can be vital and can help improve the software language models. The extensive evaluation of CodeGRU shows that it outperforms the state-of-the-art models. The results further suggest that the proposed approach can help reduce the vocabulary size and is of practical use for software developers."
}, {
    "py/object": "data.DataClassPaper",
    "Title": "Deep Learning Based Code Completion Models for Programming Codes",
    "year": 2019,
    "ML_Techniques": "LSTM",
    "Category": "Code completion",
    "Sub_category": "",
    "Venue": "ISCSIC",
    "Link": "https://dl.acm.org/doi/10.1145/3386164.3389083",
    "bibtex": "inproceedings{Wang2019_494,\n    author = \"Wang, Shuai and Liu, Jinyang and Qiu, Ye and Ma, Zhiyi and Liu, Junfei and Wu, Zhonghai\",\n    title = \"Deep Learning Based Code Completion Models for Programming Codes\",\n    year = \"2019\",\n    isbn = \"9781450376617\",\n    publisher = \"Association for Computing Machinery\",\n    address = \"New York, NY, USA\",\n    url = \"https://doi.org/10.1145/3386164.3389083\",\n    doi = \"10.1145/3386164.3389083\",\n    booktitle = \"Proceedings of the 2019 3rd International Symposium on Computer Science and Intelligent Control\",\n    articleno = \"16\",\n    numpages = \"9\",\n    keywords = \"Deep Learning, Software Engineering, Artificial Intelligence, Programming Language\",\n    location = \"Amsterdam, Netherlands\",\n    series = \"ISCSIC 2019\"\n}\n\n",
    "abstract": "With the fast development of Information Technology, program software and mobile applications have been widely used in the world, and are playing important roles in human's daily life. Thus, writing programming codes has been important work in many fields. however, it is a hard and time-cost task which presents a great amount of workload to programmers. To make programmers' work easier, intelligent code completion models have been a popular research topic in recent years. This paper designs Deep Learning based models to automatically complete programming codes, which are LSTM-based neural networks, and are combined with several techniques such as Word Embedding models in NLP (Natural Language Processing), and Multihead Attention Mechanism. Moreover, in the models, this paper raises a new algorithm of generating input sequences from partial AST (Abstract Syntax Tree) that have most relevance with nodes to be predicted which is named as RZT (Reverse Zig-zag Traverse) Algorithm, and is the first work of applying Multihead Attention Block into this task. This paper makes insight into codes of several different programming languages, and the models this paper presents show good performances in accuracy comparing with the state-of-art models."
}, {
    "py/object": "data.DataClassPaper",
    "Title": "Deep Learning-Based Logging Recommendation Using Merged Code Representation",
    "year": 2021,
    "ML_Techniques": "LSTM",
    "Category": "Code completion",
    "Sub_category": "",
    "Venue": "ITCS",
    "Link": "https://link.springer.com/chapter/10.1007/978-981-15-9354-3_5",
    "bibtex": "InProceedings{Lee2021_495,\n    author = \"Lee, Suin and Lee, Youngseok and Lee, Chan-Gun and Woo, Honguk\",\n    editor = \"Kim, Hyuncheol and Kim, Kuinam J.\",\n    title = \"Deep Learning-Based Logging Recommendation Using Merged Code Representation\",\n    booktitle = \"IT Convergence and Security\",\n    year = \"2021\",\n    publisher = \"Springer Singapore\",\n    address = \"Singapore\",\n    pages = \"49--53\",\n    abstract = \"When developing a large scale software product, it is essential to share a common set of structural coding guidelines and standards among the project team members. In this paper, we propose MergeLogging, a deep learning-based merged network using various code representations for automated logging decisions or other tasks. MergeLogging archives the enhanced recommendation ability that utilizes orthogonal code features from code representations. Our case study with three open-source project datasets demonstrates that logging accuracy can reach as high as 93{\\\\%}.\",\n    isbn = \"978-981-15-9354-3\"\n}\n\n",
    "abstract": "When developing a large scale software product, it is essential to share a common set of structural coding guidelines and standards among the project team members. In this paper, we propose MergeLogging, a deep learning-based merged network using various code representations for automated logging decisions or other tasks. MergeLogging archives the enhanced recommendation ability that utilizes orthogonal code features from code representations. Our case study with three open-source project datasets demonstrates that logging accuracy can reach as high as 93%."
}, {
    "py/object": "data.DataClassPaper",
    "Title": "Improve Language Modeling for Code Completion Through Learning General Token Repetition of Source Code with Optimized Memory",
    "year": 2019,
    "ML_Techniques": "MNN",
    "Category": "Code completion",
    "Sub_category": "",
    "Venue": "IJSEKE",
    "Link": "https://www.worldscientific.com/doi/abs/10.1142/S0218194019400229",
    "bibtex": "article{Yang2019_496,\n    author = \"Yang, Yixiao and Chen, Xiang and Sun, Jiaguang\",\n    title = \"Improve Language Modeling for Code Completion Through Learning General Token Repetition of Source Code with Optimized Memory\",\n    journal = \"International Journal of Software Engineering and Knowledge Engineering\",\n    volume = \"29\",\n    number = \"11n12\",\n    pages = \"1801-1818\",\n    year = \"2019\",\n    doi = \"10.1142/S0218194019400229\",\n    URL = \"https://doi.org/10.1142/S0218194019400229\",\n    eprint = \"https://doi.org/10.1142/S0218194019400229\",\n    abstract = \"In last few years, applying language model to source code is the state-of-the-art method for solving the problem of code completion. However, compared with natural language, code has more obvious repetition characteristics. For example, a variable can be used many times in the following code. Variables in source code have a high chance to be repetitive. Cloned code and templates, also have the property of token repetition. Capturing the token repetition of source code is important. In different projects, variables or types are usually named differently. This means that a model trained in a finite data set will encounter a lot of unseen variables or types in another data set. How to model the semantics of the unseen data and how to predict the unseen data based on the patterns of token repetition are two challenges in code completion. Hence, in this paper, token repetition is modelled as a graph, we propose a novel REP model which is based on deep neural graph network to learn the code toke repetition. The REP model is to identify the edge connections of a graph to recognize the token repetition. For predicting the token repetition of token n, the information of all the previous tokens needs to be considered. We use memory neural network (MNN) to model the semantics of each distinct token to make the framework of REP model more targeted. The experiments indicate that the REP model performs better than LSTM model. Compared with Attention-Pointer network, we also discover that the attention mechanism does not work in all situations. The proposed REP model could achieve similar or slightly better prediction accuracy compared to Attention-Pointer network and consume less training time. We also find other attention mechanism which could further improve the prediction accuracy.\"\n}\n\n",
    "abstract": "In last few years, applying language model to source code is the state-of-the-art method for solving the problem of code completion. However, compared with natural language, code has more obvious repetition characteristics. For example, a variable can be used many times in the following code. Variables in source code have a high chance to be repetitive. Cloned code and templates, also have the property of token repetition. Capturing the token repetition of source code is important. In different projects, variables or types are usually named differently. This means that a model trained in a finite data set will encounter a lot of unseen variables or types in another data set. How to model the semantics of the unseen data and how to predict the unseen data based on the patterns of token repetition are two challenges in code completion. Hence, in this paper, token repetition is modelled as a graph, we propose a novel REP model which is based on deep neural graph network to learn the code toke repetition. The REP model is to identify the edge connections of a graph to recognize the token repetition. For predicting the token repetition of token n, the information of all the previous tokens needs to be considered. We use memory neural network (MNN) to model the semantics of each distinct token to make the framework of REP model more targeted. The experiments indicate that the REP model performs better than LSTM model. Compared with Attention-Pointer network, we also discover that the attention mechanism does not work in all situations. The proposed REP model could achieve similar or slightly better prediction accuracy compared to Attention-Pointer network and consume less training time. We also find other attention mechanism which could further improve the prediction accuracy.\n\n"
}, {
    "py/object": "data.DataClassPaper",
    "Title": "Improving Code Recommendations by Combining Neural and Classical Machine Learning Approaches",
    "year": 2020,
    "ML_Techniques": "RNN, PN",
    "Category": "Code completion",
    "Sub_category": "",
    "Venue": "ICSEW",
    "Link": "https://dl.acm.org/doi/10.1145/3387940.3391489",
    "bibtex": "inproceedings{Schumacher2020_497,\n    author = \"Schumacher, Max Eric Henry and Le, Kim Tuyen and Andrzejak, Artur\",\n    title = \"Improving Code Recommendations by Combining Neural and Classical Machine Learning Approaches\",\n    year = \"2020\",\n    isbn = \"9781450379632\",\n    publisher = \"Association for Computing Machinery\",\n    address = \"New York, NY, USA\",\n    url = \"https://doi.org/10.1145/3387940.3391489\",\n    doi = \"10.1145/3387940.3391489\",\n    booktitle = \"Proceedings of the IEEE/ACM 42nd International Conference on Software Engineering Workshops\",\n    pages = \"476\u2013482\",\n    numpages = \"7\",\n    keywords = \"neural networks, code recommendations, machine learning\",\n    location = \"Seoul, Republic of Korea\",\n    series = \"ICSEW'20\"\n}\n\n",
    "abstract": "Code recommendation systems for software engineering are designed to accelerate the development of large software projects. A classical example is code completion or next token prediction offered by modern integrated development environments. A particular challenging case for such systems are dynamic languages like Python due to limited type information at editing time. Recently, researchers proposed machine learning approaches to address this challenge. In particular, the Probabilistic Higher Order Grammar technique (Bielik et al., ICML 2016) uses a grammar-based approach with a classical machine learning schema to exploit local context. A method by Li et al., (IJCAI 2018) uses deep learning methods, in detail a Recurrent Neural Network coupled with a Pointer Network. We compare these two approaches quantitatively on a large corpus of Python files from GitHub. We also propose a combination of both approaches, where a neural network decides which schema to use for each prediction. The proposed method achieves a slightly better accuracy than either of the systems alone. This demonstrates the potential of ensemble-like methods for code completion and recommendation tasks in dynamically typed languages."
}, {
    "py/object": "data.DataClassPaper",
    "Title": "Intelligent Code Completion with Bayesian Networks",
    "year": 2015,
    "ML_Techniques": "BN",
    "Category": "Code completion",
    "Sub_category": "",
    "Venue": "TOSEM",
    "Link": "https://dl.acm.org/doi/abs/10.1145/2744200",
    "bibtex": "article{Proksch2015_498,\n    author = \"Proksch, Sebastian and Lerch, Johannes and Mezini, Mira\",\n    title = \"Intelligent Code Completion with Bayesian Networks\",\n    year = \"2015\",\n    issue_date = \"December 2015\",\n    publisher = \"Association for Computing Machinery\",\n    address = \"New York, NY, USA\",\n    volume = \"25\",\n    number = \"1\",\n    issn = \"1049-331X\",\n    url = \"https://doi.org/10.1145/2744200\",\n    doi = \"10.1145/2744200\",\n    abstract = \"Code completion is an integral part of modern Integrated Development Environments (IDEs). Developers often use it to explore Application Programming Interfaces (APIs). It is also useful to reduce the required amount of typing and to help avoid typos. Traditional code completion systems propose all type-correct methods to the developer. Such a list is often very long with many irrelevant items. More intelligent code completion systems have been proposed in prior work to reduce the list of proposed methods to relevant items.This work extends one of these existing approaches, the Best Matching Neighbor (BMN) algorithm. We introduce Bayesian networks as an alternative underlying model, use additional context information for more precise recommendations, and apply clustering techniques to improve model sizes. We compare our new approach, Pattern-based Bayesian Networks (PBN), to the existing BMN algorithm. We extend previously used evaluation methodologies and, in addition to prediction quality, we also evaluate model size and inference speed.Our results show that the additional context information we collect improves prediction quality, especially for queries that do not contain method calls. We also show that PBN can obtain comparable prediction quality to BMN, while model size and inference speed scale better with large input sizes.\",\n    journal = \"ACM Trans. Softw. Eng. Methodol.\",\n    month = \"December\",\n    articleno = \"3\",\n    numpages = \"31\",\n    keywords = \"productivity, machine learning, integrated development environments, Content assist, code completion, evaluation, code recommender\"\n}\n\n",
    "abstract": "Code completion is an integral part of modern Integrated Development Environments (IDEs). Developers often use it to explore Application Programming Interfaces (APIs). It is also useful to reduce the required amount of typing and to help avoid typos. Traditional code completion systems propose all type-correct methods to the developer. Such a list is often very long with many irrelevant items. More intelligent code completion systems have been proposed in prior work to reduce the list of proposed methods to relevant items.\n\nThis work extends one of these existing approaches, the Best Matching Neighbor (BMN) algorithm. We introduce Bayesian networks as an alternative underlying model, use additional context information for more precise recommendations, and apply clustering techniques to improve model sizes. We compare our new approach, Pattern-based Bayesian Networks (PBN), to the existing BMN algorithm. We extend previously used evaluation methodologies and, in addition to prediction quality, we also evaluate model size and inference speed.\n\nOur results show that the additional context information we collect improves prediction quality, especially for queries that do not contain method calls. We also show that PBN can obtain comparable prediction quality to BMN, while model size and inference speed scale better with large input sizes."
}, {
    "py/object": "data.DataClassPaper",
    "Title": "JavaScript Code Suggestion Based on Deep Learning",
    "year": 2019,
    "ML_Techniques": "LSTM",
    "Category": "Code completion",
    "Sub_category": "",
    "Venue": "ICIAI",
    "Link": "https://dl.acm.org/doi/10.1145/3319921.3319922",
    "bibtex": "inproceedings{Zhong2019_499,\n    author = \"Zhong, Chaoliang and Yang, Ming and Sun, Jun\",\n    title = \"JavaScript Code Suggestion Based on Deep Learning\",\n    year = \"2019\",\n    isbn = \"9781450361286\",\n    publisher = \"Association for Computing Machinery\",\n    address = \"New York, NY, USA\",\n    url = \"https://doi.org/10.1145/3319921.3319922\",\n    doi = \"10.1145/3319921.3319922\",\n    abstract = \"Code suggestion system is widely used in integrated development environments (IDEs) for generating code recommendations while editing to improve program efficiency. Current most common systems focus on the settings that complete a single code unit or predict likely next single unit. In this paper, we describe a code suggestion prototype system for JavaScript based on Jupyter Notebook [1] (an IDE) to provide multiple successive code units completion. Our main work is as follows: 1. Provide a JavaScript pre-processing solution for feature extraction; 2. Apply several deep learning technologies, including LSTM [2], attention mechanism (AM) [3] and sparse point network (SPN) [4] to support system performance; 3. Design a solution for model deployment and provide post-processing methods to improve user experience. Offline model performance shows that the LSTM + SPN has achieved a 79.73\\% all-token accuracy rate and 44.34\\% identifier accuracy rate among top 5 predictions respectively. Online evaluation shows that the demo system fits practical application experience.\",\n    booktitle = \"Proceedings of the 2019 3rd International Conference on Innovation in Artificial Intelligence\",\n    pages = \"145\u2013149\",\n    numpages = \"5\",\n    keywords = \"Code suggestion, Code completion, Deep learning\",\n    location = \"Suzhou, China\",\n    series = \"ICIAI 2019\"\n}\n\n",
    "abstract": "Code suggestion system is widely used in integrated development environments (IDEs) for generating code recommendations while editing to improve program efficiency. Current most common systems focus on the settings that complete a single code unit or predict likely next single unit. In this paper, we describe a code suggestion prototype system for JavaScript based on Jupyter Notebook [1] (an IDE) to provide multiple successive code units completion. Our main work is as follows: 1. Provide a JavaScript pre-processing solution for feature extraction; 2. Apply several deep learning technologies, including LSTM [2], attention mechanism (AM) [3] and sparse point network (SPN) [4] to support system performance; 3. Design a solution for model deployment and provide post-processing methods to improve user experience. Offline model performance shows that the LSTM + SPN has achieved a 79.73% all-token accuracy rate and 44.34% identifier accuracy rate among top 5 predictions respectively. Online evaluation shows that the demo system fits practical application experience."
}, {
    "py/object": "data.DataClassPaper",
    "Title": "Learning from examples to improve code completion systems",
    "year": 2009,
    "ML_Techniques": "BMN, ARM",
    "Category": "Code completion",
    "Sub_category": "",
    "Venue": "FSE",
    "Link": "https://dl.acm.org/doi/10.1145/1595696.1595728",
    "bibtex": "inproceedings{Zhong2019_499,\n    author = \"Zhong, Chaoliang and Yang, Ming and Sun, Jun\",\n    title = \"JavaScript Code Suggestion Based on Deep Learning\",\n    year = \"2019\",\n    isbn = \"9781450361286\",\n    publisher = \"Association for Computing Machinery\",\n    address = \"New York, NY, USA\",\n    url = \"https://doi.org/10.1145/3319921.3319922\",\n    doi = \"10.1145/3319921.3319922\",\n    abstract = \"Code suggestion system is widely used in integrated development environments (IDEs) for generating code recommendations while editing to improve program efficiency. Current most common systems focus on the settings that complete a single code unit or predict likely next single unit. In this paper, we describe a code suggestion prototype system for JavaScript based on Jupyter Notebook [1] (an IDE) to provide multiple successive code units completion. Our main work is as follows: 1. Provide a JavaScript pre-processing solution for feature extraction; 2. Apply several deep learning technologies, including LSTM [2], attention mechanism (AM) [3] and sparse point network (SPN) [4] to support system performance; 3. Design a solution for model deployment and provide post-processing methods to improve user experience. Offline model performance shows that the LSTM + SPN has achieved a 79.73\\% all-token accuracy rate and 44.34\\% identifier accuracy rate among top 5 predictions respectively. Online evaluation shows that the demo system fits practical application experience.\",\n    booktitle = \"Proceedings of the 2019 3rd International Conference on Innovation in Artificial Intelligence\",\n    pages = \"145\u2013149\",\n    numpages = \"5\",\n    keywords = \"Code suggestion, Code completion, Deep learning\",\n    location = \"Suzhou, China\",\n    series = \"ICIAI 2019\"\n}\n\n",
    "abstract": "The suggestions made by current IDE's code completion features are based exclusively on static type system of the programming language. As a result, often proposals are made which are irrelevant for a particular working context. Also, these suggestions are ordered alphabetically rather than by their relevance in a particular context. In this paper, we present intelligent code completion systems that learn from existing code repositories. We have implemented three such systems, each using the information contained in repositories in a different way. We perform a large-scale quantitative evaluation of these systems, integrate the best performing one into Eclipse, and evaluate the latter also by a user study. Our experiments give evidence that intelligent code completion systems which learn from examples significantly outperform mainstream code completion systems in terms of the relevance of their suggestions and thus have the potential to enhance developers' productivity."
}, {
    "py/object": "data.DataClassPaper",
    "Title": "Multi-task Learning based Pre-trained Language Model for Code Completion",
    "year": 2020,
    "ML_Techniques": "TF",
    "Category": "Code completion",
    "Sub_category": "",
    "Venue": "ASE",
    "Link": "https://ieeexplore.ieee.org/abstract/document/9285991",
    "bibtex": "INPROCEEDINGS{Liu2020_501,\n    author = \"{Liu}, F. and {Li}, G. and {Zhao}, Y. and {Jin}, Z.\",\n    booktitle = \"2020 35th IEEE/ACM International Conference on Automated Software Engineering (ASE)\",\n    title = \"Multi-task Learning based Pre-trained Language Model for Code Completion\",\n    year = \"2020\",\n    volume = \"\",\n    number = \"\",\n    pages = \"473-485\",\n    doi = \"\"\n}\n\n",
    "abstract": "Code completion is one of the most useful features in the Integrated Development Environments (IDEs), which can accelerate software development by suggesting the next probable token based on the contextual code in real-time. Recent studies have shown that statistical language modeling techniques can improve the performance of code completion tools through learning from large-scale software repositories. However, these models suffer from two major drawbacks: a) Existing research uses static embeddings, which map a word to the same vector regardless of its context. The differences in the meaning of a token in varying contexts are lost when each token is associated with a single representation; b) Existing language model based code completion models perform poor on completing identifiers, and the type information of the identifiers is ignored in most of these models. To address these challenges, in this paper, we develop a multi-task learning based pre-trained language model for code understanding and code generation with a Transformer-based neural architecture. We pre-train it with hybrid objective functions that incorporate both code understanding and code generation tasks. Then we fine-tune the pre-trained model on code completion. During the completion, our model does not directly predict the next token. Instead, we adopt multi-task learning to predict the token and its type jointly and utilize the predicted type to assist the token prediction. Experiments results on two real-world datasets demonstrate the effectiveness of our model when compared with state-of-the-art methods."
}, {
    "py/object": "data.DataClassPaper",
    "Title": "Neural Comment Generation for Source Code with Auxiliary Code Classification Task",
    "year": 2019,
    "ML_Techniques": "EN-DE",
    "Category": "Code completion",
    "Sub_category": "",
    "Venue": "APSEC",
    "Link": "https://ieeexplore.ieee.org/document/8945708",
    "bibtex": "INPROCEEDINGS{Chen2019_503,\n    author = \"{Chen}, M. and {Wan}, X.\",\n    booktitle = \"2019 26th Asia-Pacific Software Engineering Conference (APSEC)\",\n    title = \"Neural Comment Generation for Source Code with Auxiliary Code Classification Task\",\n    year = \"2019\",\n    volume = \"\",\n    number = \"\",\n    pages = \"522-529\",\n    doi = \"10.1109/APSEC48747.2019.00076\"\n}\n\n",
    "abstract": "Code comments help program developers understand programs, read and navigate source code, thus resulting in more efficient software maintenance. Unfortunately, many codes are not commented adequately, or the code comments are missing. So developers have to spend additional time in reading source code. In this paper, we propose a new approach to automatically generating comments for source codes. Following the intuition behind the traditional sequence-to-sequence (Seq2Seq) model for machine translation, we propose a tree-to-sequence (Tree2Seq) model for code comment generation, which leverages an encoder to capture the structure information of source code. More importantly, code classification is involved as an auxiliary task for aiding the Tree2Seq model. We build a multi-task learning model to achieve this goal. We evaluate our models on a benchmark dataset with automatic metrics like BLEU, ROUGE, and METEOR. Experimental results show that our proposed Tree2Seq model outperforms traditional Seq2Seq model with attention, and our proposed multi-task learning model outperforms the state-of-the-art approaches by a substantial margin."
}, {
    "py/object": "data.DataClassPaper",
    "Title": "Probabilistic model for code with decision trees",
    "year": 2016,
    "ML_Techniques": "DT",
    "Category": "Code completion",
    "Sub_category": ",Code induction",
    "Venue": "OOPSLA",
    "Link": "https://dl.acm.org/doi/10.1145/2983990.2984041",
    "bibtex": "INPROCEEDINGS{Chen2019_503,\n    author = \"{Chen}, M. and {Wan}, X.\",\n    booktitle = \"2019 26th Asia-Pacific Software Engineering Conference (APSEC)\",\n    title = \"Neural Comment Generation for Source Code with Auxiliary Code Classification Task\",\n    year = \"2019\",\n    volume = \"\",\n    number = \"\",\n    pages = \"522-529\",\n    doi = \"10.1109/APSEC48747.2019.00076\"\n}\n\n",
    "abstract": "In this paper we introduce a new approach for learning precise and general probabilistic models of code based on decision tree learning. Our approach directly benefits an emerging class of statistical programming tools which leverage probabilistic models of code learned over large codebases (e.g., GitHub) to make predictions about new programs (e.g., code completion, repair, etc).\n\nThe key idea is to phrase the problem of learning a probabilistic model of code as learning a decision tree in a domain specific language over abstract syntax trees (called TGen). This allows us to condition the prediction of a program element on a dynamically computed context. Further, our problem formulation enables us to easily instantiate known decision tree learning algorithms such as ID3, but also to obtain new variants we refer to as ID3+ and E13, not previously explored and ones that outperform ID3 in prediction accuracy.\n\nOur approach is general and can be used to learn a probabilistic model of any programming language. We implemented our approach in a system called Deep3 and evaluated it for the challenging task of learning probabilistic models of JavaScript and Python. Our experimental results indicate that Deep3 predicts elements of JavaScript and Python code with precision above 82% and 69%, respectively. Further, Deep3 often significantly outperforms state-of-the-art approaches in overall prediction accuracy"
}, {
    "py/object": "data.DataClassPaper",
    "Title": "Pythia: AI-assisted Code Completion System",
    "year": 2019,
    "ML_Techniques": "LSTM",
    "Category": "Code completion",
    "Sub_category": "",
    "Venue": "KDD",
    "Link": "https://dl.acm.org/doi/abs/10.1145/3292500.3330699",
    "bibtex": "INPROCEEDINGS{Chen2019_503,\n    author = \"{Chen}, M. and {Wan}, X.\",\n    booktitle = \"2019 26th Asia-Pacific Software Engineering Conference (APSEC)\",\n    title = \"Neural Comment Generation for Source Code with Auxiliary Code Classification Task\",\n    year = \"2019\",\n    volume = \"\",\n    number = \"\",\n    pages = \"522-529\",\n    doi = \"10.1109/APSEC48747.2019.00076\"\n}\n\n",
    "abstract": "In this paper, we propose a novel end-to-end approach for AI-assisted code completion called Pythia. It generates ranked lists of method and API recommendations which can be used by software developers at edit time. The system is currently deployed as part of Intellicode extension in Visual Studio Code IDE. Pythia exploits state-of-the-art large-scale deep learning models trained on code contexts extracted from abstract syntax trees. It is designed to work at a high throughput predicting the best matching code completions on the order of 100 ms.\n\nWe describe the architecture of the system, perform comparisons to frequency-based approach and invocation-based Markov Chain language model, and discuss challenges serving Pythia models on lightweight client devices.\n\nThe offline evaluation results obtained on 2700 Python open source software GitHub repositories show a top-5 accuracy of 92%, surpassing the baseline models by 20% averaged over classes, for both intra and cross-project settings."
}, {
    "py/object": "data.DataClassPaper",
    "Title": "Statistical machine translation outperforms neural machine translation in software engineering: why and how",
    "year": 2020,
    "ML_Techniques": "NMT",
    "Category": "Code completion",
    "Sub_category": ",Code induction",
    "Venue": "RL+SE&PL",
    "Link": "https://dl.acm.org/doi/10.1145/3416506.3423576",
    "bibtex": "INPROCEEDINGS{Chen2019_503,\n    author = \"{Chen}, M. and {Wan}, X.\",\n    booktitle = \"2019 26th Asia-Pacific Software Engineering Conference (APSEC)\",\n    title = \"Neural Comment Generation for Source Code with Auxiliary Code Classification Task\",\n    year = \"2019\",\n    volume = \"\",\n    number = \"\",\n    pages = \"522-529\",\n    doi = \"10.1109/APSEC48747.2019.00076\"\n}\n\n",
    "abstract": "Neural Machine Translation (NMT) is the current trend approach\nin Natural Language Processing (NLP) to solve the problem of automatically inferring the content of target language given the source\nlanguage. The ability of NMT is to learn deep knowledge inside languages by deep learning approaches. However, prior works show\nthat NMT has its own drawbacks in NLP and in some research\nproblems of Software Engineering (SE). In this work, we provide a\nhypothesis that SE corpus has inherent characteristics that NMT\nwill confront challenges compared to the state-of-the-art translation engine based on Statistical Machine Translation. We introduce\na problem which is significant in SE and has characteristics that\nchallenges the ability of NMT to learn correct sequences, called\nPrefix Mapping. We implement and optimize the original SMT and\nNMT to mitigate those challenges. By the evaluation, we show that\nSMT outperforms NMT for this research problem, which provides\npotential directions to optimize the current NMT engines for specific classes of parallel corpus. By achieving the accuracy from 65%\nto 90% for code tokens generation of 1000 Github code corpus, we\nshow the potential of using MT for code completion at token level."
}, {
    "py/object": "data.DataClassPaper",
    "Title": "You Autocomplete Me: Poisoning Vulnerabilities in Neural Code Completion",
    "year": 2021,
    "ML_Techniques": "TF",
    "Category": "Code completion",
    "Sub_category": "",
    "Venue": "USENIX Security",
    "Link": "https://www.usenix.org/conference/usenixsecurity21/presentation/schuster",
    "bibtex": "inproceedings{Schuster2021_508,\n    author = \"Schuster, R. and Song, Congzheng and Tromer, Eran and Shmatikov, Vitaly\",\n    title = \"You Autocomplete Me: Poisoning Vulnerabilities in Neural Code Completion\",\n    booktitle = \"30th {USENIX} Security Symposium ({USENIX} Security 21)\",\n    year = \"2021\",\n    address = \"Vancouver, B.C.\",\n    url = \"https://www.usenix.org/conference/usenixsecurity21/presentation/schuster\",\n    publisher = \"{USENIX} Association\",\n    month = \"August\"\n}\n\n",
    "abstract": "Code autocompletion is an integral feature of modern code editors and IDEs. The latest generation of autocompleters uses neural language models, trained on public open-source code repositories, to suggest likely (not just statically feasible) completions given the current context.\nWe demonstrate that neural code autocompleters are vulnerable to poisoning attacks. By adding a few specially-crafted files to the autocompleter's training corpus (data poisoning), or else by directly fine-tuning the autocompleter on these files (model poisoning), the attacker can influence its suggestions for attacker-chosen contexts. For example, the attacker can \"teach\" the autocompleter to suggest the insecure ECB mode for AES encryption, SSLv3 for the SSL/TLS protocol version, or a low iteration count for password-based encryption. Moreover, we show that these attacks can be targeted: an autocompleter poisoned by a targeted attack is much more likely to suggest the insecure completion for files from a specific repo or specific developer.\nWe quantify the efficacy of targeted and untargeted data- and model-poisoning attacks against state-of-the-art autocompleters based on Pythia and GPT-2. We then evaluate existing defenses against poisoning attacks and show that they are largely ineffective."
}, {
    "py/object": "data.DataClassPaper",
    "Title": "Code smell detection by deep direct-learning and transfer-learning",
    "year": 2021,
    "ML_Techniques": "CNN, RNN, AE",
    "Category": "Quality assessment",
    "Sub_category": "Code smell detection",
    "Venue": "JSS",
    "Link": "",
    "bibtex": "article{Sharma2021_510,\n    author = \"Sharma, Tushar and Efstathiou, Vasiliki and Louridas, Panos and Spinellis, Diomidis\",\n    title = \"Code smell detection by deep direct-learning and transfer-learning\",\n    journal = \"Journal of Systems and Software\",\n    volume = \"176\",\n    pages = \"110936\",\n    year = \"2021\",\n    issn = \"0164-1212\",\n    doi = \"https://doi.org/10.1016/j.jss.2021.110936\",\n    url = \"https://www.sciencedirect.com/science/article/pii/S0164121221000339\",\n    keywords = \"Code smells, Smell detection tools, Deep learning, Transfer-learning\"\n}\n\n",
    "abstract": "Context:\nAn excessive number of code smells make a software system hard to evolve and maintain. Machine learning methods, in addition to metric-based and heuristic-based methods, have been recently applied to detect code smells; however, current methods are considered far from mature.\n\nObjective:\nFirst, explore the feasibility of applying deep learning models to detect smells without extensive feature engineering. Second, investigate the possibility of applying transfer-learning in the context of detecting code smells.\n\nMethods:\nWe train smell detection models based on Convolution Neural Networks and Recurrent Neural Networks as their principal hidden layers along with autoencoder models. For the first objective, we perform training and evaluation on C# samples, whereas for the second objective, we train the models from C# code and evaluate the models over Java code samples and vice-versa.\n\nResults:\nWe find it feasible to detect smells using deep learning methods though the models\u2019 performance is smell-specific. Our experiments show that transfer-learning is definitely feasible for implementation smells with performance comparable to that of direct-learning. This work opens up a new paradigm to detect code smells by transfer-learning especially for the programming languages where the comprehensive code smell detection tools are not available."
}, {
    "py/object": "data.DataClassPaper",
    "Title": "A Hybrid Approach To Detect Code Smells using Deep Learning",
    "year": 2018,
    "ML_Techniques": "AE, ANN",
    "Category": "Quality assessment",
    "Sub_category": "Code smell detection",
    "Venue": "ENASE",
    "Link": "",
    "bibtex": "inproceedings{Hadj-Kacem2018_511,\n    author = \"Hadj-Kacem, Mouna and Bouassida, Nadia\",\n    title = \"A Hybrid Approach To Detect Code Smells using Deep Learning.\",\n    booktitle = \"ENASE\",\n    pages = \"137--146\",\n    year = \"2018\"\n}\n\n",
    "abstract": "The detection of code smells is a fundamental prerequisite for guiding the subsequent steps in the refactoring\nprocess. The more the detection results are accurate, the more the performance of the refactoring on the\nsoftware is improved. Given its influential role in the software maintenance, this challenging research topic\nhas so far attracted an increasing interest. However, the lack of consensus about the definition of code smells in\nthe literature has led to a considerable diversity of the existing results. To reduce the confusion associated with\nthis lack of consensus, there is a real need to achieve a deep and consistent representation of the code smells.\nRecently, the advance of deep learning has demonstrated an undeniable contribution in many research fields\nincluding the pattern recognition issues. In this paper, we propose a hybrid detection approach based on deep\nAuto-encoder and Artificial Neural Network algorithms. Four code smells (God Class, Data Class, Feature\nEnvy and Long Method) are the focus of our experiment on four adopted datasets that are extracted from\n74 open source systems. The values of recall and precision measurements have demonstrated high accuracy\nresults."
}, {
    "py/object": "data.DataClassPaper",
    "Title": "Deep learning based code smell detection",
    "year": 2019,
    "ML_Techniques": "CNN, RNN",
    "Category": "Quality assessment",
    "Sub_category": "Code smell detection",
    "Venue": "TSE",
    "Link": "",
    "bibtex": "article{Liu2019_512,\n    author = \"Liu, Hui and Jin, Jiahao and Xu, Zhifeng and Bu, Yifan and Zou, Yanzhen and Zhang, Lu\",\n    title = \"Deep learning based code smell detection\",\n    journal = \"IEEE Transactions on Software Engineering\",\n    year = \"2019\",\n    publisher = \"IEEE\"\n}\n\n",
    "abstract": "Code smells are structures in the source code that suggest the possibility of refactorings. Consequently, developers may\nidentify refactoring opportunities by detecting code smells. However, manual identification of code smells is challenging and tedious. To\nthis end, a number of approaches have been proposed to identify code smells automatically or semi-automatically. Most of such\napproaches rely on manually designed heuristics to map manually selected source code metrics into predictions. However, it is\nchallenging to manually select the best features. It is also difficult to manually construct the optimal heuristics. To this end, in this paper\nwe propose a deep learning based novel approach to detecting code smells. The key insight is that deep neural networks and\nadvanced deep learning techniques could automatically select features of source code for code smell detection, and could\nautomatically build the complex mapping between such features and predictions. A big challenge for deep learning based smell\ndetection is that deep learning often requires a large number of labeled training data (to tune a large number of parameters within the\nemployed deep neural network) whereas existing datasets for code smell detection are rather small. To this end, we propose an\nautomatic approach to generating labeled training data for the neural network based classifier, which does not require any human\nintervention. As an initial try, we apply the proposed approach to four common and well-known code smells, i.e., feature envy, long\nmethod, large class, and misplaced class. Evaluation results on open-source applications suggest that the proposed approach\nsignificantly improves the state-of-the-art."
}, {
    "py/object": "data.DataClassPaper",
    "Title": "Adaptive Deep Code Search",
    "year": 2020,
    "ML_Techniques": "RNN",
    "Category": "Code search",
    "Sub_category": "",
    "Venue": "ICPC",
    "Link": "",
    "bibtex": "article{Liu2019_512,\n    author = \"Liu, Hui and Jin, Jiahao and Xu, Zhifeng and Bu, Yifan and Zou, Yanzhen and Zhang, Lu\",\n    title = \"Deep learning based code smell detection\",\n    journal = \"IEEE Transactions on Software Engineering\",\n    year = \"2019\",\n    publisher = \"IEEE\"\n}\n\n",
    "abstract": "\nSearching code in a large-scale codebase using natural language queries is a common practice during software development. Deep learning-based code search methods demonstrate superior performance if models are trained with large amount of text-code pairs. However, few deep code search models can be easily transferred from one codebase to another. It can be very costly to prepare training data for a new codebase and re-train an appropriate deep learning model. In this paper, we propose AdaCS, an adaptive deep code search method that can be trained once and transferred to new codebases. AdaCS decomposes the learning process into embedding domain-specific words and matching general syntactic patterns. Firstly, an unsupervised word embedding technique is used to construct a matching matrix to represent the lexical similarities. Then, a recurrent neural network is used to capture latent syntactic patterns from these matching matrices in a supervised way. As the supervised task learns general syntactic patterns that exist across domains, AdaCS is transferable to new codebases. Experimental results show that: when extended to new software projects never seen in the training data, AdaCS is more robust and significantly outperforms state-of-the-art deep code search methods."
}, {
    "py/object": "data.DataClassPaper",
    "Title": "Exploiting Code Knowledge Graph for Bug Localization via Bi-directional Attention",
    "year": 2020,
    "ML_Techniques": "Bi-LSTM",
    "Category": "Program comprehension",
    "Sub_category": "",
    "Venue": "ICPC",
    "Link": "",
    "bibtex": "article{Liu2019_512,\n    author = \"Liu, Hui and Jin, Jiahao and Xu, Zhifeng and Bu, Yifan and Zou, Yanzhen and Zhang, Lu\",\n    title = \"Deep learning based code smell detection\",\n    journal = \"IEEE Transactions on Software Engineering\",\n    year = \"2019\",\n    publisher = \"IEEE\"\n}\n\n",
    "abstract": "Bug localization automatic localize relevant source files given a natural language description of bug within a software project. For a large project containing hundreds and thousands of source files, developers need cost lots of time to understand bug reports generated by quality assurance and localize these buggy source files. Traditional methods are heavily depending on the information retrieval technologies which rank the similarity between source files and bug reports in lexical level. Recently, deep learning based models are used to extract semantic information of code with significant improvements for bug localization. However, programming language is a highly structural and logical language, which contains various relations within and cross source files. Thus, we propose KGBugLocator to utilize knowledge graph embeddings to extract these interrelations of code, and a keywords supervised bi-directional attention mechanism regularize model with interactive information between source files and bug reports. With extensive experiments on four different projects, we prove our model can reach the new the-state-of-art(SOTA) for bug localization."
}, {
    "py/object": "data.DataClassPaper",
    "Title": "GGF: A Graph-based Method for Programming Language Syntax Error Correction",
    "year": 2020,
    "ML_Techniques": "GGNN",
    "Category": "Program comprehension",
    "Sub_category": "",
    "Venue": "ICPC",
    "Link": "",
    "bibtex": "article{Liu2019_512,\n    author = \"Liu, Hui and Jin, Jiahao and Xu, Zhifeng and Bu, Yifan and Zou, Yanzhen and Zhang, Lu\",\n    title = \"Deep learning based code smell detection\",\n    journal = \"IEEE Transactions on Software Engineering\",\n    year = \"2019\",\n    publisher = \"IEEE\"\n}\n\n",
    "abstract": "Syntax errors combined with obscure error messages generated by compilers usually annoy programmers and cause them to waste a lot of time on locating errors. The existing models do not utilize the structure in the code and just treat the code as token sequences. It causes low accuracy and poor performance on this task. In this paper, we propose a novel deep supervised learning model, called Graph-based Grammar Fix(GGF), to help programmers locate and fix the syntax errors. GGF treats the code as a mixture of the token sequences and graphs. The graphs build upon the Abstract Syntax Tree (AST) structure information. GGF encodes an erroneous code with its sub-AST structure, predicts the error position using pointer network and generates the right token. We utilized the DeepFix dataset which contains 46500 correct C programs and 6975 programs with errors written by students taking an introductory programming course. GGF is trained with the correct programs from the DeepFix dataset with intentionally injected syntax errors. After training, GGF could fix 4054 (58.12%) of the erroneous code, while the existing state of the art tool DeepFix fixes 1365 (19.57%) of the erroneous code."
}, {
    "py/object": "data.DataClassPaper",
    "Title": "A Multi-Modal Transformer-based Code Summarization Approach for Smart Contracts",
    "year": 2021,
    "ML_Techniques": "TF",
    "Category": "Code summarization",
    "Sub_category": "",
    "Venue": "ICPC",
    "Link": "",
    "bibtex": "article{Liu2019_512,\n    author = \"Liu, Hui and Jin, Jiahao and Xu, Zhifeng and Bu, Yifan and Zou, Yanzhen and Zhang, Lu\",\n    title = \"Deep learning based code smell detection\",\n    journal = \"IEEE Transactions on Software Engineering\",\n    year = \"2019\",\n    publisher = \"IEEE\"\n}\n\n",
    "abstract": "Code comment has been an important part of computer programs, greatly facilitating the understanding and maintenance of source code. However, high-quality code comments are often unavailable in smart contracts, the increasingly popular programs that run on the blockchain. In this paper, we propose a Multi-Modal Transformer-based (MMTrans) code summarization approach for smart contracts. Specifically, the MMTrans learns the representation of source code from the two heterogeneous modalities of the Abstract Syntax Tree (AST), i.e., Structure-based Traversal (SBT) sequences and graphs. The SBT sequence provides the global semantic information of AST, while the graph convolution focuses on the local details. The MMTrans uses two encoders to extract both global and local semantic information from the two modalities respectively, and then uses a joint decoder to generate code comments. Both the encoders and the decoder employ the multi-head attention structure of the Transformer to enhance the ability to capture the long-range dependencies between code tokens. We build a dataset with over 300K <method, comment> pairs of smart contracts, and evaluate the MMTrans on it. The experimental results demonstrate that the MMTrans outperforms the state-of-the-art baselines in terms of four evaluation metrics by a substantial margin, and can generate higher quality comments."
}, {
    "py/object": "data.DataClassPaper",
    "Title": "Exploiting Method Names to Improve Code Summarization: A Deliberation Multi-Task Learning Approach",
    "year": 2021,
    "ML_Techniques": "EN-DE",
    "Category": "Code summarization",
    "Sub_category": "",
    "Venue": "ICPC",
    "Link": "",
    "bibtex": "article{Liu2019_512,\n    author = \"Liu, Hui and Jin, Jiahao and Xu, Zhifeng and Bu, Yifan and Zou, Yanzhen and Zhang, Lu\",\n    title = \"Deep learning based code smell detection\",\n    journal = \"IEEE Transactions on Software Engineering\",\n    year = \"2019\",\n    publisher = \"IEEE\"\n}\n\n",
    "abstract": "Code summaries are brief natural language descriptions of source code pieces. The main purpose of code summarization is to assist developers in understanding code and to reduce documentation workload. In this paper, we design a novel multi-task learning (MTL) approach for code summarization through mining the relationship between method code summaries and method names. More specifically, since a method's name can be considered as a shorter version of its code summary, we first introduce the tasks of generation and informativeness prediction of method names as two auxiliary training objectives for code summarization. A novel two-pass deliberation mechanism is then incorporated into our MTL architecture to generate more consistent intermediate states fed into a summary decoder, especially when informative method names do not exist. To evaluate our deliberation MTL approach, we carried out a large-scale experiment on two existing datasets for Java and Python. The experiment results show that our technique can be easily applied to many state-of-the-art neural models for code summarization and improve their performance. Meanwhile, our approach shows significant superiority when generating summaries for methods with non-informative names."
}, {
    "py/object": "data.DataClassPaper",
    "Title": "Locating Faulty Methods with a Mixed RNN and Attention Model",
    "year": 2021,
    "ML_Techniques": "RNN",
    "Category": "Testing",
    "Sub_category": "",
    "Venue": "ICPC",
    "Link": "",
    "bibtex": "article{Liu2019_512,\n    author = \"Liu, Hui and Jin, Jiahao and Xu, Zhifeng and Bu, Yifan and Zou, Yanzhen and Zhang, Lu\",\n    title = \"Deep learning based code smell detection\",\n    journal = \"IEEE Transactions on Software Engineering\",\n    year = \"2019\",\n    publisher = \"IEEE\"\n}\n\n",
    "abstract": "IR-based fault localization approaches achieves promising results when locating faulty files by comparing a bug report with source code. Unfortunately, they become less effective to locate faulty methods. We conduct a preliminary study to explore its challenges, and identify three problems: the semantic gap problem, the representation sparseness problem, and the single revision problem. To tackle these problems, we propose MRAM, a mixed RNN and attention model, which combines bug-fixing features and method structured features to explore both implicit and explicit relevance between methods and bug reports for method level fault localization task. The core ideas of our model are: (1) constructing code revision graphs from code, commits and past bug reports, which reveal the latent relations among methods to augment short methods and as well provide all revisions of code and past fixes to train more accurate models; (2) embedding three method structured features (token sequences, API invocation sequences, and comments) jointly with RNN and soft attention to represent source methods and obtain their implicit relevance with bug reports; and (3) integrating multirevision bug-fixing features, which provide the explicit relevance between bug reports and methods, to improve the performance. We have implemented MRAM and conducted a controlled experiment on five open-source projects. Comparing with stateof-the-art approaches, our MRAM improves MRR values by 3.8- 5.1% (3.7-5.4%) when the dataset contains (does not contain) localized bug reports. Our statistics test shows that our improvements are significant"
}, {
    "py/object": "data.DataClassPaper",
    "Title": "Project-Level Encoding for Neural Source Code Summarization of Subroutines",
    "year": 2021,
    "ML_Techniques": "AE",
    "Category": "Code summarization",
    "Sub_category": "",
    "Venue": "ICPC",
    "Link": "",
    "bibtex": "article{Liu2019_512,\n    author = \"Liu, Hui and Jin, Jiahao and Xu, Zhifeng and Bu, Yifan and Zou, Yanzhen and Zhang, Lu\",\n    title = \"Deep learning based code smell detection\",\n    journal = \"IEEE Transactions on Software Engineering\",\n    year = \"2019\",\n    publisher = \"IEEE\"\n}\n\n",
    "abstract": "Source code summarization of a subroutine is the task of writing a short, natural language description of that subroutine. The description usually serves in documentation aimed at programmers, where even brief phrase (e.g. \"compresses data to a zip file\") can help readers rapidly comprehend what a subroutine does without resorting to reading the code itself. Techniques based on neural networks (and encoder-decoder model designs in particular) have established themselves as the state-of-the-art. Yet a problem widely recognized with these models is that they assume the information needed to create a summary is present within the code being summarized itself - an assumption which is at odds with program comprehension literature. Thus a current research frontier lies in the question of encoding source code context into neural models of summarization. In this paper, we present a project-level encoder to improve models of code summarization. By project-level, we mean that we create a vectorized representation of selected code files in a software project, and use that representation to augment the encoder of state-of-the-art neural code summarization techniques. We demonstrate how our encoder improves several existing models, and provide guidelines for maximizing improvement while controlling time and resource costs in model size."
}]